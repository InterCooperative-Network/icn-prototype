
# File Summary:
# /home/matt/icn-prototype/code_manager.py - 7912 bytes - Included
# /home/matt/icn-prototype/update_validation.py - 1085 bytes - Included
# /home/matt/icn-prototype/concatenate_code_files.py - 4869 bytes - Included
# /home/matt/icn-prototype/setup.py - 513 bytes - Included
# /home/matt/icn-prototype/update_imports.py - 1584 bytes - Included
# /home/matt/icn-prototype/did/base_did.py - 8125 bytes - Included
# /home/matt/icn-prototype/did/identity_provider.py - 1754 bytes - Included
# /home/matt/icn-prototype/did/token_manager.py - 7371 bytes - Included
# /home/matt/icn-prototype/did/credential.py - 3190 bytes - Included
# /home/matt/icn-prototype/did/did.py - 6778 bytes - Included
# /home/matt/icn-prototype/did/privacy.py - 1846 bytes - Included
# /home/matt/icn-prototype/did/layered_did.py - 1459 bytes - Included
# /home/matt/icn-prototype/did/registry.py - 1529 bytes - Included
# /home/matt/icn-prototype/did/membership_card.py - 1527 bytes - Included
# /home/matt/icn-prototype/did/__init__.py - 0 bytes - Included
# /home/matt/icn-prototype/api/server.py - 5851 bytes - Included
# /home/matt/icn-prototype/api/__init__.py - 0 bytes - Included
# /home/matt/icn-prototype/tests/__init__.py - 60 bytes - Included
# /home/matt/icn-prototype/tests/integration/test_cooldown_management.py - 1102 bytes - Included
# /home/matt/icn-prototype/tests/integration/test_consensus_mechanism.py - 10902 bytes - Included
# /home/matt/icn-prototype/tests/integration/test_block_creation.py - 11204 bytes - Included
# /home/matt/icn-prototype/tests/integration/test_shard_management.py - 10810 bytes - Included
# /home/matt/icn-prototype/tests/integration/test_transaction_processing.py - 11207 bytes - Included
# /home/matt/icn-prototype/tests/integration/test_smart_contract_execution.py - 13339 bytes - Included
# /home/matt/icn-prototype/tests/integration/__init__.py - 0 bytes - Included
# /home/matt/icn-prototype/tests/performance/test_scalability.py - 10845 bytes - Included
# /home/matt/icn-prototype/tests/performance/test_stress_resilience.py - 12792 bytes - Included
# /home/matt/icn-prototype/tests/performance/test_load_handling.py - 12150 bytes - Included
# /home/matt/icn-prototype/tests/performance/__init__.py - 0 bytes - Included
# /home/matt/icn-prototype/tests/unit/test_proof_of_cooperation.py - 10692 bytes - Included
# /home/matt/icn-prototype/tests/unit/test_contract_executor.py - 9655 bytes - Included
# /home/matt/icn-prototype/tests/unit/test_block.py - 10172 bytes - Included
# /home/matt/icn-prototype/tests/unit/test_validator_manager.py - 1238 bytes - Included
# /home/matt/icn-prototype/tests/unit/test_shard.py - 10959 bytes - Included
# /home/matt/icn-prototype/tests/unit/test_node.py - 7500 bytes - Included
# /home/matt/icn-prototype/tests/unit/test_transaction.py - 7391 bytes - Included
# /home/matt/icn-prototype/tests/unit/test_blockchain.py - 5893 bytes - Included
# /home/matt/icn-prototype/tests/unit/test_smart_contract.py - 10483 bytes - Included
# /home/matt/icn-prototype/tests/unit/__init__.py - 0 bytes - Included
# /home/matt/icn-prototype/system/marketplace.py - 2585 bytes - Included
# /home/matt/icn-prototype/system/reputation.py - 9930 bytes - Included
# /home/matt/icn-prototype/system/governance.py - 13214 bytes - Included
# /home/matt/icn-prototype/system/storage.py - 1971 bytes - Included
# /home/matt/icn-prototype/system/__init__.py - 0 bytes - Included
# /home/matt/icn-prototype/blockchain/blockchain.py - 46419 bytes - Included
# /home/matt/icn-prototype/blockchain/__init__.py - 434 bytes - Included
# /home/matt/icn-prototype/blockchain/utils/metrics.py - 6083 bytes - Included
# /home/matt/icn-prototype/blockchain/utils/validation.py - 8132 bytes - Included
# /home/matt/icn-prototype/blockchain/utils/__init__.py - 201 bytes - Included
# /home/matt/icn-prototype/blockchain/utils/crypto.py - 7870 bytes - Included
# /home/matt/icn-prototype/blockchain/network/config.py - 10286 bytes - Included
# /home/matt/icn-prototype/blockchain/network/manager.py - 20088 bytes - Included
# /home/matt/icn-prototype/blockchain/network/discovery/discovery.py - 16429 bytes - Included
# /home/matt/icn-prototype/blockchain/network/sync/sync_manager.py - 29290 bytes - Included
# /home/matt/icn-prototype/blockchain/network/protocol/base.py - 10078 bytes - Included
# /home/matt/icn-prototype/blockchain/network/protocol/dispatcher.py - 22324 bytes - Included
# /home/matt/icn-prototype/blockchain/network/transport/transport.py - 15697 bytes - Included
# /home/matt/icn-prototype/blockchain/core/node.py - 9410 bytes - Included
# /home/matt/icn-prototype/blockchain/core/block.py - 8336 bytes - Included
# /home/matt/icn-prototype/blockchain/core/transaction.py - 11471 bytes - Included
# /home/matt/icn-prototype/blockchain/core/blockchain.py - 8966 bytes - Included
# /home/matt/icn-prototype/blockchain/core/__init__.py - 299 bytes - Included
# /home/matt/icn-prototype/blockchain/core/shard/validation_manager.py - 6705 bytes - Included
# /home/matt/icn-prototype/blockchain/core/shard/transaction_manager.py - 5115 bytes - Included
# /home/matt/icn-prototype/blockchain/core/shard/state_manager.py - 7540 bytes - Included
# /home/matt/icn-prototype/blockchain/core/shard/shard_types.py - 3173 bytes - Included
# /home/matt/icn-prototype/blockchain/core/shard/base.py - 12484 bytes - Included
# /home/matt/icn-prototype/blockchain/core/shard/cross_shard_manager.py - 7344 bytes - Included
# /home/matt/icn-prototype/blockchain/core/shard/__init__.py - 503 bytes - Included
# /home/matt/icn-prototype/blockchain/contracts/contract_executor.py - 11587 bytes - Included
# /home/matt/icn-prototype/blockchain/contracts/smart_contract.py - 14617 bytes - Included
# /home/matt/icn-prototype/blockchain/contracts/__init__.py - 207 bytes - Included
# /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation.py - 8868 bytes - Included
# /home/matt/icn-prototype/blockchain/consensus/__init__.py - 336 bytes - Included
# /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/metrics_manager.py - 10069 bytes - Included
# /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/reputation_manager.py - 17285 bytes - Included
# /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/validator_manager.py - 9018 bytes - Included
# /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/types.py - 11674 bytes - Included
# /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/sanctions_manager.py - 10255 bytes - Included
# /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/collusion_detector.py - 8568 bytes - Included
# /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/base.py - 8036 bytes - Included
# /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/cooldown_manager.py - 6715 bytes - Included
# /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/__init__.py - 0 bytes - Included


# Project Directory Structure (up to depth 3):
icn-prototype/
    requirements.txt
    pytest.ini
    code_manager.py
    update_validation.py
    concatenate_code_files.py
    setup.py
    .coverage
    update_imports.py
    did/
        base_did.py
        identity_provider.py
        token_manager.py
        credential.py
        did.py
        privacy.py
        layered_did.py
        registry.py
        membership_card.py
        __init__.py
    .pytest_cache/
        CACHEDIR.TAG
        .gitignore
        README.md
        v/
            cache/
                nodeids
                lastfailed
                stepwise
    .code_backups/
        validation_manager.py.20241025_183911.bak
        validation_manager.py.20241025_183906.bak
    api/
        server.py
        __init__.py
    .vscode/
        settings.json
    tests/
        __init__.py
        integration/
            test_cooldown_management.py
            test_consensus_mechanism.py
            test_block_creation.py
            test_shard_management.py
            test_transaction_processing.py
            test_smart_contract_execution.py
            __init__.py
            network/
        performance/
            test_scalability.py
            test_stress_resilience.py
            test_load_handling.py
            __init__.py
        unit/
            test_proof_of_cooperation.py
            test_contract_executor.py
            test_block.py
            test_validator_manager.py
            test_shard.py
            test_node.py
            test_transaction.py
            test_blockchain.py
            test_smart_contract.py
            __init__.py
            network/
    system/
        marketplace.py
        reputation.py
        governance.py
        storage.py
        __init__.py
    blockchain/
        blockchain.py
        blockchain.py.backup
        __init__.py
        utils/
            metrics.py
            validation.py
            __init__.py
            crypto.py
        network/
            config.py
            manager.py
            discovery/
                discovery.py
            sync/
                sync_manager.py
            protocol/
                base.py
                dispatcher.py
            transport/
                transport.py
        core/
            shard.py.backup
            node.py
            block.py
            transaction.py
            blockchain.py
            __init__.py
            shard/
                validation_manager.py
                transaction_manager.py
                state_manager.py
                shard_types.py
                base.py
                cross_shard_manager.py
                __init__.py
        contracts/
            contract_executor.py
            smart_contract.py
            __init__.py
        consensus/
            proof_of_cooperation.py
            __init__.py
            proof_of_cooperation/
                metrics_manager.py
                reputation_manager.py
                validator_manager.py
                types.py
                sanctions_manager.py
                collusion_detector.py
                base.py
                cooldown_manager.py
                __init__.py


# Code Files Concatenation:



# ============================================================
# File: /home/matt/icn-prototype/code_manager.py
# Size: 7912 bytes
# Last Modified: Fri Oct 25 18:36:38 2024
# Language: py
# ============================================================

```py
    import os
    import re
    from typing import Dict, List, Optional, Tuple
    import difflib
    
    class CodeManager:
        """
        Manages code updates based on specially formatted input files.
        Input files should have a header in this format:
        
        ```
        # TARGET: path/to/file.py
        # MODE: [replace|update|append]
        # SECTION: [optional] function or class name
        # DESCRIPTION: What this change does
        ```
        """
        
        def __init__(self, project_root: str):
            self.project_root = project_root
            self.backup_dir = os.path.join(project_root, '.code_backups')
            os.makedirs(self.backup_dir, exist_ok=True)
    
        def process_file(self, input_file: str, dry_run: bool = True) -> bool:
            """Process a code update file."""
            try:
                # Read and parse the input file
                with open(input_file, 'r') as f:
                    content = f.read()
    
                # Parse header
                header = self._parse_header(content)
                if not header:
                    print(f"Invalid header in {input_file}")
                    return False
    
                # Get the code content
                code = self._extract_code(content)
                if not code:
                    print(f"No code found in {input_file}")
                    return False
    
                # Get target file path
                target_file = os.path.join(self.project_root, header['target'])
                if not os.path.exists(target_file):
                    print(f"Target file not found: {target_file}")
                    return False
    
                # Create backup
                if not dry_run:
                    self._backup_file(target_file)
    
                # Process based on mode
                if header['mode'] == 'replace':
                    success = self._replace_code(target_file, code, dry_run)
                elif header['mode'] == 'update':
                    success = self._update_code(target_file, code, header.get('section'), dry_run)
                elif header['mode'] == 'append':
                    success = self._append_code(target_file, code, dry_run)
                else:
                    print(f"Unknown mode: {header['mode']}")
                    return False
    
                if success and not dry_run:
                    print(f"Successfully updated {target_file}")
                elif success:
                    print(f"Dry run successful for {target_file}")
                return success
    
            except Exception as e:
                print(f"Error processing {input_file}: {str(e)}")
                return False
    
        def _parse_header(self, content: str) -> Optional[Dict[str, str]]:
            """Parse the header section of the input file."""
            header_pattern = r"#\s*TARGET:\s*(.+)\n#\s*MODE:\s*(.+)\n(?:#\s*SECTION:\s*(.+)\n)?#\s*DESCRIPTION:\s*(.+)"
            match = re.match(header_pattern, content)
            if not match:
                return None
    
            return {
                'target': match.group(1).strip(),
                'mode': match.group(2).strip().lower(),
                'section': match.group(3).strip() if match.group(3) else None,
                'description': match.group(4).strip()
            }
    
        def _extract_code(self, content: str) -> Optional[str]:
            """Extract the code section after the header."""
            lines = content.split('\n')
            start_idx = 0
            for i, line in enumerate(lines):
                if not line.strip().startswith('#'):
                    start_idx = i
                    break
            return '\n'.join(lines[start_idx:]).strip()
    
        def _backup_file(self, filepath: str) -> None:
            """Create a backup of the target file."""
            import time
            import shutil
            
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            backup_name = f"{os.path.basename(filepath)}.{timestamp}.bak"
            backup_path = os.path.join(self.backup_dir, backup_name)
            
            shutil.copy2(filepath, backup_path)
    
        def _replace_code(self, target_file: str, new_code: str, dry_run: bool) -> bool:
            """Replace entire file content."""
            if dry_run:
                with open(target_file, 'r') as f:
                    old_code = f.read()
                self._show_diff(old_code, new_code)
                return True
    
            try:
                with open(target_file, 'w') as f:
                    f.write(new_code)
                return True
            except Exception as e:
                print(f"Error replacing code: {str(e)}")
                return False
    
        def _update_code(self, target_file: str, new_code: str, section: Optional[str], dry_run: bool) -> bool:
            """Update specific section of code."""
            try:
                with open(target_file, 'r') as f:
                    content = f.read()
    
                if section:
                    # Find the section (class or function)
                    section_pattern = rf"(class|def)\s+{section}\b[^\n]*:"
                    match = re.search(section_pattern, content)
                    if not match:
                        print(f"Section '{section}' not found")
                        return False
    
                    # Find section bounds
                    start = match.start()
                    end = self._find_section_end(content, start)
                    
                    updated_content = content[:start] + new_code + content[end:]
                else:
                    updated_content = new_code
    
                if dry_run:
                    self._show_diff(content, updated_content)
                    return True
    
                with open(target_file, 'w') as f:
                    f.write(updated_content)
                return True
    
            except Exception as e:
                print(f"Error updating code: {str(e)}")
                return False
    
        def _append_code(self, target_file: str, new_code: str, dry_run: bool) -> bool:
            """Append code to end of file."""
            try:
                with open(target_file, 'r') as f:
                    content = f.read()
    
                updated_content = content.rstrip() + '\n\n' + new_code + '\n'
    
                if dry_run:
                    self._show_diff(content, updated_content)
                    return True
    
                with open(target_file, 'w') as f:
                    f.write(updated_content)
                return True
    
            except Exception as e:
                print(f"Error appending code: {str(e)}")
                return False
    
        def _find_section_end(self, content: str, start: int) -> int:
            """Find the end of a code section based on indentation."""
            lines = content[start:].split('\n')
            if not lines:
                return start
    
            # Get section indentation level
            first_line = lines[0]
            section_indent = len(first_line) - len(first_line.lstrip())
            
            # Find where indentation returns to original level
            current_pos = start + len(first_line) + 1
            for line in lines[1:]:
                if line.strip() and len(line) - len(line.lstrip()) <= section_indent:
                    return current_pos
                current_pos += len(line) + 1
    
            return len(content)
    
        def _show_diff(self, old_code: str, new_code: str) -> None:
            """Show a diff of the changes."""
            diff = difflib.unified_diff(
                old_code.splitlines(keepends=True),
                new_code.splitlines(keepends=True),
                fromfile='old',
                tofile='new'
            )
            print(''.join(diff))
    
    def main():
        """Command line interface for the code manager."""
        import argparse
        
        parser = argparse.ArgumentParser(description="Manage code updates in the project")
        parser.add_argument('input_file', help="File containing the code update")
        parser.add_argument('--project-root', default='.', help="Root directory of the project")
        parser.add_argument('--dry-run', action='store_true', help="Show changes without applying them")
        
        args = parser.parse_args()
        
        manager = CodeManager(args.project_root)
        success = manager.process_file(args.input_file, args.dry_run)
        
        return 0 if success else 1
    
    if __name__ == "__main__":
        exit(main())
```


# ============================================================
# File: /home/matt/icn-prototype/update_validation.py
# Size: 1085 bytes
# Last Modified: Fri Oct 25 18:39:35 2024
# Language: py
# ============================================================

```py
    # TARGET: blockchain/core/shard/validation_manager.py
    # MODE: update
    # SECTION: validate_transaction
    # DESCRIPTION: Add new validation checks for transaction amounts
    
    def validate_transaction(self, transaction: Transaction) -> bool:
        """
        Validate a transaction before adding to pool.
        
        Args:
            transaction: Transaction to validate
            
        Returns:
            bool: True if transaction is valid
        """
        try:
            # Check cache first
            tx_id = transaction.transaction_id
            if tx_id in self.validation_cache:
                return self.validation_cache[tx_id]
    
            # Basic validation
            if not transaction.validate():
                logger.error(f"Transaction {tx_id} failed basic validation")
                self.validation_cache[tx_id] = False
                return False
    
            # NEW: Check transaction amount
            if transaction.data.get('amount', 0) <= 0:
                logger.error(f"Transaction {tx_id} has invalid amount")
                self.validation_cache[tx_id] = False
                return False
    
            # Rest of the validation logic...
```


# ============================================================
# File: /home/matt/icn-prototype/concatenate_code_files.py
# Size: 4869 bytes
# Last Modified: Sat Oct 26 04:13:36 2024
# Language: py
# ============================================================

```py
    import os
    import time
    
    # Define directories and files to exclude
    EXCLUDE_DIRS = ["__pycache__", ".git", "node_modules", "build", "dist", "venv", ".idea", "icn_env", "docs", "icn-docs"]
    EXCLUDE_FILES = [".pyc", ".pyo", ".log", ".tmp", ".cache", ".DS_Store"]
    
    def tree_structure(startpath, max_depth=3):
        """
        Generate a visual representation of the directory structure up to a specified depth,
        excluding irrelevant directories and files.
        """
        tree_str = ""
        start_depth = startpath.rstrip(os.path.sep).count(os.path.sep)
    
        for root, dirs, files in os.walk(startpath):
            depth = root.count(os.path.sep) - start_depth
            if depth > max_depth:
                continue
    
            # Exclude irrelevant directories
            dirs[:] = [d for d in dirs if d not in EXCLUDE_DIRS]
    
            indent = " " * 4 * depth
            tree_str += f"{indent}{os.path.basename(root)}/\n"
    
            sub_indent = " " * 4 * (depth + 1)
            for file in files:
                if any(file.endswith(ext) for ext in EXCLUDE_FILES):
                    continue
                tree_str += f"{sub_indent}{file}\n"
    
        return tree_str
    
    
    def concatenate_code_files(source_dir, output_file, extensions=None, max_depth=3):
        """
        Concatenate code files from a directory, excluding cache files, documentation files,
        and irrelevant directories like 'icn-docs'.
        """
        if extensions is None:
            extensions = [".py", ".rs", ".js", ".ts", ".c"]
    
        # Remove the old output file if it exists
        if os.path.exists(output_file):
            os.remove(output_file)
            print(f"Removed old output file: {output_file}")
    
        # Generate the tree structure
        tree_str = tree_structure(source_dir, max_depth=max_depth)
    
        # Prepare file content and summary as strings
        content_str = ""
        summary_str = "\n# File Summary:\n"
    
        file_summary = []  # To store summary info for each file
    
        for root, dirs, files in os.walk(source_dir):
            # Exclude irrelevant directories
            dirs[:] = [d for d in dirs if d not in EXCLUDE_DIRS]
    
            # Skip any directory containing 'icn-docs' or 'docs' in its path
            if "icn-docs" in root.split(os.path.sep) or "docs" in root.split(os.path.sep):
                continue
    
            for file in files:
                # Skip excluded file types
                if any(file.endswith(ext) for ext in EXCLUDE_FILES):
                    continue
    
                file_path = os.path.join(root, file)
    
                # Only include files with relevant extensions
                if not any(file.endswith(ext) for ext in extensions):
                    continue
    
                try:
                    file_size = os.path.getsize(file_path)
    
                    with open(file_path, "rb") as binary_check:
                        if b"\0" in binary_check.read(1024):
                            file_summary.append((file_path, file_size, "Skipped (Binary)"))
                            continue
    
                    with open(file_path, "r", encoding="utf-8", errors="ignore") as infile:
                        last_modified = time.ctime(os.path.getmtime(file_path))
                        lang = file.split(".")[-1]
    
                        # File metadata
                        content_str += f"\n\n# {'='*60}\n"
                        content_str += f"# File: {file_path}\n"
                        content_str += f"# Size: {file_size} bytes\n"
                        content_str += f"# Last Modified: {last_modified}\n"
                        content_str += f"# Language: {lang}\n"
                        content_str += f"# {'='*60}\n\n"
    
                        # Syntax-highlighted code block
                        content_str += f"```{lang}\n"
                        file_content = infile.read()
    
                        # Ensure consistent indentation for readability
                        indented_content = "\n".join("    " + line for line in file_content.splitlines())
                        content_str += indented_content
                        content_str += "\n```\n"
    
                        file_summary.append((file_path, file_size, "Included"))
                except Exception as e:
                    print(f"Error reading {file_path}: {e}")
                    file_summary.append((file_path, "N/A", f"Error: {e}"))
    
        # Construct the summary string
        for file_info in file_summary:
            summary_str += f"# {file_info[0]} - {file_info[1]} bytes - {file_info[2]}\n"
    
        # Write everything to the output file
        with open(output_file, "w", encoding="utf-8") as outfile:
            outfile.write(summary_str + "\n\n")
            outfile.write("# Project Directory Structure (up to depth {}):\n".format(max_depth))
            outfile.write(tree_str)
            outfile.write("\n\n# Code Files Concatenation:\n\n")
            outfile.write(content_str)
    
        print(f"Concatenation complete! Check the output file: {output_file}")
    
    
    # Example usage
    concatenate_code_files("/home/matt/icn-prototype", "ICN_code_dump.txt", max_depth=3)
```


# ============================================================
# File: /home/matt/icn-prototype/setup.py
# Size: 513 bytes
# Last Modified: Tue Oct 22 17:47:03 2024
# Language: py
# ============================================================

```py
    # setup.py
    
    from setuptools import setup, find_packages
    
    setup(
        name="icn-prototype",
        version="0.1",
        packages=find_packages(),
        install_requires=[
            'pycryptodome',         # for cryptographic operations
            'cryptography',         # for additional crypto functionality
            'flask',               # for the API
            'flask-jwt-extended',  # for JWT auth
            'werkzeug',           # for utilities
            'pytest',             # for testing
        ],
        python_requires='>=3.8',
    )
```


# ============================================================
# File: /home/matt/icn-prototype/update_imports.py
# Size: 1584 bytes
# Last Modified: Fri Oct 25 18:30:46 2024
# Language: py
# ============================================================

```py
    import os
    
    def update_imports(directory):
        """Update all imports of types to shard_types in Python files."""
        replacements = [
            ('from .shard_types import', 'from .shard_types import'),
            ('from blockchain.core.shard.shard_types import', 'from blockchain.core.shard.shard_types import'),
            ('from ..core.shard.shard_types import', 'from ..core.shard.shard_types import')
        ]
        
        # Walk through all Python files
        for root, _, files in os.walk(directory):
            for file in files:
                if file.endswith('.py'):
                    filepath = os.path.join(root, file)
                    try:
                        # Read file content
                        with open(filepath, 'r') as f:
                            content = f.read()
                        
                        # Check if any replacements are needed
                        original_content = content
                        for old, new in replacements:
                            if old in content:
                                content = content.replace(old, new)
                        
                        # Only write if changes were made
                        if content != original_content:
                            print(f"Updating imports in {filepath}")
                            with open(filepath, 'w') as f:
                                f.write(content)
                    
                    except Exception as e:
                        print(f"Error processing {filepath}: {e}")
    
    if __name__ == "__main__":
        # Run from project root directory
        update_imports(".")
        print("Import updates completed!")
```


# ============================================================
# File: /home/matt/icn-prototype/did/base_did.py
# Size: 8125 bytes
# Last Modified: Sun Oct 27 00:32:46 2024
# Language: py
# ============================================================

```py
    # base_did.py
    
    from __future__ import annotations
    from dataclasses import dataclass, field
    from typing import List, Dict, Optional, Union
    import hashlib
    import logging
    from cryptography.fernet import Fernet
    from cryptography.hazmat.primitives.asymmetric import rsa, padding
    from cryptography.hazmat.primitives import serialization, hashes
    from datetime import datetime
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class BaseDID:
        """
        Base class for Decentralized Identifiers (DID).
        
        This class handles core identity functions, including key generation, DID creation,
        encryption, cooperative and community memberships, dual reputation management, 
        role-based access control (RBAC), and federation with other DAOs.
        
        Attributes:
        - private_key: RSA private key for asymmetric encryption.
        - public_key: RSA public key for DID generation and encryption.
        - cooperative_memberships: List of cooperatives where the DID has membership.
        - community_memberships: List of communities where the DID has membership.
        - reputation_scores: Dictionary of reputation scores (economic and civil).
        - roles: Dictionary of roles and permissions for cooperatives and communities.
        - metadata: Additional metadata related to the DID.
        """
    
        private_key: rsa.RSAPrivateKey = field(init=False)
        public_key: rsa.RSAPublicKey = field(init=False)
        cooperative_memberships: List[str] = field(default_factory=list)
        community_memberships: List[str] = field(default_factory=list)
        reputation_scores: Dict[str, Dict[str, float]] = field(default_factory=lambda: {"economic": {}, "civil": {}})
        roles: Dict[str, Dict[str, List[str]]] = field(default_factory=lambda: {"cooperative": {}, "community": {}})
        metadata: Dict = field(default_factory=dict)
    
        def __post_init__(self):
            """
            Generate RSA keys and initialize Fernet encryption for sensitive data.
            """
            self.private_key = rsa.generate_private_key(public_exponent=65537, key_size=2048)
            self.public_key = self.private_key.public_key()
            self._encryption_key = Fernet.generate_key()
            self._cipher_suite = Fernet(self._encryption_key)
            logger.info("DID initialized with new RSA keys and Fernet encryption.")
    
        def generate_did(self) -> str:
            """
            Generate a DID string based on the SHA-256 hash of the public key.
    
            Returns:
            - str: The generated DID.
            """
            pub_bytes = self.public_key.public_bytes(
                encoding=serialization.Encoding.DER,
                format=serialization.PublicFormat.SubjectPublicKeyInfo,
            )
            did = f"did:icn:{hashlib.sha256(pub_bytes).hexdigest()[:16]}"
            logger.info(f"DID generated: {did}")
            return did
    
        # Cooperative and Community Membership Management
    
        def add_membership(self, dao_type: str, dao_id: str) -> None:
            """
            Add membership to a cooperative or community DAO.
    
            Args:
            - dao_type: 'cooperative' or 'community' indicating the type of DAO.
            - dao_id: The ID of the DAO to add.
            """
            if dao_type == 'cooperative' and dao_id not in self.cooperative_memberships:
                self.cooperative_memberships.append(dao_id)
                logger.info(f"Added cooperative membership: {dao_id}")
            elif dao_type == 'community' and dao_id not in self.community_memberships:
                self.community_memberships.append(dao_id)
                logger.info(f"Added community membership: {dao_id}")
            else:
                logger.warning(f"Invalid DAO type or duplicate membership: {dao_type}, {dao_id}")
    
        def list_memberships(self, dao_type: Optional[str] = None) -> Union[List[str], Dict[str, List[str]]]:
            """
            List memberships for cooperatives, communities, or both.
    
            Args:
            - dao_type: Optional, 'cooperative' or 'community'.
    
            Returns:
            - List[str] | Dict[str, List[str]]: Memberships for the specified type or both.
            """
            if dao_type == 'cooperative':
                return self.cooperative_memberships
            elif dao_type == 'community':
                return self.community_memberships
            else:
                return {
                    "cooperative": self.cooperative_memberships,
                    "community": self.community_memberships,
                }
    
        # Dual Reputation System
    
        def update_reputation(self, category: str, score: float, dao_type: str, evidence: Optional[Dict] = None) -> None:
            """
            Update reputation score for a specific category within cooperatives or communities.
    
            Args:
            - category: The category for the reputation score (e.g., 'trustworthiness').
            - score: The score to be added.
            - dao_type: 'economic' or 'civil' indicating the reputation type.
            - evidence: Optional evidence for reputation updates.
            """
            if dao_type not in self.reputation_scores:
                logger.warning(f"Invalid DAO type for reputation update: {dao_type}")
                return
    
            old_score = self.reputation_scores[dao_type].get(category, 0)
            new_score = old_score + score
            self.reputation_scores[dao_type][category] = new_score
            logger.info(f"{dao_type.capitalize()} reputation updated for '{category}': {new_score}")
    
            if evidence:
                if "reputation_evidence" not in self.metadata:
                    self.metadata["reputation_evidence"] = {}
                self.metadata["reputation_evidence"][category] = evidence
    
        def get_total_reputation(self, dao_type: str) -> float:
            """
            Calculate total reputation score for cooperatives or communities.
    
            Args:
            - dao_type: 'economic' or 'civil'.
    
            Returns:
            - float: The total reputation score.
            """
            total_reputation = sum(self.reputation_scores.get(dao_type, {}).values())
            logger.info(f"Total {dao_type} reputation calculated: {total_reputation}")
            return total_reputation
    
        # Role-Based Access Control (RBAC)
    
        def add_role(self, role: str, permissions: List[str], dao_type: str) -> None:
            """
            Add a role with permissions for cooperatives or communities.
    
            Args:
            - role: The role name (e.g., 'admin', 'member').
            - permissions: List of permissions associated with the role.
            - dao_type: 'cooperative' or 'community'.
            """
            if dao_type not in self.roles:
                logger.warning(f"Invalid DAO type for role assignment: {dao_type}")
                return
    
            self.roles[dao_type][role] = permissions
            logger.info(f"Role '{role}' added in {dao_type} with permissions: {permissions}")
    
        def has_permission(self, role: str, permission: str, dao_type: str) -> bool:
            """
            Check if the DID has a specific permission within a cooperative or community.
    
            Args:
            - role: The role name.
            - permission: The permission to check.
            - dao_type: 'cooperative' or 'community'.
    
            Returns:
            - bool: True if the permission exists for the role, False otherwise.
            """
            has_perm = permission in self.roles.get(dao_type, {}).get(role, [])
            logger.info(f"Permission check for {dao_type} role '{role}' and permission '{permission}': {has_perm}")
            return has_perm
    
        # Federation Management
    
        def federate_with_dao(self, dao_id: str, dao_type: str, terms: Dict) -> None:
            """
            Establish a federation with another cooperative or community.
    
            Args:
            - dao_id: The ID of the DAO to federate with.
            - dao_type: 'cooperative' or 'community'.
            - terms: Dictionary outlining the terms of federation.
            """
            if "federations" not in self.metadata:
                self.metadata["federations"] = []
            
            federation = {
                "dao_id": dao_id,
                "dao_type": dao_type,
                "terms": terms,
                "established_at": datetime.now().isoformat()
            }
            self.metadata["federations"].append(federation)
            logger.info(f"Federated with {dao_type} '{dao_id}' under terms: {terms}")
```


# ============================================================
# File: /home/matt/icn-prototype/did/identity_provider.py
# Size: 1754 bytes
# Last Modified: Sun Oct 27 00:35:34 2024
# Language: py
# ============================================================

```py
    # identity_provider.py
    
    from abc import ABC, abstractmethod
    from credential import Credential
    from typing import Dict
    
    class IdentityProvider(ABC):
        """
        Abstract base class for identity providers in the ICN.
        
        This class defines the interface for issuing and verifying credentials for 
        cooperatives and communities, along with OAuth-like integration.
        """
        
        @abstractmethod
        def issue_credential(self, subject: str, claims: Dict, dao_type: str) -> Credential:
            """
            Issue a verifiable credential for a cooperative or community.
    
            Args:
            - subject: The subject DID.
            - claims: Claims related to the credential.
            - dao_type: 'cooperative' or 'community'.
    
            Returns:
            - Credential: The issued credential.
            """
            pass
    
        @abstractmethod
        def verify_credential(self, credential: Credential) -> bool:
            """
            Verify the cryptographic proof of a credential.
    
            Args:
            - credential: The credential to verify.
    
            Returns:
            - bool: True if the credential is valid, False otherwise.
            """
            pass
    
        def request_oauth_credential(self, client_id: str, redirect_uri: str, dao_type: str) -> str:
            """
            Implement OAuth-like flow for external applications to request credentials from cooperatives or communities.
            
            Args:
            - client_id: Client ID requesting access.
            - redirect_uri: Redirect URI after consent.
            - dao_type: 'cooperative' or 'community'.
    
            Returns:
            - str: Authorization URL for credential request.
            """
            return f"https://auth.icn.org/oauth/authorize?client_id={client_id}&redirect_uri={redirect_uri}&dao_type={dao_type}"
```


# ============================================================
# File: /home/matt/icn-prototype/did/token_manager.py
# Size: 7371 bytes
# Last Modified: Sun Oct 27 00:36:59 2024
# Language: py
# ============================================================

```py
    # token_manager.py
    
    from membership_card import MembershipCard
    from typing import Dict, Optional, List
    
    class TokenManager:
        """
        Token Manager for managing cooperative and community tokens within the ICN system.
        
        This manager handles the issuance, upgrading, and federation of membership cards, 
        supporting both cooperative and community memberships. It allows for staking, 
        federation, and enhanced token management features.
        
        Attributes:
        - tokens: Dictionary mapping member DIDs to their respective membership cards.
        """
        
        def __init__(self):
            """
            Initialize the TokenManager with an empty dictionary for tokens.
            """
            self.tokens: Dict[str, MembershipCard] = {}
    
        def create_membership_card(self, dao_type: str, dao_id: str, member_did: str, metadata: Dict) -> MembershipCard:
            """
            Create and issue a new membership card for a cooperative or community member.
    
            Args:
            - dao_type: 'cooperative' or 'community', indicating the type of DAO.
            - dao_id: The ID of the DAO issuing the card.
            - member_did: The DID of the member receiving the card.
            - metadata: Additional metadata related to the membership (e.g., roles, permissions).
    
            Returns:
            - MembershipCard: The newly issued membership card.
    
            Raises:
            - ValueError: If a membership card already exists for the given member DID.
            """
            if member_did in self.tokens:
                raise ValueError(f"Membership card already exists for member DID: {member_did}")
            
            card = MembershipCard(dao_id=dao_id, member_did=member_did, metadata=metadata, dao_type=dao_type)
            self.tokens[member_did] = card
            return card
    
        def upgrade_membership_card(self, member_did: str, upgrades: Dict) -> Optional[MembershipCard]:
            """
            Upgrade a membership card with new metadata.
    
            Args:
            - member_did: The DID of the member whose card is being upgraded.
            - upgrades: New metadata to add to the card (e.g., added roles, permissions).
    
            Returns:
            - MembershipCard | None: The upgraded membership card, or None if not found.
    
            Raises:
            - ValueError: If the membership card has been revoked.
            """
            card = self.tokens.get(member_did)
            if card is None:
                return None
            if card.is_revoked:
                raise ValueError(f"Cannot upgrade revoked membership card for member DID: {member_did}")
    
            card.metadata.update(upgrades)
            return card
    
        def revoke_membership_card(self, member_did: str) -> bool:
            """
            Revoke a membership card, making it invalid for cooperative or community access.
    
            Args:
            - member_did: The DID of the member whose card is being revoked.
    
            Returns:
            - bool: True if revocation was successful, False if the card was not found or already revoked.
            """
            card = self.tokens.get(member_did)
            if card is None or card.is_revoked:
                return False
    
            card.revoke()
            return True
    
        def federate_membership_card(self, member_did: str, federation_terms: Dict) -> Optional[MembershipCard]:
            """
            Federate a membership card with another DAO (cooperative or community).
    
            Args:
            - member_did: The DID of the member whose card is being federated.
            - federation_terms: Terms of the federation agreement (e.g., sharing resources, joint initiatives).
    
            Returns:
            - MembershipCard | None: The federated membership card, or None if not found.
            """
            card = self.tokens.get(member_did)
            if card is None or card.is_revoked:
                return None
    
            # Add federation terms to the membership card metadata
            if "federation_terms" not in card.metadata:
                card.metadata["federation_terms"] = []
            card.metadata["federation_terms"].append(federation_terms)
    
            return card
    
        def stake_membership_card(self, member_did: str, duration: int) -> bool:
            """
            Stake a membership card for cooperative or community rewards.
    
            Args:
            - member_did: The DID of the member staking the card.
            - duration: Duration of staking in days.
    
            Returns:
            - bool: True if staking was successful, False otherwise.
            """
            card = self.tokens.get(member_did)
            if card and not card.is_revoked:
                card.metadata["staked"] = True
                card.metadata["staking_duration"] = duration
                return True
            return False
    
        def unstake_membership_card(self, member_did: str) -> bool:
            """
            Unstake a previously staked membership card, making it active again.
    
            Args:
            - member_did: The DID of the member unstaking the card.
    
            Returns:
            - bool: True if unstaking was successful, False otherwise.
            """
            card = self.tokens.get(member_did)
            if card and card.metadata.get("staked"):
                card.metadata["staked"] = False
                del card.metadata["staking_duration"]
                return True
            return False
    
        def list_membership_cards(self, dao_type: Optional[str] = None) -> Dict[str, MembershipCard]:
            """
            List all membership cards, optionally filtered by DAO type.
    
            Args:
            - dao_type: Optional, 'cooperative' or 'community', to filter by type.
    
            Returns:
            - Dict[str, MembershipCard]: Dictionary of membership cards filtered by DAO type, if specified.
            """
            if dao_type:
                return {did: card for did, card in self.tokens.items() if card.dao_type == dao_type}
            return self.tokens
    
        def get_membership_card(self, member_did: str) -> Optional[MembershipCard]:
            """
            Retrieve a specific membership card by member DID.
    
            Args:
            - member_did: The DID of the member whose card is being retrieved.
    
            Returns:
            - MembershipCard | None: The membership card if found, otherwise None.
            """
            return self.tokens.get(member_did)
    
        def transfer_membership(self, from_did: str, to_did: str, dao_type: str, dao_id: str) -> bool:
            """
            Transfer a membership from one DID to another within a specific DAO.
    
            Args:
            - from_did: The DID of the member transferring the membership.
            - to_did: The DID of the recipient member.
            - dao_type: 'cooperative' or 'community'.
            - dao_id: The ID of the DAO where the membership is being transferred.
    
            Returns:
            - bool: True if transfer was successful, False otherwise.
    
            Raises:
            - ValueError: If the source DID has no valid membership or the membership is revoked.
            """
            card = self.tokens.get(from_did)
            if card is None or card.is_revoked or card.dao_id != dao_id or card.dao_type != dao_type:
                raise ValueError(f"No valid membership found for transfer from DID: {from_did}")
    
            # Create a new membership card for the recipient DID
            new_card = MembershipCard(
                dao_id=dao_id,
                member_did=to_did,
                metadata=card.metadata,
                dao_type=dao_type
            )
            self.tokens[to_did] = new_card
            del self.tokens[from_did]  # Remove the old card after transfer
    
            return True
```


# ============================================================
# File: /home/matt/icn-prototype/did/credential.py
# Size: 3190 bytes
# Last Modified: Sun Oct 27 00:35:07 2024
# Language: py
# ============================================================

```py
    # credential.py
    
    from dataclasses import dataclass, field
    from typing import Dict, Optional
    from datetime import datetime, timedelta
    
    @dataclass
    class Credential:
        """
        Verifiable credential for the ICN system, with support for cooperative and community DAOs.
        
        Attributes:
        - issuer: The DID that issued the credential.
        - subject: The DID that holds the credential.
        - claims: Claims related to the credential (economic or civil).
        - dao_type: Type of DAO ('cooperative' or 'community').
        - issued_at: Timestamp when the credential was issued.
        - expires_at: Optional expiration timestamp for the credential.
        - proof: Cryptographic proof of the credential's validity.
        """
        issuer: str
        subject: str
        claims: Dict
        dao_type: str
        issued_at: datetime = field(default_factory=datetime.now)
        expires_at: Optional[datetime] = None
        proof: Optional[Dict] = None
    
        def verify(self) -> bool:
            """
            Verify the cryptographic proof of the credential.
            
            Returns:
            - bool: True if the credential is valid, False otherwise.
            """
            if not self.proof:
                return False
            # Implement cryptographic verification logic here
            return True
    
        def revoke(self) -> None:
            """
            Revoke the credential by setting its expiration date to the current time.
            """
            self.expires_at = datetime.now()
    
        def is_expired(self) -> bool:
            """
            Check if the credential is expired.
            
            Returns:
            - bool: True if the credential is expired, False otherwise.
            """
            return self.expires_at and datetime.now() > self.expires_at
    
        def selective_disclosure(self, fields: List[str]) -> Dict:
            """
            Selectively disclose specific fields of the credential.
            
            Args:
            - fields: List of fields to disclose.
    
            Returns:
            - Dict: Disclosed fields of the credential.
            """
            return {field: self.claims[field] for field in fields if field in self.claims}
    
    class CredentialTemplate:
        """
        Credential template for creating standard credentials within cooperatives and communities.
        
        Attributes:
        - template_name: Name of the credential template.
        - claims: Predefined claims for the credential.
        - dao_type: Type of DAO for the credential ('cooperative' or 'community').
        """
        def __init__(self, template_name: str, claims: Dict, dao_type: str):
            self.template_name = template_name
            self.claims = claims
            self.dao_type = dao_type
    
        def apply_template(self, subject_did: str, issuer_did: str) -> Credential:
            """
            Create a credential based on the template.
            
            Args:
            - subject_did: DID of the subject receiving the credential.
            - issuer_did: DID of the issuer.
            
            Returns:
            - Credential: The newly created credential.
            """
            return Credential(
                issuer=issuer_did,
                subject=subject_did,
                claims=self.claims,
                dao_type=self.dao_type,
                expires_at=datetime.now() + timedelta(days=365)
            )
```


# ============================================================
# File: /home/matt/icn-prototype/did/did.py
# Size: 6778 bytes
# Last Modified: Wed Oct 23 15:22:57 2024
# Language: py
# ============================================================

```py
    # did/did.py
    from __future__ import annotations
    from dataclasses import dataclass, field
    from typing import Dict, List, Optional
    import logging
    from datetime import datetime
    import hashlib
    from cryptography.fernet import Fernet
    from cryptography.hazmat.primitives import hashes
    from cryptography.hazmat.primitives.asymmetric import rsa, padding
    from cryptography.hazmat.primitives import serialization
    from abc import ABC, abstractmethod
    
    logger = logging.getLogger(__name__)
    
    
    @dataclass
    class Credential:
        """Verifiable credential for the ICN system."""
    
        issuer: str
        subject: str
        claims: Dict
        issued_at: datetime = field(default_factory=datetime.now)
        expires_at: Optional[datetime] = None
        proof: Optional[Dict] = None
    
        def verify(self) -> bool:
            """Verify the credential's cryptographic proof."""
            if not self.proof:
                return False
            # Implement cryptographic verification
            return True
    
        def revoke(self) -> None:
            """Revoke the credential."""
            self.expires_at = datetime.now()
    
    
    class IdentityProvider(ABC):
        """Abstract base class for identity providers."""
    
        @abstractmethod
        def issue_credential(self, subject: str, claims: Dict) -> Credential:
            pass
    
        @abstractmethod
        def verify_credential(self, credential: Credential) -> bool:
            pass
    
    
    class DID:
        """Decentralized Identifier implementation for ICN."""
    
        def __init__(self, cooperative_id: Optional[str] = None):
            self._private_key = rsa.generate_private_key(
                public_exponent=65537, key_size=2048
            )
            self._public_key = self._private_key.public_key()
            self.cooperative_memberships: List[str] = []
            self.reputation_scores: Dict[str, float] = {}
            self.credentials: List[Credential] = []
            self.metadata: Dict = {}
            if cooperative_id:
                self.add_cooperative_membership(cooperative_id)
    
            # Create encryption key for sensitive data
            self._encryption_key = Fernet.generate_key()
            self._cipher_suite = Fernet(self._encryption_key)
    
        def generate_did(self) -> str:
            """Generate the DID string."""
            pub_bytes = self._public_key.public_bytes(
                encoding=serialization.Encoding.DER,
                format=serialization.PublicFormat.SubjectPublicKeyInfo,
            )
            return f"did:icn:{hashlib.sha256(pub_bytes).hexdigest()[:16]}"
    
        def encrypt_data(self, data: str) -> bytes:
            """Encrypt data using the public key."""
            try:
                return self._public_key.encrypt(
                    data.encode(),
                    padding.OAEP(
                        mgf=padding.MGF1(algorithm=hashes.SHA256()),
                        algorithm=hashes.SHA256(),
                        label=None,
                    ),
                )
            except Exception as e:
                logger.error(f"Encryption failed: {e}")
                raise
    
        def decrypt_data(self, encrypted_data: bytes) -> str:
            """Decrypt data using the private key."""
            try:
                decrypted = self._private_key.decrypt(
                    encrypted_data,
                    padding.OAEP(
                        mgf=padding.MGF1(algorithm=hashes.SHA256()),
                        algorithm=hashes.SHA256(),
                        label=None,
                    ),
                )
                return decrypted.decode()
            except Exception as e:
                logger.error(f"Decryption failed: {e}")
                raise
    
        def add_cooperative_membership(self, cooperative_id: str) -> None:
            """Add membership to a cooperative."""
            if cooperative_id not in self.cooperative_memberships:
                self.cooperative_memberships.append(cooperative_id)
                logger.info(f"Added membership to cooperative: {cooperative_id}")
    
        def update_reputation(
            self, category: str, score: float, evidence: Optional[Dict] = None
        ) -> None:
            """Update reputation score with optional evidence."""
            if score < 0:
                logger.warning(f"Negative reputation score update: {score}")
    
            old_score = self.reputation_scores.get(category, 0)
            self.reputation_scores[category] = old_score + score
    
            if evidence:
                if "reputation_evidence" not in self.metadata:
                    self.metadata["reputation_evidence"] = {}
                self.metadata["reputation_evidence"][category] = evidence
    
        def get_total_reputation(self) -> float:
            """Calculate total reputation across all categories."""
            return sum(self.reputation_scores.values())
    
        def export_public_credentials(self) -> Dict:
            """Export public credentials and memberships."""
            return {
                "did": self.generate_did(),
                "cooperative_memberships": self.cooperative_memberships,
                "reputation_scores": self.reputation_scores,
                "public_credentials": [
                    {k: v for k, v in c.__dict__.items() if k != "proof"}
                    for c in self.credentials
                ],
            }
    
    
    class DIDRegistry:
        """Registry for DIDs in the ICN system."""
    
        def __init__(self):
            self.dids: Dict[str, DID] = {}
            self.revoked_dids: Dict[str, datetime] = {}
            self._identity_providers: Dict[str, IdentityProvider] = {}
    
        def register_did(self, did: DID) -> str:
            """Register a new DID."""
            did_id = did.generate_did()
            if did_id in self.revoked_dids:
                raise ValueError(f"DID {did_id} has been revoked")
            self.dids[did_id] = did
            logger.info(f"Registered new DID: {did_id}")
            return did_id
    
        def resolve_did(self, did_id: str) -> Optional[DID]:
            """Resolve a DID to its full object."""
            if did_id in self.revoked_dids:
                logger.warning(f"Attempted to resolve revoked DID: {did_id}")
                return None
            return self.dids.get(did_id)
    
        def verify_did(self, did_id: str) -> bool:
            """Verify a DID's validity."""
            if did_id in self.revoked_dids:
                return False
            return did_id in self.dids
    
        def revoke_did(self, did_id: str, reason: str) -> None:
            """Revoke a DID."""
            if did_id in self.dids:
                self.revoked_dids[did_id] = datetime.now()
                del self.dids[did_id]
                logger.warning(f"DID revoked: {did_id}, reason: {reason}")
    
        def register_identity_provider(self, name: str, provider: IdentityProvider) -> None:
            """Register a new identity provider."""
            self._identity_providers[name] = provider
            logger.info(f"Registered identity provider: {name}")
    
        def get_identity_provider(self, name: str) -> Optional[IdentityProvider]:
            """Get an identity provider by name."""
            return self._identity_providers.get(name)
```


# ============================================================
# File: /home/matt/icn-prototype/did/privacy.py
# Size: 1846 bytes
# Last Modified: Sun Oct 27 00:35:25 2024
# Language: py
# ============================================================

```py
    # privacy.py
    
    from typing import List
    from base_did import BaseDID
    
    class Privacy:
        """
        Privacy-preserving techniques for cooperatives and communities in ICN.
        
        This module handles privacy-preserving features, including stealth addresses,
        selective credential disclosure, and zero-knowledge proofs.
        """
        
        def generate_stealth_address(self, did: BaseDID, dao_type: str) -> str:
            """
            Generate a stealth address for interactions with a cooperative or community.
    
            Args:
            - did: The DID generating the stealth address.
            - dao_type: 'cooperative' or 'community'.
    
            Returns:
            - str: The generated stealth address.
            """
            stealth_address = f"stealth:{did.generate_did()}:{dao_type}"
            return stealth_address
    
        def verify_zero_knowledge_proof(self, proof_data: bytes, dao_type: str) -> bool:
            """
            Verify a zero-knowledge proof for a cooperative or community interaction.
    
            Args:
            - proof_data: The zk-SNARK proof data.
            - dao_type: 'cooperative' or 'community'.
    
            Returns:
            - bool: True if the proof is valid, False otherwise.
            """
            # Placeholder for zk-SNARK verification logic specific to DAO type
            return True
    
        def selective_disclosure(self, did: BaseDID, dao_type: str, fields: List[str]) -> Dict:
            """
            Selectively disclose specific information for cooperatives or communities.
    
            Args:
            - did: The DID requesting selective disclosure.
            - dao_type: 'cooperative' or 'community'.
            - fields: Fields to disclose.
    
            Returns:
            - Dict: The disclosed information.
            """
            data_to_disclose = did.export_public_credentials().get(dao_type, {})
            return {field: data_to_disclose.get(field) for field in fields}
```


# ============================================================
# File: /home/matt/icn-prototype/did/layered_did.py
# Size: 1459 bytes
# Last Modified: Sun Oct 27 00:23:00 2024
# Language: py
# ============================================================

```py
    # layered_did.py
    
    from base_did import BaseDID
    from typing import Dict, Optional
    from dataclasses import field
    
    class LayeredDID(BaseDID):
        """
        Layered Decentralized Identifier (Layered DID).
        
        This class extends the base DID and allows for the creation of sub-DIDs, 
        which are specific to each cooperative. This provides users with a layer of 
        privacy and separation when interacting with different cooperatives, without 
        linking their activities to their base DID.
    
        Attributes:
        - sub_dids: A dictionary mapping cooperative IDs to their respective sub-DIDs.
        """
        sub_dids: Dict[str, str] = field(default_factory=dict)
    
        def add_sub_did(self, cooperative_id: str) -> str:
            """
            Generate and store a sub-DID specific to a cooperative.
    
            Args:
            - cooperative_id: The unique identifier of the cooperative.
    
            Returns:
            - str: The generated sub-DID.
            """
            sub_did = f"{self.generate_did()}:{hashlib.sha256(cooperative_id.encode()).hexdigest()[:8]}"
            self.sub_dids[cooperative_id] = sub_did
            return sub_did
    
        def get_sub_did(self, cooperative_id: str) -> Optional[str]:
            """
            Retrieve the sub-DID for a specific cooperative.
    
            Args:
            - cooperative_id: The cooperative's unique ID.
    
            Returns:
            - str | None: The sub-DID if found, otherwise None.
            """
            return self.sub_dids.get(cooperative_id)
```


# ============================================================
# File: /home/matt/icn-prototype/did/registry.py
# Size: 1529 bytes
# Last Modified: Sun Oct 27 00:26:07 2024
# Language: py
# ============================================================

```py
    # registry.py
    
    from typing import Dict, Optional
    from base_did import BaseDID
    from datetime import datetime
    import logging
    
    logger = logging.getLogger(__name__)
    
    class DIDRegistry:
        """
        Registry for managing DIDs within the InterCooperative Network (ICN).
        
        This registry handles registration, resolution, verification, and revocation of DIDs,
        as well as integration with identity providers.
        """
        def __init__(self):
            self.dids: Dict[str, BaseDID] = {}
            self.revoked_dids: Dict[str, datetime] = {}
            self._identity_providers: Dict[str, IdentityProvider] = {}
    
        def register_did(self, did: BaseDID) -> str:
            """Register a new DID within the registry."""
            did_id = did.generate_did()
            if did_id in self.revoked_dids:
                raise ValueError(f"DID {did_id} has been revoked")
            self.dids[did_id] = did
            logger.info(f"Registered new DID: {did_id}")
            return did_id
    
        def resolve_did(self, did_id: str) -> Optional[BaseDID]:
            """Resolve a DID to its corresponding object."""
            if did_id in self.revoked_dids:
                logger.warning(f"Attempted to resolve revoked DID: {did_id}")
                return None
            return self.dids.get(did_id)
    
        def revoke_did(self, did_id: str, reason: str) -> None:
            """Revoke a DID."""
            if did_id in self.dids:
                self.revoked_dids[did_id] = datetime.now()
                del self.dids[did_id]
                logger.warning(f"DID revoked: {did_id}, reason: {reason}")
```


# ============================================================
# File: /home/matt/icn-prototype/did/membership_card.py
# Size: 1527 bytes
# Last Modified: Sun Oct 27 00:23:27 2024
# Language: py
# ============================================================

```py
    # membership_card.py
    
    from dataclasses import dataclass, field
    from typing import Dict
    
    @dataclass
    class MembershipCard:
        """
        Soulbound Membership Card representing cooperative membership.
        
        This card is issued by cooperatives to their members, allowing them to participate 
        in the cooperative and access its products and services. These tokens cannot be 
        transferred and are permanently bound to the member's DID.
    
        Attributes:
        - cooperative_id: The unique identifier of the cooperative issuing the card.
        - member_did: The DID of the member to whom the card is issued.
        - metadata: Additional data about the membership, such as roles or permissions.
        - is_revoked: A boolean indicating whether the membership has been revoked.
        """
        cooperative_id: str
        member_did: str
        metadata: Dict = field(default_factory=dict)
        is_revoked: bool = False
    
        def issue(self, member_did: str, metadata: Dict) -> MembershipCard:
            """
            Issue a new membership card for a cooperative member.
    
            Args:
            - member_did: The DID of the member receiving the card.
            - metadata: Additional data about the membership (e.g., roles, permissions).
    
            Returns:
            - MembershipCard: The issued membership card.
            """
            self.member_did = member_did
            self.metadata.update(metadata)
            return self
    
        def revoke(self) -> None:
            """
            Revoke the membership card, invalidating it.
            """
            self.is_revoked = True
```


# ============================================================
# File: /home/matt/icn-prototype/did/__init__.py
# Size: 0 bytes
# Last Modified: Tue Oct 22 00:20:15 2024
# Language: py
# ============================================================

```py

```


# ============================================================
# File: /home/matt/icn-prototype/api/server.py
# Size: 5851 bytes
# Last Modified: Wed Oct 23 15:22:56 2024
# Language: py
# ============================================================

```py
    import sys
    import os
    
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    
    
    from flask import Flask, request, jsonify
    from flask_jwt_extended import (
        JWTManager,
        create_access_token,
        jwt_required,
        get_jwt_identity,
    )
    from werkzeug.security import generate_password_hash, check_password_hash
    from functools import wraps
    from blockchain.blockchain import Blockchain
    from did.did import DID, DIDRegistry
    from system.governance import Governance, Proposal
    from system.marketplace import Marketplace
    from system.storage import DistributedStorage
    
    app = Flask(__name__)
    app.config["JWT_SECRET_KEY"] = "your_jwt_secret_key"  # Replace with a secure key
    jwt = JWTManager(app)
    
    blockchain = Blockchain()
    did_registry = DIDRegistry()
    governance = Governance(blockchain)
    marketplace = Marketplace(blockchain, did_registry)
    storage = DistributedStorage(blockchain)
    
    users_db = {}
    
    
    def role_required(required_role):
        def decorator(f):
            @wraps(f)
            def wrapper(*args, **kwargs):
                current_user = get_jwt_identity()
                if current_user["role"] != required_role:
                    return jsonify({"message": "Access forbidden: insufficient role"}), 403
                return f(*args, **kwargs)
    
            return wrapper
    
        return decorator
    
    
    @app.route("/register", methods=["POST"])
    def register():
        username = request.json.get("username")
        password = request.json.get("password")
        role = request.json.get("role", "user")
    
        if username in users_db:
            return jsonify({"message": "User already exists"}), 400
    
        did = DID()
        did_id = did_registry.register_did(did)
    
        hashed_password = generate_password_hash(password)
        users_db[username] = {"password": hashed_password, "role": role, "did": did_id}
    
        return (
            jsonify({"message": f"User {username} registered successfully", "did": did_id}),
            201,
        )
    
    
    @app.route("/login", methods=["POST"])
    def login():
        username = request.json.get("username")
        password = request.json.get("password")
    
        user = users_db.get(username)
    
        if not user or not check_password_hash(user["password"], password):
            return jsonify({"message": "Invalid username or password"}), 401
    
        access_token = create_access_token(
            identity={"username": username, "role": user["role"], "did": user["did"]}
        )
        return jsonify(access_token=access_token), 200
    
    
    @app.route("/create_proposal", methods=["POST"])
    @jwt_required()
    def create_proposal():
        current_user = get_jwt_identity()
        proposal_data = request.json
        proposal = Proposal(
            id=f"proposal_{len(governance.proposals) + 1}",
            title=proposal_data["title"],
            description=proposal_data["description"],
            creator=current_user["did"],
            proposal_type=proposal_data["type"],
            options=proposal_data.get("options"),
            amount=proposal_data.get("amount"),
            stages=proposal_data.get("stages"),
        )
        proposal_id = governance.create_proposal(proposal)
        return jsonify({"message": "Proposal created", "proposal_id": proposal_id}), 201
    
    
    @app.route("/vote", methods=["POST"])
    @jwt_required()
    def vote():
        current_user = get_jwt_identity()
        proposal_id = request.json.get("proposal_id")
        vote = request.json.get("vote")
        voting_power = request.json.get("voting_power", 1)
    
        if governance.cast_vote(proposal_id, vote, current_user["did"], voting_power):
            return jsonify({"message": "Vote cast successfully"}), 200
        return jsonify({"message": "Failed to cast vote"}), 400
    
    
    @app.route("/finalize_proposal", methods=["POST"])
    @jwt_required()
    @role_required("admin")
    def finalize_proposal():
        proposal_id = request.json.get("proposal_id")
    
        if governance.finalize_proposal(proposal_id):
            return jsonify({"message": "Proposal finalized successfully"}), 200
        return jsonify({"message": "Failed to finalize proposal"}), 400
    
    
    @app.route("/create_listing", methods=["POST"])
    @jwt_required()
    def create_listing():
        current_user = get_jwt_identity()
        listing_data = request.json
        listing_id = marketplace.create_listing(
            f"listing_{len(marketplace.listings) + 1}",
            current_user["did"],
            listing_data["item"],
            listing_data["price"],
        )
        if listing_id:
            return jsonify({"message": "Listing created", "listing_id": listing_id}), 201
        return jsonify({"message": "Failed to create listing"}), 400
    
    
    @app.route("/place_order", methods=["POST"])
    @jwt_required()
    def place_order():
        current_user = get_jwt_identity()
        order_data = request.json
        order_id = f"order_{len(marketplace.orders) + 1}"
        if marketplace.place_order(order_id, current_user["did"], order_data["listing_id"]):
            return jsonify({"message": "Order placed", "order_id": order_id}), 201
        return jsonify({"message": "Failed to place order"}), 400
    
    
    @app.route("/complete_order", methods=["POST"])
    @jwt_required()
    def complete_order():
        order_id = request.json.get("order_id")
        completed_order = marketplace.complete_order(order_id)
        if completed_order:
            return (
                jsonify({"message": "Order completed", "order": completed_order.__dict__}),
                200,
            )
        return jsonify({"message": "Failed to complete order"}), 400
    
    
    @app.route("/store_file", methods=["POST"])
    @jwt_required()
    def store_file():
        file = request.files["file"]
        file_hash = storage.store_file(file.filename, file.read())
        return jsonify({"message": "File stored", "file_hash": file_hash}), 201
    
    
    @app.route("/retrieve_file/<file_hash>", methods=["GET"])
    @jwt_required()
    def retrieve_file(file_hash):
        file_data = storage.retrieve_file(file_hash)
        if file_data:
            return file_data, 200
        return jsonify({"message": "File not found"}), 404
    
    
    if __name__ == "__main__":
        app.run(debug=True)
```


# ============================================================
# File: /home/matt/icn-prototype/api/__init__.py
# Size: 0 bytes
# Last Modified: Sun Oct 20 00:32:19 2024
# Language: py
# ============================================================

```py

```


# ============================================================
# File: /home/matt/icn-prototype/tests/__init__.py
# Size: 60 bytes
# Last Modified: Thu Oct 24 00:42:39 2024
# Language: py
# ============================================================

```py
    # tests/__init__.py
    """Test suite for the ICN blockchain."""
```


# ============================================================
# File: /home/matt/icn-prototype/tests/integration/test_cooldown_management.py
# Size: 1102 bytes
# Last Modified: Sat Oct 26 18:42:20 2024
# Language: py
# ============================================================

```py
    import unittest
    from datetime import datetime, timedelta
    from blockchain.consensus.proof_of_cooperation.cooldown_manager import CooldownManager
    from blockchain.core.node import Node
    
    class TestCooldownManagement(unittest.TestCase):
        def setUp(self):
            self.cooldown_manager = CooldownManager(base_cooldown=3, max_cooldown=10)
            self.node1 = Node(node_id="node1", cooperative_id="coop1", initial_stake=100.0)
            self.node1.reputation = 20.0
    
        def test_dynamic_cooldown_increase(self):
            # Simulate high participation rate to trigger dynamic cooldown increase
            for _ in range(5):
                self.cooldown_manager._track_activity(self.node1)
            
            self.cooldown_manager.apply_cooldown(self.node1)
            self.assertGreater(self.node1.cooldown, 3)  # Cooldown should increase
    
        def test_cooldown_decay(self):
            # Test that cooldown decreases gradually over time
            self.node1.cooldown = 5
            self.cooldown_manager.reset_cooldown(self.node1)
            self.assertEqual(self.node1.cooldown, 4)
    
    if __name__ == '__main__':
        unittest.main()
```


# ============================================================
# File: /home/matt/icn-prototype/tests/integration/test_consensus_mechanism.py
# Size: 10902 bytes
# Last Modified: Thu Oct 24 21:48:52 2024
# Language: py
# ============================================================

```py
    import unittest
    from datetime import datetime, timedelta
    from typing import List
    
    # Adjust imports based on your project structure
    from blockchain.consensus.proof_of_cooperation import ProofOfCooperation
    from blockchain.core.node import Node
    from blockchain.core.block import Block
    from blockchain.core.transaction import Transaction
    
    class TestConsensusMechanism(unittest.TestCase):
        """Test suite for the ICN Proof of Cooperation consensus mechanism."""
    
        def setUp(self):
            """Set up the consensus mechanism and initial test data."""
            self.consensus = ProofOfCooperation(min_reputation=10.0, cooldown_blocks=3)
            self.nodes = self._create_test_nodes()
            
            # Create a genesis block
            self.genesis_block = Block(
                index=0,
                previous_hash="0" * 64,
                timestamp=datetime.now() - timedelta(minutes=10),
                transactions=[],
                validator="genesis",
                shard_id=1
            )
    
        def _create_test_node(self, node_id: str, reputation_score: float = 25.0) -> Node:
            """Create a test node with predefined characteristics."""
            node = Node(node_id=node_id, cooperative_id="test_coop", initial_stake=100.0)
    
            # Assign reputation scores
            for category in node.reputation_scores:
                node.reputation_scores[category] = reputation_score
    
            # Assign validation history
            node.validation_history = [
                {"timestamp": datetime.now() - timedelta(minutes=i),
                 "category": "validation", "score_change": 1.0, "evidence": {"success": True}}
                for i in range(20)
            ]
    
            # Assign performance metrics
            node.performance_metrics = {
                "availability": 98.0,
                "validation_success_rate": 95.0,
                "network_reliability": 97.0
            }
    
            # Set node state
            node.metadata["status"] = "active"
            node.cooldown = 0
    
            # Assign shard
            node.assign_to_shard(1)
    
            # Add cooperative interactions
            node.cooperative_interactions = [f"coop_{i}" for i in range(30)]
    
            return node
    
        def _create_test_nodes(self, num_nodes: int = 5) -> List[Node]:
            """Create a list of test nodes with varying characteristics."""
            nodes = []
            for i in range(num_nodes):
                reputation = 25.0 + (i * 5.0)
                node = self._create_test_node(f"node_{i}", reputation)
                nodes.append(node)
            return nodes
    
        def _create_test_block(self, transactions: List[Transaction]) -> Block:
            """Create a test block with predefined transactions."""
            return Block(
                index=self.genesis_block.index + 1,
                previous_hash=self.genesis_block.hash,
                timestamp=datetime.now(),
                transactions=transactions,
                validator="test_validator",
                shard_id=1
            )
    
        def test_initialization(self):
            """Test initialization of the consensus mechanism."""
            self.assertEqual(self.consensus.min_reputation, 10.0)
            self.assertEqual(self.consensus.cooldown_blocks, 3)
            self.assertGreater(len(self.consensus.reputation_weights), 0)
            self.assertGreater(len(self.consensus.validation_thresholds), 0)
    
        def test_validator_selection(self):
            """Test the process of selecting a validator."""
            validator = self.consensus.select_validator(self.nodes)
            self.assertIsNotNone(validator)
            self.assertIn(validator, self.nodes)
    
            # Test selection with specific shard
            shard_validator = self.consensus.select_validator(self.nodes, shard_id=1)
            self.assertIsNotNone(shard_validator)
    
            # Test selection when all nodes are in cooldown
            for node in self.nodes:
                node.enter_cooldown(3)
            no_validator = self.consensus.select_validator(self.nodes)
            self.assertIsNone(no_validator)
    
            # Test selection with varying reputation scores
            for node in self.nodes:
                node.cooldown = 0
            high_rep_node = self._create_test_node("high_rep", 100.0)
            self.nodes.append(high_rep_node)
    
            selection_counts = {node.node_id: 0 for node in self.nodes}
            for _ in range(100):
                selected = self.consensus.select_validator(self.nodes)
                if selected:
                    selection_counts[selected.node_id] += 1
    
            self.assertGreater(selection_counts["high_rep"], selection_counts["node_0"])
    
        def test_cooperation_score_calculation(self):
            """Test calculation of cooperation scores."""
            node = self._create_test_node("test_node")
    
            score = self.consensus.calculate_cooperation_score(node)
            self.assertGreater(score, 0)
    
            # Test with lower reputation
            for category in node.reputation_scores:
                node.reputation_scores[category] = 5.0
            low_score = self.consensus.calculate_cooperation_score(node)
            self.assertLess(low_score, score)
    
            # Test with limited cooperative interactions
            node.cooperative_interactions = ["coop_1"] * 30
            limited_score = self.consensus.calculate_cooperation_score(node)
            self.assertLess(limited_score, score)
    
            # Test with lower performance metrics
            node.performance_metrics["availability"] = 50.0
            poor_score = self.consensus.calculate_cooperation_score(node)
            self.assertLess(poor_score, score)
    
        def test_block_validation(self):
            """Test the block validation process."""
            validator = self._create_test_node("test_validator")
    
            transactions = [
                Transaction(
                    sender=f"sender_{i}",
                    receiver=f"receiver_{i}",
                    action="transfer",
                    data={"amount": 10.0},
                    shard_id=1
                ) for i in range(3)
            ]
    
            valid_block = self._create_test_block(transactions)
            self.assertTrue(self.consensus.validate_block(valid_block, self.genesis_block, validator))
    
            # Test with an invalid timestamp
            invalid_block = self._create_test_block(transactions)
            invalid_block.timestamp = datetime.now() + timedelta(hours=1)
            self.assertFalse(self.consensus.validate_block(invalid_block, self.genesis_block, validator))
    
            # Test with a validator having insufficient reputation
            invalid_validator = self._create_test_node("invalid_validator", reputation_score=5.0)
            self.assertFalse(self.consensus.validate_block(valid_block, self.genesis_block, invalid_validator))
    
        def test_collusion_detection(self):
            """Test detection of collusion in transactions."""
            validator = self._create_test_node("test_validator")
    
            normal_transactions = [
                Transaction(
                    sender=f"sender_{i}",
                    receiver=f"receiver_{i}",
                    action="transfer",
                    data={"amount": 10.0},
                    shard_id=1
                ) for i in range(10)
            ]
            normal_block = self._create_test_block(normal_transactions)
    
            suspicious_transactions = [
                Transaction(
                    sender="suspicious_sender",
                    receiver=f"receiver_{i}",
                    action="transfer",
                    data={"amount": 10.0},
                    shard_id=1
                ) for i in range(10)
            ]
            suspicious_block = self._create_test_block(suspicious_transactions)
    
            self.assertFalse(self.consensus.detect_collusion(validator, normal_block))
            self.assertTrue(self.consensus.detect_collusion(validator, suspicious_block))
    
        def test_cooldown_mechanism(self):
            """Test the cooldown mechanism for validators."""
            validator = self._create_test_node("test_validator")
    
            selected = self.consensus.select_validator([validator])
            self.assertIsNotNone(selected)
            self.assertEqual(selected.cooldown, self.consensus.cooldown_blocks)
    
            # Ensure validator cannot be selected during cooldown
            new_selection = self.consensus.select_validator([validator])
            self.assertIsNone(new_selection)
    
            # Reset cooldown and test selection again
            validator.cooldown = 0
            final_selection = self.consensus.select_validator([validator])
            self.assertIsNotNone(final_selection)
    
        def test_validation_metrics(self):
            """Test tracking of validation metrics."""
            validator = self._create_test_node("test_validator")
            transactions = [
                Transaction(
                    sender=f"sender_{i}",
                    receiver=f"receiver_{i}",
                    action="transfer",
                    data={"amount": 10.0},
                    shard_id=1
                ) for i in range(3)
            ]
    
            for i in range(5):
                block = self._create_test_block(transactions)
                self.consensus.validate_block(block, self.genesis_block, validator)
    
            metrics = self.consensus.get_metrics()
            self.assertGreater(metrics["total_validations"], 0)
            self.assertGreater(metrics["successful_validations"], 0)
            self.assertGreaterEqual(metrics["success_rate"], 0)
    
        def test_shard_specific_validation(self):
            """Test validation in a shard-specific context."""
            validator = self._create_test_node("test_validator")
    
            self.assertTrue(validator.can_validate(shard_id=1))
            self.assertFalse(validator.can_validate(shard_id=2))
    
            # Ensure validator selection for a specific shard
            selected = self.consensus.select_validator(self.nodes, shard_id=1)
            if selected:
                self.assertIn(1, selected.shard_assignments)
    
        def test_progressive_reputation_requirements(self):
            """Test progressive reputation requirements for new nodes."""
            new_node = self._create_test_node("new_node")
            new_node.total_validations = 0
    
            # Set lower reputation
            for category in new_node.reputation_scores:
                new_node.reputation_scores[category] = self.consensus.min_reputation * 0.6
    
            self.assertTrue(self.consensus._can_participate(new_node))
    
            # Increase validations and recheck eligibility
            new_node.total_validations = 20
            self.assertFalse(self.consensus._can_participate(new_node))
    
        def test_validator_history(self):
            """Test tracking of validator history."""
            for _ in range(5):
                validator = self.consensus.select_validator(self.nodes)
                if validator:
                    self.assertIn(
                        validator.node_id,
                        [record[0] for record in self.consensus.validator_history]
                    )
    
            # Ensure history length is capped
            for _ in range(1000):
                self.consensus.validator_history.append(("test_node", datetime.now(), 1))
            self.assertLessEqual(len(self.consensus.validator_history), 1000)
    
    if __name__ == '__main__':
        unittest.main()
```


# ============================================================
# File: /home/matt/icn-prototype/tests/integration/test_block_creation.py
# Size: 11204 bytes
# Last Modified: Fri Oct 25 13:29:26 2024
# Language: py
# ============================================================

```py
    import unittest
    from datetime import datetime, timedelta
    import sys
    import os
    from typing import List, Dict, Optional
    import hashlib
    import json
    
    # Add project root to Python path
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    sys.path.insert(0, project_root)
    
    from blockchain.core.block import Block
    from blockchain.core.transaction import Transaction
    from blockchain.core.shard import Shard
    from blockchain.core.node import Node
    from blockchain.consensus.proof_of_cooperation import ProofOfCooperation
    
    class TestBlockCreation(unittest.TestCase):
        """Integration tests for block creation in the ICN blockchain."""
    
        def setUp(self):
            """Set up test environment before each test."""
            self.shard = Shard(shard_id=1, max_transactions_per_block=5)
            self.consensus = ProofOfCooperation()
            self.validator = self._create_test_validator()
            self.test_transactions = self._create_test_transactions()
    
        def _create_test_validator(self) -> Node:
            """Create a test validator node."""
            validator = Node(
                node_id="test_validator",
                cooperative_id="test_coop",
                initial_stake=100.0
            )
            validator.reputation_scores = {
                "validation": 25.0,
                "transaction_validation": 25.0,
                "resource_sharing": 25.0,
                "cooperative_growth": 25.0
            }
            validator.performance_metrics = {
                "availability": 98.0,
                "validation_success_rate": 95.0,
                "network_reliability": 97.0
            }
            validator.assign_to_shard(1)
            return validator
    
        def _create_test_transactions(self) -> List[Transaction]:
            """Create test transactions with varied characteristics."""
            transactions = []
            for i in range(10):
                tx = Transaction(
                    sender=f"sender_{i}",
                    receiver=f"receiver_{i}",
                    action="transfer",
                    data={"amount": 10.0 * (i + 1)},
                    shard_id=1,
                    priority=min(i % 5 + 1, 5),
                    cooperative_tags={f"tag_{i}"}
                )
                transactions.append(tx)
            return transactions
    
        def test_basic_block_creation(self):
            """Test creation of a basic valid block."""
            # Add some transactions to the shard
            for tx in self.test_transactions[:3]:
                self.shard.add_transaction(tx)
    
            # Create block
            block = self.shard.create_block(validator="test_validator")
            
            # Verify block properties
            self.assertIsNotNone(block)
            self.assertEqual(block.index, self.shard.height)
            self.assertEqual(block.validator, "test_validator")
            self.assertEqual(block.shard_id, self.shard.shard_id)
            self.assertEqual(len(block.transactions), 3)
            self.assertIsNotNone(block.merkle_root)
            self.assertIsNotNone(block.hash)
            
            # Verify block can be added to shard
            self.assertTrue(self.shard.add_block(block))
            self.assertEqual(self.shard.height, block.index + 1)
    
        def test_transaction_ordering_in_block(self):
            """Test that transactions are properly ordered in block by priority."""
            # Add transactions with different priorities
            for tx in self.test_transactions[:5]:
                self.shard.add_transaction(tx)
    
            block = self.shard.create_block(validator="test_validator")
            self.assertIsNotNone(block)
    
            # Verify transactions are ordered by priority
            for i in range(len(block.transactions) - 1):
                self.assertGreaterEqual(
                    block.transactions[i].priority,
                    block.transactions[i + 1].priority
                )
    
        def test_block_size_limits(self):
            """Test enforcement of block size limits."""
            # Add maximum number of transactions
            for tx in self.test_transactions[:self.shard.max_transactions_per_block]:
                self.shard.add_transaction(tx)
    
            # Create block
            block = self.shard.create_block(validator="test_validator")
            self.assertIsNotNone(block)
            self.assertEqual(len(block.transactions), self.shard.max_transactions_per_block)
    
            # Try to add one more transaction
            extra_tx = self.test_transactions[self.shard.max_transactions_per_block]
            self.shard.add_transaction(extra_tx)
            
            block = self.shard.create_block(validator="test_validator")
            self.assertEqual(len(block.transactions), self.shard.max_transactions_per_block)
    
        def test_cross_shard_block_creation(self):
            """Test creation of blocks with cross-shard transactions."""
            # Create cross-shard transaction
            cross_shard_tx = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={"amount": 100.0, "target_shard": 2},
                shard_id=1,
                cross_shard_refs=["ref_1"]
            )
            
            # Add transactions
            self.shard.add_transaction(cross_shard_tx)
            for tx in self.test_transactions[:2]:
                self.shard.add_transaction(tx)
    
            # Create block
            block = self.shard.create_block(validator="test_validator")
            self.assertIsNotNone(block)
            
            # Verify cross-shard references
            self.assertIn(cross_shard_tx.transaction_id, 
                         [tx.transaction_id for tx in block.transactions])
            self.assertTrue(block.cross_shard_refs)
    
        def test_block_validation(self):
            """Test comprehensive block validation."""
            # Add transactions
            for tx in self.test_transactions[:3]:
                self.shard.add_transaction(tx)
    
            # Create valid block
            valid_block = self.shard.create_block(validator="test_validator")
            self.assertTrue(valid_block.validate(self.shard.chain[-1]))
    
            # Test with invalid previous hash
            invalid_block = Block(
                index=valid_block.index,
                previous_hash="invalid_hash",
                timestamp=datetime.now(),
                transactions=valid_block.transactions.copy(),
                validator="test_validator",
                shard_id=1
            )
            self.assertFalse(invalid_block.validate(self.shard.chain[-1]))
    
            # Test with future timestamp
            future_block = Block(
                index=valid_block.index,
                previous_hash=valid_block.previous_hash,
                timestamp=datetime.now() + timedelta(hours=1),
                transactions=valid_block.transactions.copy(),
                validator="test_validator",
                shard_id=1
            )
            self.assertFalse(future_block.validate(self.shard.chain[-1]))
    
        def test_merkle_root_calculation(self):
            """Test Merkle root calculation with different transaction sets."""
            # Test with no transactions
            empty_block = Block(
                index=0,
                previous_hash="0" * 64,
                timestamp=datetime.now(),
                transactions=[],
                validator="test_validator",
                shard_id=1
            )
            self.assertIsNotNone(empty_block.merkle_root)
    
            # Test with one transaction
            single_tx_block = Block(
                index=0,
                previous_hash="0" * 64,
                timestamp=datetime.now(),
                transactions=[self.test_transactions[0]],
                validator="test_validator",
                shard_id=1
            )
            self.assertIsNotNone(single_tx_block.merkle_root)
            self.assertNotEqual(single_tx_block.merkle_root, empty_block.merkle_root)
    
            # Test with multiple transactions
            multi_tx_block = Block(
                index=0,
                previous_hash="0" * 64,
                timestamp=datetime.now(),
                transactions=self.test_transactions[:3],
                validator="test_validator",
                shard_id=1
            )
            self.assertIsNotNone(multi_tx_block.merkle_root)
            self.assertNotEqual(multi_tx_block.merkle_root, single_tx_block.merkle_root)
    
        def test_block_metadata(self):
            """Test block metadata handling."""
            # Add transactions
            for tx in self.test_transactions[:3]:
                self.shard.add_transaction(tx)
    
            # Create block with metadata
            block = self.shard.create_block(validator="test_validator")
            block.metadata["test_key"] = "test_value"
    
            # Verify metadata serialization
            block_dict = block.to_dict()
            restored_block = Block.from_dict(block_dict)
            self.assertEqual(restored_block.metadata["test_key"], "test_value")
    
        def test_sequential_block_creation(self):
            """Test creation of sequential blocks."""
            created_blocks = []
            
            # Create several blocks sequentially
            for i in range(3):
                # Add new transactions
                for tx in self.test_transactions[i*3:(i+1)*3]:
                    self.shard.add_transaction(tx)
                    
                # Create and add block
                block = self.shard.create_block(validator="test_validator")
                self.assertTrue(self.shard.add_block(block))
                created_blocks.append(block)
    
            # Verify block sequence
            for i in range(1, len(created_blocks)):
                self.assertEqual(
                    created_blocks[i].previous_hash,
                    created_blocks[i-1].hash
                )
                self.assertEqual(
                    created_blocks[i].index,
                    created_blocks[i-1].index + 1
                )
                self.assertGreater(
                    created_blocks[i].timestamp,
                    created_blocks[i-1].timestamp
                )
    
        def test_resource_impact_tracking(self):
            """Test tracking of resource impact in blocks."""
            # Add transactions with varying resource impacts
            for tx in self.test_transactions[:3]:
                self.shard.add_transaction(tx)
    
            block = self.shard.create_block(validator="test_validator")
            self.assertIsNotNone(block)
    
            # Calculate total resource impact
            total_computation = sum(tx.resource_cost["computation"] for tx in block.transactions)
            total_storage = sum(tx.resource_cost["storage"] for tx in block.transactions)
            total_bandwidth = sum(tx.resource_cost["bandwidth"] for tx in block.transactions)
    
            # Verify reasonable resource usage
            self.assertGreater(total_computation, 0)
            self.assertGreater(total_storage, 0)
            self.assertGreater(total_bandwidth, 0)
    
        def test_cooperative_score_aggregation(self):
            """Test aggregation of cooperative scores in blocks."""
            # Add transactions with varying cooperative scores
            for tx in self.test_transactions[:3]:
                self.shard.add_transaction(tx)
    
            block = self.shard.create_block(validator="test_validator")
            self.assertIsNotNone(block)
    
            # Calculate total cooperative impact
            total_score = sum(tx.get_cooperative_score() for tx in block.transactions)
            
            # Verify positive cooperative impact
            self.assertGreater(total_score, 0)
            self.assertGreater(total_score, len(block.transactions))  # Should be higher than just count
    
    if __name__ == "__main__":
        unittest.main()
```


# ============================================================
# File: /home/matt/icn-prototype/tests/integration/test_shard_management.py
# Size: 10810 bytes
# Last Modified: Fri Oct 25 14:07:09 2024
# Language: py
# ============================================================

```py
    import unittest
    from datetime import datetime, timedelta
    import sys
    import os
    from typing import List, Dict, Set
    import hashlib
    import json
    import random
    
    # Add project root to Python path
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    sys.path.insert(0, project_root)
    
    from blockchain.core.shard import Shard
    from blockchain.core.transaction import Transaction
    from blockchain.core.block import Block
    from blockchain.core.node import Node
    from blockchain.consensus.proof_of_cooperation import ProofOfCooperation
    
    class TestShardManagement(unittest.TestCase):
        """Integration tests for shard management in the ICN blockchain."""
    
        def setUp(self):
            """Set up test environment before each test."""
            self.main_shard = Shard(shard_id=0, max_transactions_per_block=5)
            self.nodes = self._create_test_nodes()
            self.consensus = ProofOfCooperation()
            self.test_transactions = self._create_test_transactions()
    
        def _create_test_nodes(self, num_nodes: int = 5) -> List[Node]:
            """Create test nodes with varied capabilities."""
            nodes = []
            for i in range(num_nodes):
                node = Node(
                    node_id=f"node_{i}",
                    cooperative_id="test_coop",
                    initial_stake=100.0
                )
                # Vary node capabilities for modular shards
                node.reputation_scores = {
                    "validation": 20.0 + i * 2,
                    "resource_sharing": 20.0 + i * 2,
                    "cooperative_growth": 20.0 + i * 2,
                    "innovation": 20.0 + i * 2
                }
                node.performance_metrics = {
                    "availability": 95.0 + i,
                    "validation_success_rate": 95.0 + i,
                    "network_reliability": 95.0 + i
                }
                node.assign_to_shard(i % 3)  # Modular shard assignment
                nodes.append(node)
            return nodes
    
        def _create_test_transactions(self, num_transactions: int = 10) -> List[Transaction]:
            """Create test transactions with modular shard adaptation."""
            transactions = []
            for i in range(num_transactions):
                tx = Transaction(
                    sender=f"sender_{i}",
                    receiver=f"receiver_{i}",
                    action="transfer",
                    data={"amount": 10.0 * (i + 1)},
                    shard_id=i % 3,  # Adapted for modular shard
                    priority=min(i % 5 + 1, 5),
                    cooperative_tags={f"tag_{i}"}
                )
                transactions.append(tx)
            return transactions
    
        def test_shard_creation_and_initialization(self):
            """Test basic shard creation and initialization."""
            shard = Shard(shard_id=1, max_transactions_per_block=5)
            
            # Verify basic properties
            self.assertEqual(shard.shard_id, 1)
            self.assertEqual(shard.max_transactions_per_block, 5)
            self.assertEqual(shard.height, 1)  # Should start at 1 after genesis
            self.assertTrue(shard.chain)  # Should have genesis block
            
            # Verify genesis block
            genesis = shard.chain[0]
            self.assertEqual(genesis.index, 0)
            self.assertEqual(genesis.previous_hash, "0" * 64)
            self.assertEqual(genesis.validator, "genesis")
            self.assertEqual(genesis.shard_id, 1)
    
        def test_node_shard_assignment(self):
            """Test assigning nodes to shards."""
            shard_1 = Shard(shard_id=1)
            shard_2 = Shard(shard_id=2)
    
            # Assign nodes to shards
            for node in self.nodes[:3]:
                self.assertTrue(node.assign_to_shard(1))
                self.assertIn(1, node.shard_assignments)
    
            for node in self.nodes[2:]:  # Overlapping assignment for node_2
                self.assertTrue(node.assign_to_shard(2))
                self.assertIn(2, node.shard_assignments)
    
            # Verify node can't be assigned to too many shards
            node = self.nodes[0]
            for i in range(5):  # Try to assign to more shards than allowed
                node.assign_to_shard(i)
            self.assertLessEqual(len(node.shard_assignments), 3)
    
        def test_transaction_distribution(self):
            """Test transaction distribution across shards."""
            shards = {i: Shard(shard_id=i) for i in range(3)}
            
            # Add transactions to appropriate shards
            for tx in self.test_transactions:
                shard = shards[tx.shard_id]
                self.assertTrue(shard.add_transaction(tx))
                
            # Verify distribution
            for shard_id, shard in shards.items():
                shard_txs = len(shard.pending_transactions)
                self.assertGreaterEqual(shard_txs, 0)
                self.assertLessEqual(shard_txs, shard.max_transactions_per_block * 2)
    
        def test_cross_shard_transaction_handling(self):
            """Test handling of cross-shard transactions."""
            shard_1 = Shard(shard_id=1)
            shard_2 = Shard(shard_id=2)
    
            # Create cross-shard transaction
            cross_tx = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={
                    "amount": 100.0,
                    "target_shard": 2
                },
                shard_id=1,
                cross_shard_refs=["ref_1"]
            )
    
            # Add to source shard
            self.assertTrue(shard_1.add_transaction(cross_tx))
            
            # Create and verify block with cross-shard transaction
            block = shard_1.create_block("test_validator")
            self.assertIsNotNone(block)
            self.assertTrue(block.cross_shard_refs)
            
            # Verify cross-shard reference tracking
            self.assertIn(2, shard_1.cross_shard_references)
    
        def test_shard_load_balancing(self):
            """Test shard load balancing mechanisms."""
            shards = {i: Shard(shard_id=i) for i in range(3)}
            
            # Add varied load to shards
            for i, tx in enumerate(self.test_transactions):
                # Deliberately overload shard 0
                if i < 5:
                    shards[0].add_transaction(tx)
                else:
                    shard_id = i % 3
                    shards[shard_id].add_transaction(tx)
    
            # Verify load distribution
            load_stats = {
                shard_id: len(shard.pending_transactions) 
                for shard_id, shard in shards.items()
            }
            
            # Check that no shard is overloaded
            for load in load_stats.values():
                self.assertLessEqual(load, Shard.max_transactions_per_block * 2)
    
        def test_shard_state_management(self):
            """Test shard state management and persistence."""
            # Add transactions and create blocks
            for tx in self.test_transactions[:3]:
                self.main_shard.add_transaction(tx)
                
            initial_state = self.main_shard.state.copy()
            
            # Create block
            block = self.main_shard.create_block("test_validator")
            self.assertTrue(self.main_shard.add_block(block))
            
            # Verify state updates
            self.assertNotEqual(self.main_shard.state, initial_state)
            self.assertEqual(self.main_shard.height, 2)  # Genesis + 1
    
            # Test state rollback
            self.main_shard.state = initial_state
            self.assertEqual(self.main_shard.state, initial_state)
    
        def test_shard_synchronization(self):
            """Test synchronization between shards."""
            shard_1 = Shard(shard_id=1)
            shard_2 = Shard(shard_id=2)
    
            # Create cross-shard transaction
            cross_tx = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={
                    "amount": 100.0,
                    "target_shard": 2
                },
                shard_id=1
            )
    
            # Process in source shard
            shard_1.add_transaction(cross_tx)
            block_1 = shard_1.create_block("test_validator")
            shard_1.add_block(block_1)
    
            # Verify target shard can validate cross-shard references
            self.assertIn(2, shard_1.cross_shard_references)
            reference = list(shard_1.cross_shard_references[2])[0]
            self.assertTrue(shard_2.validate_cross_shard_ref(reference))
    
        def test_shard_metrics_and_monitoring(self):
            """Test shard performance metrics and monitoring."""
            # Generate some activity
            for tx in self.test_transactions[:5]:
                self.main_shard.add_transaction(tx)
            
            block = self.main_shard.create_block("test_validator")
            self.main_shard.add_block(block)
    
            # Get metrics
            metrics = self.main_shard.get_metrics()
            
            # Verify metric fields
            self.assertIn("total_transactions", metrics)
            self.assertIn("average_block_time", metrics)
            self.assertIn("pending_count", metrics)
            self.assertIn("chain_size", metrics)
            
            # Verify metric values
            self.assertEqual(metrics["shard_id"], self.main_shard.shard_id)
            self.assertGreater(metrics["total_transactions"], 0)
            self.assertGreaterEqual(metrics["chain_size"], 2)  # Genesis + 1
    
        def test_shard_recovery(self):
            """Test shard recovery from invalid states."""
            # Create some valid state
            for tx in self.test_transactions[:3]:
                self.main_shard.add_transaction(tx)
            
            valid_block = self.main_shard.create_block("test_validator")
            self.main_shard.add_block(valid_block)
            
            # Save valid state
            valid_state = self.main_shard.to_dict()
            
            # Corrupt shard state
            self.main_shard.chain.append("invalid_block")
            self.assertFalse(self.main_shard.validate_chain())
            
            # Recover from valid state
            recovered_shard = Shard.from_dict(valid_state)
            self.assertTrue(recovered_shard.validate_chain())
            self.assertEqual(recovered_shard.height, 2)  # Genesis + 1
    
        def test_shard_consensus_integration(self):
            """Test integration between shard management and consensus."""
            # Assign validators to shard
            validators = self.nodes[:3]
            for node in validators:
                node.assign_to_shard(self.main_shard.shard_id)
    
            # Add transactions
            for tx in self.test_transactions[:3]:
                self.main_shard.add_transaction(tx)
    
            # Select validator and create block
            validator = self.consensus.select_validator(validators, self.main_shard.shard_id)
            self.assertIsNotNone(validator)
            
            block = self.main_shard.create_block(validator.node_id)
            self.assertIsNotNone(block)
            
            # Validate and add block
            self.assertTrue(self.consensus.validate_block(block, self.main_shard.chain[-1], validator))
            self.assertTrue(self.main_shard.add_block(block))
    
    if __name__ == "__main__":
        unittest.main()
```


# ============================================================
# File: /home/matt/icn-prototype/tests/integration/test_transaction_processing.py
# Size: 11207 bytes
# Last Modified: Fri Oct 25 13:27:53 2024
# Language: py
# ============================================================

```py
    import unittest
    from datetime import datetime, timedelta
    import sys
    import os
    from typing import List, Dict, Optional
    import json
    
    # Add project root to Python path
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    sys.path.insert(0, project_root)
    
    from blockchain.core.transaction import Transaction
    from blockchain.core.block import Block
    from blockchain.core.node import Node
    from blockchain.core.blockchain import Blockchain
    from blockchain.consensus.proof_of_cooperation import ProofOfCooperation
    
    class TestTransactionProcessing(unittest.TestCase):
        """Integration tests for transaction processing in the ICN blockchain."""
    
        def setUp(self):
            """Set up test environment before each test."""
            self.test_transactions = self._create_test_transactions()
    
        def _create_test_transactions(self, num_transactions: int = 5) -> List[Transaction]:
            """Create test transactions with varied characteristics."""
            transactions = []
            for i in range(num_transactions):
                tx = Transaction(
                    sender=f"sender_{i}",
                    receiver=f"receiver_{i}",
                    action="transfer",
                    data={"amount": 10.0 * (i + 1)},
                    shard_id=i % 3,  # Use fixed number of shards for testing
                    priority=min(i + 1, 5),
                    cooperative_tags={f"tag_{i}"},
                    cross_shard_refs=[f"ref_{j}" for j in range(i % 3)]
                )
                transactions.append(tx)
            return transactions
    
        def test_transaction_creation_and_validation(self):
            """Test basic transaction creation and validation."""
            # Test valid transaction
            tx = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={"amount": 100.0},
                shard_id=0,
                priority=1
            )
            self.assertTrue(tx.validate())
            self.assertIsNotNone(tx.transaction_id)
    
            # Test invalid action
            with self.assertRaises(ValueError):
                Transaction(
                    sender="user1",
                    receiver="user2",
                    action="invalid_action",
                    data={"amount": 100.0},
                    shard_id=0
                )
    
            # Test invalid priority
            with self.assertRaises(ValueError):
                Transaction(
                    sender="user1",
                    receiver="user2",
                    action="transfer",
                    data={"amount": 100.0},
                    shard_id=0,
                    priority=10  # Invalid priority
                )
    
        def test_transaction_data_limits(self):
            """Test transaction data size limits."""
            # Test transaction with data at limit
            large_data = {"data": "x" * (Transaction.MAX_DATA_SIZE - 100)}  # Leave room for other fields
            tx = Transaction(
                sender="user1",
                receiver="user2",
                action="store",
                data=large_data,
                shard_id=0
            )
            self.assertTrue(tx.validate())
    
            # Test transaction exceeding data limit
            too_large_data = {"data": "x" * (Transaction.MAX_DATA_SIZE + 1000)}
            tx = Transaction(
                sender="user1",
                receiver="user2",
                action="store",
                data=too_large_data,
                shard_id=0
            )
            self.assertFalse(tx.validate())
    
        def test_cross_shard_functionality(self):
            """Test cross-shard transaction handling."""
            # Create cross-shard transaction
            tx = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={
                    "amount": 100.0,
                    "target_shard": 1
                },
                shard_id=0,
                cross_shard_refs=["ref_1", "ref_2"]
            )
    
            # Test cross-shard detection
            self.assertTrue(tx.is_cross_shard())
            self.assertEqual(tx.get_target_shards(), {0, 1})
    
            # Test cross-shard reference limit
            tx_many_refs = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={"amount": 100.0},
                shard_id=0,
                cross_shard_refs=["ref_" + str(i) for i in range(Transaction.MAX_CROSS_SHARD_REFS + 1)]
            )
            self.assertFalse(tx_many_refs.validate())
    
        def test_resource_cost_calculation(self):
            """Test resource cost calculation."""
            # Test basic resource cost
            tx = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={"amount": 100.0},
                shard_id=0
            )
            self.assertGreater(tx.get_resource_impact(), 0)
            
            # Test increased cost with large data
            large_data = {"data": "x" * 10000}
            tx_large = Transaction(
                sender="user1",
                receiver="user2",
                action="store",
                data=large_data,
                shard_id=0
            )
            self.assertGreater(tx_large.get_resource_impact(), tx.get_resource_impact())
    
            # Test cross-shard overhead
            tx_cross_shard = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={"amount": 100.0},
                shard_id=0,
                cross_shard_refs=["ref_1", "ref_2"]
            )
            self.assertGreater(tx_cross_shard.get_resource_impact(), tx.get_resource_impact())
    
        def test_cooperative_score(self):
            """Test cooperative score calculation."""
            # Basic transaction
            tx_basic = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={"amount": 100.0},
                shard_id=0
            )
            base_score = tx_basic.get_cooperative_score()
    
            # Transaction with cooperative tags
            tx_cooperative = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={"amount": 100.0},
                shard_id=0,
                cooperative_tags={"sharing", "community"}
            )
            self.assertGreater(tx_cooperative.get_cooperative_score(), base_score)
    
            # Cross-shard transaction
            tx_cross_shard = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={"amount": 100.0, "target_shard": 1},
                shard_id=0
            )
            self.assertGreater(tx_cross_shard.get_cooperative_score(), base_score)
    
        def test_serialization(self):
            """Test transaction serialization and deserialization."""
            original_tx = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={"amount": 100.0},
                shard_id=0,
                priority=2,
                cooperative_tags={"tag1", "tag2"},
                cross_shard_refs=["ref_1"]
            )
    
            # Convert to dictionary
            tx_dict = original_tx.to_dict()
    
            # Create new transaction from dictionary
            restored_tx = Transaction.from_dict(tx_dict)
    
            # Verify all attributes match
            self.assertEqual(restored_tx.transaction_id, original_tx.transaction_id)
            self.assertEqual(restored_tx.sender, original_tx.sender)
            self.assertEqual(restored_tx.receiver, original_tx.receiver)
            self.assertEqual(restored_tx.action, original_tx.action)
            self.assertEqual(restored_tx.data, original_tx.data)
            self.assertEqual(restored_tx.shard_id, original_tx.shard_id)
            self.assertEqual(restored_tx.priority, original_tx.priority)
            self.assertEqual(restored_tx.cooperative_tags, original_tx.cooperative_tags)
            self.assertEqual(restored_tx.cross_shard_refs, original_tx.cross_shard_refs)
    
        def test_metadata_handling(self):
            """Test transaction metadata handling."""
            tx = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={"amount": 100.0},
                shard_id=0
            )
    
            # Verify required metadata fields
            self.assertIn("created_at", tx.metadata)
            self.assertIn("data_size", tx.metadata)
            self.assertIn("version", tx.metadata)
    
            # Verify metadata persistence through serialization
            tx_dict = tx.to_dict()
            restored_tx = Transaction.from_dict(tx_dict)
            
            # Compare metadata fields individually, ignoring timestamp precision
            self.assertEqual(
                tx.metadata["data_size"], 
                restored_tx.metadata["data_size"]
            )
            self.assertEqual(
                tx.metadata["version"], 
                restored_tx.metadata["version"]
            )
            
            # For timestamp, verify format and rough equality
            original_time = datetime.fromisoformat(tx.metadata["created_at"])
            restored_time = datetime.fromisoformat(restored_tx.metadata["created_at"])
            
            # Should be within 1 second of each other
            self.assertLess(
                abs((original_time - restored_time).total_seconds()),
                1.0
            )
            
        def test_timestamp_validation(self):
            """Test transaction timestamp validation."""
            # Current timestamp should be valid
            tx_current = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={"amount": 100.0},
                shard_id=0,
                timestamp=datetime.now()
            )
            self.assertTrue(tx_current.validate())
    
            # Future timestamp should be invalid
            tx_future = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={"amount": 100.0},
                shard_id=0,
                timestamp=datetime.now() + timedelta(minutes=10)
            )
            self.assertFalse(tx_future.validate())
    
            # Old timestamp should be invalid
            tx_old = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={"amount": 100.0},
                shard_id=0,
                timestamp=datetime.now() - timedelta(days=2)
            )
            self.assertFalse(tx_old.validate())
    
        def test_transaction_ordering(self):
            """Test transaction ordering by priority."""
            # Create transactions with different priorities
            transactions = []
            for i in range(1, 6):
                tx = Transaction(
                    sender=f"user{i}",
                    receiver=f"user{i+1}",
                    action="transfer",
                    data={"amount": 100.0},
                    shard_id=0,
                    priority=i
                )
                transactions.append(tx)
    
            # Shuffle and sort by priority
            import random
            random.shuffle(transactions)
            sorted_transactions = sorted(transactions, key=lambda x: x.priority, reverse=True)
    
            # Verify order
            for i in range(len(sorted_transactions) - 1):
                self.assertGreaterEqual(
                    sorted_transactions[i].priority,
                    sorted_transactions[i + 1].priority
                )
    
    if __name__ == "__main__":
        unittest.main()
```


# ============================================================
# File: /home/matt/icn-prototype/tests/integration/test_smart_contract_execution.py
# Size: 13339 bytes
# Last Modified: Fri Oct 25 13:35:57 2024
# Language: py
# ============================================================

```py
    import unittest
    from datetime import datetime, timedelta
    import sys
    import os
    from typing import List, Dict, Optional
    import asyncio
    import json
    import hashlib
    
    # Add project root to Python path
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    sys.path.insert(0, project_root)
    
    from blockchain.contracts.smart_contract import SmartContract, ContractExecutionError
    from blockchain.contracts.contract_executor import ContractExecutor
    from blockchain.core.node import Node
    from blockchain.core.shard import Shard
    
    class TestSmartContractExecution(unittest.TestCase):
        """Integration tests for smart contract execution in the ICN blockchain."""
    
        def setUp(self):
            """Set up test environment before each test."""
            self.executor = ContractExecutor(initial_mana=1000)
            self.test_node = self._create_test_node()
            
            # Basic test contract for reuse
            self.basic_contract = self._create_test_contract("basic_contract")
            
            # Set up async event loop
            self.loop = asyncio.new_event_loop()
            asyncio.set_event_loop(self.loop)
    
        def tearDown(self):
            """Clean up after tests."""
            self.loop.close()
    
        def _create_test_node(self) -> Node:
            """Create a test node for contract interactions."""
            node = Node(
                node_id="test_node",
                cooperative_id="test_coop",
                initial_stake=100.0
            )
            node.reputation_scores = {
                "validation": 25.0,
                "resource_sharing": 25.0,
                "cooperative_growth": 25.0,
                "innovation": 25.0
            }
            return node
    
        def _create_test_contract(self, contract_id: str, mana_cost: int = 10) -> SmartContract:
            """Create a test smart contract."""
            code = """
    def execute(input_data, state):
        # Initialize state if needed
        if 'count' not in state:
            state['count'] = 0
        if 'values' not in state:
            state['values'] = []
            
        # Process input
        value = input_data.get('value', 0)
        operation = input_data.get('operation', 'add')
        
        if operation == 'add':
            state['values'].append(value)
            state['count'] += 1
            return {'result': value, 'count': state['count']}
        elif operation == 'sum':
            total = sum(state['values'])
            return {'result': total, 'count': state['count']}
        elif operation == 'clear':
            state['values'] = []
            state['count'] = 0
            return {'result': None, 'count': 0}
        else:
            raise ValueError(f"Unknown operation: {operation}")
    """
            return SmartContract(
                contract_id=contract_id,
                code=code,
                creator="test_creator",
                mana_cost=mana_cost
            )
    
        async def test_basic_contract_execution(self):
            """Test basic contract deployment and execution."""
            # Deploy contract
            success = await self.executor.deploy_contract(self.basic_contract)
            self.assertTrue(success)
    
            # Execute contract with different operations
            result = await self.executor.execute_contract(
                self.basic_contract.contract_id,
                {"value": 42, "operation": "add"},
                "test_creator"
            )
            self.assertEqual(result["result"]["result"], 42)
            self.assertEqual(result["result"]["count"], 1)
    
            result = await self.executor.execute_contract(
                self.basic_contract.contract_id,
                {"value": 58, "operation": "add"},
                "test_creator"
            )
            self.assertEqual(result["result"]["count"], 2)
    
            result = await self.executor.execute_contract(
                self.basic_contract.contract_id,
                {"operation": "sum"},
                "test_creator"
            )
            self.assertEqual(result["result"]["result"], 100)
    
        async def test_mana_consumption(self):
            """Test mana consumption and regeneration."""
            initial_mana = self.executor.mana_pool
    
            # Deploy and execute contract
            await self.executor.deploy_contract(self.basic_contract)
            result = await self.executor.execute_contract(
                self.basic_contract.contract_id,
                {"value": 42, "operation": "add"},
                "test_creator"
            )
    
            # Verify mana consumption
            self.assertEqual(
                self.executor.mana_pool,
                initial_mana - self.basic_contract.mana_cost
            )
    
            # Test mana regeneration
            await self.executor.regenerate_mana()
            self.assertGreater(self.executor.mana_pool, initial_mana - self.basic_contract.mana_cost)
    
        async def test_state_persistence(self):
            """Test contract state persistence across executions."""
            await self.executor.deploy_contract(self.basic_contract)
    
            # Add values
            for i in range(3):
                await self.executor.execute_contract(
                    self.basic_contract.contract_id,
                    {"value": i * 10, "operation": "add"},
                    "test_creator"
                )
    
            # Verify state
            result = await self.executor.execute_contract(
                self.basic_contract.contract_id,
                {"operation": "sum"},
                "test_creator"
            )
            self.assertEqual(result["result"]["result"], 30)  # 0 + 10 + 20
            self.assertEqual(result["result"]["count"], 3)
    
            # Clear state
            result = await self.executor.execute_contract(
                self.basic_contract.contract_id,
                {"operation": "clear"},
                "test_creator"
            )
            self.assertEqual(result["result"]["count"], 0)
    
        async def test_concurrent_execution(self):
            """Test concurrent contract execution."""
            await self.executor.deploy_contract(self.basic_contract)
    
            # Create multiple execution tasks
            tasks = []
            for i in range(5):
                task = self.executor.execute_contract(
                    self.basic_contract.contract_id,
                    {"value": i * 10, "operation": "add"},
                    "test_creator"
                )
                tasks.append(task)
    
            # Execute concurrently
            results = await asyncio.gather(*tasks)
            
            # Verify results
            self.assertEqual(len(results), 5)
            
            # Verify final state
            sum_result = await self.executor.execute_contract(
                self.basic_contract.contract_id,
                {"operation": "sum"},
                "test_creator"
            )
            self.assertEqual(sum_result["result"]["result"], 100)  # 0 + 10 + 20 + 30 + 40
    
        async def test_error_handling(self):
            """Test contract error handling."""
            await self.executor.deploy_contract(self.basic_contract)
    
            # Test invalid operation
            with self.assertRaises(ContractExecutionError):
                await self.executor.execute_contract(
                    self.basic_contract.contract_id,
                    {"operation": "invalid_op"},
                    "test_creator"
                )
    
            # Test insufficient mana
            expensive_contract = self._create_test_contract("expensive", mana_cost=2000)
            await self.executor.deploy_contract(expensive_contract)
            
            with self.assertRaises(ContractExecutionError):
                await self.executor.execute_contract(
                    expensive_contract.contract_id,
                    {"value": 1, "operation": "add"},
                    "test_creator"
                )
    
        async def test_resource_limits(self):
            """Test contract resource limits."""
            # Create contract that tests limits
            resource_heavy_code = """
    def execute(input_data, state):
        # Test memory limit
        if input_data.get('test_memory', False):
            big_list = list(range(1000000))  # Should exceed memory limit
            
        # Test computation limit
        if input_data.get('test_computation', False):
            n = 100
            result = [[i*j for j in range(n)] for i in range(n)]
            
        return {"status": "completed"}
    """
            resource_contract = SmartContract(
                contract_id="resource_test",
                code=resource_heavy_code,
                creator="test_creator",
                mana_cost=20
            )
    
            await self.executor.deploy_contract(resource_contract)
    
            # Test memory limit
            with self.assertRaises(ContractExecutionError):
                await self.executor.execute_contract(
                    resource_contract.contract_id,
                    {"test_memory": True},
                    "test_creator"
                )
    
            # Test computation limit
            with self.assertRaises(ContractExecutionError):
                await self.executor.execute_contract(
                    resource_contract.contract_id,
                    {"test_computation": True},
                    "test_creator"
                )
    
        async def test_cooperative_features(self):
            """Test cooperative aspects of contract execution."""
            # Create contract with cooperative features
            coop_code = """
    def execute(input_data, state):
        if 'shared_resources' not in state:
            state['shared_resources'] = {}
        
        action = input_data.get('action')
        resource = input_data.get('resource')
        amount = input_data.get('amount', 0)
        
        if action == 'share':
            if resource not in state['shared_resources']:
                state['shared_resources'][resource] = 0
            state['shared_resources'][resource] += amount
            return {
                'status': 'shared',
                'resource': resource,
                'total': state['shared_resources'][resource]
            }
        elif action == 'use':
            if resource not in state['shared_resources']:
                raise ValueError(f"Resource {resource} not available")
            if state['shared_resources'][resource] < amount:
                raise ValueError(f"Insufficient {resource}")
            state['shared_resources'][resource] -= amount
            return {
                'status': 'used',
                'resource': resource,
                'remaining': state['shared_resources'][resource]
            }
                
        return {'status': 'error', 'message': 'Invalid action'}
    """
            coop_contract = SmartContract(
                contract_id="cooperative_test",
                code=coop_code,
                creator="test_creator",
                mana_cost=15
            )
    
            await self.executor.deploy_contract(coop_contract)
    
            # Test resource sharing
            result = await self.executor.execute_contract(
                coop_contract.contract_id,
                {
                    "action": "share",
                    "resource": "cpu_time",
                    "amount": 100
                },
                "test_creator"
            )
            self.assertEqual(result["result"]["total"], 100)
    
            # Test resource usage
            result = await self.executor.execute_contract(
                coop_contract.contract_id,
                {
                    "action": "use",
                    "resource": "cpu_time",
                    "amount": 30
                },
                "test_creator"
            )
            self.assertEqual(result["result"]["remaining"], 70)
    
            # Test insufficient resources
            with self.assertRaises(ContractExecutionError):
                await self.executor.execute_contract(
                    coop_contract.contract_id,
                    {
                        "action": "use",
                        "resource": "cpu_time",
                        "amount": 100
                    },
                    "test_creator"
                )
    
        def test_contract_metrics(self):
            """Test contract execution metrics tracking."""
            async def run_metrics_test():
                await self.executor.deploy_contract(self.basic_contract)
    
                # Execute contract multiple times
                for i in range(5):
                    await self.executor.execute_contract(
                        self.basic_contract.contract_id,
                        {"value": i, "operation": "add"},
                        "test_creator"
                    )
    
                # Get metrics
                metrics = self.basic_contract.get_metrics()
                
                # Verify metrics
                self.assertEqual(metrics["execution_count"], 5)
                self.assertGreater(metrics["total_mana_consumed"], 0)
                self.assertIsNotNone(metrics["last_executed"])
                self.assertGreater(metrics["state_size"], 0)
    
            self.loop.run_until_complete(run_metrics_test())
    
        def test_contract_authorization(self):
            """Test contract authorization controls."""
            async def run_auth_test():
                await self.executor.deploy_contract(self.basic_contract)
    
                # Test unauthorized execution
                with self.assertRaises(ContractExecutionError):
                    await self.executor.execute_contract(
                        self.basic_contract.contract_id,
                        {"value": 1, "operation": "add"},
                        "unauthorized_user"
                    )
    
                # Add authorized user
                self.basic_contract.authorize_caller("new_user")
                
                # Test authorized execution
                result = await self.executor.execute_contract(
                    self.basic_contract.contract_id,
                    {"value": 1, "operation": "add"},
                    "new_user"
                )
                self.assertIsNotNone(result)
    
            self.loop.run_until_complete(run_auth_test())
    
    if __name__ == "__main__":
        unittest.main()
```


# ============================================================
# File: /home/matt/icn-prototype/tests/integration/__init__.py
# Size: 0 bytes
# Last Modified: Wed Oct 23 19:46:07 2024
# Language: py
# ============================================================

```py

```


# ============================================================
# File: /home/matt/icn-prototype/tests/performance/test_scalability.py
# Size: 10845 bytes
# Last Modified: Sat Oct 26 00:27:39 2024
# Language: py
# ============================================================

```py
    import unittest
    import sys
    import os
    import random
    from typing import List
    import time
    import tqdm
    from contextlib import contextmanager
    import psutil
    import gc
    import logging
    
    # Add project root to Python path
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    sys.path.insert(0, project_root)
    
    from blockchain.core.shard import Shard, ShardConfig
    from blockchain.core.transaction import Transaction
    from blockchain.core.node import Node
    from blockchain.consensus.proof_of_cooperation import ProofOfCooperation
    
    # Configure logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    class TestScalability(unittest.TestCase):
        """Test scalability characteristics of the ICN blockchain."""
    
        TIMEOUT_TRANSACTION_TEST = 30
        TIMEOUT_SHARD_TEST = 30
        TIMEOUT_CROSS_SHARD_TEST = 30
        MAX_MEMORY_PERCENT = 80  # Max memory usage threshold
        MAX_RETRIES = 1000  # Max retry limit for block creation
    
        def setUp(self):
            """Set up test environment."""
            logger.info("Setting up scalability test environment...")
            self.config = ShardConfig(
                max_transactions_per_block=100,
                max_pending_transactions=500,
                max_cross_shard_refs=10
            )
            self.shards = [Shard(shard_id=i, config=self.config) for i in range(3)]
            self.nodes = self._create_test_nodes(6)
            self.consensus = ProofOfCooperation()
            logger.info("Setup complete.")
    
        def tearDown(self):
            """Clean up after each test."""
            self.shards = None
            self.nodes = None
            self.consensus = None
            gc.collect()
    
        def _create_test_nodes(self, num_nodes: int) -> List[Node]:
            """Create test nodes with varied capabilities."""
            nodes = []
            for i in range(num_nodes):
                node = Node(
                    node_id=f"node_{i}",
                    cooperative_id=f"coop_{i % 2}",
                    initial_stake=100.0
                )
                node.reputation_scores = {
                    "validation": 20.0 + i,
                    "resource_sharing": 20.0 + i * 0.5,
                    "cooperative_growth": 20.0 + i * 0.3,
                    "innovation": 20.0 + i * 0.2
                }
                shard_id = i % len(self.shards)
                node.assign_to_shard(shard_id)
                nodes.append(node)
            return nodes
    
        def _check_memory_usage(self):
            """Check current memory usage and raise exception if too high."""
            process = psutil.Process(os.getpid())
            memory_percent = process.memory_percent()
            if memory_percent > self.MAX_MEMORY_PERCENT:
                raise MemoryError(f"Memory usage too high: {memory_percent:.1f}%")
            return memory_percent
    
        @contextmanager
        def timeout(self, seconds, test_name):
            """Context manager for test timeouts."""
            start_time = time.time()
            try:
                yield
            finally:
                elapsed_time = time.time() - start_time
                if elapsed_time > seconds:
                    logger.warning(f"{test_name} timed out after {seconds} seconds")
                else:
                    logger.info(f"{test_name} completed in {elapsed_time:.2f} seconds")
    
        def _process_transactions(self, transactions: List[Transaction], batch_size: int):
            """Process transactions in batches with memory checks."""
            with tqdm.tqdm(total=len(transactions), desc="Processing Transactions", leave=True, dynamic_ncols=True) as progress_bar:
                for i in range(0, len(transactions), batch_size):
                    batch = transactions[i:i + batch_size]
                    for tx in batch:
                        shard_id = tx.shard_id
                        self.shards[shard_id].add_transaction(tx)
                    self._check_memory_usage()
                    progress_bar.update(len(batch))
                    gc.collect()
    
        def _create_and_add_blocks(self, shard, validators):
            """Create and add blocks until no pending transactions remain."""
            retry_count = 0
            while shard.pending_transactions and retry_count < self.MAX_RETRIES:
                validator = self.consensus.select_validator(validators)
                if validator:
                    block = shard.create_block(validator.node_id)
                    if block:
                        shard.add_block(block)
                retry_count += 1
                gc.collect()
            if retry_count == self.MAX_RETRIES:
                logger.warning(f"Max retries reached for shard {shard.shard_id}, some transactions may remain unprocessed.")
    
        def test_transaction_throughput_scaling(self):
            """Test how transaction throughput scales with increasing load."""
            logger.info("\nTesting transaction throughput scaling...")
            transaction_counts = [50, 100, 200]
            results = {}
    
            for count in transaction_counts:
                logger.info(f"\nProcessing {count} transactions...")
                transactions = self._generate_test_transactions(count)
    
                with self.timeout(self.TIMEOUT_TRANSACTION_TEST, f"Transaction test (count: {count})"):
                    start_time = time.time()
                    self._process_transactions(transactions, batch_size=10)
    
                    for shard in self.shards:
                        validators = [n for n in self.nodes if shard.shard_id in n.shard_assignments]
                        self._create_and_add_blocks(shard, validators)
    
                    elapsed_time = time.time() - start_time
                    transactions_per_second = count / elapsed_time
                    results[count] = {
                        "elapsed_time": elapsed_time,
                        "tps": transactions_per_second
                    }
                    logger.info(f"Completed {count} transactions at {transactions_per_second:.2f} TPS")
    
            for i in range(len(transaction_counts) - 1):
                count_ratio = transaction_counts[i + 1] / transaction_counts[i]
                time_ratio = results[transaction_counts[i + 1]]["elapsed_time"] / results[transaction_counts[i]]["elapsed_time"]
                self.assertLess(time_ratio, count_ratio * 1.5)
    
        def test_shard_scaling(self):
            """Test how system performance scales with number of shards."""
            logger.info("\nTesting shard scaling...")
            transaction_count = 100
            shard_counts = [1, 2, 4]
            results = {}
    
            base_transactions = self._generate_test_transactions(transaction_count)
    
            for shard_count in shard_counts:
                logger.info(f"\nTesting with {shard_count} shards...")
                test_shards = [Shard(shard_id=i, config=self.config) for i in range(shard_count)]
                test_nodes = self._create_test_nodes(shard_count * 2)
    
                with self.timeout(self.TIMEOUT_SHARD_TEST, f"Shard test (count: {shard_count})"):
                    start_time = time.time()
    
                    self._process_transactions(base_transactions, batch_size=10)
    
                    for shard in test_shards:
                        validators = [n for n in test_nodes if shard.shard_id in n.shard_assignments]
                        self._create_and_add_blocks(shard, validators)
    
                    elapsed_time = time.time() - start_time
                    results[shard_count] = {
                        "elapsed_time": elapsed_time,
                        "tps": transaction_count / elapsed_time
                    }
                    logger.info(f"Completed test with {shard_count} shards at {transaction_count / elapsed_time:.2f} TPS")
    
            for i in range(len(shard_counts) - 1):
                shard_ratio = shard_counts[i + 1] / shard_counts[i]
                speedup = results[shard_counts[i]]["elapsed_time"] / results[shard_counts[i + 1]]["elapsed_time"]
                expected_speedup = shard_ratio * 0.4
                if speedup < expected_speedup:
                    logger.warning(f"Speedup of {speedup:.2f} is less than expected ({expected_speedup:.2f})")
                self.assertGreater(speedup, expected_speedup)
    
        def test_cross_shard_scalability(self):
            """Test scalability of cross-shard transactions."""
            logger.info("\nTesting cross-shard scalability...")
            transaction_count = 100
            cross_shard_percentages = [0, 20, 40]
            results = {}
    
            for percentage in cross_shard_percentages:
                logger.info(f"\nTesting with {percentage}% cross-shard transactions...")
                transactions = self._generate_test_transactions(transaction_count, cross_shard_percentage=percentage)
    
                with self.timeout(self.TIMEOUT_CROSS_SHARD_TEST, f"Cross-shard test (percentage: {percentage}%)"):
                    start_time = time.time()
                    self._process_transactions(transactions, batch_size=10)
    
                    for shard in self.shards:
                        validators = [n for n in self.nodes if shard.shard_id in n.shard_assignments]
                        self._create_and_add_blocks(shard, validators)
    
                    elapsed_time = time.time() - start_time
                    transactions_per_second = transaction_count / elapsed_time
                    results[percentage] = {
                        "elapsed_time": elapsed_time,
                        "tps": transactions_per_second
                    }
                    logger.info(f"Completed {percentage}% cross-shard test at {transactions_per_second:.2f} TPS")
    
            base_time = results[0]["elapsed_time"]
            for percentage in cross_shard_percentages[1:]:
                self.assertLess(results[percentage]["elapsed_time"] / base_time, 3.0)
    
        def _generate_test_transactions(self, count: int, cross_shard_percentage: int = 0) -> List[Transaction]:
            """Generate test transactions with specified cross-shard percentage."""
            transactions = []
            for i in range(count):
                is_cross_shard = random.randint(1, 100) <= cross_shard_percentage
    
                shard_id = random.randint(0, len(self.shards) - 1)
                target_shard = None
                cross_shard_refs = []
    
                if is_cross_shard:
                    target_shard = random.randint(0, len(self.shards) - 1)
                    while target_shard == shard_id:
                        target_shard = random.randint(0, len(self.shards) - 1)
                    cross_shard_refs = [f"ref_{i}"]
    
                tx = Transaction(
                    sender=f"sender_{i}",
                    receiver=f"receiver_{i}",
                    action="transfer",
                    data={
                        "amount": random.uniform(1, 100),
                        "target_shard": target_shard
                    } if is_cross_shard else {
                        "amount": random.uniform(1, 100)
                    },
                    shard_id=shard_id,
                    priority=random.randint(1, 5),
                    cross_shard_refs=cross_shard_refs
                )
                transactions.append(tx)
    
            return transactions
    
    if __name__ == '__main__':
        unittest.main(verbosity=2)
```


# ============================================================
# File: /home/matt/icn-prototype/tests/performance/test_stress_resilience.py
# Size: 12792 bytes
# Last Modified: Fri Oct 25 23:28:34 2024
# Language: py
# ============================================================

```py
    # tests/performance/test_scalability.py
    
    import unittest
    from datetime import datetime, timedelta
    import sys
    import os
    import random
    from typing import List, Dict
    import time
    import tqdm
    from contextlib import contextmanager
    
    # Add project root to Python path
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    sys.path.insert(0, project_root)
    
    from blockchain.core.shard import Shard, ShardConfig
    from blockchain.core.transaction import Transaction
    from blockchain.core.block import Block
    from blockchain.core.node import Node
    from blockchain.consensus.proof_of_cooperation import ProofOfCooperation
    
    class TestScalability(unittest.TestCase):
        """Test scalability characteristics of the ICN blockchain."""
        
        # Maximum time for each test in seconds
        TIMEOUT_TRANSACTION_TEST = 60
        TIMEOUT_SHARD_TEST = 60
        TIMEOUT_CROSS_SHARD_TEST = 60
    
        def setUp(self):
            """Set up test environment."""
            print("\nSetting up scalability test environment...")
            self.config = ShardConfig(
                max_transactions_per_block=1000,
                max_pending_transactions=5000,
                max_cross_shard_refs=100
            )
            self.shards = [Shard(shard_id=i, config=self.config) for i in range(5)]
            self.nodes = self._create_test_nodes(20)  # 20 nodes across shards
            self.consensus = ProofOfCooperation()
            print("Setup complete.")
    
        def _create_test_nodes(self, num_nodes: int) -> List[Node]:
            """Create test nodes with varied capabilities."""
            nodes = []
            for i in range(num_nodes):
                node = Node(
                    node_id=f"node_{i}",
                    cooperative_id=f"coop_{i % 3}",  # Distribute across 3 cooperatives
                    initial_stake=100.0
                )
                # Vary node capabilities
                node.reputation_scores = {
                    "validation": 20.0 + i,
                    "resource_sharing": 20.0 + i * 0.5,
                    "cooperative_growth": 20.0 + i * 0.3,
                    "innovation": 20.0 + i * 0.2
                }
                # Assign to random shard
                shard_id = random.randint(0, len(self.shards) - 1)
                node.assign_to_shard(shard_id)
                nodes.append(node)
            return nodes
    
        @contextmanager
        def timeout(self, seconds, test_name):
            """Context manager for test timeouts with progress bar."""
            start_time = time.time()
            progress_bar = tqdm.tqdm(total=seconds, desc=f"Running {test_name}", 
                                    unit="s", leave=True)
    
            def update_progress():
                elapsed = int(time.time() - start_time)
                if elapsed <= seconds:
                    progress_bar.n = elapsed
                    progress_bar.refresh()
    
            try:
                while True:
                    if time.time() - start_time > seconds:
                        raise TimeoutError(f"Test {test_name} timed out after {seconds} seconds")
                    update_progress()
                    yield
                    break
            finally:
                progress_bar.close()
    
        def test_transaction_throughput_scaling(self):
            """Test how transaction throughput scales with increasing load."""
            print("\nTesting transaction throughput scaling...")
            transaction_counts = [100, 500, 1000]  # Reduced counts for faster testing
            results = {}
    
            for count in transaction_counts:
                print(f"\nProcessing {count} transactions...")
                with self.timeout(self.TIMEOUT_TRANSACTION_TEST, f"Transaction test (count: {count})"):
                    # Generate test transactions
                    transactions = self._generate_test_transactions(count)
                    
                    # Measure processing time
                    start_time = time.time()
                    
                    # Process transactions with progress bar
                    for tx in tqdm.tqdm(transactions, desc="Adding transactions", leave=False):
                        shard_id = tx.shard_id
                        self.shards[shard_id].add_transaction(tx)
    
                    # Process blocks with progress bar
                    pending_blocks = True
                    while pending_blocks:
                        pending_blocks = False
                        for shard in self.shards:
                            if len(shard.pending_transactions) > 0:
                                pending_blocks = True
                                validator = self.consensus.select_validator(
                                    [n for n in self.nodes if shard.shard_id in n.shard_assignments]
                                )
                                if validator:
                                    block = shard.create_block(validator.node_id)
                                    if block:
                                        shard.add_block(block)
    
                    elapsed_time = time.time() - start_time
                    transactions_per_second = count / elapsed_time
                    
                    results[count] = {
                        "elapsed_time": elapsed_time,
                        "tps": transactions_per_second
                    }
                    print(f"Completed {count} transactions at {transactions_per_second:.2f} TPS")
    
            # Verify scaling characteristics
            for i in range(len(transaction_counts) - 1):
                count_ratio = transaction_counts[i + 1] / transaction_counts[i]
                time_ratio = results[transaction_counts[i + 1]]["elapsed_time"] / \
                            results[transaction_counts[i]]["elapsed_time"]
                
                # Time increase should be less than proportional to transaction increase
                self.assertLess(time_ratio, count_ratio * 1.5)
    
        def test_shard_scaling(self):
            """Test how system performance scales with number of shards."""
            print("\nTesting shard scaling...")
            transaction_count = 500  # Reduced for faster testing
            shard_counts = [1, 2, 4]  # Reduced counts for faster testing
            results = {}
    
            base_transactions = self._generate_test_transactions(transaction_count)
    
            for shard_count in shard_counts:
                print(f"\nTesting with {shard_count} shards...")
                with self.timeout(self.TIMEOUT_SHARD_TEST, f"Shard test (count: {shard_count})"):
                    test_shards = [Shard(shard_id=i, config=self.config) 
                                  for i in range(shard_count)]
                    test_nodes = self._create_test_nodes(shard_count * 4)
                    
                    start_time = time.time()
                    
                    # Process transactions with progress bar
                    for tx in tqdm.tqdm(base_transactions, desc="Processing transactions", leave=False):
                        tx.shard_id = random.randint(0, shard_count - 1)
                        test_shards[tx.shard_id].add_transaction(tx)
    
                    # Process blocks
                    pending_blocks = True
                    with tqdm.tqdm(desc="Processing blocks", leave=False) as pbar:
                        while pending_blocks:
                            pending_blocks = False
                            for shard in test_shards:
                                if len(shard.pending_transactions) > 0:
                                    pending_blocks = True
                                    validator = self.consensus.select_validator(
                                        [n for n in test_nodes if shard.shard_id in n.shard_assignments]
                                    )
                                    if validator:
                                        block = shard.create_block(validator.node_id)
                                        if block:
                                            shard.add_block(block)
                            pbar.update(1)
    
                    elapsed_time = time.time() - start_time
                    results[shard_count] = {
                        "elapsed_time": elapsed_time,
                        "tps": transaction_count / elapsed_time
                    }
                    print(f"Completed test with {shard_count} shards at {transaction_count / elapsed_time:.2f} TPS")
    
            # Verify scaling efficiency
            for i in range(len(shard_counts) - 1):
                shard_ratio = shard_counts[i + 1] / shard_counts[i]
                speedup = results[shard_counts[i]]["elapsed_time"] / \
                         results[shard_counts[i + 1]]["elapsed_time"]
                
                # Should achieve at least 50% of perfect linear speedup
                self.assertGreater(speedup, shard_ratio * 0.5)
    
        def test_cross_shard_scalability(self):
            """Test scalability of cross-shard transactions."""
            print("\nTesting cross-shard scalability...")
            transaction_count = 500  # Reduced for faster testing
            cross_shard_percentages = [0, 20, 50]  # Reduced for faster testing
            results = {}
    
            for percentage in cross_shard_percentages:
                print(f"\nTesting with {percentage}% cross-shard transactions...")
                with self.timeout(self.TIMEOUT_CROSS_SHARD_TEST, 
                                f"Cross-shard test (percentage: {percentage}%)"):
                    transactions = self._generate_test_transactions(
                        transaction_count, 
                        cross_shard_percentage=percentage
                    )
                    
                    start_time = time.time()
                    
                    # Process transactions with progress bar
                    for tx in tqdm.tqdm(transactions, desc="Processing transactions", leave=False):
                        shard_id = tx.shard_id
                        self.shards[shard_id].add_transaction(tx)
    
                    # Process blocks
                    pending_shards = set(range(len(self.shards)))
                    with tqdm.tqdm(desc="Processing blocks", leave=False) as pbar:
                        while pending_shards:
                            for shard_id in list(pending_shards):
                                shard = self.shards[shard_id]
                                if not shard.pending_transactions:
                                    pending_shards.remove(shard_id)
                                    continue
                                    
                                validator = self.consensus.select_validator(
                                    [n for n in self.nodes if shard_id in n.shard_assignments]
                                )
                                if validator:
                                    block = shard.create_block(validator.node_id)
                                    if block:
                                        shard.add_block(block)
                            pbar.update(1)
    
                    elapsed_time = time.time() - start_time
                    results[percentage] = {
                        "elapsed_time": elapsed_time,
                        "tps": transaction_count / elapsed_time
                    }
                    print(f"Completed {percentage}% cross-shard test at {transaction_count / elapsed_time:.2f} TPS")
    
            # Verify cross-shard scaling characteristics
            base_time = results[0]["elapsed_time"]
            for percentage in cross_shard_percentages[1:]:
                # Even at 50% cross-shard, shouldn't be more than 3x slower
                self.assertLess(
                    results[percentage]["elapsed_time"] / base_time,
                    3.0
                )
    
        def _generate_test_transactions(
            self, 
            count: int, 
            cross_shard_percentage: int = 0
        ) -> List[Transaction]:
            """Generate test transactions with specified cross-shard percentage."""
            transactions = []
            for i in range(count):
                # Determine if this should be a cross-shard transaction
                is_cross_shard = random.randint(1, 100) <= cross_shard_percentage
                
                shard_id = random.randint(0, len(self.shards) - 1)
                target_shard = None
                cross_shard_refs = []
                
                if is_cross_shard:
                    target_shard = random.randint(0, len(self.shards) - 1)
                    while target_shard == shard_id:
                        target_shard = random.randint(0, len(self.shards) - 1)
                    cross_shard_refs = [f"ref_{i}"]
    
                tx = Transaction(
                    sender=f"sender_{i}",
                    receiver=f"receiver_{i}",
                    action="transfer",
                    data={
                        "amount": random.uniform(1, 100),
                        "target_shard": target_shard
                    } if is_cross_shard else {
                        "amount": random.uniform(1, 100)
                    },
                    shard_id=shard_id,
                    priority=random.randint(1, 5),
                    cross_shard_refs=cross_shard_refs
                )
                transactions.append(tx)
                
            return transactions
    
    if __name__ == '__main__':
        unittest.main(verbosity=2)
```


# ============================================================
# File: /home/matt/icn-prototype/tests/performance/test_load_handling.py
# Size: 12150 bytes
# Last Modified: Sat Oct 26 04:28:09 2024
# Language: py
# ============================================================

```py
    import unittest
    from datetime import datetime, timedelta
    import sys
    import os
    import random
    import asyncio
    import time
    import signal
    from concurrent.futures import ThreadPoolExecutor, as_completed
    from typing import List, Dict, Set
    import logging
    
    # Add project root to Python path
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    sys.path.insert(0, project_root)
    
    from blockchain.core.shard import Shard, ShardConfig
    from blockchain.core.transaction import Transaction
    from blockchain.core.block import Block
    from blockchain.core.node import Node
    from blockchain.consensus.proof_of_cooperation import ProofOfCooperation
    
    logger = logging.getLogger(__name__)
    
    def timeout_handler(signum, frame):
        """Handle timeout signal"""
        raise TimeoutError("Test execution timed out")
    
    class TestLoadHandling(unittest.TestCase):
        """Test suite for load handling capabilities of the ICN blockchain."""
        
        TIMEOUT = 10  # Reduced timeout to 10 seconds
        TRANSACTION_BATCH_SIZE = 50  # Further reduced batch size
        MAX_PROCESSING_TIME = 3  # Reduced processing time
    
        def setUp(self):
            """Set up test environment before each test."""
            # Configure logging
            logging.basicConfig(level=logging.INFO)
            
            self.config = ShardConfig(
                max_transactions_per_block=50,    # Further reduced
                max_pending_transactions=200,     # Further reduced
                max_cross_shard_refs=5,          # Further reduced
                pruning_interval=60,
                min_block_interval=0,
                max_block_size=1024 * 1024,
                max_state_size=10 * 1024 * 1024
            )
            
            self.num_shards = 2  # Reduced to minimum for testing
            self.shards = [Shard(shard_id=i, config=self.config) for i in range(self.num_shards)]
            self.nodes = self._create_test_nodes(6)  # Reduced number of nodes
            self.consensus = ProofOfCooperation()
    
            # Set up signal handler for timeouts
            signal.signal(signal.SIGALRM, timeout_handler)
    
        def tearDown(self):
            """Clean up after each test."""
            # Reset signal handler and clear any pending alarms
            signal.alarm(0)
            signal.signal(signal.SIGALRM, signal.SIG_DFL)
    
        def _create_test_nodes(self, num_nodes: int) -> List[Node]:
            """Create test nodes with varied capabilities."""
            nodes = []
            for i in range(num_nodes):
                node = Node(
                    node_id=f"node_{i}",
                    cooperative_id=f"coop_{i % 2}",  # Reduced cooperatives
                    initial_stake=100.0
                )
                node.reputation_scores = {
                    "validation": 20.0 + i * 0.5,
                    "resource_sharing": 20.0 + i * 0.3,
                    "cooperative_growth": 20.0 + i * 0.2,
                    "innovation": 20.0 + i * 0.1
                }
                shard_id = i % self.num_shards
                node.assign_to_shard(shard_id)
                nodes.append(node)
            return nodes
    
        def _generate_test_transactions(self, count: int) -> List[Transaction]:
            """Generate test transactions."""
            transactions = []
            for i in range(count):
                is_cross_shard = random.random() < 0.1  # Reduced cross-shard probability to 10%
                
                shard_id = random.randint(0, self.num_shards - 1)
                target_shard = None
                cross_shard_refs = []
                
                if is_cross_shard:
                    target_shard = (shard_id + 1) % self.num_shards
                    cross_shard_refs = [f"ref_{i}_{target_shard}"]
    
                tx = Transaction(
                    sender=f"sender_{i}",
                    receiver=f"receiver_{i}",
                    action="transfer",
                    data={
                        "amount": random.uniform(1, 100),
                        "target_shard": target_shard
                    } if is_cross_shard else {
                        "amount": random.uniform(1, 100)
                    },
                    shard_id=shard_id,
                    priority=random.randint(1, 5),
                    cross_shard_refs=cross_shard_refs
                )
                transactions.append(tx)
                
            logger.info(f"Generated {count} transactions")
            return transactions
    
        async def _process_transactions_async(self, transactions: List[Transaction]) -> None:
            """Process transactions asynchronously with timeout."""
            try:
                async with asyncio.timeout(self.MAX_PROCESSING_TIME):
                    for batch_start in range(0, len(transactions), self.TRANSACTION_BATCH_SIZE):
                        batch = transactions[batch_start:batch_start + self.TRANSACTION_BATCH_SIZE]
                        tasks = []
                        for tx in batch:
                            shard = self.shards[tx.shard_id]
                            tasks.append(asyncio.create_task(self._add_transaction_async(shard, tx)))
                        await asyncio.gather(*tasks)
                        logger.info(f"Processed batch of {len(batch)} transactions")
            except asyncio.TimeoutError:
                logger.warning("Transaction processing timed out")
    
        async def _add_transaction_async(self, shard: Shard, transaction: Transaction) -> None:
            """Add a transaction to a shard asynchronously."""
            try:
                shard.add_transaction(transaction)
            except Exception as e:
                logger.error(f"Error adding transaction: {e}")
    
        def _process_blocks(self, max_attempts: int = 100) -> None:
            """Process pending transactions into blocks with attempt limit."""
            attempts = 0
            processed_any = True
            
            while processed_any and attempts < max_attempts:
                processed_any = False
                attempts += 1
                
                for shard in self.shards:
                    if shard.pending_transactions:
                        validator = self.consensus.select_validator(self.nodes, shard.shard_id)
                        if validator:
                            block = shard.create_block(validator.node_id)
                            if block and shard.add_block(block):
                                processed_any = True
                                logger.info(f"Processed block in shard {shard.shard_id}")
                
                if attempts % 10 == 0:
                    logger.info(f"Block processing attempt {attempts}")
    
        def _validate_shard_blocks(self, shard: Shard) -> bool:
            """Validate all blocks in a shard."""
            try:
                for i in range(1, len(shard.chain)):
                    if not shard.chain[i].validate(shard.chain[i-1]):
                        return False
                return True
            except Exception as e:
                logger.error(f"Shard validation failed: {str(e)}")
                return False
    
        def _verify_system_state(self) -> None:
            """Verify overall system state consistency."""
            for shard in self.shards:
                self.assertTrue(shard.validate_chain())
                self.assertIsNotNone(shard.state_manager.state)
                self.assertGreaterEqual(len(shard.transaction_manager.processed_transactions), 0)
                self.assertIsNotNone(shard.validation_manager.validation_cache)
    
        def _verify_cross_shard_state(self) -> None:
            """Verify cross-shard reference consistency."""
            for shard in self.shards:
                cross_refs = shard.cross_shard_manager.get_metrics()
                self.assertGreaterEqual(cross_refs["cross_shard_operations"], 0)
                self.assertGreaterEqual(cross_refs["validated_refs"], 0)
    
        def _capture_shard_states(self) -> Dict[int, int]:
            """Capture current state sizes of all shards."""
            return {
                shard.shard_id: len(str(shard.state_manager.state))
                for shard in self.shards
            }
    
        def _reset_system_state(self) -> None:
            """Reset system state for next test."""
            for shard in self.shards:
                shard.transaction_manager.clear_all()
                shard.state_manager.state = {}
                shard.validation_manager.clear_cache()
    
        def test_high_transaction_load(self):
            """Test system performance under high transaction load."""
            transaction_counts = [20, 50]  # Further reduced counts
            
            for count in transaction_counts:
                with self.subTest(transaction_count=count):
                    signal.alarm(self.TIMEOUT)
                    try:
                        transactions = self._generate_test_transactions(count)
                        
                        start_time = time.time()
                        asyncio.run(self._process_transactions_async(transactions))
                        self._process_blocks()
                        
                        elapsed_time = time.time() - start_time
                        tps = count / elapsed_time
                        
                        logger.info(f"Processed {count} transactions in {elapsed_time:.2f} seconds ({tps:.2f} TPS)")
                        self._verify_system_state()
                        self._reset_system_state()
                    finally:
                        signal.alarm(0)
    
        def test_concurrent_validation(self):
            """Test concurrent block validation across shards."""
            signal.alarm(self.TIMEOUT)
            try:
                transactions = self._generate_test_transactions(20)  # Further reduced
                asyncio.run(self._process_transactions_async(transactions))
                
                with ThreadPoolExecutor(max_workers=self.num_shards) as executor:
                    futures = []
                    for shard in self.shards:
                        future = executor.submit(self._validate_shard_blocks, shard)
                        futures.append(future)
                    
                    for future in as_completed(futures):
                        result = future.result(timeout=self.TIMEOUT)
                        self.assertTrue(result)
            finally:
                signal.alarm(0)
    
        def test_cross_shard_load(self):
            """Test system performance with heavy cross-shard transactions."""
            signal.alarm(self.TIMEOUT)
            try:
                transactions = []
                for i in range(20):  # Further reduced
                    source_shard = i % self.num_shards
                    target_shard = (source_shard + 1) % self.num_shards
                    
                    tx = Transaction(
                        sender=f"sender_{i}",
                        receiver=f"receiver_{i}",
                        action="transfer",
                        data={
                            "amount": random.uniform(1, 100),
                            "target_shard": target_shard
                        },
                        shard_id=source_shard,
                        cross_shard_refs=[f"ref_{i}_{target_shard}"]
                    )
                    transactions.append(tx)
                
                start_time = time.time()
                asyncio.run(self._process_transactions_async(transactions))
                self._process_blocks()
                    
                elapsed_time = time.time() - start_time
                self._verify_cross_shard_state()
                
                tps = len(transactions) / elapsed_time
                logger.info(f"Cross-shard processing rate: {tps:.2f} TPS")
            finally:
                signal.alarm(0)
    
        def test_state_growth_under_load(self):
            """Test state management under continuous load."""
            signal.alarm(self.TIMEOUT)
            try:
                initial_states = self._capture_shard_states()
                
                for i in range(2):  # Further reduced iterations
                    transactions = self._generate_test_transactions(20)  # Further reduced
                    asyncio.run(self._process_transactions_async(transactions))
                    self._process_blocks()
                    
                    current_states = self._capture_shard_states()
                    for shard_id, state_size in current_states.items():
                        self.assertLess(
                            state_size, 
                            self.config.max_state_size,
                            f"Shard {shard_id} exceeded max state size"
                        )
            finally:
                signal.alarm(0)
    
    if __name__ == '__main__':
        unittest.main(verbosity=2)
```


# ============================================================
# File: /home/matt/icn-prototype/tests/performance/__init__.py
# Size: 0 bytes
# Last Modified: Wed Oct 23 19:46:07 2024
# Language: py
# ============================================================

```py

```


# ============================================================
# File: /home/matt/icn-prototype/tests/unit/test_proof_of_cooperation.py
# Size: 10692 bytes
# Last Modified: Thu Oct 24 14:41:47 2024
# Language: py
# ============================================================

```py
    import unittest
    from datetime import datetime, timedelta
    import sys
    import os
    from typing import List
    import random
    
    # Add project root to Python path
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    sys.path.insert(0, project_root)
    
    from blockchain.consensus.proof_of_cooperation import ProofOfCooperation
    from blockchain.core.node import Node
    from blockchain.core.block import Block
    from blockchain.core.transaction import Transaction
    
    class TestProofOfCooperation(unittest.TestCase):
        """Test cases for the ProofOfCooperation consensus mechanism."""
    
        def setUp(self):
            """Set up test fixtures before each test method."""
            self.poc = ProofOfCooperation(min_reputation=10.0, cooldown_blocks=3)
            self.test_nodes = self._create_test_nodes()
            
            # Create genesis block
            self.genesis_block = Block(
                index=0,
                previous_hash="0" * 64,
                timestamp=datetime.now() - timedelta(minutes=10),
                transactions=[],
                validator="genesis",
                shard_id=1
            )
    
        def _initialize_test_node(self, node_id: str) -> Node:
            """Initialize a test node with all required attributes."""
            node = Node(
                node_id=node_id,
                cooperative_id="test_coop",
                initial_stake=100.0
            )
            
            # Ensure sufficient reputation
            base_score = 25.0  # Well above min_reputation
            for category in node.reputation_scores:
                node.reputation_scores[category] = base_score
                
            # Add successful validation history
            node.validation_history = [
                {
                    "timestamp": datetime.now() - timedelta(minutes=i),
                    "category": "validation",
                    "score_change": 1.0,
                    "evidence": {"success": True}
                }
                for i in range(20)
            ]
            
            # Set high performance metrics
            node.performance_metrics = {
                "availability": 98.0,
                "validation_success_rate": 95.0,
                "network_reliability": 97.0
            }
            
            # Set active state
            node.metadata["status"] = "active"
            node.cooldown = 0
            node.total_validations = 15  # Experienced node
            
            # Add shard assignment
            node.assign_to_shard(1)  # Assign to test shard
            node.active_shards[1] = datetime.now() - timedelta(hours=1)
            
            # Add diverse cooperative interactions
            node.cooperative_interactions = [
                f"coop_{i % 5}" for i in range(30)
            ]
            
            return node
    
        def _create_test_nodes(self, num_nodes: int = 5) -> List[Node]:
            """Create a list of test nodes."""
            return [
                self._initialize_test_node(f"node_{i}")
                for i in range(num_nodes)
            ]
    
        def _create_test_block(self, index: int, previous_block: Block, validator_id: str) -> Block:
            """Create a test block properly linked to previous block."""
            return Block(
                index=index,
                previous_hash=previous_block.hash,
                timestamp=datetime.now(),
                transactions=[
                    Transaction(
                        sender=f"user_{i}",
                        receiver=f"user_{i+1}",
                        action="transfer",
                        data={"amount": 10.0},
                        shard_id=1
                    )
                    for i in range(3)
                ],
                validator=validator_id,
                shard_id=1
            )
    
        def test_initialization(self):
            """Test ProofOfCooperation initialization."""
            self.assertEqual(self.poc.min_reputation, 10.0)
            self.assertEqual(self.poc.cooldown_blocks, 3)
            self.assertGreater(len(self.poc.reputation_weights), 0)
            self.assertGreater(len(self.poc.validation_thresholds), 0)
            self.assertTrue(0 < self.poc.reputation_decay_factor <= 1)
    
        def test_calculate_cooperation_score(self):
            """Test cooperation score calculation."""
            node = self._initialize_test_node("score_test_node")
            
            # Test basic score calculation
            score = self.poc.calculate_cooperation_score(node)
            self.assertGreater(score, 0)
            
            # Test with shard_id
            shard_score = self.poc.calculate_cooperation_score(node, shard_id=1)
            self.assertGreater(shard_score, 0)
            
            # Test node in cooldown
            node.enter_cooldown(3)
            cooldown_score = self.poc.calculate_cooperation_score(node)
            self.assertEqual(cooldown_score, 0)
    
        def test_validator_selection(self):
            """Test validator selection process."""
            nodes = [
                self._initialize_test_node(f"select_node_{i}")
                for i in range(5)
            ]
            
            # Test basic selection
            validator = self.poc.select_validator(nodes)
            self.assertIsNotNone(validator)
            self.assertIn(validator, nodes)
            
            # Test selection with shard_id
            shard_validator = self.poc.select_validator(nodes, shard_id=1)
            self.assertIsNotNone(shard_validator)
            
            # Test with all nodes in cooldown
            for node in nodes:
                node.enter_cooldown(3)
            no_validator = self.poc.select_validator(nodes)
            self.assertIsNone(no_validator)
    
        def test_block_validation(self):
            """Test block validation process."""
            validator = self._initialize_test_node("test_validator")
            
            # Create a valid test block
            test_block = self._create_test_block(1, self.genesis_block, validator.node_id)
            
            # Verify block validation
            is_valid = self.poc.validate_block(test_block, self.genesis_block, validator)
            self.assertTrue(is_valid)
            
            # Test invalid block (future timestamp)
            invalid_block = Block(
                index=1,
                previous_hash=self.genesis_block.hash,
                timestamp=datetime.now() + timedelta(hours=1),
                transactions=[],
                validator=validator.node_id,
                shard_id=1
            )
            is_invalid = self.poc.validate_block(invalid_block, self.genesis_block, validator)
            self.assertFalse(is_invalid)
    
        def test_collusion_detection(self):
            """Test collusion detection mechanism."""
            node = self._initialize_test_node("collusion_test_node")
            
            # Create block with diverse transactions
            diverse_block = Block(
                index=1,
                previous_hash=self.genesis_block.hash,
                timestamp=datetime.now(),
                transactions=[
                    Transaction(
                        sender=f"user_{i}",
                        receiver=f"user_{i+1}",
                        action="transfer",
                        data={"amount": 10.0},
                        shard_id=1
                    )
                    for i in range(5)
                ],
                validator=node.node_id,
                shard_id=1
            )
            
            # Create block with obvious collusion pattern
            collusion_transactions = [
                Transaction(
                    sender="colluding_user",
                    receiver=f"receiver_{i}",  # Fixed variable scope issue
                    action="transfer",
                    data={"amount": 10.0},
                    shard_id=1
                )
                for i in range(5)
            ]
            
            collusion_block = Block(
                index=2,
                previous_hash=self.genesis_block.hash,
                timestamp=datetime.now(),
                transactions=collusion_transactions,
                validator=node.node_id,
                shard_id=1
            )
            
            # Test detection
            diverse_collusion = self.poc.detect_collusion(node, diverse_block)
            self.assertFalse(diverse_collusion)
            
            repeated_collusion = self.poc.detect_collusion(node, collusion_block)
            self.assertTrue(repeated_collusion)
    
        def test_diversity_factor(self):
            """Test diversity factor calculation."""
            diverse_node = self._initialize_test_node("diverse_node")
            diverse_node.cooperative_interactions = [f"coop_{i}" for i in range(10)]
            diverse_factor = self.poc._calculate_diversity_factor(diverse_node)
            
            limited_node = self._initialize_test_node("limited_node")
            limited_node.cooperative_interactions = ["coop_1"] * 10
            limited_factor = self.poc._calculate_diversity_factor(limited_node)
            
            self.assertGreater(diverse_factor, limited_factor)
    
        def test_consistency_factor(self):
            """Test consistency factor calculation."""
            node = self._initialize_test_node("consistency_node")
            
            # Test with successful validations
            node.validation_history = [
                {"evidence": {"success": True}} for _ in range(10)
            ]
            high_consistency = self.poc._calculate_consistency_factor(node)
            
            # Test with mixed success
            node.validation_history = [
                {"evidence": {"success": i % 2 == 0}} for i in range(10)
            ]
            mixed_consistency = self.poc._calculate_consistency_factor(node)
            
            self.assertGreater(high_consistency, mixed_consistency)
    
        def test_performance_factor(self):
            """Test performance factor calculation."""
            node = self._initialize_test_node("performance_node")
            
            # Test high performance
            node.performance_metrics = {
                "availability": 98.0,
                "validation_success_rate": 95.0,
                "network_reliability": 97.0
            }
            high_performance = self.poc._calculate_performance_factor(node)
            
            # Test lower performance
            node.performance_metrics = {
                "availability": 85.0,
                "validation_success_rate": 82.0,
                "network_reliability": 88.0
            }
            lower_performance = self.poc._calculate_performance_factor(node)
            
            self.assertGreater(high_performance, lower_performance)
    
        def test_metrics(self):
            """Test consensus metrics collection."""
            # Record some validation activity
            for i in range(5):
                self.poc.performance_metrics["total_validations"] += 1
                self.poc.performance_metrics["successful_validations"] += (i % 2)
            
            metrics = self.poc.get_metrics()
            
            self.assertIn("total_validations", metrics)
            self.assertIn("successful_validations", metrics)
            self.assertIn("average_block_time", metrics)
            self.assertIn("collusion_detections", metrics)
            self.assertGreaterEqual(metrics["total_validations"], 5)
    
    if __name__ == '__main__':
        unittest.main()
```


# ============================================================
# File: /home/matt/icn-prototype/tests/unit/test_contract_executor.py
# Size: 9655 bytes
# Last Modified: Thu Oct 24 21:17:19 2024
# Language: py
# ============================================================

```py
    """
    tests/unit/test_contract_executor.py
    
    Unit tests for the ContractExecutor class, handling contract deployment,
    execution, and lifecycle management.
    """
    
    import pytest
    from datetime import datetime, timedelta
    import sys
    import os
    import asyncio
    from typing import Dict, List
    import logging
    
    # Add project root to Python path
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    sys.path.insert(0, project_root)
    
    from blockchain.contracts.contract_executor import ContractExecutor
    from blockchain.contracts.smart_contract import SmartContract, ContractExecutionError
    
    class TestContractExecutor:
        """Test cases for the ContractExecutor class."""
    
        @pytest.fixture(autouse=True)
        def setup(self):
            """Setup test instance with fresh ContractExecutor."""
            self.executor = ContractExecutor(initial_mana=1000, mana_regen_rate=10)
    
        @pytest.fixture
        def basic_contract_code(self):
            """Fixture providing basic test contract code."""
            return """
    def execute(input_data, state):
        a = input_data.get('a', 0)
        b = input_data.get('b', 0)
        result = a + b
        state['last_result'] = result
        return result
    """
    
        @pytest.fixture
        def test_contract(self, basic_contract_code):
            """Fixture providing a test contract instance."""
            return SmartContract(
                contract_id="test_contract",
                code=basic_contract_code,
                creator="test_creator",
                mana_cost=10
            )
    
        @pytest.mark.asyncio
        async def test_deploy_contract(self, test_contract):
            """Test contract deployment functionality."""
            # Test successful deployment
            success = await self.executor.deploy_contract(test_contract)
            assert success
            assert test_contract.contract_id in self.executor.contracts
            
            # Test duplicate deployment
            success = await self.executor.deploy_contract(test_contract)
            assert not success
            
            # Test contract with invalid code
            invalid_contract = SmartContract(
                contract_id="invalid_contract",
                code="invalid python code :",
                creator="test_creator"
            )
            success = await self.executor.deploy_contract(invalid_contract)
            assert not success
    
        @pytest.mark.asyncio
        async def test_execute_contract(self, test_contract):
            """Test contract execution."""
            await self.executor.deploy_contract(test_contract)
            
            result = await self.executor.execute_contract(
                test_contract.contract_id,
                {"a": 5, "b": 3},
                "test_creator"
            )
            assert result is not None
            assert result.get("result") == 8
            
            # Test insufficient mana
            self.executor.mana_pool = 5
            with pytest.raises(ContractExecutionError):
                await self.executor.execute_contract(
                    test_contract.contract_id,
                    {"a": 1, "b": 2},
                    "test_creator"
                )
    
        @pytest.mark.asyncio
        async def test_execution_queue(self, test_contract):
            """Test contract execution queue functionality."""
            await self.executor.deploy_contract(test_contract)
            
            queue_success = await self.executor.queue_execution(
                test_contract.contract_id,
                {"a": 1, "b": 2},
                "test_creator"
            )
            assert queue_success
    
            # Test queue size limit
            self.executor.max_queue_size = 1
            queue_success = await self.executor.queue_execution(
                test_contract.contract_id,
                {"a": 3, "b": 4},
                "test_creator"
            )
            assert not queue_success
    
        @pytest.mark.asyncio
        async def test_dependency_management(self, basic_contract_code):
            """Test contract dependency management."""
            base_contract = SmartContract(
                contract_id="base_contract",
                code=basic_contract_code,
                creator="test_creator"
            )
            
            dependent_contract = SmartContract(
                contract_id="dependent_contract",
                code="""
    def execute(input_data, state):
        value = input_data.get('value', 0)
        state['processed'] = value * 2
        return state['processed']
    """,
                creator="test_creator"
            )
            dependent_contract.dependencies.add(base_contract.contract_id)
            
            # Test deployment order validation
            with pytest.raises(ContractExecutionError):
                await self.executor.deploy_contract(dependent_contract)
            
            await self.executor.deploy_contract(base_contract)
            success = await self.executor.deploy_contract(dependent_contract)
            assert success
    
        @pytest.mark.asyncio
        async def test_mana_regeneration(self, test_contract):
            """Test mana regeneration functionality."""
            initial_mana = self.executor.mana_pool
            
            await self.executor.deploy_contract(test_contract)
            await self.executor.execute_contract(
                test_contract.contract_id,
                {"a": 1, "b": 2},
                "test_creator"
            )
            
            used_mana = initial_mana - self.executor.mana_pool
            await self.executor.regenerate_mana()
            assert self.executor.mana_pool > initial_mana - used_mana
    
        def test_metrics_collection(self):
            """Test metrics collection and reporting."""
            metrics = self.executor.get_metrics()
            
            assert "total_executions" in metrics
            assert "failed_executions" in metrics
            assert "total_mana_consumed" in metrics
            assert "average_execution_time" in metrics
            assert "contracts_deployed" in metrics
            assert "queue_length" in metrics
    
        @pytest.mark.asyncio
        async def test_execution_limits(self):
            """Test contract execution limits and restrictions."""
            long_running_contract = SmartContract(
                contract_id="long_running",
                code="""
    def execute(input_data, state):
        import time
        time.sleep(6)  # Exceed time limit
        return True
    """,
                creator="test_creator"
            )
            
            await self.executor.deploy_contract(long_running_contract)
            
            with pytest.raises(ContractExecutionError):
                await self.executor.execute_contract(
                    long_running_contract.contract_id,
                    {},
                    "test_creator"
                )
    
        @pytest.mark.asyncio
        async def test_concurrent_execution(self, test_contract):
            """Test concurrent contract execution handling."""
            await self.executor.deploy_contract(test_contract)
            
            tasks = []
            for i in range(5):
                task = self.executor.execute_contract(
                    test_contract.contract_id,
                    {"a": i, "b": i},
                    "test_creator"
                )
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            successful = [r for r in results if not isinstance(r, Exception)]
            assert len(successful) == 5
    
        @pytest.mark.asyncio
        async def test_error_recovery(self):
            """Test error recovery and state management."""
            failing_contract = SmartContract(
                contract_id="failing_contract",
                code="""
    def execute(input_data, state):
        if input_data.get('fail', False):
            raise ValueError('Intended failure')
        state['value'] = input_data.get('value', 0)
        return state['value']
    """,
                creator="test_creator"
            )
            
            await self.executor.deploy_contract(failing_contract)
            
            result = await self.executor.execute_contract(
                failing_contract.contract_id,
                {"value": 42},
                "test_creator"
            )
            assert result["result"] == 42
            
            with pytest.raises(ContractExecutionError):
                await self.executor.execute_contract(
                    failing_contract.contract_id,
                    {"fail": True},
                    "test_creator"
                )
            
            result = await self.executor.execute_contract(
                failing_contract.contract_id,
                {"value": 100},
                "test_creator"
            )
            assert result["result"] == 100
    
        @pytest.mark.asyncio
        async def test_authorization(self, test_contract):
            """Test contract authorization controls."""
            await self.executor.deploy_contract(test_contract)
            
            with pytest.raises(ContractExecutionError):
                await self.executor.execute_contract(
                    test_contract.contract_id,
                    {"a": 1, "b": 2},
                    "unauthorized_user"
                )
            
            test_contract.authorize_caller("new_user")
            result = await self.executor.execute_contract(
                test_contract.contract_id,
                {"a": 1, "b": 2},
                "new_user"
            )
            assert result is not None
    
        @pytest.mark.asyncio
        async def test_contract_cleanup(self, basic_contract_code):
            """Test contract cleanup and resource management."""
            contracts = []
            for i in range(5):
                contract = SmartContract(
                    contract_id=f"contract_{i}",
                    code=basic_contract_code,
                    creator="test_creator"
                )
                contracts.append(contract)
                await self.executor.deploy_contract(contract)
            
            metrics = self.executor.get_metrics()
            assert metrics["contracts_deployed"] == 5
            
            for contract in contracts:
                assert contract.contract_id in self.executor.contracts
```


# ============================================================
# File: /home/matt/icn-prototype/tests/unit/test_block.py
# Size: 10172 bytes
# Last Modified: Thu Oct 24 00:59:22 2024
# Language: py
# ============================================================

```py
    # tests/unit/test_block.py
    
    import unittest
    from datetime import datetime, timedelta
    import json
    import hashlib
    import sys
    import os
    from typing import List
    
    # Add project root to Python path
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    sys.path.insert(0, project_root)
    
    from blockchain.core.block import Block
    from blockchain.core.transaction import Transaction
    
    class TestBlock(unittest.TestCase):
        """Test cases for the Block class."""
    
        def setUp(self):
            """Set up test fixtures before each test method."""
            self.sample_transactions = self._create_sample_transactions()
            
            # Create previous block first
            self.previous_block = Block(
                index=0,
                previous_hash="0" * 64,
                timestamp=datetime.now() - timedelta(minutes=5),
                transactions=[],
                validator="genesis",
                shard_id=1
            )
    
            # Create current block with correct previous hash
            self.block = Block(
                index=1,
                previous_hash=self.previous_block.hash,  # Use actual hash from previous block
                timestamp=datetime.now(),
                transactions=self.sample_transactions[:2],
                validator="node1",
                shard_id=1
            )
    
        def _create_sample_transactions(self) -> List[Transaction]:
            """Create sample transactions for testing."""
            transactions = []
            for i in range(1, 6):
                tx = Transaction(
                    sender=f"user{i}",
                    receiver=f"user{i+1}",
                    action="transfer",
                    data={"amount": 10.0 * i},
                    shard_id=1  # All transactions in same shard
                )
                transactions.append(tx)
            return transactions
    
        def test_initialization(self):
            """Test block initialization and attribute setting."""
            self.assertEqual(self.block.index, 1)
            self.assertEqual(self.block.previous_hash, self.previous_block.hash)
            self.assertEqual(self.block.validator, "node1")
            self.assertEqual(self.block.shard_id, 1)
            self.assertEqual(len(self.block.transactions), 2)
            self.assertIsNotNone(self.block.merkle_root)
            self.assertIsNotNone(self.block.hash)
            self.assertEqual(self.block.nonce, 0)
            self.assertEqual(self.block.version, "1.0")
            self.assertIn("created_at", self.block.metadata)
    
        def test_merkle_root_calculation(self):
            """Test Merkle root calculation with different scenarios."""
            # Test with existing transactions
            merkle_root = self.block.calculate_merkle_root()
            self.assertEqual(merkle_root, self.block.merkle_root)
            
            # Test with empty transactions
            empty_block = Block(
                index=0,
                previous_hash="0",
                timestamp=datetime.now(),
                transactions=[],
                validator="genesis",
                shard_id=0
            )
            self.assertEqual(
                empty_block.merkle_root,
                hashlib.sha256(b"empty").hexdigest()
            )
            
            # Test with odd number of transactions
            odd_block = Block(
                index=2,
                previous_hash=self.block.hash,
                timestamp=datetime.now(),
                transactions=self.sample_transactions[:3],
                validator="node1",
                shard_id=1
            )
            self.assertIsNotNone(odd_block.merkle_root)
            
            # Verify Merkle root changes with transaction modification
            original_root = self.block.merkle_root
            modified_tx = self.block.transactions[0]
            modified_tx.data["amount"] = 999.9
            new_root = self.block.calculate_merkle_root()
            self.assertNotEqual(original_root, new_root)
    
        def test_hash_calculation(self):
            """Test block hash calculation and verification."""
            # Test initial hash
            initial_hash = self.block.hash
            calculated_hash = self.block.calculate_hash()
            self.assertEqual(initial_hash, calculated_hash)
            
            # Test hash changes with block modifications
            self.block.nonce += 1
            new_hash = self.block.calculate_hash()
            self.assertNotEqual(initial_hash, new_hash)
            
            # Test hash changes with timestamp modification
            original_timestamp = self.block.timestamp
            self.block.timestamp += timedelta(seconds=1)
            newer_hash = self.block.calculate_hash()
            self.assertNotEqual(new_hash, newer_hash)
            # Restore timestamp for other tests
            self.block.timestamp = original_timestamp
            
            # Verify hash format
            self.assertTrue(all(c in "0123456789abcdef" for c in self.block.hash))
            self.assertEqual(len(self.block.hash), 64)  # SHA-256 produces 64 hex chars
    
        def test_validation(self):
            """Test block validation logic."""
            # Test valid block
            self.assertTrue(self.block.validate(self.previous_block))
            
            # Test invalid hash
            original_hash = self.block.hash
            self.block.hash = "invalid_hash"
            self.assertFalse(self.block.validate(self.previous_block))
            self.block.hash = original_hash
            
            # Test future timestamp
            original_timestamp = self.block.timestamp
            self.block.timestamp = datetime.now() + timedelta(hours=1)
            self.assertFalse(self.block.validate(self.previous_block))
            self.block.timestamp = original_timestamp
            
            # Test invalid previous hash
            original_prev_hash = self.block.previous_hash
            self.block.previous_hash = "wrong_hash"
            self.assertFalse(self.block.validate(self.previous_block))
            self.block.previous_hash = original_prev_hash
    
        def test_add_transaction(self):
            """Test adding transactions to the block."""
            initial_tx_count = len(self.block.transactions)
            new_tx = self.sample_transactions[3]  # Unused transaction
            
            # Test adding valid transaction
            self.assertTrue(self.block.add_transaction(new_tx))
            self.assertEqual(len(self.block.transactions), initial_tx_count + 1)
            
            # Verify Merkle root was updated
            self.assertNotEqual(self.block.merkle_root, "")
            
            # Test adding transaction with wrong shard_id
            wrong_shard_tx = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={"amount": 50.0},
                shard_id=2  # Different shard
            )
            self.assertFalse(self.block.add_transaction(wrong_shard_tx))
            
            # Test adding duplicate transaction
            self.assertFalse(self.block.add_transaction(new_tx))
    
        def test_block_size(self):
            """Test block size calculations and limits."""
            # Add maximum transactions
            for tx in self.sample_transactions:
                self.block.add_transaction(tx)
                
            # Verify block can be serialized
            block_dict = self.block.to_dict()
            block_json = json.dumps(block_dict)
            
            # Simulate block size calculation
            block_size = len(block_json.encode('utf-8'))
            self.assertGreater(block_size, 0)
    
        def test_cross_shard_references(self):
            """Test cross-shard reference handling."""
            # Add cross-shard reference
            ref = "cross_shard_ref_123"
            self.block.cross_shard_refs.append(ref)
            
            # Verify serialization includes references
            block_dict = self.block.to_dict()
            self.assertIn("cross_shard_refs", block_dict)
            self.assertIn(ref, block_dict["cross_shard_refs"])
            
            # Verify deserialization preserves references
            new_block = Block.from_dict(block_dict)
            self.assertIn(ref, new_block.cross_shard_refs)
    
        def test_metadata(self):
            """Test block metadata handling."""
            # Test default metadata
            self.assertIn("created_at", self.block.metadata)
            
            # Add custom metadata
            self.block.metadata["test_key"] = "test_value"
            
            # Verify serialization includes metadata
            block_dict = self.block.to_dict()
            self.assertIn("metadata", block_dict)
            self.assertEqual(block_dict["metadata"]["test_key"], "test_value")
            
            # Verify deserialization preserves metadata
            new_block = Block.from_dict(block_dict)
            self.assertEqual(new_block.metadata["test_key"], "test_value")
    
        def test_serialization(self):
            """Test block serialization and deserialization."""
            # Convert block to dictionary
            block_dict = self.block.to_dict()
            
            # Verify dictionary structure
            self.assertIn("index", block_dict)
            self.assertIn("previous_hash", block_dict)
            self.assertIn("timestamp", block_dict)
            self.assertIn("transactions", block_dict)
            self.assertIn("validator", block_dict)
            self.assertIn("hash", block_dict)
            self.assertIn("merkle_root", block_dict)
            self.assertIn("shard_id", block_dict)
            self.assertIn("version", block_dict)
            
            # Create new block from dictionary
            new_block = Block.from_dict(block_dict)
            
            # Verify all attributes match
            self.assertEqual(new_block.index, self.block.index)
            self.assertEqual(new_block.previous_hash, self.block.previous_hash)
            self.assertEqual(new_block.validator, self.block.validator)
            self.assertEqual(new_block.shard_id, self.block.shard_id)
            self.assertEqual(new_block.hash, self.block.hash)
            self.assertEqual(new_block.merkle_root, self.block.merkle_root)
            
            # Verify transactions were properly deserialized
            self.assertEqual(len(new_block.transactions), len(self.block.transactions))
            for orig_tx, new_tx in zip(self.block.transactions, new_block.transactions):
                self.assertEqual(orig_tx.transaction_id, new_tx.transaction_id)
                self.assertEqual(orig_tx.sender, new_tx.sender)
                self.assertEqual(orig_tx.receiver, new_tx.receiver)
                self.assertEqual(orig_tx.data, new_tx.data)
    
    if __name__ == '__main__':
        unittest.main()
```


# ============================================================
# File: /home/matt/icn-prototype/tests/unit/test_validator_manager.py
# Size: 1238 bytes
# Last Modified: Sat Oct 26 18:41:44 2024
# Language: py
# ============================================================

```py
    import unittest
    from datetime import datetime, timedelta
    from blockchain.consensus.proof_of_cooperation.validator_manager import ValidatorManager
    from blockchain.core.node import Node
    
    class TestValidatorManager(unittest.TestCase):
        def setUp(self):
            self.manager = ValidatorManager(min_reputation=10.0, cooldown_blocks=3)
            self.node1 = Node(node_id="node1", cooperative_id="coop1", initial_stake=100.0)
            self.node1.reputation = 25.0
    
        def test_validator_selection(self):
            # Test that node1 can be selected as a validator
            validator = self.manager.select_validator([self.node1])
            self.assertEqual(validator, self.node1)
            self.assertEqual(validator.cooldown, 3)
    
        def test_validator_ineligibility_due_to_cooldown(self):
            # Put node1 into cooldown and test that it cannot be selected
            self.node1.cooldown = 1
            validator = self.manager.select_validator([self.node1])
            self.assertIsNone(validator)
    
        def test_priority_calculation(self):
            # Test the priority calculation for validator selection
            score = self.manager._calculate_priority_score(self.node1)
            self.assertGreater(score, 0)
    
    if __name__ == '__main__':
        unittest.main()
```


# ============================================================
# File: /home/matt/icn-prototype/tests/unit/test_shard.py
# Size: 10959 bytes
# Last Modified: Sat Oct 26 04:32:13 2024
# Language: py
# ============================================================

```py
    import unittest
    from datetime import datetime, timedelta
    import sys
    import os
    from typing import List, Dict, Optional, Set
    import logging
    
    # Add project root to Python path
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    sys.path.insert(0, project_root)
    
    from blockchain.core.shard import Shard, ShardConfig
    from blockchain.core.transaction import Transaction
    from blockchain.core.block import Block
    
    logger = logging.getLogger(__name__)
    
    class TestShard(unittest.TestCase):
        """Test cases for the modular Shard implementation."""
    
        def setUp(self):
            """Set up test environment before each test."""
            self.config = ShardConfig(
                max_transactions_per_block=5,
                max_pending_transactions=10,
                max_cross_shard_refs=3,
                pruning_interval=60,
                min_block_interval=0,  # Set to 0 for testing
                max_block_size=1024 * 1024,  # 1MB
                max_state_size=10 * 1024 * 1024  # 10MB
            )
            self.shard = Shard(shard_id=1, config=self.config)
            
            # Initialize some balances in state for testing
            self.shard.state_manager.state = {
                "balances": {
                    "user0": 1000.0,
                    "user1": 1000.0,
                    "user2": 1000.0,
                    "user3": 1000.0,
                    "user4": 1000.0
                }
            }
            
            self.sample_transactions = self._create_sample_transactions()
    
        def _create_sample_transactions(self) -> List[Transaction]:
            """Create sample transactions for testing."""
            return [
                Transaction(
                    sender=f"user{i}",
                    receiver=f"user{i+1}",
                    action="transfer",
                    data={"amount": 50.0},  # Changed from 10.0 to make changes more noticeable
                    shard_id=1
                ) for i in range(4)
            ]
    
        def test_initialization(self):
            """Test shard initialization with all components."""
            self.assertEqual(self.shard.shard_id, 1)
            self.assertIsInstance(self.shard.transaction_manager.pending_transactions, list)
            self.assertIsInstance(self.shard.state_manager.state, dict)
            self.assertEqual(len(self.shard.chain), 1)  # Genesis block
            self.assertEqual(self.shard.height, 1)
            self.assertEqual(self.shard.chain[0].validator, "genesis")
    
        def test_genesis_block(self):
            """Test genesis block creation and properties."""
            genesis = self.shard.chain[0]
            self.assertEqual(genesis.index, 0)
            self.assertEqual(genesis.previous_hash, "0" * 64)
            self.assertEqual(len(genesis.transactions), 0)
            self.assertEqual(genesis.validator, "genesis")
            self.assertEqual(genesis.shard_id, 1)
            self.assertTrue(genesis.validate(None))
    
        def test_transaction_management(self):
            """Test transaction management functionality."""
            # Test valid transaction addition
            tx = self.sample_transactions[0]
            self.assertTrue(self.shard.add_transaction(tx))
            self.assertEqual(len(self.shard.pending_transactions), 1)
    
            # Test duplicate transaction
            self.assertFalse(self.shard.add_transaction(tx))
    
            # Test transaction with wrong shard_id
            invalid_tx = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={"amount": 50.0},
                shard_id=2
            )
            self.assertFalse(self.shard.add_transaction(invalid_tx))
    
        def test_state_management(self):
            """Test state management and updates."""
            initial_state = self.shard.state_manager.state.copy()
            initial_balance = initial_state["balances"]["user0"]
    
            # Add and process transaction
            tx = self.sample_transactions[0]
            self.shard.add_transaction(tx)
            block = self.shard.create_block("test_validator")
            self.assertTrue(self.shard.add_block(block))
    
            # Verify balance changes
            new_state = self.shard.state_manager.state
            self.assertEqual(
                new_state["balances"]["user0"],
                initial_balance - 50.0  # Verify sender balance decreased
            )
            self.assertEqual(
                new_state["balances"]["user1"],
                initial_balance + 50.0  # Verify receiver balance increased
            )
    
        def test_create_block(self):
            """Test block creation from pending transactions."""
            for tx in self.sample_transactions[:3]:
                self.shard.add_transaction(tx)
    
            block = self.shard.create_block("test_validator")
            self.assertIsNotNone(block)
            self.assertEqual(block.index, self.shard.height)
            self.assertEqual(block.shard_id, self.shard.shard_id)
            self.assertEqual(len(block.transactions), 3)
    
        def test_add_block(self):
            """Test adding blocks to the shard."""
            for tx in self.sample_transactions[:3]:
                self.shard.add_transaction(tx)
            
            block = self.shard.create_block("test_validator")
            initial_height = self.shard.height
            
            self.assertTrue(self.shard.add_block(block))
            self.assertEqual(self.shard.height, initial_height + 1)
            self.assertEqual(len(self.shard.pending_transactions), 0)
    
        def test_cross_shard_operations(self):
            """Test cross-shard operations and references."""
            cross_tx = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={
                    "amount": 50.0,
                    "target_shard": 2
                },
                shard_id=1,
                cross_shard_refs=["ref_1"]
            )
    
            self.assertTrue(self.shard.add_transaction(cross_tx))
            block = self.shard.create_block("test_validator")
            self.assertIsNotNone(block)
            self.assertTrue(len(block.cross_shard_refs) > 0)
    
            # Verify cross-shard reference tracking
            self.assertTrue(self.shard.add_block(block))
            cross_shard_metrics = self.shard.cross_shard_manager.get_metrics()
            self.assertGreater(cross_shard_metrics["cross_shard_operations"], 0)
    
        def test_state_consistency(self):
            """Test state consistency across operations."""
            initial_state = self.shard.state_manager.state.copy()
            amount = 50.0  # Transaction amount
            
            # Add and process transactions
            for tx in self.sample_transactions[:3]:
                self.shard.add_transaction(tx)
    
            block = self.shard.create_block("test_validator")
            self.shard.add_block(block)
    
            # Verify state changes are consistent
            new_state = self.shard.state_manager.state
            for tx in block.transactions:
                # Get initial balances
                initial_sender_balance = initial_state["balances"][tx.sender]
                initial_receiver_balance = initial_state["balances"][tx.receiver]
                
                # Get new balances
                sender_balance = new_state["balances"][tx.sender]
                receiver_balance = new_state["balances"][tx.receiver]
                
                # Verify balances
                self.assertEqual(sender_balance, initial_sender_balance - amount)
                self.assertEqual(receiver_balance, initial_receiver_balance + amount)
                self.assertGreaterEqual(sender_balance, 0)
                self.assertGreater(receiver_balance, initial_state["balances"][tx.receiver])
    
        def test_manager_coordination(self):
            """Test coordination between different managers."""
            tx = self.sample_transactions[0]
            
            # Verify transaction gets properly distributed to managers
            self.shard.add_transaction(tx)
            self.assertIn(tx, self.shard.transaction_manager.pending_transactions)
            self.assertTrue(self.shard.validation_manager.validate_transaction(tx))
    
            # Create and add block
            block = self.shard.create_block("test_validator")
            initial_state = self.shard.state_manager.state.copy()
            
            self.assertTrue(self.shard.add_block(block))
            self.assertNotEqual(self.shard.state_manager.state, initial_state)
            self.assertEqual(len(self.shard.transaction_manager.pending_transactions), 0)
    
        def test_transaction_validation(self):
            """Test transaction validation in shard context."""
            valid_tx = self.sample_transactions[0]
            self.assertTrue(self.shard.validation_manager.validate_transaction(valid_tx))
    
            # Test invalid amount
            invalid_tx = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={"amount": -50.0},
                shard_id=1
            )
            self.assertFalse(self.shard.validation_manager.validate_transaction(invalid_tx))
    
            # Test insufficient balance
            large_tx = Transaction(
                sender="user1",
                receiver="user2",
                action="transfer",
                data={"amount": 2000.0},
                shard_id=1
            )
            self.assertFalse(self.shard.validation_manager.validate_transaction(large_tx))
    
        def test_validate_chain(self):
            """Test chain validation functionality."""
            # Add some blocks
            for tx in self.sample_transactions[:3]:
                self.shard.add_transaction(tx)
                
            block = self.shard.create_block("test_validator")
            self.shard.add_block(block)
            
            self.assertTrue(self.shard.validate_chain())
    
        def test_get_metrics(self):
            """Test metrics collection across all managers."""
            # Generate some activity
            for tx in self.sample_transactions[:3]:
                self.shard.add_transaction(tx)
                
            block = self.shard.create_block("test_validator")
            self.shard.add_block(block)
            
            metrics = self.shard.get_metrics()
            
            self.assertIn("total_transactions", metrics)
            self.assertIn("blocks_created", metrics)
            self.assertIn("pending_transactions", metrics)
            self.assertIn("state_size", metrics)
            self.assertEqual(metrics["shard_id"], self.shard.shard_id)
    
        def test_serialization(self):
            """Test shard serialization and deserialization."""
            # Add some data
            for tx in self.sample_transactions[:3]:
                self.shard.add_transaction(tx)
            block = self.shard.create_block("test_validator")
            self.shard.add_block(block)
    
            # Serialize
            shard_dict = self.shard.to_dict()
    
            # Deserialize
            new_shard = Shard.from_dict(shard_dict)
    
            # Verify properties
            self.assertEqual(new_shard.shard_id, self.shard.shard_id)
            self.assertEqual(new_shard.height, self.shard.height)
            self.assertEqual(len(new_shard.chain), len(self.shard.chain))
            self.assertEqual(
                new_shard.state_manager.state["balances"],
                self.shard.state_manager.state["balances"]
            )
    
    if __name__ == '__main__':
        unittest.main()
```


# ============================================================
# File: /home/matt/icn-prototype/tests/unit/test_node.py
# Size: 7500 bytes
# Last Modified: Wed Oct 23 19:57:52 2024
# Language: py
# ============================================================

```py
    import unittest
    from datetime import datetime, timedelta
    from blockchain.core.block import Block
    from blockchain.core.transaction import Transaction
    from blockchain.core.node import Node
    from blockchain.core.shard import Shard
    from blockchain.consensus.proof_of_cooperation import ProofOfCooperation
    
    class TestBlock(unittest.TestCase):
        def setUp(self):
            """Set up test environment before each test method."""
            self.transactions = [
                Transaction(
                    sender="user1",
                    receiver="user2", 
                    action="transfer",
                    data={"amount": 10.0}
                ),
                Transaction(
                    sender="user2",
                    receiver="user3",
                    action="transfer",
                    data={"amount": 5.0}
                )
            ]
            
            self.block = Block(
                index=1,
                previous_hash="abc123",
                timestamp=datetime.now(),
                transactions=self.transactions,
                validator="node1",
                shard_id=1
            )
    
        def test_initialization(self):
            """Test block initialization with proper values."""
            self.assertEqual(self.block.index, 1)
            self.assertEqual(self.block.previous_hash, "abc123")
            self.assertEqual(self.block.validator, "node1")
            self.assertEqual(self.block.shard_id, 1)
            self.assertEqual(len(self.block.transactions), 2)
            self.assertIsNotNone(self.block.merkle_root)
    
        def test_calculate_merkle_root(self):
            """Test Merkle root calculation."""
            merkle_root = self.block.calculate_merkle_root()
            self.assertEqual(merkle_root, self.block.merkle_root)
            
            # Test with empty transactions
            empty_block = Block(
                index=0,
                previous_hash="0",
                timestamp=datetime.now(),
                transactions=[],
                validator="genesis",
                shard_id=0
            )
            self.assertIsNotNone(empty_block.merkle_root)
    
        def test_calculate_hash(self):
            """Test block hash calculation."""
            initial_hash = self.block.hash
            new_hash = self.block.calculate_hash()
            self.assertEqual(initial_hash, new_hash)
            
            # Test hash changes with different transactions
            self.block.transactions.append(
                Transaction(
                    sender="user3",
                    receiver="user4",
                    action="transfer",
                    data={"amount": 15.0}
                )
            )
            self.assertNotEqual(initial_hash, self.block.calculate_hash())
    
        def test_validate(self):
            """Test block validation logic."""
            # Create a previous block
            previous_block = Block(
                index=0,
                previous_hash="0" * 64,
                timestamp=datetime.now() - timedelta(minutes=5),
                transactions=[],
                validator="genesis",
                shard_id=1
            )
            
            # Test valid block
            self.assertTrue(self.block.validate(previous_block))
            
            # Test invalid cases
            self.block.hash = "invalid_hash"
            self.assertFalse(self.block.validate(previous_block))
            
            self.block.hash = self.block.calculate_hash()
            self.block.timestamp = datetime.now() + timedelta(hours=1)
            self.assertFalse(self.block.validate(previous_block))
    
        def test_add_transaction(self):
            """Test adding transactions to the block."""
            new_tx = Transaction(
                sender="user3",
                receiver="user4",
                action="transfer",
                data={"amount": 15.0},
                shard_id=1
            )
            
            initial_merkle_root = self.block.merkle_root
            self.assertTrue(self.block.add_transaction(new_tx))
            self.assertNotEqual(initial_merkle_root, self.block.merkle_root)
            
            # Test adding transaction with wrong shard_id
            invalid_tx = Transaction(
                sender="user4",
                receiver="user5",
                action="transfer",
                data={"amount": 20.0},
                shard_id=2
            )
            self.assertFalse(self.block.add_transaction(invalid_tx))
    
        def test_to_dict_and_from_dict(self):
            """Test converting block to dict and back."""
            block_dict = self.block.to_dict()
            new_block = Block.from_dict(block_dict)
            
            self.assertEqual(new_block.index, self.block.index)
            self.assertEqual(new_block.previous_hash, self.block.previous_hash)
            self.assertEqual(new_block.validator, self.block.validator)
            self.assertEqual(len(new_block.transactions), len(self.block.transactions))
            self.assertEqual(new_block.hash, self.block.hash)
    
    class TestNode(unittest.TestCase):
        def setUp(self):
            """Set up test environment before each test method."""
            self.node = Node(
                node_id="test_node",
                cooperative_id="test_coop",
                initial_stake=100.0
            )
    
        def test_initialization(self):
            """Test node initialization with proper values."""
            self.assertEqual(self.node.node_id, "test_node")
            self.assertEqual(self.node.cooperative_id, "test_coop")
            self.assertEqual(self.node.stake, 100.0)
            self.assertEqual(self.node.metadata["status"], "active")
            self.assertGreater(len(self.node.reputation_scores), 0)
    
        def test_update_reputation(self):
            """Test updating reputation scores."""
            category = "validation"
            initial_score = self.node.reputation_scores[category]
            
            # Test positive update
            success = self.node.update_reputation(
                category=category,
                score=5.0,
                cooperative_id="test_coop",
                evidence={"type": "successful_validation"}
            )
            self.assertTrue(success)
            self.assertEqual(self.node.reputation_scores[category], initial_score + 5.0)
            
            # Test invalid category
            success = self.node.update_reputation(
                category="invalid_category",
                score=3.0
            )
            self.assertFalse(success)
    
        def test_assign_to_shard(self):
            """Test shard assignment logic."""
            # Test successful assignment
            self.assertTrue(self.node.assign_to_shard(1))
            self.assertIn(1, self.node.shard_assignments)
            
            # Test maximum shard limit
            self.node.assign_to_shard(2)
            self.node.assign_to_shard(3)
            self.assertFalse(self.node.assign_to_shard(4))
    
        def test_can_validate(self):
            """Test validation eligibility checks."""
            # Test initial state
            self.assertTrue(self.node.can_validate())
            
            # Test cooldown period
            self.node.enter_cooldown(2)
            self.assertFalse(self.node.can_validate())
            
            # Test shard-specific validation
            self.node.assign_to_shard(1)
            self.assertTrue(self.node.can_validate(1))
            self.assertFalse(self.node.can_validate(2))
    
        def test_to_dict_from_dict(self):
            """Test converting node to dict and back."""
            node_dict = self.node.to_dict()
            restored_node = Node.from_dict(node_dict)
            
            self.assertEqual(restored_node.node_id, self.node.node_id)
            self.assertEqual(restored_node.cooperative_id, self.node.cooperative_id)
            self.assertEqual(restored_node.stake, self.node.stake)
            self.assertEqual(restored_node.reputation_scores, self.node.reputation_scores)
    
    if __name__ == '__main__':
        unittest.main()
```


# ============================================================
# File: /home/matt/icn-prototype/tests/unit/test_transaction.py
# Size: 7391 bytes
# Last Modified: Thu Oct 24 01:07:38 2024
# Language: py
# ============================================================

```py
    # tests/unit/test_transaction.py
    
    import unittest
    from datetime import datetime, timedelta
    import json
    import sys
    import os
    import hashlib
    from typing import Dict
    
    # Add project root to Python path
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    sys.path.insert(0, project_root)
    
    from blockchain.core.transaction import Transaction
    
    class TestTransaction(unittest.TestCase):
        """Test cases for the Transaction class."""
    
        def setUp(self):
            """Set up test fixtures before each test method."""
            self.transaction_data = {
                "amount": 100.0,
                "fee": 1.0,
                "metadata": {"type": "transfer"}
            }
            
            self.transaction = Transaction(
                sender="sender123",
                receiver="receiver456",
                action="transfer",
                data=self.transaction_data.copy(),
                shard_id=1
            )
    
        def test_initialization(self):
            """Test transaction initialization and attribute setting."""
            self.assertEqual(self.transaction.sender, "sender123")
            self.assertEqual(self.transaction.receiver, "receiver456")
            self.assertEqual(self.transaction.action, "transfer")
            self.assertEqual(self.transaction.data["amount"], 100.0)
            self.assertEqual(self.transaction.shard_id, 1)
            self.assertIsNotNone(self.transaction.timestamp)
            self.assertIsNotNone(self.transaction.transaction_id)
    
        def test_invalid_initialization(self):
            """Test transaction initialization with invalid data."""
            # Test empty sender
            with self.assertRaises(ValueError):
                Transaction(
                    sender="",
                    receiver="receiver456",
                    action="transfer",
                    data=self.transaction_data,
                    shard_id=1
                )
    
            # Test empty receiver
            with self.assertRaises(ValueError):
                Transaction(
                    sender="sender123",
                    receiver="",
                    action="transfer",
                    data=self.transaction_data,
                    shard_id=1
                )
    
            # Test empty action
            with self.assertRaises(ValueError):
                Transaction(
                    sender="sender123",
                    receiver="receiver456",
                    action="",
                    data=self.transaction_data,
                    shard_id=1
                )
    
        def test_transaction_id_consistency(self):
            """Test that transaction ID remains consistent after serialization."""
            # Create two identical transactions
            tx1 = Transaction(
                sender="sender123",
                receiver="receiver456",
                action="transfer",
                data=self.transaction_data.copy(),
                shard_id=1
            )
            
            # Convert to dict and back
            tx_dict = tx1.to_dict()
            tx2 = Transaction.from_dict(tx_dict)
            
            # IDs should match
            self.assertEqual(tx1.transaction_id, tx2.transaction_id)
            
            # Create transaction with same data but different timestamp
            tx3 = Transaction(
                sender="sender123",
                receiver="receiver456",
                action="transfer",
                data=self.transaction_data.copy(),
                shard_id=1
            )
            
            # IDs should be different due to timestamp
            self.assertNotEqual(tx1.transaction_id, tx3.transaction_id)
    
        def test_validation(self):
            """Test transaction validation."""
            # Valid transaction should pass
            self.assertTrue(self.transaction.validate())
            
            # Test invalid timestamp
            tx = Transaction(
                sender="sender123",
                receiver="receiver456",
                action="transfer",
                data=self.transaction_data.copy(),
                shard_id=1
            )
            tx.timestamp = datetime.now() + timedelta(hours=1)
            self.assertFalse(tx.validate())
            
            # Test invalid shard_id
            tx = Transaction(
                sender="sender123",
                receiver="receiver456",
                action="transfer",
                data=self.transaction_data.copy(),
                shard_id=-1
            )
            self.assertFalse(tx.validate())
            
            # Test invalid data type
            tx = Transaction(
                sender="sender123",
                receiver="receiver456",
                action="transfer",
                data="invalid_data",  # Should be dict
                shard_id=1
            )
            self.assertFalse(tx.validate())
    
        def test_serialization(self):
            """Test transaction serialization and deserialization."""
            # Convert to dictionary
            tx_dict = self.transaction.to_dict()
            
            # Verify dictionary structure
            self.assertIn("transaction_id", tx_dict)
            self.assertIn("sender", tx_dict)
            self.assertIn("receiver", tx_dict)
            self.assertIn("action", tx_dict)
            self.assertIn("data", tx_dict)
            self.assertIn("timestamp", tx_dict)
            self.assertIn("shard_id", tx_dict)
            
            # Create new transaction from dictionary
            new_tx = Transaction.from_dict(tx_dict)
            
            # Verify all attributes match
            self.assertEqual(new_tx.transaction_id, self.transaction.transaction_id)
            self.assertEqual(new_tx.sender, self.transaction.sender)
            self.assertEqual(new_tx.receiver, self.transaction.receiver)
            self.assertEqual(new_tx.action, self.transaction.action)
            self.assertEqual(new_tx.data, self.transaction.data)
            self.assertEqual(new_tx.shard_id, self.transaction.shard_id)
            self.assertEqual(new_tx.timestamp, self.transaction.timestamp)
    
        def test_hash_consistency(self):
            """Test that transaction hash calculation is consistent."""
            tx1_hash = self.transaction.calculate_hash()
            tx1_dict = self.transaction.to_dict()
            tx2 = Transaction.from_dict(tx1_dict)
            tx2_hash = tx2.calculate_hash()
            
            self.assertEqual(tx1_hash, tx2_hash)
            
            # Modify transaction and verify hash changes
            self.transaction.data["amount"] = 200.0
            self.assertNotEqual(self.transaction.calculate_hash(), tx1_hash)
    
        def test_deep_copy_data(self):
            """Test that transaction data is properly deep copied."""
            nested_data = {
                "amount": 100.0,
                "metadata": {
                    "tags": ["test", "transfer"],
                    "extra": {"note": "test transaction"}
                }
            }
            
            tx = Transaction(
                sender="sender123",
                receiver="receiver456",
                action="transfer",
                data=nested_data,
                shard_id=1
            )
            
            # Modify original data
            nested_data["metadata"]["tags"].append("modified")
            
            # Transaction data should be unchanged
            self.assertEqual(len(tx.data["metadata"]["tags"]), 2)
            self.assertNotIn("modified", tx.data["metadata"]["tags"])
    
        def test_timestamp_serialization(self):
            """Test that timestamp is properly serialized and deserialized."""
            tx_dict = self.transaction.to_dict()
            new_tx = Transaction.from_dict(tx_dict)
            
            self.assertEqual(
                self.transaction.timestamp.isoformat(),
                new_tx.timestamp.isoformat()
            )
    
    if __name__ == '__main__':
        unittest.main()
```


# ============================================================
# File: /home/matt/icn-prototype/tests/unit/test_blockchain.py
# Size: 5893 bytes
# Last Modified: Thu Oct 24 01:25:41 2024
# Language: py
# ============================================================

```py
    import pytest
    import asyncio
    from datetime import datetime
    
    from blockchain.core.blockchain import Blockchain
    from blockchain.core.node import Node
    from blockchain.core.block import Block
    from blockchain.contracts.smart_contract import SmartContract
    from blockchain.core.transaction import Transaction
    
    @pytest.fixture
    def blockchain():
        """
        Fixture to create a fresh instance of the Blockchain for each test.
        """
        return Blockchain(num_shards=3, initial_mana=1000, mana_regen_rate=10)
    
    def test_initialization(blockchain):
        """
        Test the initialization of the Blockchain.
        """
        assert isinstance(blockchain, Blockchain)
        assert blockchain.cooperative_mana == 1000
        assert blockchain.mana_regen_rate == 10
        assert len(blockchain.shards) == 3
        assert blockchain.genesis_block_created is True
    
    def test_register_node(blockchain):
        """
        Test node registration functionality.
        """
        node = Node(node_id="node_1")
        assert blockchain.register_node(node) is True
        assert node.node_id in blockchain.nodes
    
        # Duplicate registration should fail
        assert blockchain.register_node(node) is False
    
    def test_create_shard(blockchain):
        """
        Test shard creation in the Blockchain.
        """
        assert blockchain.create_shard(3) is True
        assert 3 in blockchain.shards
    
        # Attempt to create an existing shard
        assert blockchain.create_shard(3) is False
    
    def test_add_transaction(blockchain):
        """
        Test adding a transaction to the Blockchain.
        """
        transaction = {
            "sender": "alice",
            "receiver": "bob",
            "action": "transfer",
            "data": {"amount": 50}
        }
    
        # Add a valid transaction
        assert blockchain.add_transaction(transaction) is True
    
        # Add an invalid transaction
        invalid_transaction = "invalid_format"
        assert blockchain.add_transaction(invalid_transaction) is False
    
    def test_create_block(blockchain):
        """
        Test block creation in the Blockchain.
        """
        node = Node(node_id="node_1")
        blockchain.register_node(node)
    
        # Create a block in a valid shard
        shard_id = 0
        block = blockchain.create_block(shard_id)
        assert block is not None
        assert isinstance(block, Block)
    
        # Attempt to create a block in an invalid shard
        invalid_shard_id = 99
        assert blockchain.create_block(invalid_shard_id) is None
    
    def test_add_block(blockchain):
        """
        Test adding a block to the Blockchain.
        """
        node = Node(node_id="node_1")
        blockchain.register_node(node)
    
        block = Block(
            index=1,
            previous_hash=blockchain.chain[-1].hash,
            timestamp=datetime.now(),
            transactions=[],
            validator="node_1",
            shard_id=0
        )
    
        # Add a valid block
        assert blockchain.add_block(block) is True
    
        # Add an invalid block (invalid previous hash)
        invalid_block = Block(
            index=2,
            previous_hash="invalid_hash",
            timestamp=datetime.now(),
            transactions=[],
            validator="node_1",
            shard_id=0
        )
        assert blockchain.add_block(invalid_block) is False
    
    def test_mana_regeneration(blockchain):
        """
        Test mana regeneration functionality.
        """
        # Deplete some mana
        blockchain.cooperative_mana -= 100
        blockchain.regenerate_mana()
    
        # Check if mana regenerated correctly
        assert blockchain.cooperative_mana == 910  # 1000 - 100 + 10
    
    def test_get_chain_metrics(blockchain):
        """
        Test retrieving blockchain metrics.
        """
        metrics = blockchain.get_chain_metrics()
        assert isinstance(metrics, dict)
        assert metrics["chain_length"] == 1  # Genesis block
        assert metrics["cooperative_mana"] == 1000
        assert metrics["active_nodes"] == 0
        assert metrics["active_shards"] == 3
    
    def test_validate_chain(blockchain):
        """
        Test the entire blockchain validation.
        """
        node = Node(node_id="node_1")
        blockchain.register_node(node)
    
        block = Block(
            index=1,
            previous_hash=blockchain.chain[-1].hash,
            timestamp=datetime.now(),
            transactions=[],
            validator="node_1",
            shard_id=0
        )
        blockchain.add_block(block)
    
        # Validate the blockchain
        assert blockchain.validate_chain() is True
    
        # Corrupt the chain
        blockchain.chain[-1].previous_hash = "corrupt_hash"
        assert blockchain.validate_chain() is False
    
    def test_smart_contract_deployment(blockchain):
        """
        Test deploying a smart contract to the Blockchain.
        """
        contract = SmartContract(
            contract_id="contract_1",
            creator="node_1",
            code="dummy_code",
            mana_cost=100
        )
    
        result = asyncio.run(blockchain.deploy_smart_contract(contract))
        assert result is True
        assert "contract_1" in blockchain.smart_contracts
    
        # Deploy an invalid contract (e.g., insufficient mana)
        contract_2 = SmartContract(
            contract_id="contract_2",
            creator="node_1",
            code="dummy_code",
            mana_cost=2000  # Exceeds available mana
        )
    
        result = asyncio.run(blockchain.deploy_smart_contract(contract_2))
        assert result is False
    
    def test_smart_contract_execution(blockchain):
        """
        Test executing a smart contract on the Blockchain.
        """
        contract = SmartContract(
            contract_id="contract_1",
            creator="node_1",
            code="dummy_code",
            mana_cost=50
        )
    
        asyncio.run(blockchain.deploy_smart_contract(contract))
    
        input_data = {"param": "value"}
        result = asyncio.run(blockchain.execute_smart_contract(
            contract_id="contract_1",
            input_data=input_data,
            caller="node_1"
        ))
        assert result is not None
    
        # Attempt to execute a non-existent contract
        result = asyncio.run(blockchain.execute_smart_contract(
            contract_id="non_existent",
            input_data=input_data,
            caller="node_1"
        ))
        assert result is None
```


# ============================================================
# File: /home/matt/icn-prototype/tests/unit/test_smart_contract.py
# Size: 10483 bytes
# Last Modified: Thu Oct 24 21:05:29 2024
# Language: py
# ============================================================

```py
    import unittest
    from datetime import datetime, timedelta
    import sys
    import os
    from typing import Dict, Optional
    
    # Add project root to Python path
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    sys.path.insert(0, project_root)
    
    from blockchain.contracts.smart_contract import SmartContract, ContractExecutionError
    
    class TestSmartContract(unittest.TestCase):
        """Test cases for the SmartContract class."""
    
        def setUp(self):
            """Set up test fixtures before each test method."""
            self.sample_code = """
    def execute(input_data, state):
        # Simple contract that adds numbers
        a = input_data.get('a', 0)
        b = input_data.get('b', 0)
        result = a + b
        state['last_result'] = result
        return result
    """
            self.contract = SmartContract(
                contract_id="test_contract",
                code=self.sample_code,
                creator="test_creator",
                mana_cost=10,
                version="1.0"
            )
    
        def test_initialization(self):
            """Test smart contract initialization and attributes."""
            self.assertEqual(self.contract.contract_id, "test_contract")
            self.assertEqual(self.contract.creator, "test_creator")
            self.assertEqual(self.contract.mana_cost, 10)
            self.assertEqual(self.contract.version, "1.0")
            self.assertEqual(self.contract.state, {})
            self.assertEqual(self.contract.execution_count, 0)
            self.assertEqual(self.contract.total_mana_consumed, 0)
            self.assertIsNone(self.contract.last_executed)
            self.assertIn(self.contract.creator, self.contract.allowed_callers)
    
        def test_execute_valid_contract(self):
            """Test execution of a valid contract."""
            input_data = {"a": 5, "b": 3}
            result = self.contract.execute(input_data, available_mana=20)
            
            self.assertEqual(result["result"], 8)
            self.assertEqual(result["mana_used"], 10)
            self.assertEqual(self.contract.state["last_result"], 8)
            self.assertEqual(self.contract.execution_count, 1)
            self.assertEqual(self.contract.total_mana_consumed, 10)
            self.assertIsNotNone(self.contract.last_executed)
    
        def test_execute_insufficient_mana(self):
            """Test execution with insufficient mana."""
            input_data = {"a": 5, "b": 3}
            
            with self.assertRaises(ContractExecutionError) as context:
                self.contract.execute(input_data, available_mana=5)
            
            self.assertIn("Insufficient mana", str(context.exception))
            self.assertEqual(self.contract.execution_count, 0)
            self.assertEqual(self.contract.total_mana_consumed, 0)
    
        def test_execute_invalid_code(self):
            """Test execution with invalid contract code."""
            invalid_contract = SmartContract(
                contract_id="invalid_contract",
                code="def invalid_function(): return 'no execute'",
                creator="test_creator",
                mana_cost=10
            )
            
            with self.assertRaises(ContractExecutionError) as context:
                invalid_contract.execute({}, available_mana=20)
            
            self.assertIn("Contract missing execute function", str(context.exception))
    
        def test_execute_with_state_updates(self):
            """Test contract execution with state updates."""
            # First execution
            result1 = self.contract.execute({"a": 5, "b": 3}, available_mana=20)
            self.assertEqual(self.contract.state["last_result"], 8)
            
            # Second execution
            result2 = self.contract.execute({"a": 2, "b": 4}, available_mana=20)
            self.assertEqual(self.contract.state["last_result"], 6)
            
            self.assertEqual(self.contract.execution_count, 2)
            self.assertEqual(self.contract.total_mana_consumed, 20)
    
        def test_execution_limits(self):
            """Test contract execution limits."""
            # Set low daily limit for testing
            self.contract.restrictions["max_daily_executions"] = 2
            
            # First execution
            self.contract.execute({"a": 1, "b": 2}, available_mana=20)
            # Second execution
            self.contract.execute({"a": 3, "b": 4}, available_mana=20)
            
            # Third execution should fail
            with self.assertRaises(ContractExecutionError) as context:
                self.contract.execute({"a": 5, "b": 6}, available_mana=20)
            
            self.assertIn("Daily execution limit exceeded", str(context.exception))
            self.assertEqual(self.contract.execution_count, 2)
    
        def test_authorize_and_revoke_caller(self):
            """Test caller authorization management."""
            new_caller = "new_caller"
            
            # Test authorization
            self.assertTrue(self.contract.authorize_caller(new_caller))
            self.assertIn(new_caller, self.contract.allowed_callers)
            
            # Test revocation
            self.assertTrue(self.contract.revoke_caller(new_caller))
            self.assertNotIn(new_caller, self.contract.allowed_callers)
            
            # Test creator cannot be revoked
            self.assertFalse(self.contract.revoke_caller(self.contract.creator))
            self.assertIn(self.contract.creator, self.contract.allowed_callers)
    
        def test_update_restrictions(self):
            """Test updating contract restrictions."""
            new_restrictions = {
                "max_state_size": 2048,
                "max_execution_time": 10
            }
            
            self.assertTrue(self.contract.update_restrictions(new_restrictions))
            self.assertEqual(self.contract.restrictions["max_state_size"], 2048)
            self.assertEqual(self.contract.restrictions["max_execution_time"], 10)
            
            # Test invalid restriction update
            invalid_restrictions = {"invalid_key": 100}
            self.assertFalse(self.contract.update_restrictions(invalid_restrictions))
    
        def test_serialization(self):
            """Test contract serialization and deserialization."""
            # Execute contract to populate some data
            self.contract.execute({"a": 5, "b": 3}, available_mana=20)
            
            # Convert to dictionary
            contract_dict = self.contract.to_dict()
            
            # Create new contract from dictionary
            new_contract = SmartContract.from_dict(contract_dict)
            
            # Verify attributes
            self.assertEqual(new_contract.contract_id, self.contract.contract_id)
            self.assertEqual(new_contract.creator, self.contract.creator)
            self.assertEqual(new_contract.code, self.contract.code)
            self.assertEqual(new_contract.mana_cost, self.contract.mana_cost)
            self.assertEqual(new_contract.version, self.contract.version)
            self.assertEqual(new_contract.state, self.contract.state)
            self.assertEqual(new_contract.restrictions, self.contract.restrictions)
    
        def test_execution_history(self):
            """Test execution history tracking."""
            # Multiple executions
            self.contract.execute({"a": 1, "b": 2}, available_mana=20)
            self.contract.execute({"a": 3, "b": 4}, available_mana=20)
            
            # Check history
            self.assertEqual(len(self.contract.execution_history), 2)
            
            # Verify history entries
            latest_execution = self.contract.execution_history[-1]
            self.assertIn("timestamp", latest_execution)
            self.assertIn("execution_time", latest_execution)
            self.assertIn("mana_used", latest_execution)
            self.assertIn("state_size", latest_execution)
    
        def test_get_metrics(self):
            """Test contract metrics calculation."""
            # Execute contract
            self.contract.execute({"a": 5, "b": 3}, available_mana=20)
            
            metrics = self.contract.get_metrics()
            
            self.assertEqual(metrics["contract_id"], "test_contract")
            self.assertEqual(metrics["version"], "1.0")
            self.assertEqual(metrics["creator"], "test_creator")
            self.assertEqual(metrics["execution_count"], 1)
            self.assertEqual(metrics["total_mana_consumed"], 10)
            self.assertGreater(metrics["state_size"], 0)
    
        def test_state_size_limit(self):
            """Test contract state size limitations."""
            # Create contract that grows state
            growing_code = """
    def execute(input_data, state):
        # Add large data to state
        state['data'] = 'x' * input_data['size']
        return len(state['data'])
    """
            growing_contract = SmartContract(
                contract_id="growing_contract",
                code=growing_code,
                creator="test_creator",
                mana_cost=10
            )
            
            # Set small state size limit
            growing_contract.restrictions["max_state_size"] = 100
            
            # Execute with small state update
            growing_contract.execute({"size": 50}, available_mana=20)
            
            # Execute with too large state update
            with self.assertRaises(ContractExecutionError) as context:
                growing_contract.execute({"size": 200}, available_mana=20)
            
            self.assertIn("State size limit exceeded", str(context.exception))
    
        def test_dependencies(self):
            """Test contract dependency management."""
            dependency_id = "dependency_contract"
            
            # Add dependency
            self.contract.dependencies.add(dependency_id)
            self.assertIn(dependency_id, self.contract.dependencies)
            
            # Verify serialization includes dependencies
            contract_dict = self.contract.to_dict()
            self.assertIn(dependency_id, contract_dict["dependencies"])
            
            # Create new contract from dict and verify dependencies
            new_contract = SmartContract.from_dict(contract_dict)
            self.assertIn(dependency_id, new_contract.dependencies)
    
        def test_metadata_updates(self):
            """Test contract metadata management."""
            # Update metadata
            self.contract.metadata["description"] = "Test contract"
            self.contract.metadata["tags"].add("test")
            
            # Verify serialization includes metadata
            contract_dict = self.contract.to_dict()
            self.assertEqual(contract_dict["metadata"]["description"], "Test contract")
            self.assertIn("test", contract_dict["metadata"]["tags"])
            
            # Create new contract and verify metadata
            new_contract = SmartContract.from_dict(contract_dict)
            self.assertEqual(new_contract.metadata["description"], "Test contract")
            self.assertIn("test", new_contract.metadata["tags"])
    
    if __name__ == '__main__':
        unittest.main()
```


# ============================================================
# File: /home/matt/icn-prototype/tests/unit/__init__.py
# Size: 0 bytes
# Last Modified: Wed Oct 23 19:46:07 2024
# Language: py
# ============================================================

```py

```


# ============================================================
# File: /home/matt/icn-prototype/system/marketplace.py
# Size: 2585 bytes
# Last Modified: Mon Oct 21 16:24:43 2024
# Language: py
# ============================================================

```py
    from typing import Dict
    
    class Listing:
        def __init__(self, id, seller, item, price):
            self.id = id
            self.seller = seller
            self.item = item
            self.price = price
    
    class Order:
        def __init__(self, id, buyer, listing):
            self.id = id
            self.buyer = buyer
            self.listing = listing
            self.status = "pending"
    
    class Marketplace:
        def __init__(self, blockchain, did_registry):
            self.blockchain = blockchain
            self.did_registry = did_registry
            self.listings: Dict[str, Listing] = {}
            self.orders: Dict[str, Order] = {}
    
        def create_listing(self, listing_id, seller_did, item, price):
            seller = self.did_registry.resolve_did(seller_did)
            if not seller:
                return None
            
            listing = Listing(listing_id, seller_did, item, price)
            self.listings[listing_id] = listing
            self.blockchain.add_new_block(f"Listing created: {listing_id}", 1)  # Assume shard 1 for marketplace
            return listing_id
    
        def remove_listing(self, listing_id, seller_did):
            listing = self.listings.get(listing_id)
            if listing and listing.seller == seller_did:
                del self.listings[listing_id]
                self.blockchain.add_new_block(f"Listing removed: {listing_id}", 1)
                return True
            return False
    
        def place_order(self, order_id, buyer_did, listing_id):
            listing = self.listings.get(listing_id)
            buyer = self.did_registry.resolve_did(buyer_did)
            if not listing or not buyer:
                return False
            
            order = Order(order_id, buyer_did, listing)
            self.orders[order_id] = order
            self.blockchain.add_new_block(f"Order placed: {order_id}", 1)
            return True
    
        def complete_order(self, order_id):
            order = self.orders.get(order_id)
            if not order:
                return None
            
            # In a real system, you'd implement escrow release here
            order.status = "completed"
            self.blockchain.add_new_block(f"Order completed: {order_id}", 1)
            return order
    
        def get_listing(self, listing_id):
            return self.listings.get(listing_id)
    
        def get_order(self, order_id):
            return self.orders.get(order_id)
    
        def list_listings(self):
            return self.listings
    
        def list_orders(self):
            return self.orders
    
        def get_seller_reputation(self, seller_did):
            seller = self.did_registry.resolve_did(seller_did)
            if seller:
                return seller.get_reputation_scores().get("marketplace", 0)
            return 0
```


# ============================================================
# File: /home/matt/icn-prototype/system/reputation.py
# Size: 9930 bytes
# Last Modified: Wed Oct 23 00:52:39 2024
# Language: py
# ============================================================

```py
    # system/reputation.py
    
    from typing import Dict, List, Optional, Set
    from datetime import datetime, timedelta
    import logging
    from dataclasses import dataclass, field
    import math
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class ReputationEvent:
        """Represents a reputation-changing event."""
        category: str
        score: float
        timestamp: datetime
        evidence: Optional[Dict] = None
        decay_rate: float = 0.1
    
        def get_current_value(self, current_time: datetime) -> float:
            """Calculate the current value of the reputation event with decay."""
            age = (current_time - self.timestamp).total_seconds() / (24 * 3600)  # age in days
            return self.score * math.exp(-self.decay_rate * age)
    
    class ReputationCategory:
        """Manages reputation for a specific category."""
        
        def __init__(self, name: str, weight: float = 1.0, 
                     decay_rate: float = 0.1):
            self.name = name
            self.weight = weight
            self.decay_rate = decay_rate
            self.events: List[ReputationEvent] = []
            self.minimum_score = 0.0
            self.maximum_score = float('inf')
    
        def add_event(self, score: float, evidence: Optional[Dict] = None) -> None:
            """Add a new reputation event."""
            event = ReputationEvent(
                category=self.name,
                score=score,
                timestamp=datetime.now(),
                evidence=evidence,
                decay_rate=self.decay_rate
            )
            self.events.append(event)
    
        def get_current_score(self) -> float:
            """Calculate current score with decay."""
            current_time = datetime.now()
            total_score = sum(event.get_current_value(current_time) 
                             for event in self.events)
            return max(min(total_score, self.maximum_score), self.minimum_score)
    
        def prune_old_events(self, max_age_days: int = 30) -> None:
            """Remove events older than specified age."""
            cutoff_time = datetime.now() - timedelta(days=max_age_days)
            self.events = [event for event in self.events 
                          if event.timestamp >= cutoff_time]
    
    class ReputationSystem:
        """Enhanced reputation system for ICN."""
        
        def __init__(self):
            self.categories: Dict[str, ReputationCategory] = {
                "validation": ReputationCategory("validation", 1.0, 0.1),
                "voting": ReputationCategory("voting", 1.2, 0.05),
                "proposal_creation": ReputationCategory("proposal_creation", 1.5, 0.03),
                "development": ReputationCategory("development", 2.0, 0.02),
                "budget_management": ReputationCategory("budget_management", 1.8, 0.08),
                "community_building": ReputationCategory("community_building", 1.3, 0.04),
                "resource_sharing": ReputationCategory("resource_sharing", 1.4, 0.06),
                "cooperative_growth": ReputationCategory("cooperative_growth", 1.6, 0.03),
                "conflict_resolution": ReputationCategory("conflict_resolution", 1.7, 0.05),
                "sustainability": ReputationCategory("sustainability", 1.5, 0.04),
                "participation": ReputationCategory("participation", 1.1, 0.07),
                "innovation": ReputationCategory("innovation", 1.9, 0.02),
            }
            self.user_reputations: Dict[str, Dict[str, ReputationCategory]] = {}
            self.user_metadata: Dict[str, Dict] = {}
            self.registered_users: Set[str] = set()
            
        def add_user(self, user_id: str, metadata: Optional[Dict] = None) -> None:
            """Initialize reputation categories for a new user."""
            if user_id not in self.user_reputations:
                self.user_reputations[user_id] = {
                    name: ReputationCategory(name, cat.weight, cat.decay_rate)
                    for name, cat in self.categories.items()
                }
                self.user_metadata[user_id] = metadata or {}
                self.registered_users.add(user_id)
                logger.info(f"Initialized reputation for user: {user_id}")
    
        def remove_user(self, user_id: str) -> bool:
            """Remove a user from the reputation system."""
            if user_id in self.user_reputations:
                del self.user_reputations[user_id]
                del self.user_metadata[user_id]
                self.registered_users.remove(user_id)
                logger.info(f"Removed user: {user_id}")
                return True
            return False
    
        def get_all_users(self) -> List[str]:
            """Get list of all registered users."""
            return list(self.registered_users)
    
        def update_reputation(self, user_id: str, score: float, 
                             category: str, evidence: Optional[Dict] = None) -> bool:
            """Update a user's reputation with evidence."""
            if user_id not in self.user_reputations:
                logger.warning(f"Unknown user: {user_id}")
                return False
            
            if category not in self.user_reputations[user_id]:
                logger.warning(f"Unknown category: {category}")
                return False
    
            if score == 0:
                return True
    
            self.user_reputations[user_id][category].add_event(score, evidence)
            logger.info(f"Updated reputation for {user_id} in {category}: {score}")
            
            # Update participation category automatically
            if category != "participation":
                self.user_reputations[user_id]["participation"].add_event(
                    abs(score) * 0.1,  # Small participation score for any activity
                    {"source_category": category}
                )
            
            return True
    
        def get_reputation(self, user_id: str) -> Dict[str, float]:
            """Get current reputation scores for a user."""
            if user_id not in self.user_reputations:
                return {}
            
            return {
                category: rep_category.get_current_score()
                for category, rep_category in self.user_reputations[user_id].items()
            }
    
        def get_total_reputation(self, user_id: str) -> float:
            """Calculate total weighted reputation score."""
            if user_id not in self.user_reputations:
                return 0.0
            
            scores = self.get_reputation(user_id)
            weighted_scores = [
                score * self.categories[category].weight
                for category, score in scores.items()
            ]
            return sum(weighted_scores)
    
        def get_user_ranking(self, category: Optional[str] = None) -> List[tuple]:
            """Get users ranked by reputation in a category or overall."""
            if category and category not in self.categories:
                return []
    
            rankings = []
            for user_id in self.registered_users:
                if category:
                    score = self.get_reputation(user_id).get(category, 0)
                else:
                    score = self.get_total_reputation(user_id)
                rankings.append((user_id, score))
    
            return sorted(rankings, key=lambda x: x[1], reverse=True)
    
        def apply_decay(self) -> None:
            """Apply reputation decay to all users."""
            current_time = datetime.now()
            for user_reputations in self.user_reputations.values():
                for category in user_reputations.values():
                    category.prune_old_events()
    
        def get_reputation_history(self, user_id: str, category: str,
                                 days: int = 30) -> List[Dict]:
            """Get historical reputation events for a category."""
            if user_id not in self.user_reputations:
                return []
            
            category_rep = self.user_reputations[user_id].get(category)
            if not category_rep:
                return []
    
            cutoff_time = datetime.now() - timedelta(days=days)
            history = []
            
            for event in category_rep.events:
                if event.timestamp >= cutoff_time:
                    history.append({
                        'timestamp': event.timestamp,
                        'score': event.score,
                        'evidence': event.evidence,
                        'current_value': event.get_current_value(datetime.now())
                    })
                    
            return sorted(history, key=lambda x: x['timestamp'])
    
        def get_category_thresholds(self, category: str) -> Optional[Dict[str, float]]:
            """Get the minimum and maximum thresholds for a category."""
            if category not in self.categories:
                return None
                
            return {
                'minimum': self.categories[category].minimum_score,
                'maximum': self.categories[category].maximum_score
            }
    
        def set_category_thresholds(self, category: str, 
                                  minimum: float, maximum: float) -> bool:
            """Set the minimum and maximum thresholds for a category."""
            if category not in self.categories:
                return False
                
            if minimum > maximum:
                return False
                
            self.categories[category].minimum_score = minimum
            self.categories[category].maximum_score = maximum
            return True
    
        def get_system_stats(self) -> Dict:
            """Get system-wide reputation statistics."""
            stats = {
                'total_users': len(self.registered_users),
                'total_events': 0,
                'category_averages': {},
                'top_users': self.get_user_ranking()[:10]
            }
            
            for category in self.categories:
                scores = []
                total_events = 0
                for user_id in self.registered_users:
                    user_rep = self.user_reputations.get(user_id, {}).get(category)
                    if user_rep:
                        scores.append(user_rep.get_current_score())
                        total_events += len(user_rep.events)
                
                if scores:
                    stats['category_averages'][category] = sum(scores) / len(scores)
                else:
                    stats['category_averages'][category] = 0
                
                stats['total_events'] += total_events
            
            return stats
```


# ============================================================
# File: /home/matt/icn-prototype/system/governance.py
# Size: 13214 bytes
# Last Modified: Wed Oct 23 00:38:44 2024
# Language: py
# ============================================================

```py
    # system/governance.py
    
    from typing import Dict, List, Optional, Union
    from datetime import datetime, timedelta
    import logging
    from dataclasses import dataclass, field
    import math
    import json
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class Proposal:
        """Represents a governance proposal in the ICN system."""
        id: str
        title: str
        description: str
        creator: str
        proposal_type: str
        options: List[str]
        amount: Optional[float] = None
        start_time: datetime = field(default_factory=datetime.now)
        end_time: Optional[datetime] = None
        status: str = "pending"
        metadata: Dict = field(default_factory=dict)
        votes: Dict[str, int] = field(default_factory=dict)
        vote_weights: Dict[str, float] = field(default_factory=dict)
        
        def to_dict(self) -> Dict:
            """Convert proposal to dictionary format."""
            return {
                'id': self.id,
                'title': self.title,
                'description': self.description,
                'creator': self.creator,
                'type': self.proposal_type,
                'options': self.options,
                'amount': self.amount,
                'start_time': self.start_time.isoformat(),
                'end_time': self.end_time.isoformat() if self.end_time else None,
                'status': self.status,
                'metadata': self.metadata,
                'votes': self.votes,
                'vote_weights': self.vote_weights
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> 'Proposal':
            """Create proposal from dictionary."""
            proposal = cls(
                id=data['id'],
                title=data['title'],
                description=data['description'],
                creator=data['creator'],
                proposal_type=data['type'],
                options=data['options'],
                amount=data.get('amount'),
                start_time=datetime.fromisoformat(data['start_time']),
                status=data['status'],
                metadata=data.get('metadata', {})
            )
            if data.get('end_time'):
                proposal.end_time = datetime.fromisoformat(data['end_time'])
            proposal.votes = data.get('votes', {})
            proposal.vote_weights = data.get('vote_weights', {})
            return proposal
    
    class VotingSystem:
        """Manages voting mechanics for proposals."""
        
        def __init__(self, quorum_percentage: float = 0.4):
            self.quorum_percentage = quorum_percentage
            self.vote_records: Dict[str, Dict[str, Dict]] = {}
    
        def cast_vote(self, proposal_id: str, voter_id: str, choice: str,
                      weight: float = 1.0) -> bool:
            """Cast a weighted vote on a proposal."""
            if proposal_id not in self.vote_records:
                self.vote_records[proposal_id] = {}
                
            self.vote_records[proposal_id][voter_id] = {
                'choice': choice,
                'weight': weight,
                'timestamp': datetime.now()
            }
            return True
    
        def get_results(self, proposal_id: str) -> Dict[str, float]:
            """Calculate weighted voting results."""
            if proposal_id not in self.vote_records:
                return {}
                
            results = {}
            for vote_info in self.vote_records[proposal_id].values():
                choice = vote_info['choice']
                weight = vote_info['weight']
                results[choice] = results.get(choice, 0) + weight
                
            return results
    
        def has_quorum(self, proposal_id: str, total_voters: int) -> bool:
            """Check if proposal has reached quorum."""
            if proposal_id not in self.vote_records:
                return False
                
            participation = len(self.vote_records[proposal_id]) / total_voters
            return participation >= self.quorum_percentage
    
    class Governance:
        """Main governance system for the ICN."""
        
        def __init__(self, blockchain, reputation_system):
            self.blockchain = blockchain
            self.reputation_system = reputation_system
            self.proposals: Dict[str, Proposal] = {}
            self.voting_system = VotingSystem()
            self.bylaws: Dict[str, str] = {}
            self.funds: float = 0
            self.approval_thresholds = {
                "constitution": 0.75,  # Constitutional changes require 75% approval
                "bylaw": 0.66,        # Bylaw changes require 66% approval
                "budget": 0.60,       # Budget proposals require 60% approval
                "standard": 0.51      # Standard proposals require simple majority
            }
    
        def create_proposal(self, proposal: Proposal) -> bool:
            """Create a new governance proposal."""
            try:
                # Validate creator's reputation
                creator_rep = self.reputation_system.get_reputation(proposal.creator)
                if creator_rep.get('proposal_creation', 0) < 10:
                    logger.warning(f"Insufficient reputation for proposal creation: {proposal.creator}")
                    return False
    
                # Validate proposal type
                if proposal.proposal_type not in self.approval_thresholds:
                    logger.error(f"Invalid proposal type: {proposal.proposal_type}")
                    return False
    
                self.proposals[proposal.id] = proposal
                
                # Create blockchain transaction
                transaction = {
                    'type': 'proposal_creation',
                    'proposal_id': proposal.id,
                    'creator': proposal.creator,
                    'timestamp': datetime.now().isoformat()
                }
                
                self.blockchain.add_transaction(transaction)
                logger.info(f"Created proposal: {proposal.id}")
                return True
                
            except Exception as e:
                logger.error(f"Failed to create proposal: {e}")
                return False
    
        def start_voting(self, proposal_id: str, duration_days: int = 7) -> bool:
            """Start the voting period for a proposal."""
            proposal = self.proposals.get(proposal_id)
            if not proposal or proposal.status != "pending":
                return False
    
            proposal.status = "active"
            proposal.start_time = datetime.now()
            proposal.end_time = proposal.start_time + timedelta(days=duration_days)
    
            transaction = {
                'type': 'voting_start',
                'proposal_id': proposal_id,
                'start_time': proposal.start_time.isoformat(),
                'end_time': proposal.end_time.isoformat()
            }
    
            self.blockchain.add_transaction(transaction)
            logger.info(f"Started voting for proposal: {proposal_id}")
            return True
    
        def cast_vote(self, proposal_id: str, voter_id: str, choice: str) -> bool:
            """Cast a vote on an active proposal."""
            proposal = self.proposals.get(proposal_id)
            if not proposal or proposal.status != "active":
                return False
    
            if datetime.now() > proposal.end_time:
                logger.warning(f"Voting period ended for proposal: {proposal_id}")
                return False
    
            # Calculate voting power based on reputation
            reputation = self.reputation_system.get_reputation(voter_id)
            voting_power = self._calculate_voting_power(reputation)
    
            # Record vote
            if self.voting_system.cast_vote(proposal_id, voter_id, choice, voting_power):
                transaction = {
                    'type': 'vote_cast',
                    'proposal_id': proposal_id,
                    'voter': voter_id,
                    'choice': choice,
                    'weight': voting_power
                }
                self.blockchain.add_transaction(transaction)
    
                # Update voter's reputation
                self.reputation_system.update_reputation(
                    voter_id,
                    1.0,
                    'voting',
                    {'proposal_id': proposal_id}
                )
    
                logger.info(f"Recorded vote from {voter_id} on proposal {proposal_id}")
                return True
    
            return False
    
        def _calculate_voting_power(self, reputation: Dict[str, float]) -> float:
            """Calculate voting power based on reputation scores."""
            # Calculate base voting power from reputation
            base_power = sum(reputation.values()) / len(reputation)
            
            # Apply square root to prevent excessive concentration of power
            return math.sqrt(max(1.0, base_power))
    
        def finalize_proposal(self, proposal_id: str) -> bool:
            """Finalize a proposal after voting period."""
            proposal = self.proposals.get(proposal_id)
            if not proposal or proposal.status != "active":
                return False
    
            if datetime.now() < proposal.end_time:
                logger.warning(f"Voting period still active for proposal: {proposal_id}")
                return False
    
            results = self.voting_system.get_results(proposal_id)
            if not results:
                proposal.status = "failed"
                return False
    
            total_voters = len(self.reputation_system.get_all_users())
            if not self.voting_system.has_quorum(proposal_id, total_voters):
                proposal.status = "failed"
                logger.info(f"Proposal {proposal_id} failed due to lack of quorum")
                return False
    
            # Calculate approval percentage
            total_votes = sum(results.values())
            approval_percentage = results.get("approve", 0) / total_votes
    
            # Get required threshold
            threshold = self.approval_thresholds[proposal.proposal_type]
    
            if approval_percentage >= threshold:
                proposal.status = "approved"
                self._implement_proposal(proposal)
            else:
                proposal.status = "rejected"
    
            transaction = {
                'type': 'proposal_finalization',
                'proposal_id': proposal_id,
                'status': proposal.status,
                'results': results
            }
            self.blockchain.add_transaction(transaction)
    
            logger.info(f"Finalized proposal {proposal_id} with status: {proposal.status}")
            return True
    
        def _implement_proposal(self, proposal: Proposal) -> None:
            """Implement an approved proposal."""
            implementation_handlers = {
                "budget": self._implement_budget_proposal,
                "bylaw": self._implement_bylaw_proposal,
                "constitution": self._implement_constitution_proposal,
            }
            
            handler = implementation_handlers.get(proposal.proposal_type)
            if handler:
                handler(proposal)
    
        def _implement_budget_proposal(self, proposal: Proposal) -> None:
            """Implement a budget proposal."""
            if proposal.amount and self.funds >= proposal.amount:
                self.funds -= proposal.amount
                transaction = {
                    'type': 'budget_execution',
                    'proposal_id': proposal.id,
                    'amount': proposal.amount
                }
                self.blockchain.add_transaction(transaction)
    
        def _implement_bylaw_proposal(self, proposal: Proposal) -> None:
            """Implement a bylaw proposal."""
            self.bylaws[proposal.title] = proposal.description
            transaction = {
                'type': 'bylaw_update',
                'proposal_id': proposal.id,
                'title': proposal.title
            }
            self.blockchain.add_transaction(transaction)
    
        def _implement_constitution_proposal(self, proposal: Proposal) -> None:
            """Implement a constitutional proposal."""
            transaction = {
                'type': 'constitution_update',
                'proposal_id': proposal.id,
                'changes': proposal.metadata.get('changes', {})
            }
            self.blockchain.add_transaction(transaction)
    
        def get_proposal(self, proposal_id: str) -> Optional[Proposal]:
            """Get a specific proposal."""
            return self.proposals.get(proposal_id)
    
        def get_active_proposals(self) -> List[Proposal]:
            """Get all currently active proposals."""
            return [p for p in self.proposals.values() if p.status == "active"]
    
        def get_proposal_metrics(self) -> Dict:
            """Get metrics about proposal activity."""
            return {
                'total_proposals': len(self.proposals),
                'active_proposals': len([p for p in self.proposals.values() if p.status == "active"]),
                'approved_proposals': len([p for p in self.proposals.values() if p.status == "approved"]),
                'rejected_proposals': len([p for p in self.proposals.values() if p.status == "rejected"]),
                'average_participation': self._calculate_average_participation()
            }
    
        def _calculate_average_participation(self) -> float:
            """Calculate average participation rate in voted proposals."""
            voted_proposals = [p for p in self.proposals.values() 
                             if p.status in ["approved", "rejected"]]
            if not voted_proposals:
                return 0.0
    
            total_users = len(self.reputation_system.get_all_users())
            participation_rates = []
    
            for proposal in voted_proposals:
                if proposal.id in self.voting_system.vote_records:
                    participation = len(self.voting_system.vote_records[proposal.id]) / total_users
                    participation_rates.append(participation)
    
            return sum(participation_rates) / len(participation_rates) if participation_rates else 0.0
```


# ============================================================
# File: /home/matt/icn-prototype/system/storage.py
# Size: 1971 bytes
# Last Modified: Mon Oct 21 16:23:58 2024
# Language: py
# ============================================================

```py
    import hashlib
    from typing import Dict, List
    
    class DataChunk:
        def __init__(self, data: bytes):
            self.data = data
            self.hash = hashlib.sha256(data).hexdigest()
    
    class DistributedStorage:
        def __init__(self, blockchain):
            self.blockchain = blockchain
            self.data_chunks: Dict[str, DataChunk] = {}
            self.file_mappings: Dict[str, List[str]] = {}
    
        def store_file(self, file_name: str, data: bytes) -> str:
            chunk_size = 1024 * 1024  # 1 MB chunks
            chunks = [data[i:i+chunk_size] for i in range(0, len(data), chunk_size)]
            
            chunk_hashes = []
            for chunk in chunks:
                data_chunk = DataChunk(chunk)
                self.data_chunks[data_chunk.hash] = data_chunk
                chunk_hashes.append(data_chunk.hash)
            
            file_hash = hashlib.sha256(("".join(chunk_hashes)).encode()).hexdigest()
            self.file_mappings[file_hash] = chunk_hashes
            
            self.blockchain.add_new_block(f"File stored: {file_hash}", 2)  # Assume shard 2 for storage
            return file_hash
    
        def retrieve_file(self, file_hash: str) -> bytes:
            chunk_hashes = self.file_mappings.get(file_hash)
            if not chunk_hashes:
                return None
            
            file_data = b""
            for chunk_hash in chunk_hashes:
                chunk = self.data_chunks.get(chunk_hash)
                if chunk:
                    file_data += chunk.data
                else:
                    return None  # File is incomplete
            
            return file_data
    
        def delete_file(self, file_hash: str) -> bool:
            chunk_hashes = self.file_mappings.get(file_hash)
            if not chunk_hashes:
                return False
            
            for chunk_hash in chunk_hashes:
                if chunk_hash in self.data_chunks:
                    del self.data_chunks[chunk_hash]
            
            del self.file_mappings[file_hash]
            self.blockchain.add_new_block(f"File deleted: {file_hash}", 2)
            return True
```


# ============================================================
# File: /home/matt/icn-prototype/system/__init__.py
# Size: 0 bytes
# Last Modified: Tue Oct 22 00:20:15 2024
# Language: py
# ============================================================

```py

```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/blockchain.py
# Size: 46419 bytes
# Last Modified: Wed Oct 23 01:59:56 2024
# Language: py
# ============================================================

```py
    # blockchain/blockchain.py
    
    import hashlib
    import time
    import math
    import random
    import json
    import signal
    import logging
    from typing import Dict, List, Optional, Tuple, Set, Any, Union
    from dataclasses import dataclass, field
    from datetime import datetime, timedelta
    from cryptography.exceptions import InvalidKey
    from abc import ABC, abstractmethod
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class Transaction:
        """Represents a transaction in the ICN blockchain."""
        sender: str
        receiver: str
        action: str
        data: Dict
        timestamp: datetime = field(default_factory=datetime.now)
        signature: Optional[bytes] = None
        shard_id: Optional[int] = None
        transaction_id: str = field(init=False)
        
        def __post_init__(self):
            """Initialize transaction ID after creation."""
            self.transaction_id = self.calculate_id()
        
        def calculate_id(self) -> str:
            """Calculate unique transaction ID."""
            tx_data = {
                'sender': self.sender,
                'receiver': self.receiver,
                'action': self.action,
                'data': self.data,
                'timestamp': self.timestamp.isoformat(),
                'shard_id': self.shard_id
            }
            return hashlib.sha256(json.dumps(tx_data, sort_keys=True).encode()).hexdigest()
        
        def to_dict(self) -> Dict:
            """Convert transaction to dictionary format."""
            return {
                'transaction_id': self.transaction_id,
                'sender': self.sender,
                'receiver': self.receiver,
                'action': self.action,
                'data': self.data,
                'timestamp': self.timestamp.isoformat(),
                'signature': self.signature.hex() if self.signature else None,
                'shard_id': self.shard_id
            }
            
        @classmethod
        def from_dict(cls, data: Dict) -> 'Transaction':
            """Create transaction from dictionary."""
            timestamp = datetime.fromisoformat(data['timestamp'])
            signature = bytes.fromhex(data['signature']) if data.get('signature') else None
            
            return cls(
                sender=data['sender'],
                receiver=data['receiver'],
                action=data['action'],
                data=data['data'],
                timestamp=timestamp,
                signature=signature,
                shard_id=data.get('shard_id')
            )
    
        def validate(self) -> bool:
            """Validate transaction structure and data."""
            try:
                # Validate basic structure
                if not all([self.sender, self.receiver, self.action]):
                    return False
                
                # Validate timestamp
                if self.timestamp > datetime.now() + timedelta(minutes=5):
                    return False
                    
                # Validate data structure
                if not isinstance(self.data, dict):
                    return False
                    
                # Validate transaction ID
                if self.transaction_id != self.calculate_id():
                    return False
                    
                return True
                
            except Exception as e:
                logger.error(f"Transaction validation failed: {e}")
                return False
    
    @dataclass
    class Block:
        """Represents a block in the ICN blockchain."""
        index: int
        previous_hash: str
        timestamp: datetime
        transactions: List[Transaction]
        validator: str
        shard_id: int
        hash: str = ""
        nonce: int = 0
        merkle_root: str = ""
        cross_shard_refs: List[str] = field(default_factory=list)
        metadata: Dict = field(default_factory=dict)
        version: str = "1.0"
        
        def __post_init__(self):
            """Initialize block after creation."""
            if not self.merkle_root:
                self.merkle_root = self.calculate_merkle_root()
            if not self.hash:
                self.hash = self.calculate_hash()
            self.metadata['created_at'] = datetime.now().isoformat()
    
        def calculate_merkle_root(self) -> str:
            """Calculate the Merkle root of transactions."""
            if not self.transactions:
                return hashlib.sha256(b"empty").hexdigest()
            
            leaves = [hashlib.sha256(json.dumps(tx.to_dict()).encode()).hexdigest()
                     for tx in self.transactions]
            
            while len(leaves) > 1:
                if len(leaves) % 2 == 1:
                    leaves.append(leaves[-1])
                leaves = [hashlib.sha256((a + b).encode()).hexdigest()
                         for a, b in zip(leaves[::2], leaves[1::2])]
            
            return leaves[0]
    
        def calculate_hash(self) -> str:
            """Calculate the hash of the block."""
            block_dict = {
                'index': self.index,
                'previous_hash': self.previous_hash,
                'timestamp': self.timestamp.isoformat(),
                'merkle_root': self.merkle_root,
                'validator': self.validator,
                'nonce': self.nonce,
                'shard_id': self.shard_id,
                'cross_shard_refs': self.cross_shard_refs,
                'version': self.version
            }
            return hashlib.sha256(json.dumps(block_dict, sort_keys=True).encode()).hexdigest()
    
        def to_dict(self) -> Dict:
            """Convert block to dictionary format."""
            return {
                'index': self.index,
                'previous_hash': self.previous_hash,
                'timestamp': self.timestamp.isoformat(),
                'transactions': [tx.to_dict() for tx in self.transactions],
                'validator': self.validator,
                'hash': self.hash,
                'nonce': self.nonce,
                'merkle_root': self.merkle_root,
                'shard_id': self.shard_id,
                'cross_shard_refs': self.cross_shard_refs,
                'metadata': self.metadata,
                'version': self.version
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> 'Block':
            """Create block from dictionary."""
            transactions = [Transaction.from_dict(tx) for tx in data['transactions']]
            timestamp = datetime.fromisoformat(data['timestamp'])
            
            return cls(
                index=data['index'],
                previous_hash=data['previous_hash'],
                timestamp=timestamp,
                transactions=transactions,
                validator=data['validator'],
                shard_id=data['shard_id'],
                hash=data['hash'],
                nonce=data['nonce'],
                merkle_root=data['merkle_root'],
                cross_shard_refs=data.get('cross_shard_refs', []),
                metadata=data.get('metadata', {}),
                version=data.get('version', "1.0")
            )
    
        def validate(self, previous_block: Optional['Block'] = None) -> bool:
            """Validate block structure and consistency."""
            try:
                # Validate hash
                if self.hash != self.calculate_hash():
                    return False
                    
                # Validate merkle root
                if self.merkle_root != self.calculate_merkle_root():
                    return False
                    
                # Validate timestamp
                if self.timestamp > datetime.now() + timedelta(minutes=5):
                    return False
                    
                # Validate transactions
                if not all(tx.validate() for tx in self.transactions):
                    return False
                    
                # Validate against previous block if provided
                if previous_block:
                    if self.previous_hash != previous_block.hash:
                        return False
                    if self.index != previous_block.index + 1:
                        return False
                    if self.timestamp <= previous_block.timestamp:
                        return False
                        
                return True
                
            except Exception as e:
                logger.error(f"Block validation failed: {e}")
                return False
                class Shard:
        """Represents a blockchain shard."""
        
        def __init__(self, shard_id: int, max_transactions_per_block: int = 100):
            self.shard_id = shard_id
            self.chain: List[Block] = []
            self.pending_transactions: List[Transaction] = []
            self.height = 0
            self.max_transactions_per_block = max_transactions_per_block
            self.last_block_time = datetime.now()
            self.state: Dict = {}
            self.metrics: Dict = {
                'total_transactions': 0,
                'average_block_time': 0,
                'blocks_created': 0,
                'pending_count': 0
            }
            self._create_genesis_block()
    
        def _create_genesis_block(self) -> None:
            """Create genesis block for this shard."""
            genesis_block = Block(
                index=0,
                previous_hash="0" * 64,
                timestamp=datetime.now(),
                transactions=[],
                validator="genesis",
                shard_id=self.shard_id
            )
            self.chain.append(genesis_block)
            self.height = 1
            self.last_block_time = genesis_block.timestamp
            self.metrics['blocks_created'] = 1
    
        def add_transaction(self, transaction: Transaction) -> bool:
            """Add a new transaction to pending pool."""
            if transaction.shard_id != self.shard_id:
                return False
                
            if len(self.pending_transactions) >= self.max_transactions_per_block * 2:
                return False
                
            if not transaction.validate():
                return False
                
            self.pending_transactions.append(transaction)
            self.metrics['pending_count'] = len(self.pending_transactions)
            return True
    
        def create_block(self, validator: str) -> Optional[Block]:
            """Create a new block from pending transactions."""
            if not self.pending_transactions:
                return None
                
            transactions = self.pending_transactions[:self.max_transactions_per_block]
            
            new_block = Block(
                index=self.height,
                previous_hash=self.chain[-1].hash,
                timestamp=datetime.now(),
                transactions=transactions,
                validator=validator,
                shard_id=self.shard_id
            )
            
            return new_block
    
        def add_block(self, block: Block) -> bool:
            """Add a validated block to the shard chain."""
            if block.shard_id != self.shard_id:
                return False
                
            if block.index != self.height:
                return False
                
            if not block.validate(self.chain[-1]):
                return False
                
            # Update metrics
            block_time = (block.timestamp - self.last_block_time).total_seconds()
            self.metrics['average_block_time'] = (
                (self.metrics['average_block_time'] * self.metrics['blocks_created'] + block_time) /
                (self.metrics['blocks_created'] + 1)
            )
            self.metrics['blocks_created'] += 1
            self.metrics['total_transactions'] += len(block.transactions)
            
            # Remove included transactions from pending pool
            tx_ids = {tx.transaction_id for tx in block.transactions}
            self.pending_transactions = [
                tx for tx in self.pending_transactions 
                if tx.transaction_id not in tx_ids
            ]
            self.metrics['pending_count'] = len(self.pending_transactions)
            
            # Add block to chain
            self.chain.append(block)
            self.height += 1
            self.last_block_time = block.timestamp
            
            return True
    
        def get_latest_block(self) -> Block:
            """Get the latest block in this shard."""
            return self.chain[-1]
    
        def validate_chain(self) -> bool:
            """Validate the entire shard chain."""
            for i in range(1, len(self.chain)):
                if not self.chain[i].validate(self.chain[i-1]):
                    return False
            return True
    
        def get_metrics(self) -> Dict:
            """Get shard metrics and statistics."""
            return {
                'shard_id': self.shard_id,
                'height': self.height,
                'pending_transactions': len(self.pending_transactions),
                'last_block_time': self.last_block_time.isoformat(),
                **self.metrics
            }
    
    
    @dataclass
    class Node:
        """Represents a node in the ICN network."""
        
        def __init__(self, node_id: str, cooperative_id: Optional[str] = None,
                     initial_stake: float = 10.0):
            self.node_id = node_id
            self.cooperative_id = cooperative_id
            self.reputation_scores = {
                'validation': 0.0,
                'proposal_creation': 0.0,
                'voting': 0.0,
                'resource_sharing': 0.0,
                'cooperative_growth': 0.0,
                'community_building': 0.0,
                'conflict_resolution': 0.0,
                'transaction_validation': 0.0,
                'data_availability': 0.0,
                'network_stability': 0.0,
                'innovation': 0.0,
                'sustainability': 0.0
            }
            self.stake = initial_stake
            self.cooperative_interactions: List[str] = []
            self.validation_history: List[Dict] = []
            self.resource_usage: Dict[str, float] = {
                'computation': 0.0,
                'storage': 0.0,
                'bandwidth': 0.0,
                'memory': 0.0,
                'energy': 0.0
            }
            self.shard_assignments: Set[int] = set()
            self.active_shards: Dict[int, datetime] = {}
            self.last_validation = 0
            self.total_validations = 0
            self.cooldown = 0
            self.total_cycles = 0
            self.cycles_since_update: Dict[str, int] = {}
            self.performance_metrics: Dict[str, float] = {
                'response_time': 0.0,
                'availability': 100.0,
                'validation_success_rate': 100.0,
                'network_reliability': 100.0
            }
            self.metadata: Dict = {
                'creation_time': datetime.now(),
                'last_active': datetime.now(),
                'version': "1.0",
                'capabilities': set(),
                'status': "active"
            }
    
        def update_reputation(self, category: str, score: float, 
                             cooperative_id: Optional[str] = None,
                             evidence: Optional[Dict] = None) -> None:
            """Update reputation score for a category with evidence."""
            if category in self.reputation_scores:
                old_score = self.reputation_scores[category]
                self.reputation_scores[category] = max(0, old_score + score)
                
                if cooperative_id:
                    self.cooperative_interactions.append(cooperative_id)
                    
                if evidence:
                    self.validation_history.append({
                        'timestamp': datetime.now(),
                        'category': category,
                        'score_change': score,
                        'evidence': evidence
                    })
                
                self.metadata['last_active'] = datetime.now()
                
                # Trim interaction history to last 1000 interactions
                if len(self.cooperative_interactions) > 1000:
                    self.cooperative_interactions = self.cooperative_interactions[-1000:]
    
        def assign_to_shard(self, shard_id: int) -> bool:
            """Assign node to a shard."""
            if len(self.active_shards) >= 3:  # Maximum 3 active shards per node
                return False
                
            self.shard_assignments.add(shard_id)
            self.active_shards[shard_id] = datetime.now()
            return True
    
        def remove_from_shard(self, shard_id: int) -> bool:
            """Remove node from a shard."""
            if shard_id in self.active_shards:
                del self.active_shards[shard_id]
                self.shard_assignments.discard(shard_id)
                return True
            return False
    
        def can_validate(self, shard_id: Optional[int] = None) -> bool:
            """Check if node can validate blocks."""
            current_time = time.time()
            
            # Basic validation checks
            if self.cooldown > 0:
                return False
            if current_time - self.last_validation < 10:  # 10 second minimum between validations
                return False
            if self.metadata['status'] != "active":
                return False
                
            # Shard-specific validation
            if shard_id is not None:
                if shard_id not in self.active_shards:
                    return False
                if (datetime.now() - self.active_shards[shard_id]).total_seconds() > 3600:  # 1 hour timeout
                    return False
                    
            return True
    
        def enter_cooldown(self, cooldown_period: int) -> None:
            """Put node into cooldown period."""
            self.cooldown = cooldown_period
            self.metadata['status'] = "cooldown"
    
        def update_metrics(self, metrics: Dict[str, float]) -> None:
            """Update node performance metrics."""
            self.performance_metrics.update(metrics)
            self.metadata['last_active'] = datetime.now()
    
        def get_total_reputation(self) -> float:
            """Calculate total reputation across all categories."""
            return sum(self.reputation_scores.values())
    
        def to_dict(self) -> Dict:
            """Convert node state to dictionary."""
            return {
                'node_id': self.node_id,
                'cooperative_id': self.cooperative_id,
                'reputation_scores': self.reputation_scores,
                'stake': self.stake,
                'shard_assignments': list(self.shard_assignments),
                'performance_metrics': self.performance_metrics,
                'resource_usage': self.resource_usage,
                'metadata': self.metadata,
                'status': self.metadata['status']
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> 'Node':
            """Create node from dictionary."""
            node = cls(
                node_id=data['node_id'],
                cooperative_id=data['cooperative_id'],
                initial_stake=data['stake']
            )
            node.reputation_scores = data['reputation_scores']
            node.shard_assignments = set(data['shard_assignments'])
            node.performance_metrics = data['performance_metrics']
            node.resource_usage = data['resource_usage']
            node.metadata = data['metadata']
            
            return node
            class ProofOfCooperation:
        """Implements the Proof of Cooperation consensus mechanism."""
        
        def __init__(self, min_reputation: float = 10.0, cooldown_blocks: int = 3):
            self.min_reputation = min_reputation
            self.cooldown_blocks = cooldown_blocks
            self.cooperation_scores: Dict[str, float] = {}
            self.reputation_weights = {
                'cooperative_growth': 1.5,
                'proposal_participation': 1.2,
                'transaction_validation': 1.0,
                'resource_sharing': 1.3,
                'conflict_resolution': 1.1,
                'community_building': 1.4,
                'sustainability': 1.2,
                'innovation': 1.3,
                'network_stability': 1.1,
                'data_availability': 1.2
            }
            self.validation_thresholds = {
                'min_participation': 0.1,
                'min_success_rate': 0.8,
                'min_availability': 0.95,
                'max_consecutive_validations': 3
            }
            self.reputation_decay_factor = 0.99
            self.collusion_threshold = 0.8
            self.validator_history: List[Tuple[str, datetime, int]] = []  # node_id, timestamp, shard_id
            self.validation_stats: Dict[str, Dict] = {}
            self.performance_metrics: Dict[str, float] = {
                'average_block_time': 0.0,
                'total_validations': 0,
                'successful_validations': 0,
                'collusion_detections': 0
            }
    
        def calculate_cooperation_score(self, node: Node, shard_id: Optional[int] = None) -> float:
            """Calculate a node's cooperation score based on multiple factors."""
            if not node.can_validate(shard_id):
                return 0.0
    
            base_score = sum(
                score * self.reputation_weights.get(category, 1.0)
                for category, score in node.reputation_scores.items()
            )
            
            diversity_factor = self._calculate_diversity_factor(node)
            consistency_factor = self._calculate_consistency_factor(node)
            performance_factor = self._calculate_performance_factor(node)
            shard_factor = self._calculate_shard_factor(node, shard_id) if shard_id else 1.0
            
            final_score = (base_score * diversity_factor * consistency_factor * 
                          performance_factor * shard_factor)
                          
            return max(0, final_score)
    
        def _calculate_diversity_factor(self, node: Node) -> float:
            """Calculate diversity factor based on cooperative interactions."""
            recent_interactions = node.cooperative_interactions[-100:]  # Last 100 interactions
            if not recent_interactions:
                return 1.0
                
            unique_coops = len(set(recent_interactions))
            total_interactions = len(recent_interactions)
            
            diversity_score = unique_coops / total_interactions
            normalized_score = 1.0 + math.log(diversity_score + 1)
            
            return max(self.validation_thresholds['min_participation'], normalized_score)
    
        def _calculate_consistency_factor(self, node: Node) -> float:
            """Calculate consistency factor based on validation history."""
            if not node.validation_history:
                return 1.0
                
            recent_validations = node.validation_history[-50:]  # Last 50 validations
            successful = sum(1 for v in recent_validations 
                            if v.get('evidence', {}).get('success', False))
            
            success_rate = successful / len(recent_validations)
            return max(self.validation_thresholds['min_success_rate'], success_rate)
    
        def _calculate_performance_factor(self, node: Node) -> float:
            """Calculate performance factor based on node metrics."""
            metrics = node.performance_metrics
            if not metrics:
                return 1.0
    
            factors = [
                metrics.get('availability', 0) / 100,
                metrics.get('validation_success_rate', 0) / 100,
                metrics.get('network_reliability', 0) / 100
            ]
            
            avg_performance = sum(factors) / len(factors)
            return max(self.validation_thresholds['min_availability'], avg_performance)
    
        def _calculate_shard_factor(self, node: Node, shard_id: int) -> float:
            """Calculate shard-specific performance factor."""
            if shard_id not in node.active_shards:
                return 0.0
                
            # Consider time spent in shard
            time_in_shard = (datetime.now() - node.active_shards[shard_id]).total_seconds()
            shard_experience = min(1.0, time_in_shard / (24 * 3600))  # Max out at 1 day
            
            return 0.5 + (0.5 * shard_experience)
    
        def select_validator(self, nodes: List[Node], shard_id: Optional[int] = None) -> Optional[Node]:
            """Select the next validator using weighted random selection."""
            eligible_nodes = [
                node for node in nodes 
                if self._is_eligible_validator(node, shard_id)
            ]
            
            if not eligible_nodes:
                return None
                
            # Calculate scores for eligible nodes
            scores = [
                self.calculate_cooperation_score(node, shard_id) 
                for node in eligible_nodes
            ]
            total_score = sum(scores)
            
            if total_score <= 0:
                # Fallback to random selection if all scores are 0
                selected = random.choice(eligible_nodes)
            else:
                # Weighted random selection
                selection_point = random.uniform(0, total_score)
                current_sum = 0
                selected = eligible_nodes[-1]  # Default to last node
                
                for node, score in zip(eligible_nodes, scores):
                    current_sum += score
                    if current_sum >= selection_point:
                        selected = node
                        break
            
            # Record selection
            self._record_validator_selection(selected, shard_id)
            selected.enter_cooldown(self.cooldown_blocks)
            
            return selected
    
        def _is_eligible_validator(self, node: Node, shard_id: Optional[int] = None) -> bool:
            """Check if a node is eligible to validate blocks."""
            if not node.can_validate(shard_id):
                return False
                
            # Check minimum reputation requirement
            if node.get_total_reputation() < self.min_reputation:
                return False
                
            # Check performance factors
            performance_factor = self._calculate_performance_factor(node)
            if performance_factor < self.validation_thresholds['min_availability']:
                return False
                
            # Check recent selections to prevent concentration
            recent_validations = [
                v[0] for v in self.validator_history[-10:]
                if v[0] == node.node_id
            ]
            if len(recent_validations) >= self.validation_thresholds['max_consecutive_validations']:
                return False
                
            return True
    
        def _record_validator_selection(self, node: Node, shard_id: Optional[int]) -> None:
            """Record validator selection for statistics."""
            self.validator_history.append((node.node_id, datetime.now(), shard_id))
            if len(self.validator_history) > 1000:
                self.validator_history = self.validator_history[-1000:]
                
            if node.node_id not in self.validation_stats:
                self.validation_stats[node.node_id] = {
                    'selections': 0,
                    'successful_validations': 0,
                    'last_selected': None,
                    'shard_validations': {}
                }
                
            stats = self.validation_stats[node.node_id]
            stats['selections'] += 1
            stats['last_selected'] = datetime.now()
            
            if shard_id is not None:
                shard_stats = stats['shard_validations'].setdefault(shard_id, {
                    'selections': 0,
                    'successful': 0
                })
                shard_stats['selections'] += 1
    
        def validate_block(self, block: Block, previous_block: Optional[Block], 
                          validator: Node) -> bool:
            """Validate a proposed block."""
            try:
                # Verify validator eligibility
                if not self._is_eligible_validator(validator, block.shard_id):
                    return False
                    
                # Perform block validation
                if not block.validate(previous_block):
                    return False
                    
                # Verify cross-shard references if present
                if block.cross_shard_refs and not self._validate_cross_shard_refs(block):
                    return False
                    
                # Update statistics
                self._update_validation_stats(validator, block, True)
                
                return True
                
            except Exception as e:
                logger.error(f"Block validation failed: {e}")
                self._update_validation_stats(validator, block, False)
                return False
    
        def _validate_cross_shard_refs(self, block: Block) -> bool:
            """Validate cross-shard references in a block."""
            # This would include validation logic for cross-shard references
            # Implementation depends on specific cross-shard protocol
            return True
    
        def _update_validation_stats(self, validator: Node, block: Block, 
                                   success: bool) -> None:
            """Update validation statistics."""
            stats = self.validation_stats.get(validator.node_id, {
                'selections': 0,
                'successful_validations': 0,
                'shard_validations': {}
            })
            
            if success:
                stats['successful_validations'] += 1
                
            if block.shard_id is not None:
                shard_stats = stats['shard_validations'].setdefault(block.shard_id, {
                    'selections': 0,
                    'successful': 0
                })
                if success:
                    shard_stats['successful'] += 1
                    
            self.validation_stats[validator.node_id] = stats
    
    class SmartContract:
        """Represents a smart contract in the ICN blockchain."""
        
        def __init__(self, contract_id: str, code: str, creator: str, 
                     mana_cost: int = 10, version: str = "1.0"):
            self.contract_id = contract_id
            self.code = code
            self.creator = creator
            self.state: Dict = {}
            self.mana_cost = mana_cost
            self.version = version
            self.created_at = datetime.now()
            self.last_executed = None
            self.execution_count = 0
            self.total_mana_consumed = 0
            self.execution_history: List[Dict] = []
            self.metadata: Dict = {
                'created_at': self.created_at,
                'version': version,
                'creator': creator,
                'description': '',
                'tags': set()
            }
            self.dependencies: Set[str] = set()
            self.allowed_callers: Set[str] = {creator}
            self.restrictions: Dict = {
                'max_state_size': 1024 * 1024,  # 1MB
                'max_execution_time': 5,  # seconds
                'max_mana_per_execution': 100,
                'max_daily_executions': 1000
            }
            self.daily_executions = 0
            self.last_reset = datetime.now()
    
        def execute(self, input_data: Dict, available_mana: int) -> Dict:
            """Execute the smart contract code with safety checks."""
            # Reset daily execution counter if needed
            self._reset_daily_executions()
            
            # Validate execution conditions
            validation_result = self._validate_execution(input_data, available_mana)
            if validation_result.get("error"):
                return validation_result
                
            execution_start = time.time()
            try:
                # Set up secure execution environment
                local_namespace = self._setup_execution_environment(input_data)
                
                # Execute contract code
                exec(self.code, {}, local_namespace)
                
                # Validate execution result
                if "execute" not in local_namespace:
                    return {"error": "Contract missing execute function"}
                    
                # Check execution time
                if time.time() - execution_start > self.restrictions['max_execution_time']:
                    return {"error": "Execution time limit exceeded"}
                    
                # Execute contract function
                result = local_namespace["execute"](input_data, self.state)
                
                # Update contract metrics
                self._update_execution_metrics(execution_start)
                
                return {
                    "state": self.state,
                    "result": result,
                    "mana_used": self.mana_cost,
                    "execution_time": time.time() - execution_start
                }
                
            except Exception as e:
                logger.error(f"Contract execution failed: {e}")
                return {"error": str(e)}
    
        def _validate_execution(self, input_data: Dict, available_mana: int) -> Dict:
            """Validate execution conditions."""
            if self.daily_executions >= self.restrictions['max_daily_executions']:
                return {"error": "Daily execution limit exceeded"}
                
            if available_mana < self.mana_cost:
                return {"error": "Insufficient mana"}
                
            if len(str(self.state)) > self.restrictions['max_state_size']:
                return {"error": "State size limit exceeded"}
                
            return {}
    
        def _setup_execution_environment(self, input_data: Dict) -> Dict:
            """Set up secure execution environment with allowed variables."""
            return {
                "input": input_data,
                "state": self.state.copy(),
                "contract_id": self.contract_id,
                "creator": self.creator,
                "version": self.version,
                "metadata": self.metadata
            }
    
        def _update_execution_metrics(self, execution_start: float) -> None:
            """Update contract execution metrics."""
            self.last_executed = datetime.now()
            self.execution_count += 1
            self.daily_executions += 1
            self.total_mana_consumed += self.mana_cost
            
            execution_record = {
                'timestamp': self.last_executed,
                'execution_time': time.time() - execution_start,
                'mana_used': self.mana_cost,
                'state_size': len(str(self.state))
            }
            
            self.execution_history.append(execution_record)
            if len(self.execution_history) > 1000:
                self.execution_history = self.execution_history[-1000:]
    
        def _reset_daily_executions(self) -> None:
            """Reset daily execution counter if needed."""
            current_time = datetime.now()
            if (current_time - self.last_reset).days >= 1:
                self.daily_executions = 0
                self.last_reset = current_time
    
        def update_metadata(self, metadata: Dict) -> bool:
            """Update contract metadata."""
            try:
                self.metadata.update(metadata)
                return True
            except Exception as e:
                logger.error(f"Failed to update metadata: {e}")
                return False
    
        def add_dependency(self, contract_id: str) -> bool:
            """Add a contract dependency."""
            self.dependencies.add(contract_id)
            return True
    
        def authorize_caller(self, caller_id: str) -> bool:
            """Add an authorized caller."""
            self.allowed_callers.add(caller_id)
            return True
    
        def revoke_caller(self, caller_id: str) -> bool:
            """Revoke caller authorization."""
            if caller_id == self.creator:
                return False
            self.allowed_callers.discard(caller_id)
            return True
    
        def get_metrics(self) -> Dict:
            """Get comprehensive contract metrics."""
            return {
                'contract_id': self.contract_id,
                'version': self.version,
                'creator': self.creator,
                'created_at': self.created_at.isoformat(),
                'last_executed': self.last_executed.isoformat() if self.last_executed else None,
                'execution_count': self.execution_count,
                'daily_executions': self.daily_executions,
                'total_mana_consumed': self.total_mana_consumed,
                'average_mana_per_execution': (
                    self.total_mana_consumed / self.execution_count 
                    if self.execution_count > 0 else 0
                ),
                'state_size': len(str(self.state)),
                'dependencies': list(self.dependencies),
                'authorized_callers': len(self.allowed_callers),
                'restrictions': self.restrictions
            }
    
        def to_dict(self) -> Dict:
            """Convert contract to dictionary format."""
            return {
                'contract_id': self.contract_id,
                'code': self.code,
                'creator': self.creator,
                'state': self.state,
                'mana_cost': self.mana_cost,
                'version': self.version,
                'metadata': self.metadata,
                'dependencies': list(self.dependencies),
                'allowed_callers': list(self.allowed_callers),
                'restrictions': self.restrictions,
                'metrics': self.get_metrics()
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> 'SmartContract':
            """Create contract from dictionary."""
            contract = cls(
                contract_id=data['contract_id'],
                code=data['code'],
                creator=data['creator'],
                mana_cost=data['mana_cost'],
                version=data['version']
            )
            contract.state = data['state']
            contract.metadata = data['metadata']
            contract.dependencies = set(data['dependencies'])
            contract.allowed_callers = set(data['allowed_callers'])
            contract.restrictions = data['restrictions']
            return contract
    
    
    class Blockchain:
        """Main blockchain implementation for ICN."""
        
        def __init__(self, num_shards: int = 4, initial_mana: int = 1000, 
                     mana_regen_rate: int = 10):
            self.num_shards = num_shards
            self.shards: Dict[int, Shard] = {
                i: Shard(i) for i in range(num_shards)
            }
            self.nodes: List[Node] = []
            self.consensus = ProofOfCooperation()
            self.contracts: Dict[str, SmartContract] = {}
            self.cooperative_mana = initial_mana
            self.mana_regen_rate = mana_regen_rate
            self.cross_shard_queue: Dict[int, List[Transaction]] = {
                i: [] for i in range(num_shards)
            }
            self.metadata: Dict = {
                'creation_time': datetime.now(),
                'last_update': datetime.now(),
                'version': "1.0",
                'network_name': "ICN MainNet",
                'network_id': hashlib.sha256(str(time.time()).encode()).hexdigest()[:8]
            }
            self.metrics: Dict = {
                'total_transactions': 0,
                'total_blocks': 0,
                'average_block_time': 0,
                'active_nodes': 0,
                'total_mana_consumed': 0
            }
            self.state: str = "active"
            self._initialize_network()
    
        def _initialize_network(self) -> None:
            """Initialize network configuration."""
            logger.info(f"Initializing ICN network {self.metadata['network_id']}")
            self._update_metrics()
    
        def add_node(self, node: Node) -> bool:
            """Add a new node to the network."""
            if any(n.node_id == node.node_id for n in self.nodes):
                return False
                
            self.nodes.append(node)
            self.metrics['active_nodes'] = len(
                [n for n in self.nodes if n.metadata['status'] == "active"]
            )
            logger.info(f"Added node {node.node_id} to network")
            return True
    
        def remove_node(self, node_id: str) -> bool:
            """Remove a node from the network."""
            node = self._get_node(node_id)
            if not node:
                return False
                
            self.nodes = [n for n in self.nodes if n.node_id != node_id]
            self.metrics['active_nodes'] = len(
                [n for n in self.nodes if n.metadata['status'] == "active"]
            )
            logger.info(f"Removed node {node_id} from network")
            return True
    
        def _get_node(self, node_id: str) -> Optional[Node]:
            """Get a node by its ID."""
            return next((n for n in self.nodes if n.node_id == node_id), None)
    
        def add_transaction(self, transaction: Dict) -> bool:
            """Add a new transaction to the network."""
            # Determine shard for transaction
            shard_id = self._calculate_shard_id(transaction)
            
            tx = Transaction(
                sender=transaction['sender'],
                receiver=transaction['receiver'],
                action=transaction['action'],
                data=transaction['data'],
                shard_id=shard_id
            )
            
            # Add to appropriate shard
            if self.shards[shard_id].add_transaction(tx):
                self.metrics['total_transactions'] += 1
                return True
            return False
    
        def _calculate_shard_id(self, transaction: Dict) -> int:
            """Calculate which shard should handle a transaction."""
            # Simple hash-based sharding
            tx_hash = hashlib.sha256(
                json.dumps(transaction, sort_keys=True).encode()
            ).hexdigest()
            return int(tx_hash, 16) % self.num_shards
    
        def create_block(self, shard_id: int) -> Optional[Block]:
            """Create a new block in specified shard."""
            shard = self.shards.get(shard_id)
            if not shard:
                return None
                
            # Select validator
            validator = self.consensus.select_validator(self.nodes, shard_id)
            if not validator:
                return None
                
            # Create block
            block = shard.create_block(validator.node_id)
            if not block:
                return None
                
            # Process cross-shard references
            self._add_cross_shard_refs(block)
            
            return block
    
        def _add_cross_shard_refs(self, block: Block) -> None:
            """Add cross-shard references to block."""
            cross_shard_txs = [
                tx for tx in block.transactions 
                if self._is_cross_shard_transaction(tx)
            ]
            
            for tx in cross_shard_txs:
                ref = self._create_cross_shard_ref(tx)
                if ref:
                    block.cross_shard_refs.append(ref)
    
        def _is_cross_shard_transaction(self, transaction: Transaction) -> bool:
            """Check if transaction involves multiple shards."""
            return 'target_shard' in transaction.data
    
        def _create_cross_shard_ref(self, transaction: Transaction) -> Optional[str]:
            """Create a reference for cross-shard transaction."""
            try:
                ref_data = {
                    'transaction_id': transaction.transaction_id,
                    'source_shard': transaction.shard_id,
                    'target_shard': transaction.data.get('target_shard'),
                    'timestamp': transaction.timestamp.isoformat()
                }
                return hashlib.sha256(
                    json.dumps(ref_data, sort_keys=True).encode()
                ).hexdigest()
            except Exception as e:
                logger.error(f"Failed to create cross-shard reference: {e}")
                return None
    
        def add_block(self, block: Block) -> bool:
            """Add a validated block to the network."""
            shard = self.shards.get(block.shard_id)
            if not shard:
                return False
                
            # Validate block
            validator = self._get_node(block.validator)
            if not validator:
                return False
                
            if not self.consensus.validate_block(block, shard.chain[-1], validator):
                return False
                
            # Add block to shard
            if shard.add_block(block):
                self._process_block_addition(block)
                return True
                
            return False
    
        def _process_block_addition(self, block: Block) -> None:
            """Process successful block addition."""
            self.metrics['total_blocks'] += 1
            self._update_metrics()
            
            # Process cross-shard references
            if block.cross_shard_refs:
                self._process_cross_shard_refs(block)
                
            logger.info(
                f"Added block {block.index} to shard {block.shard_id}")
                    def _process_cross_shard_refs(self, block: Block) -> None:
            """Process cross-shard references in a block."""
            for ref in block.cross_shard_refs:
                ref_data = self._parse_cross_shard_ref(ref)
                if ref_data:
                    target_shard = self.shards.get(ref_data['target_shard'])
                    if target_shard:
                        tx = self._create_cross_shard_transaction(ref_data)
                        target_shard.add_transaction(tx)
    
        def _parse_cross_shard_ref(self, ref: str) -> Optional[Dict]:
            """Parse cross-shard reference into transaction data."""
            try:
                ref_data = json.loads(hashlib.sha256(ref.encode()).hexdigest())
                return ref_data
            except Exception as e:
                logger.error(f"Failed to parse cross-shard reference: {e}")
                return None
    
        def _create_cross_shard_transaction(self, ref_data: Dict) -> Transaction:
            """Create a cross-shard transaction from reference data."""
            return Transaction(
                sender='cross-shard',
                receiver='target-shard',
                action='cross-shard-transfer',
                data=ref_data,
                shard_id=ref_data['target_shard']
            )
    
        def add_smart_contract(self, contract: SmartContract) -> bool:
            """Add a new smart contract to the network."""
            if contract.contract_id in self.contracts:
                return False
    
            self.contracts[contract.contract_id] = contract
            logger.info(f"Added smart contract {contract.contract_id} to network")
            return True
    
        def execute_smart_contract(self, contract_id: str, input_data: Dict) -> Dict:
            """Execute a smart contract with given input data."""
            contract = self.contracts.get(contract_id)
            if not contract:
                return {"error": "Contract not found"}
            
            # Check available mana
            if self.cooperative_mana < contract.mana_cost:
                return {"error": "Insufficient cooperative mana"}
            
            result = contract.execute(input_data, self.cooperative_mana)
            if "error" not in result:
                self.cooperative_mana -= contract.mana_cost
                self.metrics['total_mana_consumed'] += contract.mana_cost
            return result
    
        def regenerate_mana(self) -> None:
            """Regenerate cooperative mana over time."""
            self.cooperative_mana = min(
                self.cooperative_mana + self.mana_regen_rate,
                1000  # Max mana limit for demonstration purposes
            )
            self._update_metrics()
    
        def _update_metrics(self) -> None:
            """Update blockchain network metrics."""
            self.metadata['last_update'] = datetime.now().isoformat()
            self.metrics['average_block_time'] = sum(
                shard.metrics['average_block_time'] for shard in self.shards.values()
            ) / max(1, len(self.shards))
    
        def to_dict(self) -> Dict:
            """Convert blockchain to dictionary format."""
            return {
                'num_shards': self.num_shards,
                'nodes': [node.to_dict() for node in self.nodes],
                'contracts': {cid: contract.to_dict() for cid, contract in self.contracts.items()},
                'cooperative_mana': self.cooperative_mana,
                'metrics': self.metrics,
                'metadata': self.metadata
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> 'Blockchain':
            """Create blockchain from dictionary."""
            blockchain = cls(
                num_shards=data['num_shards'],
                initial_mana=data['cooperative_mana']
            )
            blockchain.nodes = [Node.from_dict(node) for node in data['nodes']]
            blockchain.contracts = {
                cid: SmartContract.from_dict(contract) 
                for cid, contract in data['contracts'].items()
            }
            blockchain.cooperative_mana = data['cooperative_mana']
            blockchain.metrics = data['metrics']
            blockchain.metadata = data['metadata']
            return blockchain
    
    
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/__init__.py
# Size: 434 bytes
# Last Modified: Thu Oct 24 00:40:58 2024
# Language: py
# ============================================================

```py
    # blockchain/__init__.py
    """
    Import core components and make them available at the package level.
    We're using relative imports to properly handle the package hierarchy.
    """
    from .core.node import Node
    from .core.block import Block
    from .core.transaction import Transaction 
    from .core.shard import Shard
    from .core.blockchain import Blockchain
    
    __all__ = [
        "Node",
        "Block", 
        "Transaction",
        "Shard",
        "Blockchain"
    ]
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/utils/metrics.py
# Size: 6083 bytes
# Last Modified: Wed Oct 23 18:56:54 2024
# Language: py
# ============================================================

```py
    # ================================================================
    # File: blockchain/utils/metrics.py
    # Description: This file contains functions and classes for managing
    # performance and operational metrics within the ICN ecosystem.
    # These metrics are used to track node performance, block creation,
    # transaction validation, and overall network health.
    # ================================================================
    
    from typing import Dict, List
    from datetime import datetime, timedelta
    import logging
    
    logger = logging.getLogger(__name__)
    
    class MetricsManager:
        """
        The MetricsManager handles the collection, analysis, and reporting of
        performance metrics within the ICN. It tracks node performance, transaction
        throughput, validation success rates, and resource utilization to provide
        real-time feedback for improving cooperative efficiency.
        """
    
        def __init__(self):
            """
            Initialize the MetricsManager.
    
            This constructor sets up the basic metrics structure, including
            performance, transaction, and resource usage metrics.
            """
            self.metrics: Dict = {
                "total_blocks_created": 0,
                "total_transactions_processed": 0,
                "average_block_creation_time": 0.0,
                "average_transaction_validation_time": 0.0,
                "resource_utilization": {
                    "cpu": 0.0,
                    "memory": 0.0,
                    "bandwidth": 0.0,
                    "storage": 0.0,
                },
                "validation_success_rate": 0.0,
                "uptime": 0.0,
            }
            self.start_time = datetime.now()
    
        def update_block_creation(self, creation_time: float) -> None:
            """
            Update metrics related to block creation.
    
            Args:
                creation_time (float): Time taken to create a new block.
            """
            try:
                self.metrics["total_blocks_created"] += 1
                total_time = (
                    self.metrics["average_block_creation_time"]
                    * (self.metrics["total_blocks_created"] - 1)
                )
                self.metrics["average_block_creation_time"] = (
                    total_time + creation_time
                ) / self.metrics["total_blocks_created"]
                logger.info("Updated block creation metrics")
    
            except Exception as e:
                logger.error(f"Failed to update block creation metrics: {str(e)}")
    
        def update_transaction_processing(self, processing_time: float) -> None:
            """
            Update metrics related to transaction processing.
    
            Args:
                processing_time (float): Time taken to validate a transaction.
            """
            try:
                self.metrics["total_transactions_processed"] += 1
                total_time = (
                    self.metrics["average_transaction_validation_time"]
                    * (self.metrics["total_transactions_processed"] - 1)
                )
                self.metrics["average_transaction_validation_time"] = (
                    total_time + processing_time
                ) / self.metrics["total_transactions_processed"]
                logger.info("Updated transaction processing metrics")
    
            except Exception as e:
                logger.error(f"Failed to update transaction metrics: {str(e)}")
    
        def update_resource_utilization(self, utilization: Dict[str, float]) -> None:
            """
            Update resource utilization metrics.
    
            Args:
                utilization (Dict[str, float]): Resource utilization metrics for
                CPU, memory, bandwidth, and storage.
            """
            try:
                for resource, value in utilization.items():
                    if resource in self.metrics["resource_utilization"]:
                        self.metrics["resource_utilization"][resource] = max(
                            0.0, value
                        )
                logger.info("Updated resource utilization metrics")
    
            except Exception as e:
                logger.error(f"Failed to update resource utilization: {str(e)}")
    
        def update_validation_success(self, successful: bool) -> None:
            """
            Update validation success rate.
    
            Args:
                successful (bool): True if the validation was successful, False otherwise.
            """
            try:
                total_validations = self.metrics.get("total_validations", 0) + 1
                successful_validations = self.metrics.get("successful_validations", 0)
    
                if successful:
                    successful_validations += 1
    
                self.metrics["validation_success_rate"] = (
                    successful_validations / total_validations * 100
                )
                self.metrics["total_validations"] = total_validations
                self.metrics["successful_validations"] = successful_validations
    
                logger.info("Updated validation success metrics")
    
            except Exception as e:
                logger.error(f"Failed to update validation success rate: {str(e)}")
    
        def calculate_uptime(self) -> None:
            """
            Calculate the node's uptime since the start of the MetricsManager.
            """
            try:
                uptime_seconds = (datetime.now() - self.start_time).total_seconds()
                self.metrics["uptime"] = uptime_seconds / 3600  # uptime in hours
                logger.info("Calculated node uptime")
    
            except Exception as e:
                logger.error(f"Failed to calculate uptime: {str(e)}")
    
        def get_metrics(self) -> Dict:
            """
            Retrieve the current metrics.
    
            Returns:
                Dict: A dictionary containing all current metrics.
            """
            try:
                self.calculate_uptime()
                return self.metrics
    
            except Exception as e:
                logger.error(f"Failed to get metrics: {str(e)}")
                return {}
    
        def reset_metrics(self) -> None:
            """
            Reset all metrics to initial values.
            """
            try:
                self.__init__()  # Re-initialize the metrics manager
                logger.info("Reset all metrics")
    
            except Exception as e:
                logger.error(f"Failed to reset metrics: {str(e)}")
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/utils/validation.py
# Size: 8132 bytes
# Last Modified: Wed Oct 23 18:57:45 2024
# Language: py
# ============================================================

```py
    # ================================================================
    # File: blockchain/utils/validation.py
    # Description: Contains validation functions for transactions,
    # blocks, and cooperative interactions within the ICN. These functions
    # ensure data integrity, compliance with cooperative rules, and secure
    # operation of the ICN blockchain.
    # ================================================================
    
    from typing import Dict, List, Any, Optional
    import hashlib
    import logging
    from datetime import datetime, timedelta
    
    logger = logging.getLogger(__name__)
    
    def validate_transaction(transaction: Dict) -> bool:
        """
        Validate a transaction based on predefined rules.
    
        This function checks transaction structure, required fields, and
        cryptographic integrity, ensuring that transactions comply with the
        ICN’s cooperative principles.
    
        Args:
            transaction (Dict): A dictionary representing a transaction.
    
        Returns:
            bool: True if the transaction is valid, False otherwise.
        """
        try:
            # Check required fields
            required_fields = ["transaction_id", "sender", "receiver", "amount", "signature", "timestamp"]
            for field in required_fields:
                if field not in transaction:
                    logger.error(f"Transaction missing required field: {field}")
                    return False
    
            # Validate amount
            if transaction["amount"] <= 0:
                logger.error("Transaction amount must be greater than zero")
                return False
    
            # Validate timestamp
            transaction_time = datetime.fromisoformat(transaction["timestamp"])
            current_time = datetime.now()
            if transaction_time > current_time + timedelta(minutes=5):
                logger.error("Transaction timestamp is in the future")
                return False
    
            # Verify transaction signature (placeholder logic)
            if not _verify_signature(transaction):
                logger.error("Transaction signature verification failed")
                return False
    
            logger.info(f"Transaction {transaction['transaction_id']} is valid")
            return True
    
        except Exception as e:
            logger.error(f"Transaction validation failed: {str(e)}")
            return False
    
    def validate_block(block: Dict, previous_block: Optional[Dict] = None) -> bool:
        """
        Validate a block based on structure, integrity, and consistency rules.
    
        This function checks the block’s cryptographic hash, Merkle root,
        timestamp, and transactions to ensure compliance with cooperative principles.
    
        Args:
            block (Dict): A dictionary representing a block.
            previous_block (Optional[Dict]): The previous block in the chain.
    
        Returns:
            bool: True if the block is valid, False otherwise.
        """
        try:
            # Check required fields
            required_fields = ["index", "previous_hash", "timestamp", "transactions", "hash", "merkle_root"]
            for field in required_fields:
                if field not in block:
                    logger.error(f"Block missing required field: {field}")
                    return False
    
            # Validate block index
            if previous_block and block["index"] != previous_block["index"] + 1:
                logger.error("Block index is not sequential")
                return False
    
            # Validate previous hash
            if previous_block and block["previous_hash"] != previous_block["hash"]:
                logger.error("Block previous hash does not match")
                return False
    
            # Validate timestamp
            block_time = datetime.fromisoformat(block["timestamp"])
            if block_time > datetime.now() + timedelta(minutes=5):
                logger.error("Block timestamp is in the future")
                return False
    
            if previous_block and block_time <= datetime.fromisoformat(previous_block["timestamp"]):
                logger.error("Block timestamp is not after the previous block")
                return False
    
            # Validate Merkle root
            if not _validate_merkle_root(block["transactions"], block["merkle_root"]):
                logger.error("Block Merkle root validation failed")
                return False
    
            # Validate block hash
            if not _validate_block_hash(block):
                logger.error("Block hash validation failed")
                return False
    
            logger.info(f"Block {block['index']} is valid")
            return True
    
        except Exception as e:
            logger.error(f"Block validation failed: {str(e)}")
            return False
    
    def _validate_merkle_root(transactions: List[Dict], expected_merkle_root: str) -> bool:
        """
        Validate the Merkle root of a list of transactions.
    
        Args:
            transactions (List[Dict]): List of transaction dictionaries.
            expected_merkle_root (str): The expected Merkle root hash.
    
        Returns:
            bool: True if the Merkle root is valid, False otherwise.
        """
        try:
            if not transactions:
                return expected_merkle_root == hashlib.sha256(b"empty").hexdigest()
    
            # Create leaf nodes from transactions
            leaves = [hashlib.sha256(json.dumps(tx).encode()).hexdigest() for tx in transactions]
    
            # Build Merkle tree
            while len(leaves) > 1:
                if len(leaves) % 2 == 1:
                    leaves.append(leaves[-1])
                leaves = [
                    hashlib.sha256((a + b).encode()).hexdigest()
                    for a, b in zip(leaves[::2], leaves[1::2])
                ]
    
            return leaves[0] == expected_merkle_root
    
        except Exception as e:
            logger.error(f"Failed to validate Merkle root: {str(e)}")
            return False
    
    def _validate_block_hash(block: Dict) -> bool:
        """
        Validate the block's hash by recalculating it.
    
        Args:
            block (Dict): A dictionary representing a block.
    
        Returns:
            bool: True if the hash is valid, False otherwise.
        """
        try:
            block_data = {
                "index": block["index"],
                "previous_hash": block["previous_hash"],
                "timestamp": block["timestamp"],
                "merkle_root": block["merkle_root"],
            }
            recalculated_hash = hashlib.sha256(
                json.dumps(block_data, sort_keys=True).encode()
            ).hexdigest()
    
            return recalculated_hash == block["hash"]
    
        except Exception as e:
            logger.error(f"Failed to validate block hash: {str(e)}")
            return False
    
    def _verify_signature(transaction: Dict) -> bool:
        """
        Placeholder function to verify the transaction signature.
    
        This function simulates signature verification and should be replaced with
        actual cryptographic verification logic.
    
        Args:
            transaction (Dict): A dictionary representing a transaction.
    
        Returns:
            bool: True if the signature is valid, False otherwise.
        """
        # Placeholder for signature verification logic
        return True
    
    def validate_cooperative_interaction(interaction: Dict) -> bool:
        """
        Validate cooperative interactions such as votes, proposals, and resource sharing.
    
        This function ensures that cooperative interactions comply with ICN rules,
        supporting fair governance and resource management.
    
        Args:
            interaction (Dict): A dictionary representing a cooperative interaction.
    
        Returns:
            bool: True if the interaction is valid, False otherwise.
        """
        try:
            # Check required fields
            required_fields = ["interaction_id", "type", "initiator", "target", "timestamp"]
            for field in required_fields:
                if field not in interaction:
                    logger.error(f"Interaction missing required field: {field}")
                    return False
    
            # Validate timestamp
            interaction_time = datetime.fromisoformat(interaction["timestamp"])
            if interaction_time > datetime.now() + timedelta(minutes=5):
                logger.error("Interaction timestamp is in the future")
                return False
    
            logger.info(f"Cooperative interaction {interaction['interaction_id']} is valid")
            return True
    
        except Exception as e:
            logger.error(f"Cooperative interaction validation failed: {str(e)}")
            return False
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/utils/__init__.py
# Size: 201 bytes
# Last Modified: Wed Oct 23 18:24:22 2024
# Language: py
# ============================================================

```py
    # blockchain/utils/__init__.py
    
    from .metrics import Metrics
    from .validation import validate_transaction, validate_block
    
    __all__ = [
        "Metrics",
        "validate_transaction",
        "validate_block"
    ]
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/utils/crypto.py
# Size: 7870 bytes
# Last Modified: Wed Oct 23 19:24:34 2024
# Language: py
# ============================================================

```py
    # ================================================================
    # File: blockchain/utils/crypto.py
    # Description: Contains cryptographic functions for securing the ICN
    # blockchain. Includes hashing, signing, and signature verification to
    # ensure the integrity, authenticity, and confidentiality of transactions
    # and blocks.
    # ================================================================
    
    from typing import Any, Tuple, Optional
    from cryptography.hazmat.primitives import hashes, serialization
    from cryptography.hazmat.primitives.asymmetric import rsa, padding
    from cryptography.hazmat.primitives.asymmetric.utils import Prehashed
    from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
    from cryptography.hazmat.backends import default_backend
    from cryptography.hazmat.primitives.kdf.hkdf import HKDF
    from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes
    from cryptography.hazmat.primitives import hmac
    import os
    import base64
    import logging
    
    logger = logging.getLogger(__name__)
    
    # Constants for encryption/decryption
    AES_KEY_SIZE = 32
    IV_SIZE = 16
    
    def generate_rsa_key_pair() -> Tuple[rsa.RSAPrivateKey, rsa.RSAPublicKey]:
        """
        Generate an RSA key pair for signing and verification.
    
        Returns:
            Tuple: A tuple containing the RSA private key and public key.
        """
        try:
            private_key = rsa.generate_private_key(
                public_exponent=65537,
                key_size=2048,
                backend=default_backend()
            )
            public_key = private_key.public_key()
            logger.info("Generated RSA key pair")
            return private_key, public_key
    
        except Exception as e:
            logger.error(f"Failed to generate RSA key pair: {str(e)}")
            raise
    
    def sign_data(private_key: rsa.RSAPrivateKey, data: bytes) -> bytes:
        """
        Sign data using a private RSA key.
    
        Args:
            private_key (rsa.RSAPrivateKey): The private RSA key.
            data (bytes): The data to be signed.
    
        Returns:
            bytes: The signature of the data.
        """
        try:
            signature = private_key.sign(
                data,
                padding.PSS(
                    mgf=padding.MGF1(hashes.SHA256()),
                    salt_length=padding.PSS.MAX_LENGTH
                ),
                hashes.SHA256()
            )
            logger.info("Data signed successfully")
            return signature
    
        except Exception as e:
            logger.error(f"Failed to sign data: {str(e)}")
            raise
    
    def verify_signature(
        public_key: rsa.RSAPublicKey, signature: bytes, data: bytes
    ) -> bool:
        """
        Verify the signature of data using a public RSA key.
    
        Args:
            public_key (rsa.RSAPublicKey): The public RSA key.
            signature (bytes): The signature to verify.
            data (bytes): The data that was signed.
    
        Returns:
            bool: True if the signature is valid, False otherwise.
        """
        try:
            public_key.verify(
                signature,
                data,
                padding.PSS(
                    mgf=padding.MGF1(hashes.SHA256()),
                    salt_length=padding.PSS.MAX_LENGTH
                ),
                hashes.SHA256()
            )
            logger.info("Signature verified successfully")
            return True
    
        except Exception as e:
            logger.error(f"Signature verification failed: {str(e)}")
            return False
    
    def hash_data(data: bytes) -> str:
        """
        Hash data using SHA-256.
    
        Args:
            data (bytes): The data to be hashed.
    
        Returns:
            str: The SHA-256 hash of the data in hexadecimal format.
        """
        try:
            digest = hashes.Hash(hashes.SHA256(), backend=default_backend())
            digest.update(data)
            hash_hex = digest.finalize().hex()
            logger.info("Data hashed successfully")
            return hash_hex
    
        except Exception as e:
            logger.error(f"Failed to hash data: {str(e)}")
            raise
    
    def derive_key(password: bytes, salt: bytes, iterations: int = 100000) -> bytes:
        """
        Derive a cryptographic key from a password using PBKDF2-HMAC-SHA256.
    
        Args:
            password (bytes): The password to derive the key from.
            salt (bytes): The salt for key derivation.
            iterations (int): Number of iterations for the key derivation.
    
        Returns:
            bytes: The derived key.
        """
        try:
            kdf = PBKDF2HMAC(
                algorithm=hashes.SHA256(),
                length=AES_KEY_SIZE,
                salt=salt,
                iterations=iterations,
                backend=default_backend()
            )
            key = kdf.derive(password)
            logger.info("Key derived successfully from password")
            return key
    
        except Exception as e:
            logger.error(f"Failed to derive key: {str(e)}")
            raise
    
    def aes_encrypt(key: bytes, plaintext: bytes) -> Tuple[bytes, bytes]:
        """
        Encrypt data using AES in CBC mode.
    
        Args:
            key (bytes): The AES key.
            plaintext (bytes): The data to be encrypted.
    
        Returns:
            Tuple: The IV and ciphertext.
        """
        try:
            iv = os.urandom(IV_SIZE)
            cipher = Cipher(
                algorithms.AES(key),
                modes.CBC(iv),
                backend=default_backend()
            )
            encryptor = cipher.encryptor()
    
            # Pad plaintext to block size
            padding_length = AES_KEY_SIZE - (len(plaintext) % AES_KEY_SIZE)
            padded_plaintext = plaintext + bytes([padding_length] * padding_length)
    
            ciphertext = encryptor.update(padded_plaintext) + encryptor.finalize()
            logger.info("Data encrypted successfully")
            return iv, ciphertext
    
        except Exception as e:
            logger.error(f"Failed to encrypt data: {str(e)}")
            raise
    
    def aes_decrypt(key: bytes, iv: bytes, ciphertext: bytes) -> bytes:
        """
        Decrypt data using AES in CBC mode.
    
        Args:
            key (bytes): The AES key.
            iv (bytes): The initialization vector (IV).
            ciphertext (bytes): The data to be decrypted.
    
        Returns:
            bytes: The decrypted plaintext.
        """
        try:
            cipher = Cipher(
                algorithms.AES(key),
                modes.CBC(iv),
                backend=default_backend()
            )
            decryptor = cipher.decryptor()
    
            padded_plaintext = decryptor.update(ciphertext) + decryptor.finalize()
    
            # Remove padding
            padding_length = padded_plaintext[-1]
            plaintext = padded_plaintext[:-padding_length]
    
            logger.info("Data decrypted successfully")
            return plaintext
    
        except Exception as e:
            logger.error(f"Failed to decrypt data: {str(e)}")
            raise
    
    def hmac_sign(key: bytes, data: bytes) -> bytes:
        """
        Generate an HMAC signature for data using a symmetric key.
    
        Args:
            key (bytes): The symmetric key.
            data (bytes): The data to be signed.
    
        Returns:
            bytes: The HMAC signature.
        """
        try:
            hmac_obj = hmac.HMAC(key, hashes.SHA256(), backend=default_backend())
            hmac_obj.update(data)
            signature = hmac_obj.finalize()
            logger.info("HMAC signature generated successfully")
            return signature
    
        except Exception as e:
            logger.error(f"Failed to generate HMAC signature: {str(e)}")
            raise
    
    def hmac_verify(key: bytes, signature: bytes, data: bytes) -> bool:
        """
        Verify an HMAC signature for data using a symmetric key.
    
        Args:
            key (bytes): The symmetric key.
            signature (bytes): The HMAC signature to verify.
            data (bytes): The data that was signed.
    
        Returns:
            bool: True if the HMAC is valid, False otherwise.
        """
        try:
            hmac_obj = hmac.HMAC(key, hashes.SHA256(), backend=default_backend())
            hmac_obj.update(data)
            hmac_obj.verify(signature)
            logger.info("HMAC signature verified successfully")
            return True
    
        except Exception as e:
            logger.error(f"HMAC verification failed: {str(e)}")
            return False
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/network/config.py
# Size: 10286 bytes
# Last Modified: Sat Oct 26 22:30:57 2024
# Language: py
# ============================================================

```py
    # ================================================================
    # File: blockchain/network/config.py
    # Description: Network configuration settings for the ICN network.
    # Defines network parameters, protocols, and connection settings
    # for the InterCooperative Network.
    # ================================================================
    
    from dataclasses import dataclass, field
    from typing import Dict, List, Optional, Set
    import os
    import json
    import logging
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class NetworkConfig:
        """Network configuration parameters."""
        
        # Node identification
        node_id: str
        cooperative_id: Optional[str] = None
        
        # Network addresses
        host: str = "0.0.0.0"
        port: int = 30303
        discovery_port: int = 30304
        
        # Connection limits
        max_peers: int = 50
        min_peers: int = 10
        max_connections_per_ip: int = 5
        connection_timeout: int = 30
        
        # Protocol settings
        supported_protocols: Set[str] = field(default_factory=lambda: {"icn/1.0", "icn/1.1"})
        min_protocol_version: str = "icn/1.0"
        max_message_size: int = 1024 * 1024  # 1MB
        
        # Discovery settings
        discovery_interval: int = 300  # 5 minutes
        bootstrap_nodes: List[Dict[str, Any]] = field(default_factory=list)
        enable_auto_discovery: bool = True
        discovery_methods: Set[str] = field(default_factory=lambda: {"broadcast", "bootstrap", "peer"})
        
        # Resource limits
        max_inbound_connections: int = 40
        max_outbound_connections: int = 20
        max_pending_connections: int = 10
        buffer_size: int = 1024 * 16  # 16KB
        
        # Performance settings
        read_timeout: float = 30.0
        write_timeout: float = 30.0
        keepalive_interval: int = 60
        ping_interval: int = 120
        
        # Security settings
        enable_encryption: bool = True
        require_node_id_verification: bool = True
        blacklist_threshold: int = 3
        reputation_threshold: float = 0.3
        
        # Cooperative settings
        prioritize_cooperative_peers: bool = True
        cooperative_connection_bonus: float = 0.2
        min_cooperative_peers: int = 5
        
        # Metrics and monitoring
        metrics_interval: int = 60
        log_metrics: bool = True
        enable_peer_scoring: bool = True
        
        @classmethod
        def load_from_file(cls, filepath: str) -> 'NetworkConfig':
            """
            Load configuration from a JSON file.
            
            Args:
                filepath: Path to configuration file
                
            Returns:
                NetworkConfig: Loaded configuration
            """
            try:
                if not os.path.exists(filepath):
                    raise FileNotFoundError(f"Configuration file not found: {filepath}")
                    
                with open(filepath, 'r') as f:
                    config_data = json.load(f)
                    
                # Validate required fields
                if "node_id" not in config_data:
                    raise ValueError("Configuration must include node_id")
                    
                return cls(**config_data)
                
            except Exception as e:
                logger.error(f"Error loading network configuration: {str(e)}")
                raise
        
        def save_to_file(self, filepath: str) -> None:
            """
            Save configuration to a JSON file.
            
            Args:
                filepath: Path to save configuration to
            """
            try:
                # Convert config to dictionary
                config_dict = {
                    "node_id": self.node_id,
                    "cooperative_id": self.cooperative_id,
                    "host": self.host,
                    "port": self.port,
                    "discovery_port": self.discovery_port,
                    "max_peers": self.max_peers,
                    "min_peers": self.min_peers,
                    "max_connections_per_ip": self.max_connections_per_ip,
                    "connection_timeout": self.connection_timeout,
                    "supported_protocols": list(self.supported_protocols),
                    "min_protocol_version": self.min_protocol_version,
                    "max_message_size": self.max_message_size,
                    "discovery_interval": self.discovery_interval,
                    "bootstrap_nodes": self.bootstrap_nodes,
                    "enable_auto_discovery": self.enable_auto_discovery,
                    "discovery_methods": list(self.discovery_methods),
                    "max_inbound_connections": self.max_inbound_connections,
                    "max_outbound_connections": self.max_outbound_connections,
                    "max_pending_connections": self.max_pending_connections,
                    "buffer_size": self.buffer_size,
                    "read_timeout": self.read_timeout,
                    "write_timeout": self.write_timeout,
                    "keepalive_interval": self.keepalive_interval,
                    "ping_interval": self.ping_interval,
                    "enable_encryption": self.enable_encryption,
                    "require_node_id_verification": self.require_node_id_verification,
                    "blacklist_threshold": self.blacklist_threshold,
                    "reputation_threshold": self.reputation_threshold,
                    "prioritize_cooperative_peers": self.prioritize_cooperative_peers,
                    "cooperative_connection_bonus": self.cooperative_connection_bonus,
                    "min_cooperative_peers": self.min_cooperative_peers,
                    "metrics_interval": self.metrics_interval,
                    "log_metrics": self.log_metrics,
                    "enable_peer_scoring": self.enable_peer_scoring
                }
                
                # Save to file
                with open(filepath, 'w') as f:
                    json.dump(config_dict, f, indent=4)
                    
                logger.info(f"Network configuration saved to {filepath}")
                
            except Exception as e:
                logger.error(f"Error saving network configuration: {str(e)}")
                raise
        
        def validate(self) -> bool:
            """
            Validate configuration settings.
            
            Returns:
                bool: True if configuration is valid
            """
            try:
                # Validate node identification
                if not self.node_id or len(self.node_id) < 8:
                    logger.error("Invalid node_id")
                    return False
                
                # Validate network settings
                if self.port < 1024 or self.port > 65535:
                    logger.error("Invalid port number")
                    return False
                    
                if self.discovery_port < 1024 or self.discovery_port > 65535:
                    logger.error("Invalid discovery port")
                    return False
                    
                # Validate connection limits
                if self.max_peers < self.min_peers:
                    logger.error("max_peers cannot be less than min_peers")
                    return False
                    
                if self.max_inbound_connections + self.max_outbound_connections > self.max_peers:
                    logger.error("Total connections cannot exceed max_peers")
                    return False
                    
                # Validate timeouts
                if self.read_timeout <= 0 or self.write_timeout <= 0:
                    logger.error("Timeouts must be positive")
                    return False
                    
                # Validate intervals
                if (self.keepalive_interval <= 0 or self.ping_interval <= 0 or 
                    self.metrics_interval <= 0 or self.discovery_interval <= 0):
                    logger.error("Intervals must be positive")
                    return False
                    
                # Validate thresholds
                if self.reputation_threshold < 0 or self.reputation_threshold > 1:
                    logger.error("Reputation threshold must be between 0 and 1")
                    return False
                    
                # Validate cooperative settings
                if self.min_cooperative_peers > self.max_peers:
                    logger.error("min_cooperative_peers cannot exceed max_peers")
                    return False
                    
                if self.cooperative_connection_bonus < 0 or self.cooperative_connection_bonus > 1:
                    logger.error("cooperative_connection_bonus must be between 0 and 1")
                    return False
                    
                # Validate protocol settings
                if not self.supported_protocols:
                    logger.error("Must support at least one protocol version")
                    return False
                    
                if self.min_protocol_version not in self.supported_protocols:
                    logger.error("min_protocol_version must be in supported_protocols")
                    return False
                    
                return True
                
            except Exception as e:
                logger.error(f"Error validating configuration: {str(e)}")
                return False
        
        def get_discovery_config(self) -> Dict[str, Any]:
            """
            Get discovery-specific configuration.
            
            Returns:
                Dict[str, Any]: Discovery configuration parameters
            """
            return {
                "port": self.discovery_port,
                "interval": self.discovery_interval,
                "bootstrap_nodes": self.bootstrap_nodes,
                "enable_auto": self.enable_auto_discovery,
                "methods": list(self.discovery_methods)
            }
        
        def get_connection_limits(self) -> Dict[str, int]:
            """
            Get connection limit configuration.
            
            Returns:
                Dict[str, int]: Connection limits
            """
            return {
                "max_peers": self.max_peers,
                "min_peers": self.min_peers,
                "max_inbound": self.max_inbound_connections,
                "max_outbound": self.max_outbound_connections,
                "max_pending": self.max_pending_connections,
                "max_per_ip": self.max_connections_per_ip
            }
    
    # Default configuration
    DEFAULT_CONFIG = NetworkConfig(
        node_id="",  # Must be set by application
        host="0.0.0.0",
        port=30303,
        discovery_port=30304,
        bootstrap_nodes=[
            {
                "node_id": "bootstrap-1",
                "address": "bootstrap1.icn.network",
                "port": 30303
            },
            {
                "node_id": "bootstrap-2",
                "address": "bootstrap2.icn.network",
                "port": 30303
            }
        ]
    )
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/network/manager.py
# Size: 20088 bytes
# Last Modified: Sat Oct 26 22:27:34 2024
# Language: py
# ============================================================

```py
    # ================================================================
    # File: blockchain/network/manager.py
    # Description: Core network management for the ICN blockchain.
    # This module handles P2P networking, message routing, and peer
    # management for the InterCooperative Network.
    # ================================================================
    
    import asyncio
    import logging
    import json
    from typing import Dict, Set, Optional, Callable, Any, List
    from datetime import datetime
    from dataclasses import dataclass, field
    import hashlib
    import random
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class PeerInfo:
        """Information about a connected peer."""
        node_id: str
        address: str
        port: int
        last_seen: datetime = field(default_factory=datetime.now)
        reputation: float = 1.0
        cooperative_id: Optional[str] = None
        supported_protocols: Set[str] = field(default_factory=set)
        connection_attempts: int = 0
        is_active: bool = False
        metadata: Dict[str, Any] = field(default_factory=dict)
    
    @dataclass
    class Message:
        """Network message structure."""
        message_type: str
        payload: Dict[str, Any]
        sender: str
        timestamp: datetime = field(default_factory=datetime.now)
        message_id: str = field(init=False)
    
        def __post_init__(self):
            """Generate unique message ID after initialization."""
            message_data = f"{self.message_type}:{self.sender}:{self.timestamp.isoformat()}"
            self.message_id = hashlib.sha256(message_data.encode()).hexdigest()
    
    class NetworkManager:
        """
        Manages P2P networking for the ICN blockchain.
        
        Responsibilities:
        - Peer discovery and connection management
        - Message routing and broadcasting
        - Network state monitoring
        - Protocol version management
        """
    
        def __init__(self, node_id: str, host: str, port: int, max_peers: int = 50):
            """
            Initialize the network manager.
            
            Args:
                node_id: Unique identifier for this node
                host: Host address to bind to
                port: Port to listen on
                max_peers: Maximum number of peer connections
            """
            self.node_id = node_id
            self.host = host
            self.port = port
            self.max_peers = max_peers
    
            # Connection management
            self.peers: Dict[str, PeerInfo] = {}
            self.blacklisted_peers: Set[str] = set()
            self.pending_connections: Set[str] = set()
            self.connection_timeout = 30  # seconds
    
            # Message handling
            self.message_handlers: Dict[str, List[Callable]] = {}
            self.processed_messages: Set[str] = set()
            self.message_cache_size = 1000
    
            # Protocol versioning
            self.supported_protocols = {"icn/1.0", "icn/1.1"}
            self.min_protocol_version = "icn/1.0"
    
            # State
            self.is_running = False
            self.server: Optional[asyncio.Server] = None
            self.metrics: Dict[str, Any] = {
                "messages_processed": 0,
                "messages_sent": 0,
                "failed_connections": 0,
                "active_connections": 0
            }
    
        async def start(self) -> None:
            """Start the network manager and begin accepting connections."""
            if self.is_running:
                return
    
            try:
                # Start TCP server
                self.server = await asyncio.start_server(
                    self._handle_connection,
                    self.host,
                    self.port
                )
                self.is_running = True
                
                # Start background tasks
                asyncio.create_task(self._maintenance_loop())
                asyncio.create_task(self._metrics_loop())
                
                logger.info(f"Network manager started on {self.host}:{self.port}")
                
                # Serve forever
                async with self.server:
                    await self.server.serve_forever()
                    
            except Exception as e:
                logger.error(f"Failed to start network manager: {str(e)}")
                raise
    
        async def stop(self) -> None:
            """Stop the network manager and close all connections."""
            if not self.is_running:
                return
    
            try:
                # Close all peer connections
                close_tasks = [
                    self._close_peer_connection(peer_id)
                    for peer_id in list(self.peers.keys())
                ]
                await asyncio.gather(*close_tasks, return_exceptions=True)
    
                # Stop server
                if self.server:
                    self.server.close()
                    await self.server.wait_closed()
    
                self.is_running = False
                logger.info("Network manager stopped")
    
            except Exception as e:
                logger.error(f"Error stopping network manager: {str(e)}")
                raise
    
        async def connect_to_peer(self, peer_id: str, address: str, port: int) -> bool:
            """
            Establish connection to a new peer.
            
            Args:
                peer_id: Unique identifier of the peer
                address: Peer's network address
                port: Peer's port number
                
            Returns:
                bool: True if connection successful, False otherwise
            """
            if peer_id in self.blacklisted_peers:
                logger.warning(f"Attempted to connect to blacklisted peer: {peer_id}")
                return False
    
            if peer_id in self.peers:
                logger.debug(f"Already connected to peer: {peer_id}")
                return True
    
            if len(self.peers) >= self.max_peers:
                logger.warning("Maximum peer connections reached")
                return False
    
            try:
                # Attempt TCP connection
                reader, writer = await asyncio.open_connection(address, port)
    
                # Create peer info
                peer_info = PeerInfo(
                    node_id=peer_id,
                    address=address,
                    port=port
                )
    
                # Perform handshake
                if not await self._perform_handshake(reader, writer, peer_info):
                    writer.close()
                    await writer.wait_closed()
                    return False
    
                # Store peer connection
                self.peers[peer_id] = peer_info
                self.metrics["active_connections"] += 1
    
                # Start message handling loop
                asyncio.create_task(self._handle_peer_messages(reader, writer, peer_id))
    
                logger.info(f"Successfully connected to peer: {peer_id}")
                return True
    
            except Exception as e:
                logger.error(f"Failed to connect to peer {peer_id}: {str(e)}")
                self.metrics["failed_connections"] += 1
                return False
    
        async def broadcast_message(self, message_type: str, payload: Dict[str, Any]) -> None:
            """
            Broadcast a message to all connected peers.
            
            Args:
                message_type: Type of message to broadcast
                payload: Message payload data
            """
            message = Message(
                message_type=message_type,
                payload=payload,
                sender=self.node_id
            )
    
            try:
                send_tasks = []
                for peer_id, peer_info in self.peers.items():
                    if peer_info.is_active:
                        send_tasks.append(
                            self._send_message_to_peer(peer_id, message)
                        )
    
                await asyncio.gather(*send_tasks, return_exceptions=True)
                self.metrics["messages_sent"] += len(send_tasks)
    
            except Exception as e:
                logger.error(f"Error broadcasting message: {str(e)}")
    
        async def send_message(self, peer_id: str, message_type: str, payload: Dict[str, Any]) -> bool:
            """
            Send a message to a specific peer.
            
            Args:
                peer_id: ID of the peer to send to
                message_type: Type of message to send
                payload: Message payload data
                
            Returns:
                bool: True if message sent successfully, False otherwise
            """
            if peer_id not in self.peers:
                logger.warning(f"Attempted to send message to unknown peer: {peer_id}")
                return False
    
            message = Message(
                message_type=message_type,
                payload=payload,
                sender=self.node_id
            )
    
            try:
                await self._send_message_to_peer(peer_id, message)
                self.metrics["messages_sent"] += 1
                return True
    
            except Exception as e:
                logger.error(f"Failed to send message to peer {peer_id}: {str(e)}")
                return False
    
        def register_message_handler(self, message_type: str, handler: Callable) -> None:
            """
            Register a handler function for a specific message type.
            
            Args:
                message_type: Type of message to handle
                handler: Callback function to handle messages of this type
            """
            if message_type not in self.message_handlers:
                self.message_handlers[message_type] = []
            self.message_handlers[message_type].append(handler)
    
        async def _handle_connection(self, reader: asyncio.StreamReader, writer: asyncio.StreamWriter) -> None:
            """Handle incoming peer connection."""
            try:
                # Receive handshake
                handshake_data = await reader.read(1024)
                handshake = json.loads(handshake_data.decode())
    
                peer_id = handshake.get("node_id")
                if not peer_id:
                    writer.close()
                    return
    
                # Check if peer is blacklisted
                if peer_id in self.blacklisted_peers:
                    writer.close()
                    return
    
                # Create peer info
                peer_info = PeerInfo(
                    node_id=peer_id,
                    address=writer.get_extra_info('peername')[0],
                    port=writer.get_extra_info('peername')[1]
                )
    
                # Send handshake response
                response = {
                    "node_id": self.node_id,
                    "protocols": list(self.supported_protocols)
                }
                writer.write(json.dumps(response).encode())
                await writer.drain()
    
                # Store peer connection
                self.peers[peer_id] = peer_info
                self.metrics["active_connections"] += 1
    
                # Start message handling loop
                asyncio.create_task(self._handle_peer_messages(reader, writer, peer_id))
    
            except Exception as e:
                logger.error(f"Error handling connection: {str(e)}")
                writer.close()
    
        async def _handle_peer_messages(
            self,
            reader: asyncio.StreamReader,
            writer: asyncio.StreamWriter,
            peer_id: str
        ) -> None:
            """Handle incoming messages from a peer."""
            try:
                while True:
                    # Read message length
                    length_data = await reader.readexactly(4)
                    message_length = int.from_bytes(length_data, 'big')
    
                    # Read message data
                    message_data = await reader.readexactly(message_length)
                    message_dict = json.loads(message_data.decode())
    
                    # Create message object
                    message = Message(
                        message_type=message_dict["message_type"],
                        payload=message_dict["payload"],
                        sender=message_dict["sender"]
                    )
    
                    # Process message if not seen before
                    if message.message_id not in self.processed_messages:
                        self.processed_messages.add(message.message_id)
                        if len(self.processed_messages) > self.message_cache_size:
                            self.processed_messages.pop()
    
                        # Call registered handlers
                        handlers = self.message_handlers.get(message.message_type, [])
                        for handler in handlers:
                            try:
                                await handler(message, peer_id)
                            except Exception as e:
                                logger.error(f"Error in message handler: {str(e)}")
    
                        self.metrics["messages_processed"] += 1
    
            except asyncio.IncompleteReadError:
                # Connection closed
                await self._close_peer_connection(peer_id)
            except Exception as e:
                logger.error(f"Error handling messages from peer {peer_id}: {str(e)}")
                await self._close_peer_connection(peer_id)
    
        async def _send_message_to_peer(self, peer_id: str, message: Message) -> None:
            """Send a message to a specific peer."""
            if peer_id not in self.peers:
                raise ValueError(f"Unknown peer: {peer_id}")
    
            # Serialize message
            message_dict = {
                "message_type": message.message_type,
                "payload": message.payload,
                "sender": message.sender,
                "timestamp": message.timestamp.isoformat()
            }
            message_data = json.dumps(message_dict).encode()
    
            # Send message length followed by message data
            message_length = len(message_data)
            length_bytes = message_length.to_bytes(4, 'big')
    
            writer = self.peers[peer_id].writer
            writer.write(length_bytes + message_data)
            await writer.drain()
    
        async def _perform_handshake(
            self,
            reader: asyncio.StreamReader,
            writer: asyncio.StreamWriter,
            peer_info: PeerInfo
        ) -> bool:
            """Perform protocol handshake with a peer."""
            try:
                # Send handshake
                handshake = {
                    "node_id": self.node_id,
                    "protocols": list(self.supported_protocols)
                }
                writer.write(json.dumps(handshake).encode())
                await writer.drain()
    
                # Receive response
                response_data = await reader.read(1024)
                response = json.loads(response_data.decode())
    
                # Verify peer ID
                if response.get("node_id") != peer_info.node_id:
                    return False
    
                # Check protocol compatibility
                peer_protocols = set(response.get("protocols", []))
                if not peer_protocols & self.supported_protocols:
                    return False
    
                peer_info.supported_protocols = peer_protocols
                peer_info.is_active = True
                return True
    
            except Exception as e:
                logger.error(f"Handshake failed: {str(e)}")
                return False
    
        async def _close_peer_connection(self, peer_id: str) -> None:
            """Close connection with a peer."""
            if peer_id in self.peers:
                peer_info = self.peers[peer_id]
                if hasattr(peer_info, 'writer'):
                    peer_info.writer.close()
                    await peer_info.writer.wait_closed()
                del self.peers[peer_id]
                self.metrics["active_connections"] -= 1
    
        async def _maintenance_loop(self) -> None:
            """Periodic maintenance tasks."""
            while self.is_running:
                try:
                    # Remove inactive peers
                    now = datetime.now()
                    for peer_id, peer_info in list(self.peers.items()):
                        if (now - peer_info.last_seen).total_seconds() > 300:  # 5 minutes
                            await self._close_peer_connection(peer_id)
    
                    # Clear old processed messages
                    if len(self.processed_messages) > self.message_cache_size:
                        self.processed_messages = set(
                            list(self.processed_messages)[-self.message_cache_size:]
                        )
    
                except Exception as e:
                    logger.error(f"Error in maintenance loop: {str(e)}")
    
                await asyncio.sleep(60)
                # Continuing from the previous NetworkManager class...
    
        async def _metrics_loop(self) -> None:
            """Background task to update network metrics."""
            while self.is_running:
                try:
                    # Update peer metrics
                    active_peers = sum(1 for p in self.peers.values() if p.is_active)
                    total_reputation = sum(p.reputation for p in self.peers.values())
                    
                    self.metrics.update({
                        "active_peers": active_peers,
                        "total_peers": len(self.peers),
                        "average_reputation": total_reputation / max(1, len(self.peers)),
                        "blacklisted_peers": len(self.blacklisted_peers),
                        "pending_connections": len(self.pending_connections)
                    })
    
                    # Log metrics
                    if active_peers > 0:
                        logger.info(f"Network metrics: {self.metrics}")
    
                except Exception as e:
                    logger.error(f"Error updating metrics: {str(e)}")
    
                await asyncio.sleep(30)  # Update every 30 seconds
    
        def get_peer_info(self, peer_id: str) -> Optional[PeerInfo]:
            """
            Get information about a specific peer.
            
            Args:
                peer_id: ID of the peer
                
            Returns:
                Optional[PeerInfo]: Peer information if found
            """
            return self.peers.get(peer_id)
    
        def get_active_peers(self) -> List[PeerInfo]:
            """
            Get list of currently active peers.
            
            Returns:
                List[PeerInfo]: List of active peer information
            """
            return [peer for peer in self.peers.values() if peer.is_active]
    
        def blacklist_peer(self, peer_id: str, reason: str) -> None:
            """
            Add a peer to the blacklist.
            
            Args:
                peer_id: ID of the peer to blacklist
                reason: Reason for blacklisting
            """
            self.blacklisted_peers.add(peer_id)
            if peer_id in self.peers:
                asyncio.create_task(self._close_peer_connection(peer_id))
            logger.warning(f"Blacklisted peer {peer_id}: {reason}")
    
        def get_network_info(self) -> Dict[str, Any]:
            """
            Get comprehensive information about the network state.
            
            Returns:
                Dict[str, Any]: Network state information
            """
            return {
                "node_id": self.node_id,
                "address": f"{self.host}:{self.port}",
                "is_running": self.is_running,
                "metrics": self.metrics.copy(),
                "peers": {
                    peer_id: {
                        "address": f"{peer.address}:{peer.port}",
                        "last_seen": peer.last_seen.isoformat(),
                        "reputation": peer.reputation,
                        "is_active": peer.is_active,
                        "protocols": list(peer.supported_protocols)
                    }
                    for peer_id, peer in self.peers.items()
                },
                "protocols": list(self.supported_protocols),
                "min_protocol": self.min_protocol_version
            }
    
        async def ping_peer(self, peer_id: str) -> bool:
            """
            Send a ping message to check peer connectivity.
            
            Args:
                peer_id: ID of the peer to ping
                
            Returns:
                bool: True if ping successful, False otherwise
            """
            try:
                ping_payload = {
                    "timestamp": datetime.now().isoformat()
                }
                return await self.send_message(peer_id, "ping", ping_payload)
            except Exception as e:
                logger.error(f"Error pinging peer {peer_id}: {str(e)}")
                return False
    
        def update_peer_reputation(self, peer_id: str, change: float) -> None:
            """
            Update a peer's reputation score.
            
            Args:
                peer_id: ID of the peer
                change: Amount to change reputation by (positive or negative)
            """
            if peer_id in self.peers:
                peer = self.peers[peer_id]
                peer.reputation = max(0.0, min(1.0, peer.reputation + change))
                
                # Blacklist peers with consistently bad reputation
                if peer.reputation <= 0.1:
                    self.blacklist_peer(peer_id, "Low reputation score")
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/network/discovery/discovery.py
# Size: 16429 bytes
# Last Modified: Sat Oct 26 22:29:28 2024
# Language: py
# ============================================================

```py
    # ================================================================
    # File: blockchain/network/discovery/discovery.py
    # Description: Peer discovery implementation for the ICN network.
    # Handles automatic peer discovery, peer list management, and 
    # connection bootstrapping for the InterCooperative Network.
    # ================================================================
    
    import asyncio
    import logging
    import json
    import random
    from typing import Dict, Set, List, Optional, Any
    from datetime import datetime, timedelta
    from dataclasses import dataclass, field
    import socket
    import struct
    import ipaddress
    from hashlib import sha256
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class PeerRecord:
        """Information about a discovered peer."""
        node_id: str
        address: str
        port: int
        last_seen: datetime = field(default_factory=datetime.now)
        last_successful_connection: Optional[datetime] = None
        connection_attempts: int = 0
        is_bootstrap_node: bool = False
        cooperative_id: Optional[str] = None
        metadata: Dict[str, Any] = field(default_factory=dict)
        
        @property
        def peer_score(self) -> float:
            """Calculate peer score based on reliability and history."""
            if self.is_bootstrap_node:
                return 1.0
                
            # Base score starts at 0.5
            score = 0.5
            
            # Increase score for successful connections
            if self.last_successful_connection:
                hours_since_connection = (datetime.now() - self.last_successful_connection).total_seconds() / 3600
                if hours_since_connection < 24:
                    score += 0.3
                elif hours_since_connection < 72:
                    score += 0.1
                    
            # Decrease score for failed connection attempts
            score -= min(0.4, self.connection_attempts * 0.1)
            
            return max(0.0, min(1.0, score))
    
    class PeerDiscovery:
        """
        Manages peer discovery and connection management.
        
        Features:
        - Automatic peer discovery using multiple methods
        - Bootstrap node support
        - Peer scoring and prioritization
        - Connection attempt management
        - Cooperative-aware peer selection
        """
        
        def __init__(
            self,
            node_id: str,
            host: str,
            port: int,
            bootstrap_nodes: List[Dict[str, Any]] = None,
            max_peers: int = 50,
            discovery_interval: int = 300
        ):
            """
            Initialize the peer discovery system.
            
            Args:
                node_id: Unique identifier for this node
                host: Host address to bind to
                port: Port to listen on
                bootstrap_nodes: List of known bootstrap nodes
                max_peers: Maximum number of peers to maintain
                discovery_interval: Seconds between discovery attempts
            """
            self.node_id = node_id
            self.host = host
            self.port = port
            self.max_peers = max_peers
            self.discovery_interval = discovery_interval
            
            # Peer management
            self.known_peers: Dict[str, PeerRecord] = {}
            self.connected_peers: Set[str] = set()
            self.blacklisted_peers: Set[str] = set()
            self.pending_connections: Set[str] = set()
            
            # Bootstrap configuration
            self.bootstrap_nodes = bootstrap_nodes or []
            for node in self.bootstrap_nodes:
                self._add_bootstrap_node(node)
                
            # Discovery state
            self.is_running = False
            self.last_discovery = datetime.now() - timedelta(seconds=discovery_interval)
            
            # UDP discovery
            self.discovery_socket: Optional[socket.socket] = None
            self.discovery_port = port + 1
            
            # Metrics
            self.metrics = {
                "total_discoveries": 0,
                "successful_discoveries": 0,
                "failed_discoveries": 0,
                "total_connection_attempts": 0,
                "successful_connections": 0,
                "failed_connections": 0
            }
    
        async def start(self) -> None:
            """Start the peer discovery service."""
            if self.is_running:
                return
                
            try:
                # Initialize UDP discovery socket
                self.discovery_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
                self.discovery_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
                self.discovery_socket.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)
                self.discovery_socket.bind(('', self.discovery_port))
                
                self.is_running = True
                
                # Start background tasks
                asyncio.create_task(self._discovery_loop())
                asyncio.create_task(self._maintenance_loop())
                asyncio.create_task(self._listen_for_broadcasts())
                
                logger.info(f"Peer discovery started on {self.host}:{self.port}")
                
            except Exception as e:
                logger.error(f"Failed to start peer discovery: {str(e)}")
                raise
    
        async def stop(self) -> None:
            """Stop the peer discovery service."""
            if not self.is_running:
                return
                
            try:
                self.is_running = False
                
                if self.discovery_socket:
                    self.discovery_socket.close()
                    
                logger.info("Peer discovery stopped")
                
            except Exception as e:
                logger.error(f"Error stopping peer discovery: {str(e)}")
    
        async def get_peers(self, count: int = 10, cooperative_id: Optional[str] = None) -> List[PeerRecord]:
            """
            Get a list of recommended peers to connect to.
            
            Args:
                count: Number of peers to return
                cooperative_id: Optional cooperative ID to prioritize
                
            Returns:
                List[PeerRecord]: List of recommended peers
            """
            try:
                # Filter and sort peers
                available_peers = [
                    peer for peer_id, peer in self.known_peers.items()
                    if peer_id not in self.connected_peers
                    and peer_id not in self.blacklisted_peers
                    and peer_id not in self.pending_connections
                    and (not cooperative_id or peer.cooperative_id == cooperative_id)
                ]
                
                # Sort by score
                available_peers.sort(key=lambda p: p.peer_score, reverse=True)
                
                return available_peers[:count]
                
            except Exception as e:
                logger.error(f"Error getting peers: {str(e)}")
                return []
    
        def add_peer(self, node_id: str, address: str, port: int, **kwargs) -> bool:
            """
            Add a new peer to the known peers list.
            
            Args:
                node_id: Unique identifier of the peer
                address: Peer's network address
                port: Peer's port number
                **kwargs: Additional peer metadata
                
            Returns:
                bool: True if peer was added, False otherwise
            """
            try:
                if node_id in self.blacklisted_peers:
                    return False
                    
                if node_id not in self.known_peers:
                    self.known_peers[node_id] = PeerRecord(
                        node_id=node_id,
                        address=address,
                        port=port,
                        cooperative_id=kwargs.get('cooperative_id'),
                        metadata=kwargs
                    )
                else:
                    # Update existing peer record
                    peer = self.known_peers[node_id]
                    peer.address = address
                    peer.port = port
                    peer.last_seen = datetime.now()
                    peer.metadata.update(kwargs)
                    
                return True
                
            except Exception as e:
                logger.error(f"Error adding peer: {str(e)}")
                return False
    
        def blacklist_peer(self, node_id: str, reason: str) -> None:
            """
            Add a peer to the blacklist.
            
            Args:
                node_id: ID of the peer to blacklist
                reason: Reason for blacklisting
            """
            self.blacklisted_peers.add(node_id)
            if node_id in self.known_peers:
                del self.known_peers[node_id]
            logger.warning(f"Blacklisted peer {node_id}: {reason}")
    
        async def _discovery_loop(self) -> None:
            """Background task for periodic peer discovery."""
            while self.is_running:
                try:
                    # Check if discovery is needed
                    now = datetime.now()
                    if (now - self.last_discovery).total_seconds() < self.discovery_interval:
                        await asyncio.sleep(5)
                        continue
                        
                    self.last_discovery = now
                    self.metrics["total_discoveries"] += 1
                    
                    # Perform discovery methods
                    discovery_tasks = [
                        self._broadcast_discovery(),
                        self._query_bootstrap_nodes(),
                        self._query_known_peers()
                    ]
                    
                    results = await asyncio.gather(*discovery_tasks, return_exceptions=True)
                    
                    # Update metrics
                    success = sum(1 for r in results if r and not isinstance(r, Exception))
                    self.metrics["successful_discoveries"] += success
                    self.metrics["failed_discoveries"] += (len(results) - success)
                    
                    # Log results
                    logger.info(f"Discovery round completed: {success} successful methods")
                    
                except Exception as e:
                    logger.error(f"Error in discovery loop: {str(e)}")
                    
                await asyncio.sleep(5)
    
        async def _maintenance_loop(self) -> None:
            """Background task for peer list maintenance."""
            while self.is_running:
                try:
                    now = datetime.now()
                    
                    # Remove old peers
                    for peer_id in list(self.known_peers.keys()):
                        peer = self.known_peers[peer_id]
                        if not peer.is_bootstrap_node:
                            if (now - peer.last_seen).total_seconds() > 3600:  # 1 hour
                                del self.known_peers[peer_id]
                    
                    # Clear old pending connections
                    self.pending_connections = {
                        peer_id for peer_id in self.pending_connections
                        if peer_id in self.known_peers
                    }
                    
                except Exception as e:
                    logger.error(f"Error in maintenance loop: {str(e)}")
                    
                await asyncio.sleep(60)
    
        async def _broadcast_discovery(self) -> bool:
            """Broadcast discovery message on local network."""
            try:
                # Prepare discovery message
                message = {
                    "node_id": self.node_id,
                    "address": self.host,
                    "port": self.port,
                    "timestamp": datetime.now().isoformat()
                }
                
                # Broadcast message
                data = json.dumps(message).encode()
                self.discovery_socket.sendto(data, ('<broadcast>', self.discovery_port))
                
                return True
                
            except Exception as e:
                logger.error(f"Error broadcasting discovery: {str(e)}")
                return False
    
        async def _listen_for_broadcasts(self) -> None:
            """Listen for discovery broadcasts from other nodes."""
            while self.is_running:
                try:
                    # Receive broadcast
                    data, addr = await asyncio.get_event_loop().sock_recvfrom(self.discovery_socket, 1024)
                    message = json.loads(data.decode())
                    
                    # Validate message
                    required_fields = {"node_id", "address", "port", "timestamp"}
                    if not all(field in message for field in required_fields):
                        continue
                        
                    # Add peer
                    node_id = message["node_id"]
                    if node_id != self.node_id:
                        self.add_peer(
                            node_id=node_id,
                            address=message["address"],
                            port=message["port"]
                        )
                        
                except Exception as e:
                    logger.error(f"Error processing broadcast: {str(e)}")
                    
                await asyncio.sleep(0.1)
    
        async def _query_bootstrap_nodes(self) -> bool:
            """Query bootstrap nodes for peer information."""
            try:
                # Query each bootstrap node
                for node in self.bootstrap_nodes:
                    try:
                        # Create TCP connection
                        reader, writer = await asyncio.open_connection(
                            node["address"],
                            node["port"]
                        )
                        
                        # Send peer request
                        request = {
                            "message_type": "peer_request",
                            "node_id": self.node_id,
                            "timestamp": datetime.now().isoformat()
                        }
                        writer.write(json.dumps(request).encode())
                        await writer.drain()
                        
                        # Read response
                        data = await reader.read(8192)
                        response = json.loads(data.decode())
                        
                        # Process peers
                        for peer in response.get("peers", []):
                            self.add_peer(**peer)
                            
                        writer.close()
                        await writer.wait_closed()
                        
                    except Exception as e:
                        logger.error(f"Error querying bootstrap node: {str(e)}")
                        
                return True
                
            except Exception as e:
                logger.error(f"Error in bootstrap node query: {str(e)}")
                return False
    
        async def _query_known_peers(self) -> bool:
            """Query known peers for their peer lists."""
            try:
                # Select random subset of known peers
                sample_size = min(5, len(self.known_peers))
                if sample_size == 0:
                    return False
                    
                selected_peers = random.sample(list(self.known_peers.values()), sample_size)
                
                # Query each selected peer
                for peer in selected_peers:
                    try:
                        # Create TCP connection
                        reader, writer = await asyncio.open_connection(
                            peer.address,
                            peer.port
                        )
                        
                        # Send peer request
                        request = {
                            "message_type": "peer_request",
                            "node_id": self.node_id,
                            "timestamp": datetime.now().isoformat()
                        }
                        writer.write(json.dumps(request).encode())
                        await writer.drain()
                        
                        # Read response
                        data = await reader.read(8192)
                        response = json.loads(data.decode())
                        
                        # Process peers
                        for peer_data in response.get("peers", []):
                            self.add_peer(**peer_data)
                            
                        writer.close()
                        await writer.wait_closed()
                        
                    except Exception as e:
                        logger.error(f"Error querying peer {peer.node_id}: {str(e)}")
                        peer.connection_attempts += 1
                        
                return True
                
            except Exception as e:
                logger.error(f"Error in known peer query: {str(e)}")
                return False
    
        def _add_bootstrap_node(self, node: Dict[str, Any]) -> None:
            """Add a bootstrap node to known peers."""
            self.add_peer(
                node_id=node["node_id"],
                address=node["address"],
                port=node["port"],
                is_bootstrap_node=True
            )
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/network/sync/sync_manager.py
# Size: 29290 bytes
# Last Modified: Sat Oct 26 22:58:44 2024
# Language: py
# ============================================================

```py
    # ================================================================
    # File: blockchain/network/sync/sync_manager.py
    # Description: State synchronization manager for ICN network.
    # Handles blockchain state synchronization between nodes, including
    # block synchronization, state verification, and chain reorganization.
    # ================================================================
    
    import asyncio
    import logging
    from typing import Dict, Set, List, Optional, Tuple, Any
    from dataclasses import dataclass, field
    from datetime import datetime, timedelta
    import json
    import hashlib
    from enum import Enum, auto
    
    from ..config import NetworkConfig
    from ..protocol.dispatcher import MessageDispatcher, MessagePriority, MessageRoute
    from ...core.block import Block
    from ...core.transaction import Transaction
    
    logger = logging.getLogger(__name__)
    
    class SyncState(Enum):
        """State of node synchronization."""
        IDLE = auto()
        SYNCING_HEADERS = auto()
        SYNCING_BLOCKS = auto()
        SYNCING_STATE = auto()
        VERIFYING = auto()
    
    @dataclass
    class SyncProgress:
        """Track synchronization progress."""
        start_height: int
        current_height: int
        target_height: int
        start_time: datetime = field(default_factory=datetime.now)
        blocks_processed: int = 0
        blocks_verified: int = 0
        failed_blocks: int = 0
        state_size: int = 0
        
        @property
        def progress_percentage(self) -> float:
            """Calculate sync progress percentage."""
            if self.target_height == self.start_height:
                return 100.0
            return (self.current_height - self.start_height) / (self.target_height - self.start_height) * 100
    
        @property
        def blocks_per_second(self) -> float:
            """Calculate block processing rate."""
            elapsed = (datetime.now() - self.start_time).total_seconds()
            if elapsed == 0:
                return 0.0
            return self.blocks_processed / elapsed
    
        @property
        def estimated_time_remaining(self) -> timedelta:
            """Estimate remaining sync time."""
            if self.blocks_per_second == 0:
                return timedelta(hours=999)  # Large value to indicate unknown
            blocks_remaining = self.target_height - self.current_height
            seconds_remaining = blocks_remaining / self.blocks_per_second
            return timedelta(seconds=seconds_remaining)
    
    class SyncManager:
        """
        Manages blockchain state synchronization.
        
        Features:
        - Block header synchronization
        - Block data synchronization
        - State verification
        - Chain reorganization
        - Checkpoint validation
        - Parallel block downloading
        - State snapshot handling
        """
    
        def __init__(
            self,
            config: NetworkConfig,
            dispatcher: MessageDispatcher,
            chain,  # Actual blockchain instance
            max_parallel_downloads: int = 10,
            verify_interval: int = 100  # Verify every N blocks
        ):
            """Initialize the sync manager."""
            self.config = config
            self.dispatcher = dispatcher
            self.chain = chain
            self.max_parallel_downloads = max_parallel_downloads
            self.verify_interval = verify_interval
            
            # Sync state
            self.sync_state = SyncState.IDLE
            self.current_sync: Optional[SyncProgress] = None
            self.active_downloads: Set[int] = set()
            self.downloaded_blocks: Dict[int, Block] = {}
            self.verified_blocks: Set[int] = set()
            self.failed_blocks: Set[int] = set()
            
            # Peer tracking
            self.peer_heights: Dict[str, int] = {}
            self.sync_peers: Set[str] = set()
            self.banned_peers: Set[str] = set()
            
            # State verification
            self.checkpoints: Dict[int, str] = {}  # height -> state root
            self.state_roots: Dict[int, str] = {}  # height -> state root
            
            # Background tasks
            self.sync_task: Optional[asyncio.Task] = None
            self.verification_task: Optional[asyncio.Task] = None
            
            # Metrics
            self.metrics = {
                "total_syncs": 0,
                "successful_syncs": 0,
                "failed_syncs": 0,
                "blocks_downloaded": 0,
                "blocks_verified": 0,
                "reorgs_processed": 0,
                "average_sync_time": 0.0,
            }
    
        async def start(self) -> None:
            """Start the sync manager."""
            # Register message handlers
            self.dispatcher.register_handler(
                "block_headers",
                self._handle_block_headers,
                priority=MessagePriority.HIGH
            )
            self.dispatcher.register_handler(
                "block_data",
                self._handle_block_data,
                priority=MessagePriority.HIGH
            )
            self.dispatcher.register_handler(
                "state_root",
                self._handle_state_root,
                priority=MessagePriority.MEDIUM
            )
            self.dispatcher.register_handler(
                "checkpoint",
                self._handle_checkpoint,
                priority=MessagePriority.MEDIUM
            )
            
            # Start verification task
            self.verification_task = asyncio.create_task(self._verification_loop())
            
            logger.info("Sync manager started")
    
        async def stop(self) -> None:
            """Stop the sync manager."""
            if self.sync_task:
                self.sync_task.cancel()
                
            if self.verification_task:
                self.verification_task.cancel()
                
            logger.info("Sync manager stopped")
    
        async def start_sync(self, target_height: Optional[int] = None) -> bool:
            """
            Start blockchain synchronization.
            
            Args:
                target_height: Optional target height to sync to
                
            Returns:
                bool: True if sync started successfully
            """
            if self.sync_state != SyncState.IDLE:
                logger.warning("Sync already in progress")
                return False
                
            try:
                # Get current chain height
                current_height = self.chain.height
                
                # Find best peer height if no target specified
                if target_height is None:
                    peer_heights = list(self.peer_heights.values())
                    if not peer_heights:
                        logger.warning("No peers available for sync")
                        return False
                    target_height = max(peer_heights)
                
                if target_height <= current_height:
                    logger.info("Chain already synced")
                    return False
                
                # Initialize sync progress
                self.current_sync = SyncProgress(
                    start_height=current_height,
                    current_height=current_height,
                    target_height=target_height
                )
                
                # Start sync task
                self.sync_state = SyncState.SYNCING_HEADERS
                self.sync_task = asyncio.create_task(self._sync_loop())
                
                logger.info(
                    f"Starting sync from height {current_height} to {target_height}"
                )
                return True
                
            except Exception as e:
                logger.error(f"Error starting sync: {str(e)}")
                return False
    
        def get_sync_progress(self) -> Optional[SyncProgress]:
            """Get current sync progress."""
            return self.current_sync
    
        def add_checkpoint(self, height: int, state_root: str) -> None:
            """Add a trusted checkpoint."""
            self.checkpoints[height] = state_root
            logger.info(f"Added checkpoint at height {height}")
    
        async def verify_chain_state(self, height: Optional[int] = None) -> bool:
            """
            Verify chain state at specified height.
            
            Args:
                height: Height to verify, defaults to current height
                
            Returns:
                bool: True if state is valid
            """
            try:
                if height is None:
                    height = self.chain.height
                    
                # Get state root at height
                state_root = await self._calculate_state_root(height)
                if not state_root:
                    return False
                    
                # Check against checkpoint if available
                checkpoint_root = self.checkpoints.get(height)
                if checkpoint_root and checkpoint_root != state_root:
                    logger.error(f"State root mismatch at checkpoint {height}")
                    return False
                    
                # Verify against peer state roots
                peer_roots = await self._get_peer_state_roots(height)
                if not peer_roots:
                    return True  # No peers to verify against
                    
                # State is valid if it matches majority of peers
                matching_peers = sum(1 for root in peer_roots if root == state_root)
                return matching_peers > len(peer_roots) / 2
                
            except Exception as e:
                logger.error(f"Error verifying chain state: {str(e)}")
                return False
    
        async def _sync_loop(self) -> None:
            """Main synchronization loop."""
            try:
                while self.sync_state != SyncState.IDLE:
                    if self.sync_state == SyncState.SYNCING_HEADERS:
                        await self._sync_headers()
                    elif self.sync_state == SyncState.SYNCING_BLOCKS:
                        await self._sync_blocks()
                    elif self.sync_state == SyncState.SYNCING_STATE:
                        await self._sync_state()
                    elif self.sync_state == SyncState.VERIFYING:
                        await self._verify_sync()
                        
                    await asyncio.sleep(0.1)
                    
            except asyncio.CancelledError:
                logger.info("Sync loop cancelled")
            except Exception as e:
                logger.error(f"Error in sync loop: {str(e)}")
                self.metrics["failed_syncs"] += 1
                self.sync_state = SyncState.IDLE
    
        async def _sync_headers(self) -> None:
            """Synchronize block headers."""
            try:
                if not self.current_sync:
                    return
                    
                start_height = self.current_sync.current_height
                target_height = self.current_sync.target_height
                
                # Request headers in batches
                batch_size = 2000
                current_height = start_height
                
                while current_height < target_height:
                    end_height = min(current_height + batch_size, target_height)
                    
                    # Request headers from peers
                    headers = await self._request_headers(
                        current_height,
                        end_height
                    )
                    
                    if not headers:
                        logger.error("Failed to get headers")
                        self.sync_state = SyncState.IDLE
                        return
                        
                    # Verify and store headers
                    if not await self._verify_headers(headers):
                        logger.error("Header verification failed")
                        self.sync_state = SyncState.IDLE
                        return
                        
                    current_height = end_height
                    self.current_sync.current_height = current_height
                    
                # Move to block sync
                self.sync_state = SyncState.SYNCING_BLOCKS
                
            except Exception as e:
                logger.error(f"Error syncing headers: {str(e)}")
                self.sync_state = SyncState.IDLE
    
        async def _sync_blocks(self) -> None:
            """Synchronize full blocks."""
            try:
                if not self.current_sync:
                    return
                    
                while len(self.active_downloads) < self.max_parallel_downloads:
                    next_height = self._get_next_block_height()
                    if next_height is None:
                        if not self.active_downloads:
                            # All blocks downloaded
                            self.sync_state = SyncState.SYNCING_STATE
                        break
                        
                    # Start block download
                    self.active_downloads.add(next_height)
                    asyncio.create_task(self._download_block(next_height))
                    
            except Exception as e:
                logger.error(f"Error syncing blocks: {str(e)}")
                self.sync_state = SyncState.IDLE
    
        async def _sync_state(self) -> None:
            """Synchronize chain state."""
            try:
                if not self.current_sync:
                    return
                    
                # Request state snapshot
                state_data = await self._request_state_snapshot(
                    self.current_sync.current_height
                )
                
                if not state_data:
                    logger.error("Failed to get state snapshot")
                    self.sync_state = SyncState.IDLE
                    return
                    
                # Verify state
                if not await self._verify_state_snapshot(
                    state_data,
                    self.current_sync.current_height
                ):
                    logger.error("State verification failed")
                    self.sync_state = SyncState.IDLE
                    return
                    
                # Apply state
                if not await self._apply_state_snapshot(state_data):
                    logger.error("Failed to apply state snapshot")
                    self.sync_state = SyncState.IDLE
                    return
                    
                # Move to verification
                self.sync_state = SyncState.VERIFYING
                
            except Exception as e:
                logger.error(f"Error syncing state: {str(e)}")
                self.sync_state = SyncState.IDLE
    
        async def _verification_loop(self) -> None:
            """Periodic chain verification loop."""
            while True:
                try:
                    if self.chain.height % self.verify_interval == 0:
                        await self.verify_chain_state()
                        
                    await asyncio.sleep(10)
                    
                except asyncio.CancelledError:
                    break
                except Exception as e:
                    logger.error(f"Error in verification loop: {str(e)}")
                    await asyncio.sleep(10)
    
        async def _request_headers(
            self,
            start_height: int,
            end_height: int
        ) -> Optional[List[Dict[str, Any]]]:
            """Request block headers from peers."""
            try:
                response = await self.dispatcher.dispatch_message(
                    "get_headers",
                    {
                        "start_height": start_height,
                        "end_height": end_height
                    },
                    routing=MessageRoute(
                        message_type="get_headers",
                        target_shards=set(),
                        target_cooperatives=set(),
                        exclude_peers=self.banned_peers,
                        broadcast=True
                    ),
                    wait_response=True
                )
                
                if not response or "headers" not in response:
                    return None
                    
                return response["headers"]
                
            except Exception as e:
                logger.error(f"Error requesting headers: {str(e)}")
                return None
    
        async def _verify_headers(self, headers: List[Dict[str, Any]]) -> bool:
            """Verify block headers."""
            try:
                previous_hash = None
                for header in headers:
                    # Create block from header
                    block = Block.from_dict(header)
                    
                    # Verify hash chain
                    if previous_hash and block.previous_hash != previous_hash:
                        return False
                        
                    previous_hash = block.hash
                    
                    # Store header
                    self.chain.add_block_header(block)
                    
                return True
                
            except Exception as e:
                logger.error(f"Error verifying headers: {str(e)}")
                return False
    
        def _get_next_block_height(self) -> Optional[int]:
            """Get next block height to download."""
            if not self.current_sync:
                return None
                
            current_height = self.current_sync.current_height
            target_height = self.current_sync.target_height
            
            for height in range(current_height, target_height + 1):
                if (height not in self.active_downloads and
                    height not in self.downloaded_blocks and
                    height not in self.failed_blocks):
                    return height
                    
            return None
    
        async def _download_block(self, height: int) -> None:
            """Download a specific block."""
            try:
                # Request block from peers
                response = await self.dispatcher.dispatch_message(
                    "get_block",
                    {"height": height},
                    routing=MessageRoute(
                        message_type="get_block",
                        target_shards=set(),
                        target_cooperatives=set(),
                        exclude_peers=self.banned_peers,
                        broadcast=True
                    ),
                    wait_response=True
                )
                
                if not response or "block" not in response:
                    logger.error(f"Failed to download block at height {height}")
                    self.failed_blocks.add(height)
                    return
                    
                # Create and verify block
                block = Block.from_dict(response["block"])
                if not await self._verify_block(block):
                    logger.error(f"Block verification failed at height {height}")
                    self.failed_blocks.add(height)
                    return
                    
                # Store block
                self.downloaded_blocks[height] = block
                self.current_sync.blocks_processed += 1
                self.metrics["blocks_downloaded"] += 1
                
            except Exception as e:
                logger.error(f"Error downloading block {height}: {str(e)}")
                self.failed_blocks.add(height)
                
            finally:
                self.active_downloads.discard(height)
    
        async def _verify_block(self, block: Block) -> bool:
            """Verify a downloaded block."""
            try:
                # Verify basic structure
                if not block.validate(None):  # Pass None as we don't have previous block here
                    return False
                    
                # Verify transactions
                for tx in block.transactions:
                    if not await self._verify_transaction(tx):
                        return False
                        
                # Verify state transitions
                if not await self._verify_state_transitions(block):
                    return False
                    
                # Verify cooperative signatures if present
                if not await self._verify_signatures(block):
                    return False
                    
                return True
                
            except Exception as e:
                logger.error(f"Error verifying block: {str(e)}")
                return False
    
        async def _verify_transaction(self, transaction: Transaction) -> bool:
            """Verify a transaction within a block."""
            try:
                # Basic validation
                if not transaction.validate():
                    return False
                    
                # Verify signatures
                if not transaction.verify_signatures():
                    return False
                    
                # Verify state transitions
                if not await self._verify_transaction_state(transaction):
                    return False
                    
                return True
                
            except Exception as e:
                logger.error(f"Error verifying transaction: {str(e)}")
                return False
    
        async def _verify_transaction_state(self, transaction: Transaction) -> bool:
            """Verify transaction state transitions."""
            try:
                # Get pre-state
                pre_state = await self._get_account_state(transaction.sender)
                
                # Verify sender has sufficient resources
                if not await self._verify_resource_availability(transaction, pre_state):
                    return False
                    
                # Verify state transition rules
                if not await self._verify_transition_rules(transaction, pre_state):
                    return False
                    
                return True
                
            except Exception as e:
                logger.error(f"Error verifying transaction state: {str(e)}")
                return False
    
        async def _verify_state_transitions(self, block: Block) -> bool:
            """Verify state transitions in a block."""
            try:
                # Get pre-block state
                pre_state = await self._get_block_state(block.previous_hash)
                
                # Apply all transactions
                current_state = pre_state.copy()
                for tx in block.transactions:
                    if not await self._apply_transaction(tx, current_state):
                        return False
                        
                # Verify final state matches block's state root
                state_root = self._calculate_state_root_from_state(current_state)
                return state_root == block.state_root
                
            except Exception as e:
                logger.error(f"Error verifying state transitions: {str(e)}")
                return False
    
        async def _verify_signatures(self, block: Block) -> bool:
            """Verify cooperative signatures on block."""
            try:
                # Get required signers
                required_signers = await self._get_required_signers(block)
                
                # Verify all required signatures are present
                for signer in required_signers:
                    if not await self._verify_signer_signature(block, signer):
                        return False
                        
                return True
                
            except Exception as e:
                logger.error(f"Error verifying signatures: {str(e)}")
                return False
    
        async def _apply_blocks(self) -> bool:
            """Apply downloaded blocks to chain."""
            try:
                if not self.current_sync:
                    return False
                    
                current_height = self.current_sync.start_height
                target_height = self.current_sync.target_height
                
                while current_height <= target_height:
                    # Get block
                    block = self.downloaded_blocks.get(current_height)
                    if not block:
                        return False
                        
                    # Apply block
                    if not await self.chain.add_block(block):
                        return False
                        
                    # Update state roots
                    self.state_roots[current_height] = block.state_root
                    
                    current_height += 1
                    self.current_sync.blocks_verified += 1
                    self.metrics["blocks_verified"] += 1
                    
                return True
                
            except Exception as e:
                logger.error(f"Error applying blocks: {str(e)}")
                return False
    
        async def _request_state_snapshot(self, height: int) -> Optional[Dict[str, Any]]:
            """Request state snapshot from peers."""
            try:
                response = await self.dispatcher.dispatch_message(
                    "get_state_snapshot",
                    {"height": height},
                    routing=MessageRoute(
                        message_type="get_state_snapshot",
                        target_shards=set(),
                        target_cooperatives=set(),
                        exclude_peers=self.banned_peers,
                        broadcast=True
                    ),
                    wait_response=True
                )
                
                if not response or "state" not in response:
                    return None
                    
                return response["state"]
                
            except Exception as e:
                logger.error(f"Error requesting state snapshot: {str(e)}")
                return None
    
        async def _verify_state_snapshot(self, state_data: Dict[str, Any], height: int) -> bool:
            """Verify state snapshot integrity."""
            try:
                # Calculate state root
                state_root = self._calculate_state_root_from_state(state_data)
                
                # Verify against block state root
                block_state_root = self.state_roots.get(height)
                if block_state_root and state_root != block_state_root:
                    return False
                    
                # Verify against checkpoint if available
                checkpoint_root = self.checkpoints.get(height)
                if checkpoint_root and state_root != checkpoint_root:
                    return False
                    
                return True
                
            except Exception as e:
                logger.error(f"Error verifying state snapshot: {str(e)}")
                return False
    
        async def _apply_state_snapshot(self, state_data: Dict[str, Any]) -> bool:
            """Apply verified state snapshot."""
            try:
                # Backup current state
                await self._backup_current_state()
                
                # Apply new state
                return await self.chain.apply_state(state_data)
                
            except Exception as e:
                logger.error(f"Error applying state snapshot: {str(e)}")
                return False
    
        async def _verify_sync(self) -> None:
            """Verify completed synchronization."""
            try:
                if not self.current_sync:
                    return
                    
                # Verify chain continuity
                if not await self._verify_chain_continuity():
                    logger.error("Chain continuity verification failed")
                    self.sync_state = SyncState.IDLE
                    return
                    
                # Verify final state
                if not await self.verify_chain_state():
                    logger.error("Final state verification failed")
                    self.sync_state = SyncState.IDLE
                    return
                    
                # Sync completed successfully
                logger.info(
                    f"Sync completed successfully at height {self.current_sync.target_height}"
                )
                
                self.metrics["successful_syncs"] += 1
                self.sync_state = SyncState.IDLE
                self.current_sync = None
                
            except Exception as e:
                logger.error(f"Error verifying sync: {str(e)}")
                self.sync_state = SyncState.IDLE
    
        async def _backup_current_state(self) -> None:
            """Backup current chain state."""
            try:
                # TODO: Implement state backup
                pass
            except Exception as e:
                logger.error(f"Error backing up state: {str(e)}")
                raise
    
        async def _verify_chain_continuity(self) -> bool:
            """Verify continuity of synchronized chain."""
            try:
                if not self.current_sync:
                    return False
                    
                current_height = self.current_sync.start_height
                target_height = self.current_sync.target_height
                
                previous_hash = None
                while current_height <= target_height:
                    block = await self.chain.get_block(current_height)
                    if not block:
                        return False
                        
                    if previous_hash and block.previous_hash != previous_hash:
                        return False
                        
                    previous_hash = block.hash
                    current_height += 1
                    
                return True
                
            except Exception as e:
                logger.error(f"Error verifying chain continuity: {str(e)}")
                return False
    
        def get_metrics(self) -> Dict[str, Any]:
            """Get sync manager metrics."""
            metrics = self.metrics.copy()
            
            if self.current_sync:
                metrics.update({
                    "sync_progress": self.current_sync.progress_percentage,
                    "blocks_per_second": self.current_sync.blocks_per_second,
                    "estimated_time_remaining": str(self.current_sync.estimated_time_remaining),
                    "current_height": self.current_sync.current_height,
                    "target_height": self.current_sync.target_height
                })
                
            return metrics
    
    # Example usage
    async def example_usage():
        config = NetworkConfig(node_id="test_node")
        dispatcher = MessageDispatcher(config, None)  # Pass proper transport
        chain = None  # Pass actual blockchain instance
        
        sync_manager = SyncManager(config, dispatcher, chain)
        await sync_manager.start()
        
        # Start sync
        await sync_manager.start_sync(1000)  # Sync to height 1000
        
        # Wait for sync to complete
        while sync_manager.get_sync_progress():
            progress = sync_manager.get_sync_progress()
            print(f"Sync progress: {progress.progress_percentage:.2f}%")
            await asyncio.sleep(1)
        
        await sync_manager.stop()
    
    if __name__ == "__main__":
        asyncio.run(example_usage())
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/network/protocol/base.py
# Size: 10078 bytes
# Last Modified: Sat Oct 26 22:27:50 2024
# Language: py
# ============================================================

```py
    # ================================================================
    # File: blockchain/network/protocol/base.py
    # Description: Base protocol implementation for ICN network communication.
    # This module defines the core protocol structures and message types
    # used for node communication in the InterCooperative Network.
    # ================================================================
    
    from abc import ABC, abstractmethod
    from typing import Dict, Any, Optional, List
    from datetime import datetime
    import json
    import logging
    from dataclasses import dataclass, field
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class ProtocolMessage:
        """Base class for all protocol messages."""
        message_type: str
        version: str
        payload: Dict[str, Any]
        timestamp: datetime = field(default_factory=datetime.now)
        sequence: int = field(default_factory=lambda: 0)
        
        def serialize(self) -> bytes:
            """Convert message to bytes for transmission."""
            message_dict = {
                "type": self.message_type,
                "version": self.version,
                "payload": self.payload,
                "timestamp": self.timestamp.isoformat(),
                "sequence": self.sequence
            }
            return json.dumps(message_dict).encode()
        
        @classmethod
        def deserialize(cls, data: bytes) -> 'ProtocolMessage':
            """Create message from received bytes."""
            message_dict = json.loads(data.decode())
            return cls(
                message_type=message_dict["type"],
                version=message_dict["version"],
                payload=message_dict["payload"],
                timestamp=datetime.fromisoformat(message_dict["timestamp"]),
                sequence=message_dict["sequence"]
            )
    
    class Protocol(ABC):
        """Base class for network protocols."""
        
        def __init__(self, version: str):
            self.version = version
            self.message_handlers: Dict[str, List[callable]] = {}
            self.sequence_counter = 0
        
        @abstractmethod
        async def handle_message(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            """
            Handle an incoming protocol message.
            
            Args:
                message: The received message
                
            Returns:
                Optional[ProtocolMessage]: Response message if any
            """
            pass
        
        @abstractmethod
        async def create_message(self, message_type: str, payload: Dict[str, Any]) -> ProtocolMessage:
            """
            Create a new protocol message.
            
            Args:
                message_type: Type of message to create
                payload: Message payload
                
            Returns:
                ProtocolMessage: The created message
            """
            pass
    
    class HandshakeProtocol(Protocol):
        """Protocol implementation for peer handshakes."""
        
        def __init__(self):
            super().__init__("icn/1.0")
            
        async def handle_message(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            if message.message_type == "handshake_init":
                return await self.create_message("handshake_ack", {
                    "accepted": True,
                    "supported_protocols": ["icn/1.0", "icn/1.1"]
                })
            return None
            
        async def create_message(self, message_type: str, payload: Dict[str, Any]) -> ProtocolMessage:
            self.sequence_counter += 1
            return ProtocolMessage(
                message_type=message_type,
                version=self.version,
                payload=payload,
                sequence=self.sequence_counter
            )
    
    class ConsensusProtocol(Protocol):
        """Protocol implementation for consensus-related messages."""
        
        def __init__(self):
            super().__init__("icn/1.0")
            
        async def handle_message(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            handlers = {
                "block_proposal": self._handle_block_proposal,
                "block_validation": self._handle_block_validation,
                "validation_result": self._handle_validation_result
            }
            
            handler = handlers.get(message.message_type)
            if handler:
                return await handler(message)
            return None
            
        async def create_message(self, message_type: str, payload: Dict[str, Any]) -> ProtocolMessage:
            self.sequence_counter += 1
            return ProtocolMessage(
                message_type=message_type,
                version=self.version,
                payload=payload,
                sequence=self.sequence_counter
            )
        
        async def _handle_block_proposal(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            """Handle incoming block proposal."""
            try:
                # Validate block proposal
                block_data = message.payload.get("block")
                if not block_data:
                    return await self.create_message("block_validation", {
                        "accepted": False,
                        "reason": "Missing block data"
                    })
                
                # TODO: Implement actual block validation logic
                
                return await self.create_message("block_validation", {
                    "accepted": True,
                    "block_hash": block_data.get("hash")
                })
                
            except Exception as e:
                logger.error(f"Error handling block proposal: {str(e)}")
                return await self.create_message("block_validation", {
                    "accepted": False,
                    "reason": str(e)
                })
        
        async def _handle_block_validation(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            """Handle block validation message."""
            try:
                validation_result = message.payload.get("accepted", False)
                if validation_result:
                    # TODO: Implement validation confirmation logic
                    return None
                
                reason = message.payload.get("reason", "Unknown reason")
                logger.warning(f"Block validation failed: {reason}")
                return None
                
            except Exception as e:
                logger.error(f"Error handling block validation: {str(e)}")
                return None
        
        async def _handle_validation_result(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            """Handle validation result message."""
            try:
                # Process validation result
                result = message.payload.get("result", {})
                block_hash = result.get("block_hash")
                is_valid = result.get("is_valid", False)
                
                if is_valid:
                    # TODO: Implement logic for accepted validation
                    pass
                else:
                    reason = result.get("reason", "Unknown reason")
                    logger.warning(f"Validation rejected for block {block_hash}: {reason}")
                
                return None
                
            except Exception as e:
                logger.error(f"Error handling validation result: {str(e)}")
                return None
    
    class SyncProtocol(Protocol):
        """Protocol implementation for state synchronization."""
        
        def __init__(self):
            super().__init__("icn/1.0")
            
        async def handle_message(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            handlers = {
                "sync_request": self._handle_sync_request,
                "sync_response": self._handle_sync_response,
                "sync_complete": self._handle_sync_complete
            }
            
            handler = handlers.get(message.message_type)
            if handler:
                return await handler(message)
            return None
            
        async def create_message(self, message_type: str, payload: Dict[str, Any]) -> ProtocolMessage:
            self.sequence_counter += 1
            return ProtocolMessage(
                message_type=message_type,
                version=self.version,
                payload=payload,
                sequence=self.sequence_counter
            )
        
        async def _handle_sync_request(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            """Handle state sync request."""
            try:
                # Get sync parameters
                start_block = message.payload.get("start_block", 0)
                end_block = message.payload.get("end_block")
                
                # TODO: Implement state gathering logic
                
                return await self.create_message("sync_response", {
                    "start_block": start_block,
                    "end_block": end_block,
                    "state": {}  # Add actual state data
                })
                
            except Exception as e:
                logger.error(f"Error handling sync request: {str(e)}")
                return await self.create_message("sync_response", {
                    "error": str(e)
                })
        
        async def _handle_sync_response(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            """Handle state sync response."""
            try:
                state_data = message.payload.get("state", {})
                if not state_data:
                    return None
                
                # TODO: Implement state application logic
                
                return await self.create_message("sync_complete", {
                    "success": True
                })
                
            except Exception as e:
                logger.error(f"Error handling sync response: {str(e)}")
                return await self.create_message("sync_complete", {
                    "success": False,
                    "error": str(e)
                })
        
        async def _handle_sync_complete(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            """Handle sync completion message."""
            try:
                success = message.payload.get("success", False)
                if not success:
                    error = message.payload.get("error", "Unknown error")
                    logger.error(f"Sync failed: {error}")
                
                # TODO: Implement sync completion logic
                
                return None
                
            except Exception as e:
                logger.error(f"Error handling sync complete: {str(e)}")
                return None
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/network/protocol/dispatcher.py
# Size: 22324 bytes
# Last Modified: Sat Oct 26 22:35:59 2024
# Language: py
# ============================================================

```py
    # ================================================================
    # File: blockchain/network/protocol/dispatcher.py
    # Description: Message dispatcher for ICN network.
    # Handles routing and processing of network messages, providing a
    # centralized point for message handling and distribution.
    # ================================================================
    
    import asyncio
    import logging
    from typing import Dict, Set, List, Optional, Callable, Any, Union
    from dataclasses import dataclass, field
    from datetime import datetime
    import json
    from enum import Enum, auto
    import hashlib
    import traceback
    
    from ..config import NetworkConfig
    from ..transport.transport import NetworkTransport, MessageFrame
    
    logger = logging.getLogger(__name__)
    
    class MessagePriority(Enum):
        """Message priority levels."""
        HIGH = auto()    # Critical messages (consensus, block propagation)
        MEDIUM = auto()  # Important but not critical (transaction propagation)
        LOW = auto()     # Regular messages (peer discovery, metrics)
    
    @dataclass
    class MessageHandler:
        """Registered message handler information."""
        callback: Callable
        priority: MessagePriority
        requires_response: bool = False
        timeout: float = 30.0
        cooperative_only: bool = False
        max_size: Optional[int] = None
        version_requirements: Optional[Set[str]] = None
    
    @dataclass
    class PendingResponse:
        """Tracks pending message responses."""
        message_id: str
        sender: str
        timestamp: datetime
        timeout: float
        future: asyncio.Future
        message_type: str
    
    @dataclass
    class MessageRoute:
        """Message routing information."""
        message_type: str
        target_shards: Set[int]
        target_cooperatives: Set[str]
        exclude_peers: Set[str]
        broadcast: bool = False
        local_only: bool = False
    
    class MessageDispatcher:
        """
        Central message handling and routing system.
        
        Features:
        - Priority-based message processing
        - Message routing and filtering
        - Request-response handling
        - Cross-shard message propagation
        - Cooperative-aware message distribution
        - Message validation and rate limiting
        """
    
        def __init__(self, config: NetworkConfig, transport: NetworkTransport):
            """
            Initialize the message dispatcher.
            
            Args:
                config: Network configuration
                transport: Network transport layer
            """
            self.config = config
            self.transport = transport
            
            # Message handling
            self.handlers: Dict[str, MessageHandler] = {}
            self.pending_responses: Dict[str, PendingResponse] = {}
            
            # Message queues (priority-based)
            self.high_priority_queue: asyncio.Queue = asyncio.Queue()
            self.medium_priority_queue: asyncio.Queue = asyncio.Queue()
            self.low_priority_queue: asyncio.Queue = asyncio.Queue()
            
            # Rate limiting
            self.message_counts: Dict[str, int] = {}  # peer_id -> count
            self.message_timestamps: Dict[str, List[datetime]] = {}  # peer_id -> timestamps
            self.rate_limit_window = 60  # seconds
            self.rate_limit_max = 1000  # messages per window
            
            # State
            self.is_running = False
            self.processing_tasks: Set[asyncio.Task] = set()
            
            # Metrics
            self.metrics = {
                "messages_processed": 0,
                "messages_routed": 0,
                "messages_dropped": 0,
                "responses_received": 0,
                "responses_timed_out": 0,
                "rate_limit_violations": 0
            }
    
        async def start(self) -> None:
            """Start the message dispatcher."""
            if self.is_running:
                return
                
            try:
                self.is_running = True
                
                # Start worker tasks for each priority queue
                self.processing_tasks.add(
                    asyncio.create_task(self._process_queue(
                        self.high_priority_queue,
                        "high"
                    ))
                )
                self.processing_tasks.add(
                    asyncio.create_task(self._process_queue(
                        self.medium_priority_queue,
                        "medium"
                    ))
                )
                self.processing_tasks.add(
                    asyncio.create_task(self._process_queue(
                        self.low_priority_queue,
                        "low"
                    ))
                )
                
                # Start maintenance task
                self.processing_tasks.add(
                    asyncio.create_task(self._maintenance_loop())
                )
                
                logger.info("Message dispatcher started")
                
            except Exception as e:
                logger.error(f"Error starting message dispatcher: {str(e)}")
                raise
    
        async def stop(self) -> None:
            """Stop the message dispatcher."""
            if not self.is_running:
                return
                
            try:
                self.is_running = False
                
                # Cancel all pending responses
                for pending in self.pending_responses.values():
                    if not pending.future.done():
                        pending.future.cancel()
                
                # Cancel all processing tasks
                for task in self.processing_tasks:
                    task.cancel()
                    
                await asyncio.gather(*self.processing_tasks, return_exceptions=True)
                self.processing_tasks.clear()
                
                logger.info("Message dispatcher stopped")
                
            except Exception as e:
                logger.error(f"Error stopping message dispatcher: {str(e)}")
    
        def register_handler(
            self,
            message_type: str,
            callback: Callable,
            priority: MessagePriority = MessagePriority.MEDIUM,
            requires_response: bool = False,
            timeout: float = 30.0,
            cooperative_only: bool = False,
            max_size: Optional[int] = None,
            version_requirements: Optional[Set[str]] = None
        ) -> None:
            """
            Register a message handler.
            
            Args:
                message_type: Type of message to handle
                callback: Handler function
                priority: Message processing priority
                requires_response: Whether handler expects a response
                timeout: Response timeout in seconds
                cooperative_only: Whether to only accept messages from cooperative peers
                max_size: Maximum message size in bytes
                version_requirements: Required protocol versions
            """
            self.handlers[message_type] = MessageHandler(
                callback=callback,
                priority=priority,
                requires_response=requires_response,
                timeout=timeout,
                cooperative_only=cooperative_only,
                max_size=max_size,
                version_requirements=version_requirements
            )
    
        async def dispatch_message(
            self,
            message_type: str,
            payload: Dict[str, Any],
            routing: Optional[MessageRoute] = None,
            wait_response: bool = False
        ) -> Optional[Dict[str, Any]]:
            """
            Dispatch a message to the network.
            
            Args:
                message_type: Type of message to send
                payload: Message payload
                routing: Optional routing information
                wait_response: Whether to wait for response
                
            Returns:
                Optional[Dict[str, Any]]: Response payload if wait_response is True
            """
            try:
                message_id = self._generate_message_id(message_type, payload)
                
                if routing and routing.local_only:
                    # Handle message locally
                    return await self._handle_local_message(
                        message_type,
                        message_id,
                        payload
                    )
                
                # Prepare message for sending
                message = {
                    "message_id": message_id,
                    "message_type": message_type,
                    "payload": payload,
                    "timestamp": datetime.now().isoformat(),
                    "sender": self.config.node_id
                }
                
                if wait_response:
                    # Create future for response
                    future = asyncio.Future()
                    self.pending_responses[message_id] = PendingResponse(
                        message_id=message_id,
                        sender=self.config.node_id,
                        timestamp=datetime.now(),
                        timeout=30.0,
                        future=future,
                        message_type=message_type
                    )
                    
                # Route message
                success = await self._route_message(message, routing)
                if not success:
                    if wait_response:
                        self.pending_responses[message_id].future.cancel()
                        del self.pending_responses[message_id]
                    return None
                
                if wait_response:
                    try:
                        # Wait for response
                        response = await asyncio.wait_for(
                            self.pending_responses[message_id].future,
                            timeout=30.0
                        )
                        return response
                    except asyncio.TimeoutError:
                        logger.warning(f"Response timeout for message {message_id}")
                        self.metrics["responses_timed_out"] += 1
                        return None
                    finally:
                        if message_id in self.pending_responses:
                            del self.pending_responses[message_id]
                
                return None
                
            except Exception as e:
                logger.error(f"Error dispatching message: {str(e)}")
                return None
    
        async def handle_message(
            self,
            peer_id: str,
            message_data: Dict[str, Any]
        ) -> None:
            """
            Handle received message from transport layer.
            
            Args:
                peer_id: ID of sending peer
                message_data: Received message data
            """
            try:
                # Extract message information
                message_type = message_data.get("message_type")
                message_id = message_data.get("message_id")
                payload = message_data.get("payload")
                
                if not all([message_type, message_id, payload]):
                    logger.error("Invalid message format")
                    return
                    
                # Check rate limits
                if not self._check_rate_limit(peer_id):
                    logger.warning(f"Rate limit exceeded for peer {peer_id}")
                    self.metrics["rate_limit_violations"] += 1
                    return
                    
                # Get handler
                handler = self.handlers.get(message_type)
                if not handler:
                    logger.warning(f"No handler for message type: {message_type}")
                    return
                    
                # Validate message
                if not await self._validate_message(
                    message_data,
                    handler,
                    peer_id
                ):
                    return
                    
                # Queue message for processing
                await self._queue_message(
                    handler.priority,
                    peer_id,
                    message_type,
                    message_id,
                    payload
                )
                
            except Exception as e:
                logger.error(f"Error handling message: {str(e)}")
    
        async def _handle_local_message(
            self,
            message_type: str,
            message_id: str,
            payload: Dict[str, Any]
        ) -> Optional[Dict[str, Any]]:
            """Handle message locally without network transmission."""
            try:
                handler = self.handlers.get(message_type)
                if not handler:
                    logger.warning(f"No handler for local message type: {message_type}")
                    return None
                    
                # Execute handler
                response = await handler.callback(self.config.node_id, payload)
                return response
                
            except Exception as e:
                logger.error(f"Error handling local message: {str(e)}")
                return None
    
        async def _route_message(
            self,
            message: Dict[str, Any],
            routing: Optional[MessageRoute]
        ) -> bool:
            """Route message according to routing information."""
            try:
                if not routing:
                    # Broadcast to all peers
                    return await self.transport.broadcast_message(
                        message["message_type"],
                        message
                    )
                
                success = True
                sent_to_peers = set()
                
                # Send to target shards
                if routing.target_shards:
                    # TODO: Implement shard-based routing
                    pass
                
                # Send to target cooperatives
                if routing.target_cooperatives:
                    # TODO: Implement cooperative-based routing
                    pass
                
                # Broadcast if specified
                if routing.broadcast:
                    for peer_id in self.transport.get_peer_ids():
                        if (peer_id not in sent_to_peers and 
                            peer_id not in routing.exclude_peers):
                            success &= await self.transport.send_message(
                                peer_id,
                                message["message_type"],
                                message
                            )
                            sent_to_peers.add(peer_id)
                
                self.metrics["messages_routed"] += len(sent_to_peers)
                return success
                
            except Exception as e:
                logger.error(f"Error routing message: {str(e)}")
                return False
    
        async def _process_queue(
            self,
            queue: asyncio.Queue,
            priority: str
        ) -> None:
            """Process messages from a priority queue."""
            while self.is_running:
                try:
                    # Get message from queue
                    peer_id, message_type, message_id, payload = await queue.get()
                    
                    # Get handler
                    handler = self.handlers[message_type]
                    
                    try:
                        # Execute handler
                        response = await handler.callback(peer_id, payload)
                        
                        # Handle response if needed
                        if message_id in self.pending_responses:
                            pending = self.pending_responses[message_id]
                            if not pending.future.done():
                                pending.future.set_result(response)
                                self.metrics["responses_received"] += 1
                        
                        self.metrics["messages_processed"] += 1
                        
                    except Exception as e:
                        logger.error(
                            f"Error processing {priority} priority message: {str(e)}\n"
                            f"{''.join(traceback.format_exc())}"
                        )
                        self.metrics["messages_dropped"] += 1
                    
                    finally:
                        queue.task_done()
                        
                except asyncio.CancelledError:
                    break
                except Exception as e:
                    logger.error(f"Error in {priority} priority queue processing: {str(e)}")
                    await asyncio.sleep(1)
    
        async def _maintenance_loop(self) -> None:
            """Periodic maintenance tasks."""
            while self.is_running:
                try:
                    current_time = datetime.now()
                    
                    # Clean up pending responses
                    for message_id in list(self.pending_responses.keys()):
                        pending = self.pending_responses[message_id]
                        if (current_time - pending.timestamp).total_seconds() > pending.timeout:
                            if not pending.future.done():
                                pending.future.cancel()
                            del self.pending_responses[message_id]
                            self.metrics["responses_timed_out"] += 1
                    
                    # Clean up rate limiting data
                    window_start = current_time.timestamp() - self.rate_limit_window
                    for peer_id in list(self.message_timestamps.keys()):
                        self.message_timestamps[peer_id] = [
                            ts for ts in self.message_timestamps[peer_id]
                            if ts.timestamp() > window_start
                        ]
                        self.message_counts[peer_id] = len(self.message_timestamps[peer_id])
                    
                except Exception as e:
                    logger.error(f"Error in maintenance loop: {str(e)}")
                    
                await asyncio.sleep(1)
    
        def _check_rate_limit(self, peer_id: str) -> bool:
            """Check if peer has exceeded rate limit."""
            current_time = datetime.now()
            
            if peer_id not in self.message_timestamps:
                self.message_timestamps[peer_id] = []
                self.message_counts[peer_id] = 0
                
            # Add new timestamp
            self.message_timestamps[peer_id].append(current_time)
            
           # Update count
            window_start = current_time.timestamp() - self.rate_limit_window
            self.message_counts[peer_id] = sum(
                1 for ts in self.message_timestamps[peer_id]
                if ts.timestamp() > window_start
            )
            
            # Check against limit
            return self.message_counts[peer_id] <= self.rate_limit_max
    
        async def _validate_message(
            self,
            message_data: Dict[str, Any],
            handler: MessageHandler,
            peer_id: str
        ) -> bool:
            """
            Validate incoming message.
            
            Args:
                message_data: Message to validate
                handler: Handler for this message type
                peer_id: ID of sending peer
                
            Returns:
                bool: True if message is valid
            """
            try:
                # Check cooperative requirement
                if handler.cooperative_only:
                    peer_info = self.transport.get_peer_info(peer_id)
                    if not peer_info or not peer_info.cooperative_id:
                        logger.warning(f"Non-cooperative peer {peer_id} sent cooperative-only message")
                        return False
                
                # Check message size
                if handler.max_size:
                    message_size = len(json.dumps(message_data))
                    if message_size > handler.max_size:
                        logger.warning(f"Message from {peer_id} exceeds size limit")
                        return False
                
                # Check version requirements
                if handler.version_requirements:
                    peer_info = self.transport.get_peer_info(peer_id)
                    if not peer_info:
                        return False
                        
                    peer_versions = peer_info.supported_protocols
                    if not peer_versions & handler.version_requirements:
                        logger.warning(f"Peer {peer_id} doesn't support required protocol version")
                        return False
                
                return True
                
            except Exception as e:
                logger.error(f"Error validating message: {str(e)}")
                return False
    
        async def _queue_message(
            self,
            priority: MessagePriority,
            peer_id: str,
            message_type: str,
            message_id: str,
            payload: Dict[str, Any]
        ) -> None:
            """Queue message for processing according to priority."""
            try:
                message_tuple = (peer_id, message_type, message_id, payload)
                
                if priority == MessagePriority.HIGH:
                    await self.high_priority_queue.put(message_tuple)
                elif priority == MessagePriority.MEDIUM:
                    await self.medium_priority_queue.put(message_tuple)
                else:
                    await self.low_priority_queue.put(message_tuple)
                    
            except Exception as e:
                logger.error(f"Error queuing message: {str(e)}")
    
        def _generate_message_id(self, message_type: str, payload: Dict[str, Any]) -> str:
            """Generate unique message ID."""
            data = f"{self.config.node_id}:{message_type}:{json.dumps(payload, sort_keys=True)}"
            return hashlib.sha256(data.encode()).hexdigest()
    
        def get_queue_sizes(self) -> Dict[str, int]:
            """Get current size of message queues."""
            return {
                "high_priority": self.high_priority_queue.qsize(),
                "medium_priority": self.medium_priority_queue.qsize(),
                "low_priority": self.low_priority_queue.qsize()
            }
    
        def get_metrics(self) -> Dict[str, int]:
            """Get dispatcher metrics."""
            metrics = self.metrics.copy()
            metrics.update({
                "pending_responses": len(self.pending_responses),
                "registered_handlers": len(self.handlers)
            })
            return metrics
    
    # Example usage
    async def example_usage():
        config = NetworkConfig(node_id="test_node")
        transport = NetworkTransport(config)
        dispatcher = MessageDispatcher(config, transport)
        
        # Register message handler
        async def handle_test_message(peer_id: str, payload: Dict[str, Any]) -> None:
            print(f"Received test message from {peer_id}: {payload}")
            
        dispatcher.register_handler(
            "test_message",
            handle_test_message,
            priority=MessagePriority.MEDIUM
        )
        
        # Start dispatcher
        await dispatcher.start()
        
        # Dispatch message
        response = await dispatcher.dispatch_message(
            "test_message",
            {"content": "Hello world"},
            routing=MessageRoute(
                message_type="test_message",
                target_shards={1},
                target_cooperatives={"coop1"},
                exclude_peers=set(),
                broadcast=True
            )
        )
        
        # Stop dispatcher
        await dispatcher.stop()
    
    if __name__ == "__main__":
        asyncio.run(example_usage())
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/network/transport/transport.py
# Size: 15697 bytes
# Last Modified: Sat Oct 26 22:32:49 2024
# Language: py
# ============================================================

```py
    # ================================================================
    # File: blockchain/network/transport/transport.py
    # Description: Transport layer implementation for ICN network.
    # Handles low-level network communication, including message framing,
    # encryption, and reliable delivery.
    # ================================================================
    
    import asyncio
    import logging
    import struct
    import json
    from typing import Dict, Optional, Tuple, Any, Callable
    from dataclasses import dataclass
    from datetime import datetime
    import hashlib
    from cryptography.fernet import Fernet
    from ..config import NetworkConfig
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class MessageFrame:
        """Represents a framed network message."""
        message_type: str
        payload: bytes
        sequence: int
        timestamp: datetime
        flags: int = 0
        
        # Message frame format:
        # | Magic (2) | Version (2) | Flags (2) | Sequence (4) | Length (4) | Type (2) | Payload (...) | CRC (4) |
        FRAME_MAGIC = 0x1C4E  # ICN in hex
        FRAME_VERSION = 1
        HEADER_SIZE = 20
        
        def pack(self) -> bytes:
            """Pack message into bytes for transmission."""
            try:
                type_id = hash(self.message_type) & 0xFFFF  # Convert type to 16-bit identifier
                payload_len = len(self.payload)
                
                # Create header
                header = struct.pack(
                    ">HHHIH",  # Big-endian: magic, version, flags, sequence, length
                    self.FRAME_MAGIC,
                    self.FRAME_VERSION,
                    self.flags,
                    self.sequence,
                    payload_len
                )
                
                # Pack message type
                header += struct.pack(">H", type_id)
                
                # Combine header and payload
                message = header + self.payload
                
                # Add CRC
                crc = self._calculate_crc(message)
                message += struct.pack(">I", crc)
                
                return message
                
            except Exception as e:
                logger.error(f"Error packing message frame: {str(e)}")
                raise
        
        @classmethod
        def unpack(cls, data: bytes) -> 'MessageFrame':
            """Unpack bytes into message frame."""
            try:
                # Verify minimum length
                if len(data) < cls.HEADER_SIZE + 4:  # Header + CRC
                    raise ValueError("Message too short")
                    
                # Parse header
                magic, version, flags, sequence, payload_len, type_id = struct.unpack(
                    ">HHHIHH",
                    data[:cls.HEADER_SIZE]
                )
                
                # Verify magic number and version
                if magic != cls.FRAME_MAGIC:
                    raise ValueError("Invalid message magic number")
                if version != cls.FRAME_VERSION:
                    raise ValueError("Unsupported message version")
                    
                # Extract payload
                payload_start = cls.HEADER_SIZE
                payload_end = payload_start + payload_len
                payload = data[payload_start:payload_end]
                
                # Verify payload length
                if len(payload) != payload_len:
                    raise ValueError("Incomplete message payload")
                    
                # Verify CRC
                received_crc = struct.unpack(">I", data[payload_end:payload_end + 4])[0]
                calculated_crc = cls._calculate_crc(data[:payload_end])
                if received_crc != calculated_crc:
                    raise ValueError("CRC check failed")
                    
                # Reconstruct message type from type_id
                message_type = f"type_{type_id}"  # TODO: Implement proper type mapping
                
                return cls(
                    message_type=message_type,
                    payload=payload,
                    sequence=sequence,
                    timestamp=datetime.now(),
                    flags=flags
                )
                
            except Exception as e:
                logger.error(f"Error unpacking message frame: {str(e)}")
                raise
        
        @staticmethod
        def _calculate_crc(data: bytes) -> int:
            """Calculate CRC32 checksum."""
            return struct.unpack(">I", hashlib.crc32(data).to_bytes(4, 'big'))[0]
    
    class SecureChannel:
        """Handles encrypted communication channel."""
        
        def __init__(self, key: Optional[bytes] = None):
            """Initialize secure channel with optional encryption key."""
            self.key = key or Fernet.generate_key()
            self.cipher = Fernet(self.key)
            
        def encrypt(self, data: bytes) -> bytes:
            """Encrypt data."""
            try:
                return self.cipher.encrypt(data)
            except Exception as e:
                logger.error(f"Encryption error: {str(e)}")
                raise
                
        def decrypt(self, data: bytes) -> bytes:
            """Decrypt data."""
            try:
                return self.cipher.decrypt(data)
            except Exception as e:
                logger.error(f"Decryption error: {str(e)}")
                raise
    
    class NetworkTransport:
        """
        Handles reliable network transport with message framing and encryption.
        
        Features:
        - Message framing and sequencing
        - Optional encryption
        - Flow control
        - Error detection
        - Message acknowledgment
        """
        
        def __init__(self, config: NetworkConfig):
            """Initialize transport layer."""
            self.config = config
            self.sequence_counter = 0
            self.pending_messages: Dict[int, MessageFrame] = {}
            self.secure_channels: Dict[str, SecureChannel] = {}  # peer_id -> channel
            self.message_handlers: Dict[str, Callable] = {}
            self.retransmit_interval = 5.0  # seconds
            self.max_retransmissions = 3
            
            # Performance tracking
            self.metrics = {
                "messages_sent": 0,
                "messages_received": 0,
                "bytes_sent": 0,
                "bytes_received": 0,
                "retransmissions": 0,
                "failed_deliveries": 0,
                "encryption_errors": 0
            }
        
        async def send_message(
            self,
            peer_id: str,
            message_type: str,
            payload: Dict[str, Any],
            require_ack: bool = True
        ) -> bool:
            """
            Send a message to a peer.
            
            Args:
                peer_id: ID of the peer to send to
                message_type: Type of message
                payload: Message payload
                require_ack: Whether to wait for acknowledgment
                
            Returns:
                bool: True if message sent successfully
            """
            try:
                # Serialize payload
                payload_bytes = json.dumps(payload).encode()
                
                # Create message frame
                self.sequence_counter += 1
                frame = MessageFrame(
                    message_type=message_type,
                    payload=payload_bytes,
                    sequence=self.sequence_counter,
                    timestamp=datetime.now()
                )
                
                # Encrypt if necessary
                if self.config.enable_encryption and peer_id in self.secure_channels:
                    channel = self.secure_channels[peer_id]
                    frame.payload = channel.encrypt(frame.payload)
                    frame.flags |= 0x0001  # Set encryption flag
                
                # Pack frame
                message_data = frame.pack()
                
                # Send message
                writer = self._get_peer_writer(peer_id)
                if not writer:
                    return False
                    
                writer.write(message_data)
                await writer.drain()
                
                # Track metrics
                self.metrics["messages_sent"] += 1
                self.metrics["bytes_sent"] += len(message_data)
                
                # Handle acknowledgment
                if require_ack:
                    self.pending_messages[frame.sequence] = frame
                    acknowledgment = await self._wait_for_ack(frame.sequence)
                    return acknowledgment
                
                return True
                
            except Exception as e:
                logger.error(f"Error sending message to {peer_id}: {str(e)}")
                return False
        
        async def handle_connection(
            self,
            peer_id: str,
            reader: asyncio.StreamReader,
            writer: asyncio.StreamWriter
        ) -> None:
            """
            Handle incoming peer connection.
            
            Args:
                peer_id: ID of the connected peer
                reader: StreamReader for receiving data
                writer: StreamWriter for sending data
            """
            try:
                # Initialize encryption if enabled
                if self.config.enable_encryption:
                    await self._setup_secure_channel(peer_id, reader, writer)
                
                # Start message handling loop
                while True:
                    # Read header size
                    header_data = await reader.readexactly(MessageFrame.HEADER_SIZE)
                    
                    # Parse header
                    magic, version, flags, sequence, payload_len, _ = struct.unpack(
                        ">HHHIHH",
                        header_data
                    )
                    
                    # Verify magic number and version
                    if magic != MessageFrame.FRAME_MAGIC:
                        logger.error(f"Invalid message magic from {peer_id}")
                        break
                        
                    if version != MessageFrame.FRAME_VERSION:
                        logger.error(f"Unsupported message version from {peer_id}")
                        break
                    
                    # Read payload and CRC
                    remaining_data = await reader.readexactly(payload_len + 4)
                    message_data = header_data + remaining_data
                    
                    # Unpack message
                    message = MessageFrame.unpack(message_data)
                    
                    # Decrypt if necessary
                    if flags & 0x0001 and peer_id in self.secure_channels:
                        channel = self.secure_channels[peer_id]
                        message.payload = channel.decrypt(message.payload)
                    
                    # Track metrics
                    self.metrics["messages_received"] += 1
                    self.metrics["bytes_received"] += len(message_data)
                    
                    # Send acknowledgment
                    await self._send_ack(writer, sequence)
                    
                    # Handle message
                    await self._handle_message(peer_id, message)
                    
            except asyncio.IncompleteReadError:
                logger.info(f"Connection closed by peer {peer_id}")
            except Exception as e:
                logger.error(f"Error handling connection from {peer_id}: {str(e)}")
            finally:
                writer.close()
                await writer.wait_closed()
                if peer_id in self.secure_channels:
                    del self.secure_channels[peer_id]
        
        def register_handler(
            self,
            message_type: str,
            handler: Callable[[str, Dict[str, Any]], None]
        ) -> None:
            """
            Register a message handler.
            
            Args:
                message_type: Type of message to handle
                handler: Callback function
            """
            self.message_handlers[message_type] = handler
        
        async def _setup_secure_channel(
            self,
            peer_id: str,
            reader: asyncio.StreamReader,
            writer: asyncio.StreamWriter
        ) -> None:
            """Set up encrypted channel with peer."""
            try:
                # Exchange keys
                my_key = Fernet.generate_key()
                writer.write(my_key)
                await writer.drain()
                
                peer_key = await reader.readexactly(44)  # Fernet key length
                
                # Create secure channel
                channel = SecureChannel(peer_key)
                self.secure_channels[peer_id] = channel
                
            except Exception as e:
                logger.error(f"Error setting up secure channel with {peer_id}: {str(e)}")
                self.metrics["encryption_errors"] += 1
                raise
        
        async def _handle_message(self, peer_id: str, message: MessageFrame) -> None:
            """Handle received message."""
            try:
                # Deserialize payload
                payload = json.loads(message.payload.decode())
                
                # Call registered handler
                handler = self.message_handlers.get(message.message_type)
                if handler:
                    await handler(peer_id, payload)
                else:
                    logger.warning(f"No handler for message type: {message.message_type}")
                    
            except Exception as e:
                logger.error(f"Error handling message: {str(e)}")
        
        async def _send_ack(self, writer: asyncio.StreamWriter, sequence: int) -> None:
            """Send acknowledgment message."""
            try:
                ack = struct.pack(">I", sequence)
                writer.write(ack)
                await writer.drain()
            except Exception as e:
                logger.error(f"Error sending acknowledgment: {str(e)}")
        
        async def _wait_for_ack(self, sequence: int) -> bool:
            """Wait for message acknowledgment."""
            try:
                retries = 0
                while retries < self.max_retransmissions:
                    try:
                        # Wait for acknowledgment
                        await asyncio.sleep(self.retransmit_interval)
                        
                        # Check if message was acknowledged
                        if sequence not in self.pending_messages:
                            return True
                            
                        # Retransmit if necessary
                        if retries < self.max_retransmissions - 1:
                            frame = self.pending_messages[sequence]
                            message_data = frame.pack()
                            writer = self._get_peer_writer(frame.peer_id)
                            if writer:
                                writer.write(message_data)
                                await writer.drain()
                                self.metrics["retransmissions"] += 1
                        
                        retries += 1
                        
                    except Exception as e:
                        logger.error(f"Error in acknowledgment wait: {str(e)}")
                        retries += 1
                
                # Message delivery failed
                if sequence in self.pending_messages:
                    del self.pending_messages[sequence]
                self.metrics["failed_deliveries"] += 1
                return False
                
            except Exception as e:
                logger.error(f"Error waiting for acknowledgment: {str(e)}")
                return False
        
        def _get_peer_writer(self, peer_id: str) -> Optional[asyncio.StreamWriter]:
            """Get StreamWriter for a peer."""
            # TODO: Implement peer writer management
            return None
        
        def get_metrics(self) -> Dict[str, int]:
            """Get transport metrics."""
            return self.metrics.copy()
    
    # Example usage
    async def example_usage():
        config = NetworkConfig(node_id="test_node")
        transport = NetworkTransport(config)
        
        # Register message handler
        async def handle_message(peer_id: str, payload: Dict[str, Any]) -> None:
            print(f"Received message from {peer_id}: {payload}")
            
        transport.register_handler("test_message", handle_message)
        
        # Send message
        success = await transport.send_message(
            peer_id="peer1",
            message_type="test_message",
            payload={"hello": "world"}
        )
        print(f"Message sent: {success}")
    
    if __name__ == "__main__":
        asyncio.run(example_usage())
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/core/node.py
# Size: 9410 bytes
# Last Modified: Wed Oct 23 18:29:52 2024
# Language: py
# ============================================================

```py
    from __future__ import annotations
    from datetime import datetime, timedelta
    from typing import Dict, List, Set, Optional
    import logging
    import json
    
    logger = logging.getLogger(__name__)
    
    class Node:
        """
        Represents a node in the ICN network.
    
        A node is a participant in the network that can validate transactions,
        participate in consensus, and maintain portions of the blockchain.
        """
    
        def __init__(
            self,
            node_id: str,
            cooperative_id: Optional[str] = None,
            initial_stake: float = 10.0,
        ):
            self.node_id = node_id
            self.cooperative_id = cooperative_id
            self.reputation_scores = {
                "validation": 0.0,
                "proposal_creation": 0.0,
                "voting": 0.0,
                "resource_sharing": 0.0,
                "cooperative_growth": 0.0,
                "community_building": 0.0,
                "conflict_resolution": 0.0,
                "transaction_validation": 0.0,
                "data_availability": 0.0,
                "network_stability": 0.0,
                "innovation": 0.0,
                "sustainability": 0.0,
            }
            self.stake = initial_stake
            self.cooperative_interactions: List[str] = []
            self.validation_history: List[Dict] = []
            self.resource_usage: Dict[str, float] = {
                "computation": 0.0,
                "storage": 0.0,
                "bandwidth": 0.0,
                "memory": 0.0,
                "energy": 0.0,
            }
            self.shard_assignments: Set[int] = set()
            self.active_shards: Dict[int, datetime] = {}
            self.last_validation = datetime.now().timestamp()
            self.total_validations = 0
            self.cooldown = 0
            self.performance_metrics: Dict[str, float] = {
                "response_time": 0.0,
                "availability": 100.0,
                "validation_success_rate": 100.0,
                "network_reliability": 100.0,
            }
            self.metadata: Dict = {
                "creation_time": datetime.now(),
                "last_active": datetime.now(),
                "version": "1.0",
                "capabilities": set(),
                "status": "active",
            }
    
        def update_reputation(
            self,
            category: str,
            score: float,
            cooperative_id: Optional[str] = None,
            evidence: Optional[Dict] = None,
        ) -> bool:
            """Update reputation score for a category with evidence."""
            try:
                if category not in self.reputation_scores:
                    logger.error(f"Invalid reputation category: {category}")
                    return False
    
                old_score = self.reputation_scores[category]
                self.reputation_scores[category] = max(0, old_score + score)
    
                if cooperative_id:
                    self.cooperative_interactions.append(cooperative_id)
    
                if evidence:
                    self.validation_history.append(
                        {
                            "timestamp": datetime.now(),
                            "category": category,
                            "score_change": score,
                            "evidence": evidence,
                        }
                    )
    
                self.metadata["last_active"] = datetime.now()
    
                # Trim history if needed
                if len(self.cooperative_interactions) > 1000:
                    self.cooperative_interactions = self.cooperative_interactions[-1000:]
                if len(self.validation_history) > 1000:
                    self.validation_history = self.validation_history[-1000:]
    
                return True
    
            except Exception as e:
                logger.error(f"Failed to update reputation: {str(e)}")
                return False
    
        def assign_to_shard(self, shard_id: int) -> bool:
            """Assign node to a shard."""
            if len(self.active_shards) >= 3:  # Maximum 3 active shards per node
                logger.warning(f"Node {self.node_id} already assigned to maximum shards")
                return False
    
            self.shard_assignments.add(shard_id)
            self.active_shards[shard_id] = datetime.now()
            logger.info(f"Node {self.node_id} assigned to shard {shard_id}")
            return True
    
        def remove_from_shard(self, shard_id: int) -> bool:
            """Remove node from a shard."""
            if shard_id in self.active_shards:
                del self.active_shards[shard_id]
                self.shard_assignments.discard(shard_id)
                logger.info(f"Node {self.node_id} removed from shard {shard_id}")
                return True
            return False
    
        def can_validate(self, shard_id: Optional[int] = None) -> bool:
            """Check if node can validate blocks."""
            current_time = datetime.now().timestamp()
    
            # Basic validation checks
            if self.cooldown > 0:
                return False
    
            if (current_time - self.last_validation) < 10:  # 10-second minimum
                return False
    
            if self.metadata["status"] != "active":
                return False
    
            # Shard-specific validation
            if shard_id is not None:
                if shard_id not in self.active_shards:
                    return False
    
                shard_time = self.active_shards[shard_id]
                if (datetime.now() - shard_time).total_seconds() > 3600:  # 1 hour timeout
                    return False
    
            return True
    
        def enter_cooldown(self, cooldown_period: int) -> None:
            """Put node into a cooldown period."""
            self.cooldown = cooldown_period
            self.metadata["status"] = "cooldown"
            logger.info(
                f"Node {self.node_id} entered cooldown for {cooldown_period} periods"
            )
    
        def update_metrics(self, metrics: Dict[str, float]) -> None:
            """Update node performance metrics."""
            self.performance_metrics.update(metrics)
            self.metadata["last_active"] = datetime.now()
    
            # Calculate validation success rate
            if self.total_validations > 0:
                success_rate = (
                    len(
                        [
                            v
                            for v in self.validation_history
                            if v.get("evidence", {}).get("success", False)
                        ]
                    )
                    / self.total_validations
                    * 100
                )
                self.performance_metrics["validation_success_rate"] = success_rate
    
        def get_total_reputation(self) -> float:
            """Calculate total reputation across all categories."""
            return sum(self.reputation_scores.values())
    
        def record_resource_usage(self, usage: Dict[str, float]) -> None:
            """Record resource usage metrics."""
            for resource, amount in usage.items():
                if resource in self.resource_usage:
                    self.resource_usage[resource] += amount
    
            # Update availability based on resource usage
            total_usage = sum(self.resource_usage.values())
            self.performance_metrics["availability"] = max(0, 100 - (total_usage / 5))
    
        def to_dict(self) -> Dict:
            """Convert node state to dictionary."""
            return {
                "node_id": self.node_id,
                "cooperative_id": self.cooperative_id,
                "reputation_scores": self.reputation_scores,
                "stake": self.stake,
                "shard_assignments": list(self.shard_assignments),
                "active_shards": {k: v.isoformat() for k, v in self.active_shards.items()},
                "performance_metrics": self.performance_metrics,
                "resource_usage": self.resource_usage,
                "metadata": {
                    **self.metadata,
                    "creation_time": self.metadata["creation_time"].isoformat(),
                    "last_active": self.metadata["last_active"].isoformat(),
                    "capabilities": list(self.metadata["capabilities"]),
                },
                "status": self.metadata["status"],
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> Node:
            """Create node from dictionary."""
            try:
                node = cls(
                    node_id=data["node_id"],
                    cooperative_id=data["cooperative_id"],
                    initial_stake=data["stake"],
                )
                node.reputation_scores = data["reputation_scores"]
                node.shard_assignments = set(data["shard_assignments"])
                node.active_shards = {
                    int(k): datetime.fromisoformat(v)
                    for k, v in data["active_shards"].items()
                }
                node.performance_metrics = data["performance_metrics"]
                node.resource_usage = data["resource_usage"]
    
                # Restore metadata
                node.metadata.update(data["metadata"])
                node.metadata["creation_time"] = datetime.fromisoformat(
                    data["metadata"]["creation_time"]
                )
                node.metadata["last_active"] = datetime.fromisoformat(
                    data["metadata"]["last_active"]
                )
                node.metadata["capabilities"] = set(data["metadata"]["capabilities"])
    
                return node
    
            except Exception as e:
                logger.error(f"Failed to create node from dictionary: {str(e)}")
                raise ValueError("Invalid node data")
    
        def __str__(self) -> str:
            """Return a human-readable string representation of the node."""
            return (
                f"Node(id={self.node_id}, "
                f"coop={self.cooperative_id}, "
                f"status={self.metadata['status']}, "
                f"rep={self.get_total_reputation():.2f})"
            )
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/core/block.py
# Size: 8336 bytes
# Last Modified: Sat Oct 26 04:43:03 2024
# Language: py
# ============================================================

```py
    # ============================================================
    # File: blockchain/core/block.py
    # Description: Core block structure for the ICN blockchain.
    # This file defines the block class used within each shard of
    # the ICN blockchain. A block contains validated transactions
    # and includes cryptographic links to maintain chain integrity.
    # ============================================================
    
    # blockchain/core/block.py
    
    from dataclasses import dataclass, field
    from datetime import datetime, timedelta
    from typing import List, Dict, Optional
    import hashlib
    import json
    import logging
    
    from .transaction import Transaction
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class Block:
        """
        Represents a block in the ICN blockchain.
        
        A block is the fundamental unit of the blockchain, containing a list
        of transactions and cryptographic links to ensure immutability and
        integrity. Each block is validated by a node within a specific shard.
        """
    
        index: int
        previous_hash: str
        timestamp: datetime
        transactions: List[Transaction]
        validator: str
        shard_id: int
        hash: str = ""
        nonce: int = 0
        merkle_root: str = ""
        cross_shard_refs: List[str] = field(default_factory=list)
        metadata: Dict = field(default_factory=lambda: {
            "created_at": datetime.now().isoformat(),
            "version": "1.0"
        })
        version: str = "1.0"
        
        def __post_init__(self) -> None:
            """Initialize block after creation."""
            # Sort transactions by priority
            self.transactions.sort(key=lambda tx: (-tx.priority, tx.timestamp))
            
            # Calculate merkle root if not provided
            if not self.merkle_root:
                self.merkle_root = self.calculate_merkle_root()
            
            # Calculate hash if not provided
            if not self.hash:
                self.hash = self.calculate_hash()
                
            # Initialize metadata if not provided
            if "created_at" not in self.metadata:
                self.metadata["created_at"] = datetime.now().isoformat()
            if "version" not in self.metadata:
                self.metadata["version"] = self.version
    
        def calculate_merkle_root(self) -> str:
            """Calculate the Merkle root of transactions."""
            if not self.transactions:
                return hashlib.sha256(b"empty").hexdigest()
            
            # Create leaf nodes from transactions
            leaves = [tx.calculate_hash() for tx in self.transactions]
            
            # Build Merkle tree
            while len(leaves) > 1:
                if len(leaves) % 2 == 1:
                    leaves.append(leaves[-1])
                leaves = [
                    hashlib.sha256((a + b).encode()).hexdigest()
                    for a, b in zip(leaves[::2], leaves[1::2])
                ]
            
            return leaves[0]
    
        def calculate_hash(self) -> str:
            """Calculate the hash of the block."""
            block_dict = {
                "index": self.index,
                "previous_hash": self.previous_hash,
                "timestamp": self.timestamp.isoformat(),
                "merkle_root": self.merkle_root,
                "validator": self.validator,
                "nonce": self.nonce,
                "shard_id": self.shard_id,
                "cross_shard_refs": sorted(self.cross_shard_refs),
                "version": self.version,
                "transaction_ids": [tx.transaction_id for tx in self.transactions]
            }
            block_json = json.dumps(block_dict, sort_keys=True)
            return hashlib.sha256(block_json.encode()).hexdigest()
    
        def add_transaction(self, transaction: Transaction) -> bool:
            """Add a transaction to the block."""
            try:
                # Validate shard assignment
                if transaction.shard_id != self.shard_id:
                    logger.error(f"Transaction shard_id mismatch: {transaction.shard_id} != {self.shard_id}")
                    return False
                
                # Check for duplicate
                if any(tx.transaction_id == transaction.transaction_id for tx in self.transactions):
                    logger.error(f"Duplicate transaction: {transaction.transaction_id}")
                    return False
                
                # Add transaction
                self.transactions.append(transaction)
                
                # Resort transactions by priority
                self.transactions.sort(key=lambda tx: (-tx.priority, tx.timestamp))
                
                # Update merkle root and hash
                self.merkle_root = self.calculate_merkle_root()
                self.hash = self.calculate_hash()
                
                return True
                
            except Exception as e:
                logger.error(f"Error adding transaction: {str(e)}")
                return False
    
        def validate(self, previous_block: Optional['Block'] = None) -> bool:
            """Validate block structure and consistency."""
            try:
                # Validate hash
                current_hash = self.calculate_hash()
                if self.hash != current_hash:
                    logger.error("Invalid block hash")
                    return False
    
                # Validate merkle root
                current_merkle_root = self.calculate_merkle_root()
                if self.merkle_root != current_merkle_root:
                    logger.error("Invalid merkle root")
                    return False
    
                # Validate timestamp
                if self.timestamp > datetime.now() + timedelta(minutes=5):
                    logger.error("Block timestamp is in the future")
                    return False
    
                # Validate transactions
                if not all(tx.validate() for tx in self.transactions):
                    logger.error("Invalid transactions in block")
                    return False
    
                # Validate against previous block
                if previous_block:
                    if self.previous_hash != previous_block.hash:
                        logger.error("Invalid previous hash")
                        return False
                    
                    if self.index != previous_block.index + 1:
                        logger.error("Invalid block index")
                        return False
                    
                    if self.timestamp <= previous_block.timestamp:
                        logger.error("Invalid timestamp sequence")
                        return False
                        
                    if self.shard_id != previous_block.shard_id:
                        logger.error("Shard ID mismatch")
                        return False
    
                return True
    
            except Exception as e:
                logger.error(f"Block validation failed: {str(e)}")
                return False
    
        def to_dict(self) -> Dict:
            """Convert block to dictionary format."""
            return {
                "index": self.index,
                "previous_hash": self.previous_hash,
                "timestamp": self.timestamp.isoformat(),
                "transactions": [tx.to_dict() for tx in self.transactions],
                "validator": self.validator,
                "hash": self.hash,
                "nonce": self.nonce,
                "merkle_root": self.merkle_root,
                "shard_id": self.shard_id,
                "cross_shard_refs": self.cross_shard_refs.copy(),
                "metadata": self.metadata.copy(),
                "version": self.version
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> 'Block':
            """Create block instance from dictionary."""
            transactions = [Transaction.from_dict(tx) for tx in data["transactions"]]
            timestamp = datetime.fromisoformat(data["timestamp"])
            
            block = cls(
                index=data["index"],
                previous_hash=data["previous_hash"],
                timestamp=timestamp,
                transactions=transactions,
                validator=data["validator"],
                shard_id=data["shard_id"],
                hash=data["hash"],
                nonce=data["nonce"],
                merkle_root=data["merkle_root"],
                cross_shard_refs=data.get("cross_shard_refs", []).copy(),
                metadata=data.get("metadata", {}).copy(),
                version=data.get("version", "1.0")
            )
            
            return block
    
        def __str__(self) -> str:
            """Return human-readable string representation."""
            return (
                f"Block(index={self.index}, "
                f"hash={self.hash[:8]}..., "
                f"tx_count={len(self.transactions)}, "
                f"shard={self.shard_id})"
            )
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/core/transaction.py
# Size: 11471 bytes
# Last Modified: Fri Oct 25 13:25:09 2024
# Language: py
# ============================================================

```py
    # blockchain/core/transaction.py
    
    from __future__ import annotations
    from dataclasses import dataclass, field
    from datetime import datetime, timedelta
    from typing import Dict, Optional, Any, List, Set
    import hashlib
    import json
    import logging
    from copy import deepcopy
    import math
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class Transaction:
        """
        Represents a transaction in the ICN blockchain.
        
        A transaction is the fundamental unit of record in the blockchain, representing
        any action or data transfer between parties in the network. Transactions in ICN
        support cooperative principles through:
        - Cross-shard operations
        - Resource sharing tracking
        - Cooperative reputation impacts
        - Fair prioritization
        """
        
        sender: str
        receiver: str
        action: str
        data: Dict[str, Any]
        timestamp: datetime = field(default_factory=datetime.now)
        signature: Optional[bytes] = None
        shard_id: Optional[int] = None
        transaction_id: str = field(init=False)
        _is_deserialized: bool = field(default=False, init=False, repr=False)
        priority: int = field(default=1)  # 1-5, with 5 being highest
        cooperative_tags: Set[str] = field(default_factory=set)
        resource_cost: Dict[str, float] = field(default_factory=lambda: {
            "computation": 1.0,
            "storage": 1.0,
            "bandwidth": 1.0
        })
        cross_shard_refs: List[str] = field(default_factory=list)
        metadata: Dict[str, Any] = field(default_factory=dict)
    
        # Maximum sizes for various fields
        MAX_DATA_SIZE = 1024 * 1024  # 1MB
        MAX_CROSS_SHARD_REFS = 10
        VALID_PRIORITIES = {1, 2, 3, 4, 5}
        VALID_ACTIONS = {
            "transfer", "stake", "unstake", "vote", "propose",
            "deploy", "execute", "store", "share", "validate"
        }
    
        def __post_init__(self) -> None:
            """Initialize transaction ID and perform validation after creation."""
            # Validate basic inputs
            if not self.sender:
                raise ValueError("Sender cannot be empty")
            if not self.receiver:
                raise ValueError("Receiver cannot be empty")
            if not self.action:
                raise ValueError("Action cannot be empty")
            
            # Validate action
            if self.action not in self.VALID_ACTIONS:
                raise ValueError(f"Invalid action. Must be one of: {self.VALID_ACTIONS}")
                
            # Validate priority
            if self.priority not in self.VALID_PRIORITIES:
                raise ValueError(f"Invalid priority. Must be between 1-5")
    
            # Deep copy mutable fields
            self.data = deepcopy(self.data)
            self.cooperative_tags = set(self.cooperative_tags)
            self.resource_cost = deepcopy(self.resource_cost)
            self.cross_shard_refs = list(self.cross_shard_refs)
            self.metadata = deepcopy(self.metadata)
    
            # Add creation metadata
            self.metadata.update({
                "created_at": datetime.now().isoformat(),
                "data_size": len(json.dumps(self.data)),
                "version": "1.0"
            })
            
            # Calculate transaction ID
            if not hasattr(self, 'transaction_id') or not self.transaction_id:
                self.transaction_id = self.calculate_id()
    
            # Calculate and store resource costs
            self._calculate_resource_costs()
    
        def _calculate_resource_costs(self) -> None:
            """Calculate resource costs based on transaction characteristics."""
            data_size = len(json.dumps(self.data))
            
            # Base computation cost
            self.resource_cost["computation"] = 1.0
            
            # Storage cost based on data size
            self.resource_cost["storage"] = math.ceil(data_size / 1024)  # Cost per KB
            
            # Bandwidth cost including cross-shard overhead
            self.resource_cost["bandwidth"] = (
                math.ceil(data_size / 1024) * 
                (1 + 0.2 * len(self.cross_shard_refs))  # 20% overhead per cross-shard ref
            )
    
        def calculate_id(self) -> str:
            """
            Calculate unique transaction ID using transaction data.
            
            Returns:
                str: The calculated transaction ID
            """
            tx_data = {
                "sender": self.sender,
                "receiver": self.receiver,
                "action": self.action,
                "data": self.data,
                "timestamp": self.timestamp.isoformat(),
                "shard_id": self.shard_id,
                "priority": self.priority,
                "cooperative_tags": sorted(list(self.cooperative_tags))
            }
            tx_json = json.dumps(tx_data, sort_keys=True)
            return hashlib.sha256(tx_json.encode()).hexdigest()
    
        def calculate_hash(self) -> str:
            """
            Calculate cryptographic hash of the transaction.
            
            Returns:
                str: The calculated hash
            """
            tx_dict = self.to_dict()
            tx_dict.pop('signature', None)  # Remove signature from hash calculation
            tx_json = json.dumps(tx_dict, sort_keys=True)
            return hashlib.sha256(tx_json.encode()).hexdigest()
    
        def validate(self) -> bool:
            """
            Validate the transaction's structure and data.
            
            Returns:
                bool: True if the transaction is valid
            """
            try:
                # Validate required fields
                if not all([self.sender, self.receiver, self.action]):
                    logger.error("Missing required transaction fields")
                    return False
    
                # Validate timestamp
                now = datetime.now()
                if self.timestamp > now + timedelta(minutes=5):
                    logger.error(f"Transaction timestamp {self.timestamp} is in the future")
                    return False
    
                if self.timestamp < now - timedelta(days=1):
                    logger.error(f"Transaction timestamp {self.timestamp} is too old")
                    return False
    
                # Validate data structure and size
                if not isinstance(self.data, dict):
                    logger.error("Transaction data must be a dictionary")
                    return False
    
                if len(json.dumps(self.data)) > self.MAX_DATA_SIZE:
                    logger.error("Transaction data exceeds maximum size")
                    return False
    
                # Validate action
                if self.action not in self.VALID_ACTIONS:
                    logger.error(f"Invalid action: {self.action}")
                    return False
    
                # Validate shard_id if present
                if self.shard_id is not None:
                    if not isinstance(self.shard_id, int) or self.shard_id < 0:
                        logger.error("Invalid shard_id value")
                        return False
    
                # Validate cross-shard references
                if len(self.cross_shard_refs) > self.MAX_CROSS_SHARD_REFS:
                    logger.error("Too many cross-shard references")
                    return False
    
                # Validate resource costs
                if not all(cost >= 0 for cost in self.resource_cost.values()):
                    logger.error("Invalid resource costs")
                    return False
    
                # Verify transaction ID consistency
                if self.transaction_id != self.calculate_id():
                    logger.error("Transaction ID mismatch")
                    return False
    
                return True
    
            except Exception as e:
                logger.error(f"Transaction validation failed: {str(e)}")
                return False
    
        def is_cross_shard(self) -> bool:
            """Check if this is a cross-shard transaction."""
            return bool(self.cross_shard_refs) or 'target_shard' in self.data
    
        def get_target_shards(self) -> Set[int]:
            """Get all shards involved in this transaction."""
            shards = {self.shard_id} if self.shard_id is not None else set()
            if 'target_shard' in self.data:
                shards.add(self.data['target_shard'])
            return shards
    
        def get_resource_impact(self) -> float:
            """Calculate total resource impact of the transaction."""
            return sum(self.resource_cost.values())
    
        def get_cooperative_score(self) -> float:
            """Calculate cooperative impact score of the transaction."""
            base_score = 1.0
            
            # Bonus for cooperative tags
            if self.cooperative_tags:
                base_score += 0.1 * len(self.cooperative_tags)
                
            # Penalty for high resource usage
            resource_impact = self.get_resource_impact()
            if resource_impact > 10:
                base_score *= 0.9
                
            # Bonus for cross-shard cooperation
            if self.is_cross_shard():
                base_score *= 1.1
                
            return base_score
    
        def to_dict(self) -> Dict:
            """
            Convert transaction to dictionary format.
            
            Returns:
                Dict: The dictionary representation
            """
            return {
                "transaction_id": self.transaction_id,
                "sender": self.sender,
                "receiver": self.receiver,
                "action": self.action,
                "data": deepcopy(self.data),
                "timestamp": self.timestamp.isoformat(),
                "signature": self.signature.hex() if self.signature else None,
                "shard_id": self.shard_id,
                "priority": self.priority,
                "cooperative_tags": sorted(list(self.cooperative_tags)),
                "resource_cost": deepcopy(self.resource_cost),
                "cross_shard_refs": self.cross_shard_refs.copy(),
                "metadata": deepcopy(self.metadata)
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> Transaction:
            """Create transaction instance from dictionary data."""
            try:
                # Extract and convert fields
                timestamp = datetime.fromisoformat(data["timestamp"])
                signature = bytes.fromhex(data["signature"]) if data.get("signature") else None
                cooperative_tags = set(data.get("cooperative_tags", []))
                resource_cost = deepcopy(data.get("resource_cost", {
                    "computation": 1.0,
                    "storage": 1.0,
                    "bandwidth": 1.0
                }))
                
                # Create transaction
                tx = cls(
                    sender=data["sender"],
                    receiver=data["receiver"],
                    action=data["action"],
                    data=deepcopy(data["data"]),
                    timestamp=timestamp,
                    signature=signature,
                    shard_id=data.get("shard_id"),
                    priority=data.get("priority", 1),
                    cooperative_tags=cooperative_tags,
                    resource_cost=resource_cost,
                    cross_shard_refs=data.get("cross_shard_refs", []),
                    metadata=data.get("metadata", {})
                )
                
                # Set the original transaction_id
                tx.transaction_id = data["transaction_id"]
                tx._is_deserialized = True
                
                return tx
    
            except Exception as e:
                logger.error(f"Failed to create transaction from dictionary: {str(e)}")
                raise ValueError(f"Invalid transaction data: {str(e)}")
    
        def __str__(self) -> str:
            """Return a human-readable string representation."""
            return (
                f"Transaction(id={self.transaction_id[:8]}..., "
                f"action={self.action}, "
                f"sender={self.sender[:8]}..., "
                f"receiver={self.receiver[:8]}..., "
                f"shard={self.shard_id}, "
                f"priority={self.priority})"
            )
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/core/blockchain.py
# Size: 8966 bytes
# Last Modified: Thu Oct 24 02:30:11 2024
# Language: py
# ============================================================

```py
    # ================================================================
    # File: blockchain/core/blockchain.py
    # ================================================================
    # Description: Core Blockchain implementation for the ICN system.
    # 
    # This module manages the ICN blockchain, coordinating shards, nodes,
    # transactions, consensus, and smart contract execution.
    # ================================================================
    
    from __future__ import annotations
    from typing import List, Dict, Optional, Any
    from datetime import datetime, timedelta
    import logging
    import hashlib
    import asyncio
    
    from .block import Block
    from .node import Node
    from .shard import Shard
    from .transaction import Transaction
    from ..consensus.proof_of_cooperation import ProofOfCooperation
    from ..contracts.smart_contract import SmartContract
    from ..contracts.contract_executor import ContractExecutor
    
    logger = logging.getLogger(__name__)
    
    class Blockchain:
        """
        Core Blockchain implementation for the ICN system.
        Manages shards, transactions, blocks, nodes, consensus, and contracts.
        """
    
        def __init__(self, num_shards: int = 4, initial_mana: int = 1000, mana_regen_rate: int = 10):
            """
            Initialize the blockchain with specified shards, mana, and consensus.
            """
            self.nodes: Dict[str, Node] = {}
            self.shards: Dict[int, Shard] = {}
            self.chain: List[Block] = []
            self.transaction_pool: List[Transaction] = []
            self.smart_contracts: Dict[str, SmartContract] = {}
    
            self.consensus_mechanism = ProofOfCooperation()
            self.contract_executor = ContractExecutor()
    
            self.cooperative_mana = initial_mana
            self.mana_regen_rate = mana_regen_rate
            self.genesis_block_created = False
    
            self._initialize_shards(num_shards)
            self.create_genesis_block()
    
        def _initialize_shards(self, num_shards: int) -> None:
            """
            Initialize shards for parallel transaction processing.
            """
            for shard_id in range(num_shards):
                self.create_shard(shard_id)
    
        def create_genesis_block(self) -> None:
            """
            Create the genesis block with no transactions and a special validator.
            """
            if self.genesis_block_created:
                logger.warning("Genesis block already created")
                return
    
            genesis_block = Block(
                index=0,
                previous_hash="0" * 64,
                timestamp=datetime.now(),
                transactions=[],
                validator="genesis",
                shard_id=-1
            )
    
            self.chain.append(genesis_block)
            self.genesis_block_created = True
            logger.info("Genesis block created")
    
        def register_node(self, node: Node) -> bool:
            """
            Register a node and make it eligible for validation.
            """
            if not isinstance(node, Node) or node.node_id in self.nodes:
                logger.error(f"Invalid or duplicate node: {node.node_id}")
                return False
    
            node.is_validator = True
            self.nodes[node.node_id] = node
            logger.info(f"Node {node.node_id} registered as validator")
            return True
    
        def create_shard(self, shard_id: int) -> bool:
            """
            Create a new shard with the given ID.
            """
            if shard_id in self.shards:
                logger.error(f"Shard {shard_id} already exists")
                return False
    
            self.shards[shard_id] = Shard(shard_id=shard_id)
            logger.info(f"Shard {shard_id} created")
            return True
    
        def add_transaction(self, transaction: Dict) -> bool:
            """
            Add a transaction after initializing and validating it.
            """
            if not isinstance(transaction, dict):
                logger.error("Invalid transaction format")
                return False
    
            tx = Transaction(
                sender=transaction['sender'],
                receiver=transaction['receiver'],
                action=transaction['action'],
                data=transaction['data']
            )
    
            shard_id = self._calculate_shard_id(tx)
            tx.shard_id = shard_id
            tx.transaction_id = self._calculate_transaction_id(tx)
    
            if shard_id not in self.shards or not self.shards[shard_id].add_transaction(tx):
                logger.error(f"Failed to add transaction {tx.transaction_id} to shard {shard_id}")
                return False
    
            logger.info(f"Transaction {tx.transaction_id} added to shard {shard_id}")
            return True
    
        def _calculate_shard_id(self, transaction: Transaction) -> int:
            """
            Calculate the shard ID for the transaction using its hash.
            """
            tx_hash = hashlib.sha256(str(transaction).encode()).hexdigest()
            return int(tx_hash, 16) % len(self.shards)
    
        def _calculate_transaction_id(self, transaction: Transaction) -> str:
            """
            Calculate the transaction ID using the hash of its contents.
            """
            tx_hash = hashlib.sha256(str(transaction).encode()).hexdigest()
            return tx_hash
    
        def create_block(self, shard_id: Optional[int] = None) -> Optional[Block]:
            """
            Create a new block in the specified shard.
            """
            shard = self.shards.get(shard_id)
            if not shard:
                logger.error(f"Shard {shard_id} not found")
                return None
    
            validator = self.consensus_mechanism.select_validator(list(self.nodes.values()), shard_id)
            if not validator:
                logger.error(f"No eligible validator for shard {shard_id}")
                return None
    
            new_block = shard.create_block(validator.node_id)
            if new_block and self.add_block(new_block):
                return new_block
    
            return None
    
        def add_block(self, block: Block) -> bool:
            """
            Add a validated block to the chain.
            """
            if not isinstance(block, Block) or not block.validate(self.chain[-1]):
                logger.error("Block validation failed")
                return False
    
            self.chain.append(block)
            logger.info(f"Block {block.index} added to chain")
            return True
    
        def regenerate_mana(self) -> None:
            """
            Regenerate cooperative mana up to the cap.
            """
            self.cooperative_mana = min(1000, self.cooperative_mana + self.mana_regen_rate)
    
        def get_chain_metrics(self) -> Dict:
            """
            Return blockchain metrics including chain length and mana.
            """
            return {
                "chain_length": len(self.chain),
                "total_transactions": sum(len(block.transactions) for block in self.chain),
                "average_block_time": self._calculate_average_block_time(),
                "active_nodes": len(self.nodes),
                "active_shards": len(self.shards),
                "cooperative_mana": self.cooperative_mana,
                "contract_count": len(self.smart_contracts),
            }
    
        def _calculate_average_block_time(self) -> float:
            """
            Calculate the average time between blocks.
            """
            if len(self.chain) <= 1:
                return 0.0
    
            total_time = sum(
                (self.chain[i].timestamp - self.chain[i-1].timestamp).total_seconds()
                for i in range(1, len(self.chain))
            )
            return total_time / (len(self.chain) - 1)
    
        def validate_chain(self) -> bool:
            """
            Validate the integrity of the entire chain.
            """
            for i in range(1, len(self.chain)):
                if not self.chain[i].validate(self.chain[i-1]):
                    logger.error(f"Block {i} validation failed")
                    return False
    
            logger.info("Blockchain is valid")
            return True
    
        async def deploy_smart_contract(self, contract: SmartContract) -> bool:
            """
            Deploy a smart contract and register it.
            """
            if contract.contract_id in self.smart_contracts or self.cooperative_mana < contract.mana_cost:
                logger.error(f"Contract {contract.contract_id} deployment failed")
                return False
    
            self.smart_contracts[contract.contract_id] = contract
            self.cooperative_mana -= contract.mana_cost
            logger.info(f"Contract {contract.contract_id} deployed")
            return True
    
        async def execute_smart_contract(self, contract_id: str, input_data: Dict, caller: str) -> Optional[Dict]:
            """
            Execute a smart contract with the given input data.
            """
            contract = self.smart_contracts.get(contract_id)
            if not contract or self.cooperative_mana < contract.mana_cost:
                logger.error(f"Failed to execute contract {contract_id}")
                return None
    
            result = await self.contract_executor.execute_contract(contract_id, input_data, caller)
            if result is not None:
                self.cooperative_mana -= contract.mana_cost
                logger.info(f"Contract {contract_id} executed by {caller}")
            else:
                logger.error(f"Failed to execute contract {contract_id}")
    
            return result
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/core/__init__.py
# Size: 299 bytes
# Last Modified: Thu Oct 24 00:41:25 2024
# Language: py
# ============================================================

```py
    # blockchain/core/__init__.py
    """Core blockchain components."""
    from .node import Node
    from .block import Block
    from .transaction import Transaction
    from .shard import Shard
    from .blockchain import Blockchain
    
    __all__ = [
        "Node",
        "Block",
        "Transaction", 
        "Shard",
        "Blockchain"
    ]
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/core/shard/validation_manager.py
# Size: 6705 bytes
# Last Modified: Fri Oct 25 23:20:16 2024
# Language: py
# ============================================================

```py
    # blockchain/core/shard/validation_manager.py
    
    from typing import Dict, Optional, List, Set
    import logging
    from datetime import datetime, timedelta
    from .shard_types import ShardMetrics, ShardConfig
    from ..block import Block
    from ..transaction import Transaction
    
    logger = logging.getLogger(__name__)
    
    class ValidationManager:
        """Handles transaction and chain validation logic."""
        
        def __init__(self, shard_id: int, config: ShardConfig):
            self.shard_id = shard_id
            self.config = config
            self.validation_cache: Dict[str, bool] = {}
            self.metrics = ShardMetrics()
            self.last_validation_time: Dict[str, datetime] = {}
            self.last_block_time = datetime.now() - timedelta(seconds=config.min_block_interval)
            self.state: Dict[str, Dict] = {"balances": {}}
    
        def validate_transaction(self, transaction: Transaction) -> bool:
            """
            Validate a transaction before adding to pool.
            
            Args:
                transaction: Transaction to validate
                
            Returns:
                bool: True if transaction is valid
            """
            try:
                # Check cache first
                tx_id = transaction.transaction_id
                if tx_id in self.validation_cache:
                    return self.validation_cache[tx_id]
    
                # Basic validation
                if not transaction.validate():
                    logger.error(f"Transaction {tx_id} failed basic validation")
                    self.validation_cache[tx_id] = False
                    return False
    
                # Check transaction amount
                amount = transaction.data.get('amount', 0)
                if amount <= 0:
                    logger.error(f"Transaction {tx_id} has invalid amount")
                    self.validation_cache[tx_id] = False
                    return False
    
                # Check shard assignment
                if transaction.shard_id != self.shard_id:
                    logger.error(f"Transaction {tx_id} has wrong shard ID")
                    self.validation_cache[tx_id] = False
                    return False
    
                # Check balance
                sender = transaction.sender
                balances = self.state.get("balances", {})
                sender_balance = balances.get(sender, 1000.0)  # Default initial balance
                if sender_balance < amount:
                    logger.error(f"Insufficient balance for transaction {tx_id}")
                    self.validation_cache[tx_id] = False
                    return False
    
                # Cache and return success
                self.validation_cache[tx_id] = True
                return True
    
            except Exception as e:
                logger.error(f"Transaction validation failed: {str(e)}")
                return False
    
        def validate_block(self, block: Block, previous_block: Optional[Block]) -> bool:
            """
            Validate a block before adding to chain.
            
            Args:
                block: Block to validate
                previous_block: Previous block in chain for validation
                
            Returns:
                bool: True if block is valid
            """
            try:
                # Basic block validation
                if not block.validate(previous_block):
                    logger.error("Block failed basic validation")
                    return False
    
                # Check shard ID
                if block.shard_id != self.shard_id:
                    logger.error("Block has wrong shard ID")
                    return False
    
                # Validate all transactions
                for tx in block.transactions:
                    if not self.validate_transaction(tx):
                        logger.error(f"Block contains invalid transaction {tx.transaction_id}")
                        return False
    
                    # Update balances for subsequent transaction validations
                    amount = float(tx.data.get('amount', 0))
                    self.state.setdefault("balances", {})
                    self.state["balances"].setdefault(tx.sender, 1000.0)
                    self.state["balances"].setdefault(tx.receiver, 1000.0)
                    self.state["balances"][tx.sender] -= amount
                    self.state["balances"][tx.receiver] += amount
    
                # Always allow the genesis block
                if previous_block is None or block.index == 0:
                    return True
    
                # Check block timing - disabled for testing
                # current_time = datetime.now()
                # time_since_last = (current_time - self.last_block_time).total_seconds()
                # if time_since_last < self.config.min_block_interval:
                #     logger.error(f"Block created too soon after previous block")
                #     return False
    
                self.last_block_time = datetime.now()
                return True
    
            except Exception as e:
                logger.error(f"Block validation failed: {str(e)}")
                return False
    
        def clear_cache(self) -> None:
            """Clear validation cache."""
            self.validation_cache.clear()
    
        def update_state(self, state: Dict) -> None:
            """Update the validation manager's state view."""
            self.state = state.copy()
    
        def get_metrics(self) -> Dict:
            """Get validation metrics."""
            return {
                "validation_cache_size": len(self.validation_cache),
                "last_validation_times": {
                    tx_id: time.isoformat()
                    for tx_id, time in self.last_validation_time.items()
                },
                "total_validations": len(self.validation_cache),
                "failed_validations": len([v for v in self.validation_cache.values() if not v])
            }
    
        def to_dict(self) -> Dict:
            """Convert manager state to dictionary format."""
            return {
                "validation_cache": self.validation_cache.copy(),
                "metrics": self.metrics.to_dict(),
                "last_validation_time": {
                    tx_id: time.isoformat()
                    for tx_id, time in self.last_validation_time.items()
                },
                "last_block_time": self.last_block_time.isoformat(),
                "state": self.state.copy()
            }
    
        @classmethod
        def from_dict(cls, data: Dict, shard_id: int, config: ShardConfig) -> 'ValidationManager':
            """Create manager from dictionary data."""
            manager = cls(shard_id, config)
            manager.validation_cache = data["validation_cache"].copy()
            manager.metrics = ShardMetrics.from_dict(data["metrics"])
            manager.last_validation_time = {
                tx_id: datetime.fromisoformat(time_str)
                for tx_id, time_str in data["last_validation_time"].items()
            }
            manager.last_block_time = datetime.fromisoformat(data["last_block_time"])
            manager.state = data["state"].copy()
            return manager
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/core/shard/transaction_manager.py
# Size: 5115 bytes
# Last Modified: Fri Oct 25 23:16:05 2024
# Language: py
# ============================================================

```py
    # blockchain/core/shard/transaction_manager.py
    
    from typing import List, Optional, Dict, Set
    import logging
    from datetime import datetime, timedelta
    from .shard_types import ShardMetrics, ShardConfig
    from ..transaction import Transaction
    
    logger = logging.getLogger(__name__)
    
    class TransactionManager:
        """Handles transaction processing and management within a shard."""
        
        def __init__(self, shard_id: int, config: ShardConfig):
            self.shard_id = shard_id
            self.config = config
            self.pending_transactions: List[Transaction] = []
            self.processed_transactions: Set[str] = set()  # Track processed tx IDs
            self.metrics = ShardMetrics()
            self.last_prune_time = datetime.now()
    
        def add_transaction(self, transaction: Transaction) -> bool:
            """Add a new transaction to the pending pool."""
            try:
                # Check shard assignment
                if transaction.shard_id != self.shard_id:
                    logger.error(f"Transaction shard_id {transaction.shard_id} doesn't match shard {self.shard_id}")
                    return False
    
                # Check pool capacity
                if len(self.pending_transactions) >= self.config.max_pending_transactions:
                    logger.warning(f"Shard {self.shard_id} transaction pool full")
                    return False
    
                # Check for duplicate
                tx_id = transaction.transaction_id
                if tx_id in self.processed_transactions:
                    logger.warning(f"Transaction {tx_id} already processed")
                    return False
    
                if any(tx.transaction_id == tx_id for tx in self.pending_transactions):
                    logger.warning(f"Transaction {tx_id} already in pending pool")
                    return False
    
                # Add transaction
                self.pending_transactions.append(transaction)
                self.metrics.pending_count = len(self.pending_transactions)
                
                # Sort by priority
                self._sort_pending_transactions()
    
                return True
    
            except Exception as e:
                logger.error(f"Failed to add transaction: {str(e)}")
                return False
    
        def select_transactions_for_block(self) -> List[Transaction]:
            """Select and sort transactions for a new block."""
            try:
                # Get initial selection
                candidates = self.pending_transactions[:self.config.max_transactions_per_block]
                
                # Sort by priority and timestamp
                candidates.sort(key=lambda tx: (-tx.priority, tx.timestamp))
    
                # Track selected transactions
                for tx in candidates:
                    self.processed_transactions.add(tx.transaction_id)
    
                return candidates
    
            except Exception as e:
                logger.error(f"Failed to select transactions: {str(e)}")
                return []
    
        def remove_transactions(self, transaction_ids: Set[str]) -> None:
            """Remove transactions from the pending pool."""
            try:
                self.pending_transactions = [
                    tx for tx in self.pending_transactions 
                    if tx.transaction_id not in transaction_ids
                ]
                self.metrics.pending_count = len(self.pending_transactions)
    
                # Add to processed set
                self.processed_transactions.update(transaction_ids)
    
            except Exception as e:
                logger.error(f"Failed to remove transactions: {str(e)}")
    
        def get_metrics(self) -> Dict:
            """Get transaction pool metrics."""
            return {
                "pending_count": len(self.pending_transactions),
                "processed_count": len(self.processed_transactions),
                "total_transactions": self.metrics.total_transactions
            }
    
        def _sort_pending_transactions(self) -> None:
            """Sort pending transactions by priority and timestamp."""
            try:
                self.pending_transactions.sort(key=lambda tx: (-tx.priority, tx.timestamp))
            except Exception as e:
                logger.error(f"Failed to sort transactions: {str(e)}")
    
        def clear_all(self) -> None:
            """Clear all pending transactions."""
            self.pending_transactions = []
            self.metrics.pending_count = 0
            logger.info(f"Cleared all pending transactions from shard {self.shard_id}")
    
        def to_dict(self) -> Dict:
            """Convert manager state to dictionary format."""
            return {
                "pending_transactions": [tx.to_dict() for tx in self.pending_transactions],
                "processed_transactions": list(self.processed_transactions),
                "metrics": self.metrics.to_dict(),
            }
    
        @classmethod
        def from_dict(cls, data: Dict, shard_id: int, config: ShardConfig) -> 'TransactionManager':
            """Create manager from dictionary data."""
            manager = cls(shard_id, config)
            manager.pending_transactions = [
                Transaction.from_dict(tx) for tx in data["pending_transactions"]
            ]
            manager.processed_transactions = set(data["processed_transactions"])
            manager.metrics = ShardMetrics.from_dict(data["metrics"])
            return manager
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/core/shard/state_manager.py
# Size: 7540 bytes
# Last Modified: Sat Oct 26 13:59:14 2024
# Language: py
# ============================================================

```py
    from typing import Dict, Optional, List, Set, Any
    import logging
    from datetime import datetime
    from copy import deepcopy
    from .shard_types import ShardConfig, ShardMetrics
    from ..transaction import Transaction
    from ..block import Block
    
    logger = logging.getLogger(__name__)
    
    class StateManager:
        """
        Manages state and state transitions within a shard.
        
        This class handles:
        - State updates from transactions and blocks
        - State validation and consistency checks
        - State snapshots and rollbacks
        - State metrics tracking
        """
    
        def __init__(self, shard_id: int, config: ShardConfig):
            """
            Initialize the state manager.
            
            Args:
                shard_id: ID of the shard this manager belongs to
                config: Configuration parameters
            """
            self.shard_id = shard_id
            self.config = config
            self.state: Dict[str, Any] = {
                "balances": {},
                "metadata": {
                    "shard_id": shard_id,
                    "created_at": datetime.now().isoformat(),
                    "last_updated": datetime.now().isoformat(),
                    "total_transactions": 0,
                    "total_volume": 0.0,
                    "version": "1.0"
                }
            }
            self._state_snapshots: List[Dict] = []
            self.metrics = ShardMetrics()
            self.processed_transactions: Set[str] = set()
            self._backup_state: Optional[Dict] = None
    
        def update_state(self, block: Block) -> bool:
            """
            Update state based on a new block.
            
            Args:
                block: Block containing transactions to process
                
            Returns:
                bool: True if state update successful
            """
            try:
                # Create backup
                self._backup_state = deepcopy(self.state)
    
                # Process all transactions
                for tx in block.transactions:
                    if not self._process_transaction(tx):
                        self._rollback_state()
                        return False
    
                # Update metadata
                self.state["metadata"].update({
                    "last_updated": datetime.now().isoformat(),
                    "total_transactions": self.state["metadata"]["total_transactions"] + len(block.transactions),
                    "last_block": block.index
                })
    
                # Update metrics
                self.metrics.total_transactions += len(block.transactions)
                
                # Take snapshot if needed
                if self._should_snapshot():
                    self._take_snapshot()
    
                return True
    
            except Exception as e:
                logger.error(f"Failed to update state: {str(e)}")
                self._rollback_state()
                return False
    
        def _process_transaction(self, transaction: Transaction) -> bool:
            """
            Process a single transaction's state changes.
            
            Args:
                transaction: Transaction to process
                
            Returns:
                bool: True if transaction processed successfully
            """
            try:
                sender = transaction.sender
                receiver = transaction.receiver
                amount = float(transaction.data.get("amount", 0))
                
                # Initialize balances if needed
                if sender not in self.state["balances"]:
                    self.state["balances"][sender] = 1000.0  # Initial balance
                if receiver not in self.state["balances"]:
                    self.state["balances"][receiver] = 1000.0  # Initial balance
    
                # Check balance
                if self.state["balances"][sender] < amount:
                    logger.error(f"Insufficient funds for transaction {transaction.transaction_id}")
                    return False
    
                # Update balances
                self.state["balances"][sender] -= amount
                self.state["balances"][receiver] += amount
    
                # Track total volume
                self.state["metadata"]["total_volume"] += amount
    
                # Mark as processed
                self.processed_transactions.add(transaction.transaction_id)
    
                return True
    
            except Exception as e:
                logger.error(f"Failed to process transaction {transaction.transaction_id}: {str(e)}")
                return False
    
        def _should_snapshot(self) -> bool:
            """Determine if state snapshot should be taken."""
            state_size = len(str(self.state))
            return (
                len(self._state_snapshots) == 0 or 
                state_size > self.config.max_state_size * 0.9
            )
    
        def _take_snapshot(self) -> None:
            """Take a snapshot of current state."""
            try:
                snapshot = {
                    'timestamp': datetime.now().isoformat(),
                    'state': deepcopy(self.state),
                    'metrics': self.metrics.to_dict()
                }
                self._state_snapshots.append(snapshot)
                
                # Keep only last 10 snapshots
                if len(self._state_snapshots) > 10:
                    self._state_snapshots = self._state_snapshots[-10:]
    
            except Exception as e:
                logger.error(f"Failed to take state snapshot: {str(e)}")
    
        def _rollback_state(self) -> None:
            """Rollback to last backup state."""
            if self._backup_state is not None:
                self.state = deepcopy(self._backup_state)
                self._backup_state = None
    
        def get_balance(self, address: str) -> float:
            """
            Get balance for an address.
            
            Args:
                address: Address to get balance for
                
            Returns:
                float: Current balance
            """
            return self.state["balances"].get(address, 0.0)
    
        def get_metrics(self) -> Dict[str, Any]:
            """
            Get state metrics.
            
            Returns:
                Dict[str, Any]: Dictionary of metrics
            """
            return {
                "total_transactions": self.state["metadata"]["total_transactions"],
                "total_volume": self.state["metadata"]["total_volume"],
                "state_size": len(str(self.state)),
                "processed_transactions": len(self.processed_transactions)
            }
    
        def to_dict(self) -> Dict[str, Any]:
            """
            Convert state manager to dictionary format.
            
            Returns:
                Dict[str, Any]: Dictionary representation
            """
            return {
                "state": deepcopy(self.state),
                "metrics": self.metrics.to_dict(),
                "processed_transactions": list(self.processed_transactions),
                "snapshots": self._state_snapshots.copy()
            }
    
        @classmethod
        def from_dict(cls, data: Dict[str, Any], shard_id: int, config: ShardConfig) -> 'StateManager':
            """
            Create state manager from dictionary data.
            
            Args:
                data: Dictionary containing state data
                shard_id: ID of the shard
                config: Configuration parameters
                
            Returns:
                StateManager: New state manager instance
            """
            manager = cls(shard_id, config)
            manager.state = deepcopy(data.get("state", {}))
            manager._state_snapshots = data.get("snapshots", []).copy()
            manager.processed_transactions = set(data.get("processed_transactions", []))
            manager.metrics = ShardMetrics.from_dict(data.get("metrics", {}))
            return manager
    
        def __str__(self) -> str:
            """String representation."""
            return f"StateManager(shard={self.shard_id}, tx_count={self.state['metadata']['total_transactions']})"
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/core/shard/shard_types.py
# Size: 3173 bytes
# Last Modified: Fri Oct 25 23:16:16 2024
# Language: py
# ============================================================

```py
    # blockchain/core/shard/shard_types.py
    
    from __future__ import annotations
    from dataclasses import dataclass, field
    from datetime import datetime
    from typing import Dict, List, Optional, Set
    
    @dataclass
    class ShardMetrics:
        """Metrics tracking for a shard."""
        total_transactions: int = 0
        average_block_time: float = 0.0
        blocks_created: int = 0
        pending_count: int = 0
        validation_failures: int = 0
        successful_blocks: int = 0
        rejected_transactions: int = 0
        total_size_bytes: int = 0
        average_transactions_per_block: float = 0.0
        cross_shard_operations: int = 0
        active_validators: int = 0
        state_size_bytes: int = 0
    
        def to_dict(self) -> Dict:
            """Convert metrics to dictionary format."""
            return {
                field.name: getattr(self, field.name)
                for field in self.__dataclass_fields__.values()
            }
    
        @classmethod 
        def from_dict(cls, data: Dict) -> 'ShardMetrics':
            """Create metrics from dictionary."""
            return cls(**{
                k: v for k, v in data.items() 
                if k in cls.__dataclass_fields__
            })
    
    @dataclass
    class ShardConfig:
        """Configuration for a shard."""
        max_transactions_per_block: int = 100
        max_pending_transactions: int = 200
        max_cross_shard_refs: int = 50
        pruning_interval: int = 60  # minutes
        min_block_interval: int = 0  # Changed to 0 for testing
        max_block_size: int = 1024 * 1024  # 1MB
        max_state_size: int = 10 * 1024 * 1024  # 10MB
        max_validators: int = 100
        cross_shard_timeout: int = 300  # seconds
    
        def to_dict(self) -> Dict:
            """Convert config to dictionary format."""
            return {
                field.name: getattr(self, field.name)
                for field in self.__dataclass_fields__.values()
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> 'ShardConfig':
            """Create config from dictionary."""
            return cls(**{
                k: v for k, v in data.items() 
                if k in cls.__dataclass_fields__
            })
    
    @dataclass
    class CrossShardRef:
        """Represents a cross-shard reference."""
        source_shard: int
        target_shard: int
        transaction_id: str
        created_at: datetime = field(default_factory=datetime.now)
        status: str = "pending"  # pending, validated, expired
        validation_time: Optional[datetime] = None
    
        def to_dict(self) -> Dict:
            """Convert reference to dictionary format."""
            return {
                "source_shard": self.source_shard,
                "target_shard": self.target_shard,
                "transaction_id": self.transaction_id,
                "created_at": self.created_at.isoformat(),
                "status": self.status,
                "validation_time": self.validation_time.isoformat() if self.validation_time else None
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> 'CrossShardRef':
            """Create reference from dictionary."""
            data = data.copy()
            data['created_at'] = datetime.fromisoformat(data['created_at'])
            if data.get('validation_time'):
                data['validation_time'] = datetime.fromisoformat(data['validation_time'])
            return cls(**data)
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/core/shard/base.py
# Size: 12484 bytes
# Last Modified: Sat Oct 26 14:05:45 2024
# Language: py
# ============================================================

```py
    # blockchain/core/shard/base.py
    
    from typing import Dict, List, Optional, Set, Any, Union
    import logging
    from datetime import datetime
    from copy import deepcopy
    from .shard_types import ShardConfig, ShardMetrics
    from .transaction_manager import TransactionManager
    from .state_manager import StateManager
    from .validation_manager import ValidationManager
    from .cross_shard_manager import CrossShardManager
    from ..block import Block
    from ..transaction import Transaction
    
    logger = logging.getLogger(__name__)
    
    class Shard:
        """
        Main shard class that coordinates all shard components.
        
        This class serves as the primary interface for shard operations,
        delegating specific functionalities to specialized managers while
        maintaining backward compatibility with existing interfaces.
        """
    
        # Maintain class-level defaults for backward compatibility
        DEFAULT_MAX_TRANSACTIONS = 100
    
        def __init__(self, shard_id: int, config: Optional[ShardConfig] = None, **kwargs):
            """
            Initialize a new shard.
            
            Args:
                shard_id: Unique identifier for this shard
                config: Optional configuration, uses defaults if not provided
                **kwargs: Legacy support for direct parameter passing
                         (e.g., max_transactions_per_block)
            """
            if not isinstance(shard_id, int) or shard_id < 0:
                raise ValueError("Invalid shard_id. Must be non-negative integer.")
    
            # Handle legacy initialization
            if config is None:
                config = ShardConfig()
                if 'max_transactions_per_block' in kwargs:
                    config.max_transactions_per_block = kwargs['max_transactions_per_block']
                if 'max_pending_transactions' in kwargs:
                    config.max_pending_transactions = kwargs['max_pending_transactions']
    
            self.shard_id = shard_id
            self.config = config
            
            # Initialize managers
            try:
                self.transaction_manager = TransactionManager(shard_id, self.config)
                self.state_manager = StateManager(shard_id, self.config)
                self.validation_manager = ValidationManager(shard_id, self.config)
                self.cross_shard_manager = CrossShardManager(shard_id, self.config)
            except Exception as e:
                logger.error(f"Failed to initialize shard managers: {str(e)}")
                raise
            
            # Core properties
            self.chain: List[Block] = []
            self.height = 0
            self.known_validators: Set[str] = set()
            
            # Initialize genesis block and state
            self._create_genesis_block()
            self._initialize_state()
    
        def _initialize_state(self) -> None:
            """Initialize the shard's state with required structure."""
            try:
                self.state_manager.state.update({
                    "metadata": {
                        "shard_id": self.shard_id,
                        "created_at": datetime.now().isoformat(),
                        "last_updated": datetime.now().isoformat(),
                        "total_transactions": 0,
                        "total_volume": 0.0,
                        "version": "1.0"
                    }
                })
                
                # Ensure balances are initialized
                if "balances" not in self.state_manager.state:
                    self.state_manager.state["balances"] = {
                        f"user{i}": 1000.0 for i in range(10)
                    }
            except Exception as e:
                logger.error(f"Failed to initialize state: {str(e)}")
                raise
    
        def _create_genesis_block(self) -> None:
            """Create and add the genesis block."""
            try:
                genesis_block = Block(
                    index=0,
                    previous_hash="0" * 64,
                    timestamp=datetime.now(),
                    transactions=[],
                    validator="genesis",
                    shard_id=self.shard_id
                )
                
                self.chain.append(genesis_block)
                self.height = 1
                self.known_validators.add("genesis")
            except Exception as e:
                logger.error(f"Failed to create genesis block: {str(e)}")
                raise
    
        @property
        def max_transactions_per_block(self) -> int:
            """Property accessor for backward compatibility."""
            return self.config.max_transactions_per_block
    
        @classmethod
        def get_max_transactions_per_block(cls) -> int:
            """Class method accessor for backward compatibility."""
            return cls.DEFAULT_MAX_TRANSACTIONS
    
        @property
        def cross_shard_references(self) -> Dict[int, List[str]]:
            """Property accessor for cross shard references."""
            return self.cross_shard_manager.cross_shard_refs
    
        @property
        def average_block_time(self) -> float:
            """Calculate average time between blocks."""
            if len(self.chain) < 2:
                return 0.0
            
            total_time = sum(
                (self.chain[i].timestamp - self.chain[i-1].timestamp).total_seconds()
                for i in range(1, len(self.chain))
            )
            return total_time / (len(self.chain) - 1)
    
        @property
        def pending_transactions(self) -> List[Transaction]:
            """Property accessor for backward compatibility."""
            return self.transaction_manager.pending_transactions
    
        @property
        def state(self) -> Dict:
            """Property accessor for backward compatibility."""
            return self.state_manager.state
    
        def add_transaction(self, transaction: Transaction) -> bool:
            """Add a new transaction to the shard."""
            if not isinstance(transaction, Transaction):
                logger.error("Invalid transaction type")
                return False
    
            try:
                # Validate transaction
                if not self.validation_manager.validate_transaction(transaction):
                    logger.error(f"Transaction {transaction.transaction_id} failed validation")
                    return False
    
                # Add to transaction pool
                if not self.transaction_manager.add_transaction(transaction):
                    return False
    
                # Process any cross-shard aspects
                if transaction.cross_shard_refs or 'target_shard' in transaction.data:
                    self.cross_shard_manager.process_transaction(transaction)
    
                return True
    
            except Exception as e:
                logger.error(f"Failed to add transaction: {str(e)}")
                return False
    
        def create_block(self, validator: str) -> Optional[Block]:
            """Create a new block from pending transactions."""
            if not validator:
                logger.error("Invalid validator ID")
                return None
    
            try:
                transactions = self.transaction_manager.select_transactions_for_block()
                if not transactions:
                    return None
    
                block = Block(
                    index=self.height,
                    previous_hash=self.chain[-1].hash if self.chain else "0" * 64,
                    timestamp=datetime.now(),
                    transactions=transactions,
                    validator=validator,
                    shard_id=self.shard_id
                )
    
                # Add cross-shard references
                cross_shard_refs = self.cross_shard_manager.get_pending_validations()
                if cross_shard_refs:
                    block.cross_shard_refs.extend(ref.transaction_id for ref in cross_shard_refs)
    
                return block
    
            except Exception as e:
                logger.error(f"Failed to create block: {str(e)}")
                return None
    
        def add_block(self, block: Block) -> bool:
            """Add a validated block to the chain."""
            if not isinstance(block, Block):
                logger.error("Invalid block type")
                return False
    
            try:
                # Validate block
                if not self.validation_manager.validate_block(block, self.chain[-1] if self.chain else None):
                    logger.error("Block validation failed")
                    return False
    
                # Update state
                if not self.state_manager.update_state(block):
                    logger.error("State update failed")
                    return False
    
                # Add block to chain
                self.chain.append(block)
                self.height += 1
                self.known_validators.add(block.validator)
    
                # Update cross-shard references
                if block.cross_shard_refs:
                    for ref_id in block.cross_shard_refs:
                        self.cross_shard_manager.validate_reference(ref_id)
    
                # Remove processed transactions
                tx_ids = {tx.transaction_id for tx in block.transactions}
                self.transaction_manager.remove_transactions(tx_ids)
    
                return True
    
            except Exception as e:
                logger.error(f"Failed to add block: {str(e)}")
                return False
    
        def validate_chain(self) -> bool:
            """Validate the entire chain."""
            try:
                if not self.chain:
                    return True
    
                for i in range(1, len(self.chain)):
                    if not self.validation_manager.validate_block(self.chain[i], self.chain[i-1]):
                        return False
                return True
    
            except Exception as e:
                logger.error(f"Chain validation failed: {str(e)}")
                return False
    
        def get_metrics(self) -> Dict[str, Any]:
            """Get comprehensive shard metrics."""
            try:
                # Core metrics
                metrics = {
                    "shard_id": self.shard_id,
                    "height": self.height,
                    "chain_size": len(self.chain),
                    "known_validators": len(self.known_validators),
                    "last_block_time": self.chain[-1].timestamp.isoformat() if self.chain else None,
                    "average_block_time": self.average_block_time
                }
                
                # Add metrics from each manager
                metrics.update(self.state_manager.get_metrics())
                metrics.update(self.transaction_manager.get_metrics())
                metrics.update(self.cross_shard_manager.get_metrics())
                
                return metrics
    
            except Exception as e:
                logger.error(f"Failed to get metrics: {str(e)}")
                return {"error": str(e)}
    
        def to_dict(self) -> Dict[str, Any]:
            """Convert shard state to dictionary format."""
            try:
                return {
                    "shard_id": self.shard_id,
                    "height": self.height,
                    "chain": [block.to_dict() for block in self.chain],
                    "config": self.config.to_dict(),
                    "known_validators": list(self.known_validators),
                    "transaction_manager": self.transaction_manager.to_dict(),
                    "state_manager": self.state_manager.to_dict(),
                    "cross_shard_manager": self.cross_shard_manager.to_dict(),
                    "version": "1.0"
                }
            except Exception as e:
                logger.error(f"Failed to convert shard to dictionary: {str(e)}")
                raise
    
        @classmethod
        def from_dict(cls, data: Dict[str, Any]) -> 'Shard':
            """Create shard from dictionary data."""
            try:
                # Create instance with config
                config = ShardConfig.from_dict(data["config"])
                shard = cls(data["shard_id"], config)
                
                # Restore chain
                shard.chain = [Block.from_dict(block) for block in data["chain"]]
                shard.height = data["height"]
                shard.known_validators = set(data["known_validators"])
                
                # Restore managers
                shard.transaction_manager = TransactionManager.from_dict(
                    data["transaction_manager"],
                    shard.shard_id,
                    config
                )
                shard.state_manager = StateManager.from_dict(
                    data["state_manager"],
                    shard.shard_id,
                    config
                )
                shard.cross_shard_manager = CrossShardManager.from_dict(
                    data["cross_shard_manager"],
                    shard.shard_id,
                    config
                )
                
                return shard
                
            except Exception as e:
                logger.error(f"Failed to create shard from dictionary: {str(e)}")
                raise
    
        def __str__(self) -> str:
            """String representation."""
            return f"Shard(id={self.shard_id}, height={self.height}, validators={len(self.known_validators)})"
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/core/shard/cross_shard_manager.py
# Size: 7344 bytes
# Last Modified: Fri Oct 25 18:24:30 2024
# Language: py
# ============================================================

```py
    # blockchain/core/shard/cross_shard_manager.py
    
    from typing import Dict, List, Optional, Set
    import logging
    from datetime import datetime, timedelta
    from .shard_types import ShardConfig, ShardMetrics, CrossShardRef
    from ..block import Block
    from ..transaction import Transaction
    
    logger = logging.getLogger(__name__)
    
    class CrossShardManager:
        """Manages cross-shard operations and references."""
        
        def __init__(self, shard_id: int, config: ShardConfig):
            self.shard_id = shard_id
            self.config = config
            self.cross_shard_refs: Dict[int, List[CrossShardRef]] = {}  # target_shard -> refs
            self.pending_validations: Dict[str, CrossShardRef] = {}  # tx_id -> ref
            self.validated_refs: Set[str] = set()  # Set of validated tx_ids
            self.metrics = ShardMetrics()
            self.last_cleanup = datetime.now()
    
        def process_transaction(self, transaction: Transaction) -> Optional[CrossShardRef]:
            """Process a transaction for cross-shard operations."""
            try:
                # Check if this is a cross-shard transaction
                target_shard = transaction.data.get('target_shard')
                if not target_shard or target_shard == self.shard_id:
                    return None
    
                # Create cross-shard reference
                ref = CrossShardRef(
                    source_shard=self.shard_id,
                    target_shard=target_shard,
                    transaction_id=transaction.transaction_id
                )
    
                # Add to references
                if target_shard not in self.cross_shard_refs:
                    self.cross_shard_refs[target_shard] = []
                self.cross_shard_refs[target_shard].append(ref)
                
                # Add to pending validations
                self.pending_validations[transaction.transaction_id] = ref
                
                # Update metrics
                self.metrics.cross_shard_operations += 1
                
                return ref
    
            except Exception as e:
                logger.error(f"Failed to process cross-shard transaction: {str(e)}")
                return None
    
        def update_references(self, block: Block) -> None:
            """Update cross-shard references based on a new block."""
            try:
                for tx in block.transactions:
                    # Process new cross-shard references
                    if 'target_shard' in tx.data:
                        self.process_transaction(tx)
                    
                    # Check for validation confirmations
                    if 'validate_ref' in tx.data:
                        self._handle_validation_confirmation(tx)
    
            except Exception as e:
                logger.error(f"Failed to update cross-shard references: {str(e)}")
    
        def validate_reference(self, ref_id: str) -> bool:
            """Validate a cross-shard reference."""
            try:
                if ref_id not in self.pending_validations:
                    return False
    
                ref = self.pending_validations[ref_id]
                ref.status = "validated"
                ref.validation_time = datetime.now()
                
                # Move to validated set
                self.validated_refs.add(ref_id)
                del self.pending_validations[ref_id]
                
                return True
    
            except Exception as e:
                logger.error(f"Failed to validate reference: {str(e)}")
                return False
    
        def get_pending_validations(self, target_shard: Optional[int] = None) -> List[CrossShardRef]:
            """Get pending validations, optionally filtered by target shard."""
            try:
                if target_shard is not None:
                    return [
                        ref for ref in self.pending_validations.values()
                        if ref.target_shard == target_shard
                    ]
                return list(self.pending_validations.values())
    
            except Exception as e:
                logger.error(f"Failed to get pending validations: {str(e)}")
                return []
    
        def cleanup_expired_references(self) -> None:
            """Clean up expired cross-shard references."""
            try:
                current_time = datetime.now()
                
                # Only clean up periodically
                if (current_time - self.last_cleanup).total_seconds() < 60:
                    return
    
                timeout = timedelta(seconds=self.config.cross_shard_timeout)
                expired_refs = []
    
                # Find expired references
                for tx_id, ref in self.pending_validations.items():
                    if current_time - ref.created_at > timeout:
                        ref.status = "expired"
                        expired_refs.append(tx_id)
    
                # Remove expired references
                for tx_id in expired_refs:
                    del self.pending_validations[tx_id]
    
                # Update cleanup timestamp
                self.last_cleanup = current_time
    
            except Exception as e:
                logger.error(f"Failed to cleanup expired references: {str(e)}")
    
        def _handle_validation_confirmation(self, transaction: Transaction) -> None:
            """Process a validation confirmation transaction."""
            try:
                ref_id = transaction.data.get('validate_ref')
                if not ref_id:
                    return
    
                if ref_id in self.pending_validations:
                    self.validate_reference(ref_id)
    
            except Exception as e:
                logger.error(f"Failed to handle validation confirmation: {str(e)}")
    
        def get_metrics(self) -> Dict:
            """Get cross-shard operation metrics."""
            return {
                'pending_validations': len(self.pending_validations),
                'validated_refs': len(self.validated_refs),
                'cross_shard_operations': self.metrics.cross_shard_operations,
                'refs_by_shard': {
                    shard_id: len(refs)
                    for shard_id, refs in self.cross_shard_refs.items()
                }
            }
    
        def to_dict(self) -> Dict:
            """Convert manager state to dictionary format."""
            return {
                'cross_shard_refs': {
                    shard_id: [ref.to_dict() for ref in refs]
                    for shard_id, refs in self.cross_shard_refs.items()
                },
                'pending_validations': {
                    tx_id: ref.to_dict()
                    for tx_id, ref in self.pending_validations.items()
                },
                'validated_refs': list(self.validated_refs),
                'metrics': self.metrics.to_dict()
            }
    
        @classmethod
        def from_dict(cls, data: Dict, shard_id: int, config: ShardConfig) -> 'CrossShardManager':
            """Create manager from dictionary data."""
            manager = cls(shard_id, config)
            
            # Restore cross-shard references
            for shard_id_str, refs_data in data['cross_shard_refs'].items():
                shard_id = int(shard_id_str)
                manager.cross_shard_refs[shard_id] = [
                    CrossShardRef.from_dict(ref_data)
                    for ref_data in refs_data
                ]
            
            # Restore pending validations
            manager.pending_validations = {
                tx_id: CrossShardRef.from_dict(ref_data)
                for tx_id, ref_data in data['pending_validations'].items()
            }
            
            # Restore validated refs and metrics
            manager.validated_refs = set(data['validated_refs'])
            manager.metrics = ShardMetrics.from_dict(data['metrics'])
            
            return manager
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/core/shard/__init__.py
# Size: 503 bytes
# Last Modified: Fri Oct 25 23:14:47 2024
# Language: py
# ============================================================

```py
    # blockchain/core/shard/__init__.py
    
    from .base import Shard
    from .shard_types import ShardConfig, ShardMetrics, CrossShardRef
    from .transaction_manager import TransactionManager
    from .state_manager import StateManager
    from .validation_manager import ValidationManager
    from .cross_shard_manager import CrossShardManager
    
    __all__ = [
        "Shard",
        "ShardConfig",
        "ShardMetrics", 
        "CrossShardRef",
        "TransactionManager",
        "StateManager",
        "ValidationManager",
        "CrossShardManager"
    ]
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/contracts/contract_executor.py
# Size: 11587 bytes
# Last Modified: Thu Oct 24 21:40:01 2024
# Language: py
# ============================================================

```py
    """
    blockchain/contracts/contract_executor.py
    
    This module implements the ContractExecutor for the ICN blockchain, providing
    secure contract deployment, execution, and lifecycle management. It enforces
    resource limits, security constraints, and cooperative principles.
    
    Key features:
    - Secure sandbox execution environment
    - Resource management via mana system
    - Dependency resolution and validation
    - Cross-contract communication
    - State integrity protection
    - Concurrent execution handling
    """
    
    from typing import Dict, List, Optional, Set
    import logging
    from datetime import datetime
    import asyncio
    import re
    from .smart_contract import SmartContract, ContractExecutionError
    
    logger = logging.getLogger(__name__)
    
    class ContractExecutor:
        """Manages smart contract deployment, execution, and lifecycle.
    
        The ContractExecutor ensures secure and fair contract operations within
        the ICN ecosystem. It handles:
        - Contract deployment and validation
        - Secure execution environment
        - Resource management (mana)
        - Dependency resolution
        - State management
        - Concurrent execution
        """
    
        # Safe imports that contracts are allowed to use
        SAFE_IMPORTS = {
            'math', 'datetime', 'json', 'collections',
            'typing', 'dataclasses', 'enum', 'decimal'
        }
    
        # Regular expressions for code validation
        CODE_PATTERNS = {
            'import': re.compile(r'^import\s+(\w+)'),
            'from_import': re.compile(r'^from\s+(\w+)\s+import'),
            'execute_func': re.compile(r'def\s+execute\s*\([^)]*\):')
        }
    
        def __init__(self, initial_mana: int = 1000, mana_regen_rate: int = 10):
            """Initialize the ContractExecutor.
    
            Args:
                initial_mana: Starting mana pool for contract execution
                mana_regen_rate: Rate at which mana regenerates per cycle
            """
            # Contract management
            self.contracts: Dict[str, SmartContract] = {}
            self.dependency_graph: Dict[str, Set[str]] = {}
            
            # Resource management
            self.mana_pool = initial_mana
            self.mana_regen_rate = mana_regen_rate
            self.max_mana = initial_mana * 2
            
            # Execution management
            self.execution_queue: List[Dict] = []
            self.max_queue_size = 1000
            self.execution_lock = asyncio.Lock()
            
            # Performance tracking
            self.metrics = {
                "total_executions": 0,
                "failed_executions": 0,
                "total_mana_consumed": 0,
                "average_execution_time": 0.0,
                "contracts_deployed": 0,
                "successful_deployments": 0,
                "failed_deployments": 0
            }
    
        async def deploy_contract(self, contract: SmartContract) -> bool:
            """Deploy a new smart contract.
    
            Args:
                contract: SmartContract instance to deploy
    
            Returns:
                bool: True if deployment successful, False otherwise
            
            The deployment process includes:
            1. Code validation
            2. Dependency checking
            3. Security verification
            4. Resource allocation
            """
            try:
                # Check for existing contract
                if contract.contract_id in self.contracts:
                    logger.error(f"Contract {contract.contract_id} already exists")
                    return False
    
                # Validate contract code
                if not await self._validate_contract_code(contract.code):
                    return False
    
                # Check dependencies
                if not await self._validate_dependencies(contract.dependencies):
                    return False
    
                # Store contract and update graph
                self.contracts[contract.contract_id] = contract
                self.dependency_graph[contract.contract_id] = contract.dependencies.copy()
                
                # Update metrics
                self.metrics["contracts_deployed"] += 1
                self.metrics["successful_deployments"] += 1
                
                logger.info(f"Successfully deployed contract {contract.contract_id}")
                return True
    
            except Exception as e:
                logger.error(f"Contract deployment failed: {str(e)}")
                self.metrics["failed_deployments"] += 1
                return False
    
        async def _validate_contract_code(self, code: str) -> bool:
            """Validate contract code safety and structure.
    
            Args:
                code: Contract source code to validate
    
            Returns:
                bool: True if code is safe and valid
            """
            try:
                # Check for execute function
                if not self.CODE_PATTERNS['execute_func'].search(code):
                    logger.error("Contract missing execute function")
                    return False
    
                # Validate imports
                for line in code.split('\n'):
                    line = line.strip()
                    if not line or line.startswith('#'):
                        continue
    
                    # Check import statements
                    import_match = self.CODE_PATTERNS['import'].match(line)
                    from_match = self.CODE_PATTERNS['from_import'].match(line)
    
                    if import_match:
                        module = import_match.group(1)
                        if module not in self.SAFE_IMPORTS:
                            logger.error(f"Unsafe import detected: {module}")
                            return False
                    elif from_match:
                        module = from_match.group(1)
                        if module not in self.SAFE_IMPORTS:
                            logger.error(f"Unsafe import detected: {module}")
                            return False
    
                # Test compilation
                compile(code, '<string>', 'exec')
                return True
    
            except Exception as e:
                logger.error(f"Code validation failed: {str(e)}")
                return False
    
        async def execute_contract(
            self, contract_id: str, input_data: Dict, caller: str
        ) -> Dict:
            """Execute a smart contract.
    
            Args:
                contract_id: ID of contract to execute
                input_data: Input parameters for contract
                caller: ID of calling entity
    
            Returns:
                Dict containing execution results
    
            Raises:
                ContractExecutionError: If execution fails
            """
            async with self.execution_lock:
                try:
                    # Get and validate contract
                    contract = self.contracts.get(contract_id)
                    if not contract:
                        raise ContractExecutionError(f"Contract {contract_id} not found")
    
                    # Check authorization
                    if caller not in contract.allowed_callers:
                        raise ContractExecutionError(f"Caller {caller} not authorized")
    
                    # Check mana
                    if self.mana_pool < contract.mana_cost:
                        raise ContractExecutionError("Insufficient mana")
    
                    # Execute contract
                    execution_start = datetime.now()
                    result = contract.execute(input_data, self.mana_pool)
    
                    # Update resources
                    mana_used = result["mana_used"]
                    self.mana_pool = max(0, self.mana_pool - mana_used)
                    self.metrics["total_mana_consumed"] += mana_used
    
                    # Update metrics
                    execution_time = (datetime.now() - execution_start).total_seconds()
                    await self._update_metrics(execution_time, True)
    
                    return result
    
                except Exception as e:
                    await self._update_metrics(0, False)
                    raise ContractExecutionError(str(e))
    
        async def _validate_dependencies(self, dependencies: Set[str]) -> bool:
            """Validate contract dependencies.
    
            Args:
                dependencies: Set of contract IDs this contract depends on
    
            Returns:
                bool: True if dependencies are valid
            """
            try:
                # Check existence
                for dep in dependencies:
                    if dep not in self.contracts:
                        logger.error(f"Dependency not found: {dep}")
                        return False
    
                # Check for cycles
                visited: Set[str] = set()
                path: List[str] = []
    
                async def check_cycle(contract_id: str) -> bool:
                    if contract_id in path:
                        cycle = ' -> '.join(path + [contract_id])
                        logger.error(f"Circular dependency detected: {cycle}")
                        return False
    
                    if contract_id in visited:
                        return True
    
                    visited.add(contract_id)
                    path.append(contract_id)
    
                    for dep in self.dependency_graph.get(contract_id, set()):
                        if not await check_cycle(dep):
                            return False
    
                    path.pop()
                    return True
    
                # Check each dependency
                for dep in dependencies:
                    if not await check_cycle(dep):
                        return False
    
                return True
    
            except Exception as e:
                logger.error(f"Dependency validation failed: {str(e)}")
                return False
    
        async def _update_metrics(self, execution_time: float, success: bool) -> None:
            """Update executor metrics.
    
            Args:
                execution_time: Time taken for execution
                success: Whether execution was successful
            """
            try:
                self.metrics["total_executions"] += 1
                if not success:
                    self.metrics["failed_executions"] += 1
    
                # Update average execution time
                total = self.metrics["average_execution_time"] * (self.metrics["total_executions"] - 1)
                self.metrics["average_execution_time"] = (total + execution_time) / self.metrics["total_executions"]
    
            except Exception as e:
                logger.error(f"Failed to update metrics: {str(e)}")
    
        async def regenerate_mana(self) -> None:
            """Regenerate mana pool resources."""
            try:
                old_mana = self.mana_pool
                self.mana_pool = min(self.max_mana, self.mana_pool + self.mana_regen_rate)
                
                if self.mana_pool > old_mana:
                    logger.debug(f"Regenerated mana: {self.mana_pool - old_mana}")
    
            except Exception as e:
                logger.error(f"Mana regeneration failed: {str(e)}")
    
        def get_metrics(self) -> Dict:
            """Get executor metrics and statistics."""
            return {
                **self.metrics,
                "current_mana": self.mana_pool,
                "queue_length": len(self.execution_queue),
                "active_contracts": len(self.contracts)
            }
    
        async def queue_execution(self, contract_id: str, input_data: Dict, caller: str) -> bool:
            """Queue a contract execution request.
    
            Args:
                contract_id: ID of contract to execute
                input_data: Input parameters
                caller: ID of calling entity
    
            Returns:
                bool: True if successfully queued
            """
            try:
                if len(self.execution_queue) >= self.max_queue_size:
                    logger.error("Execution queue full")
                    return False
    
                self.execution_queue.append({
                    "contract_id": contract_id,
                    "input_data": input_data,
                    "caller": caller,
                    "timestamp": datetime.now()
                })
                return True
    
            except Exception as e:
                logger.error(f"Failed to queue execution: {str(e)}")
                return False
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/contracts/smart_contract.py
# Size: 14617 bytes
# Last Modified: Thu Oct 24 21:10:31 2024
# Language: py
# ============================================================

```py
    """
    blockchain/contracts/smart_contract.py
    
    This module implements the SmartContract class for the ICN blockchain, providing
    a secure, sandboxed environment for executing decentralized code. The implementation
    follows cooperative principles and ensures fair resource usage.
    
    Key features:
    - Secure execution environment with restricted capabilities
    - Resource management through mana system
    - State persistence and size limitations
    - Execution history and metrics tracking
    - Caller authorization management
    - Cross-contract dependencies
    - Daily execution limits and cooldowns
    """
    
    from __future__ import annotations
    from datetime import datetime, timedelta
    from typing import Dict, List, Set, Optional, Any, Union
    import time
    import logging
    import hashlib
    import json
    import sys
    from io import StringIO
    from copy import deepcopy
    
    logger = logging.getLogger(__name__)
    
    class ContractExecutionError(Exception):
        """Exception raised for contract execution failures.
        
        This includes:
        - Code execution errors
        - Resource limit violations
        - State size exceeded
        - Authorization failures
        - Timeout errors
        """
        pass
    
    class SmartContract:
        """Smart contract implementation for the ICN blockchain.
        
        Smart contracts are self-executing code units that run in a secure sandbox.
        They maintain state, track execution metrics, and enforce resource limits
        to ensure fair usage of network resources.
        
        Attributes:
            contract_id (str): Unique identifier for the contract
            code (str): Python source code of the contract
            creator (str): Identity of contract creator
            state (Dict): Contract's persistent state storage
            mana_cost (int): Mana required per execution
            version (str): Contract version identifier
            
        Resource Limits:
            - Maximum state size (default: 1MB)
            - Maximum execution time (default: 5s)
            - Maximum mana per execution (default: 100)
            - Maximum daily executions (default: 1000)
        """
    
        # Safe built-ins allowed in contract execution
        SAFE_BUILTINS = {
            "abs": abs,
            "bool": bool,
            "dict": dict,
            "float": float,
            "int": int,
            "len": len,
            "list": list,
            "max": max,
            "min": min,
            "round": round,
            "sorted": sorted,
            "str": str,
            "sum": sum,
        }
    
        def __init__(
            self,
            contract_id: str,
            code: str,
            creator: str,
            mana_cost: int = 10,
            version: str = "1.0",
        ) -> None:
            """Initialize a new smart contract.
            
            Args:
                contract_id: Unique identifier for the contract
                code: Contract source code in Python
                creator: Identity of the contract creator
                mana_cost: Mana cost per execution
                version: Version string for the contract
                
            The constructor initializes execution tracking, state storage,
            and resource limits while setting up the secure execution environment.
            """
            # Basic contract information
            self.contract_id = contract_id
            self.code = code
            self.creator = creator
            self.state: Dict = {}
            self.mana_cost = mana_cost
            self.version = version
            
            # Execution tracking
            self.created_at = datetime.now()
            self.last_executed: Optional[datetime] = None
            self.execution_count = 0
            self.total_mana_consumed = 0
            self.execution_history: List[Dict] = []
            
            # Previous state for rollback
            self._previous_state: Optional[Dict] = None
            
            # Metadata and capabilities
            self.metadata: Dict = {
                "created_at": self.created_at,
                "version": version,
                "creator": creator,
                "description": "",
                "tags": set(),
                "last_updated": self.created_at
            }
            
            # Dependencies and authorization
            self.dependencies: Set[str] = set()
            self.allowed_callers: Set[str] = {creator}
            
            # Resource restrictions
            self.restrictions: Dict = {
                "max_state_size": 1024 * 1024,  # 1MB
                "max_execution_time": 5,         # seconds
                "max_mana_per_execution": 100,   # mana
                "max_daily_executions": 1000,    # executions
            }
            
            # Daily execution tracking
            self.daily_executions = 0
            self.last_reset = datetime.now()
    
        def execute(self, input_data: Dict, available_mana: int) -> Dict:
            """Execute the smart contract with given input data.
            
            Args:
                input_data: Dictionary of input parameters for the contract
                available_mana: Amount of mana available for execution
                
            Returns:
                Dictionary containing:
                - execution result
                - updated state
                - mana consumed
                - execution time
                - output captured
                
            Raises:
                ContractExecutionError: If execution fails or violates restrictions
            """
            self._reset_daily_executions()
            self._backup_state()
            
            try:
                # Validate execution conditions
                validation_result = self._validate_execution(input_data, available_mana)
                if validation_result.get("error"):
                    raise ContractExecutionError(validation_result["error"])
    
                execution_start = time.time()
                stdout_capture = StringIO()
                original_stdout = sys.stdout
                sys.stdout = stdout_capture
    
                try:
                    # Set up and execute
                    local_namespace = self._setup_execution_environment(input_data)
                    exec(self.code, {}, local_namespace)
    
                    if "execute" not in local_namespace:
                        raise ContractExecutionError("Contract missing execute function")
    
                    # Execute with timing check
                    if time.time() - execution_start > self.restrictions["max_execution_time"]:
                        raise ContractExecutionError("Execution time limit exceeded")
    
                    result = local_namespace["execute"](input_data, self.state)
    
                    # Validate post-execution state
                    if len(str(self.state)) > self.restrictions["max_state_size"]:
                        self._rollback_state()
                        raise ContractExecutionError("State size limit exceeded after execution")
    
                    # Update metrics and return result
                    self._update_execution_metrics(execution_start)
                    output = stdout_capture.getvalue()
    
                    return {
                        "state": self.state,
                        "result": result,
                        "mana_used": self.mana_cost,
                        "execution_time": time.time() - execution_start,
                        "output": output,
                    }
    
                finally:
                    sys.stdout = original_stdout
    
            except ContractExecutionError:
                self._rollback_state()
                raise
            except Exception as e:
                self._rollback_state()
                logger.error(f"Contract execution failed: {str(e)}")
                raise ContractExecutionError(str(e))
    
        def _validate_execution(self, input_data: Dict, available_mana: int) -> Dict:
            """Validate all conditions required for contract execution.
            
            Performs comprehensive validation including:
            - Daily execution limits
            - Mana availability
            - Current and projected state size
            - Input data format
            """
            try:
                if self.daily_executions >= self.restrictions["max_daily_executions"]:
                    return {"error": "Daily execution limit exceeded"}
    
                if available_mana < self.mana_cost:
                    return {"error": "Insufficient mana"}
    
                # Calculate potential state size
                current_state_size = len(str(self.state))
                potential_growth = len(str(input_data)) * 2  # Conservative estimate
                if current_state_size + potential_growth > self.restrictions["max_state_size"]:
                    return {"error": "Projected state size would exceed limit"}
    
                if not isinstance(input_data, dict):
                    return {"error": "Invalid input data format"}
    
                return {}
    
            except Exception as e:
                return {"error": f"Validation failed: {str(e)}"}
    
        def _backup_state(self) -> None:
            """Create a backup of the current state for potential rollback."""
            self._previous_state = deepcopy(self.state)
    
        def _rollback_state(self) -> None:
            """Rollback to the previous state if available."""
            if self._previous_state is not None:
                self.state = self._previous_state
                self._previous_state = None
    
        def _setup_execution_environment(self, input_data: Dict) -> Dict:
            """Create a secure execution environment for the contract.
            
            Sets up a restricted namespace with only safe operations allowed.
            Provides access to contract state and metadata while preventing
            access to system resources.
            """
            return {
                "input": input_data,
                "state": self.state,
                "contract_id": self.contract_id,
                "creator": self.creator,
                "version": self.version,
                "metadata": self.metadata.copy(),
                "__builtins__": self.SAFE_BUILTINS,
            }
    
        def _update_execution_metrics(self, execution_start: float) -> None:
            """Update all execution metrics after successful execution.
            
            Updates:
            - Execution count and history
            - Mana consumption
            - Timing information
            - State size tracking
            """
            self.last_executed = datetime.now()
            self.execution_count += 1
            self.daily_executions += 1
            self.total_mana_consumed += self.mana_cost
    
            execution_record = {
                "timestamp": self.last_executed,
                "execution_time": time.time() - execution_start,
                "mana_used": self.mana_cost,
                "state_size": len(str(self.state)),
            }
    
            self.execution_history.append(execution_record)
            if len(self.execution_history) > 1000:
                self.execution_history = self.execution_history[-1000:]
    
        def _reset_daily_executions(self) -> None:
            """Reset daily execution counter if a day has passed."""
            current_time = datetime.now()
            if (current_time - self.last_reset).days >= 1:
                self.daily_executions = 0
                self.last_reset = current_time
    
        def authorize_caller(self, caller_id: str) -> bool:
            """Add a new authorized caller for the contract."""
            self.allowed_callers.add(caller_id)
            return True
    
        def revoke_caller(self, caller_id: str) -> bool:
            """Revoke a caller's authorization (except creator)."""
            if caller_id == self.creator:
                return False
            self.allowed_callers.discard(caller_id)
            return True
    
        def update_restrictions(self, new_restrictions: Dict) -> bool:
            """Update contract restrictions if valid."""
            try:
                if not all(k in self.restrictions for k in new_restrictions):
                    return False
                self.restrictions.update(new_restrictions)
                self.metadata["last_updated"] = datetime.now()
                return True
            except Exception as e:
                logger.error(f"Failed to update restrictions: {str(e)}")
                return False
    
        def get_metrics(self) -> Dict:
            """Get comprehensive contract metrics."""
            return {
                "contract_id": self.contract_id,
                "version": self.version,
                "creator": self.creator,
                "created_at": self.created_at.isoformat(),
                "last_executed": (
                    self.last_executed.isoformat() if self.last_executed else None
                ),
                "execution_count": self.execution_count,
                "daily_executions": self.daily_executions,
                "total_mana_consumed": self.total_mana_consumed,
                "average_mana_per_execution": (
                    self.total_mana_consumed / self.execution_count
                    if self.execution_count > 0
                    else 0
                ),
                "state_size": len(str(self.state)),
                "dependencies": list(self.dependencies),
                "authorized_callers": len(self.allowed_callers),
                "restrictions": self.restrictions,
            }
    
        def to_dict(self) -> Dict:
            """Convert contract to dictionary representation."""
            return {
                "contract_id": self.contract_id,
                "code": self.code,
                "creator": self.creator,
                "state": self.state,
                "mana_cost": self.mana_cost,
                "version": self.version,
                "metadata": {
                    **self.metadata,
                    "created_at": self.metadata["created_at"].isoformat(),
                    "last_updated": self.metadata["last_updated"].isoformat(),
                    "tags": list(self.metadata["tags"]),
                },
                "dependencies": list(self.dependencies),
                "allowed_callers": list(self.allowed_callers),
                "restrictions": self.restrictions,
                "metrics": self.get_metrics(),
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> "SmartContract":
            """Create contract instance from dictionary data."""
            contract = cls(
                contract_id=data["contract_id"],
                code=data["code"],
                creator=data["creator"],
                mana_cost=data["mana_cost"],
                version=data["version"],
            )
    
            contract.state = data["state"]
            contract.metadata = {
                **data["metadata"],
                "created_at": datetime.fromisoformat(data["metadata"]["created_at"]),
                "last_updated": datetime.fromisoformat(data["metadata"]["last_updated"]),
                "tags": set(data["metadata"]["tags"]),
            }
            contract.dependencies = set(data["dependencies"])
            contract.allowed_callers = set(data["allowed_callers"])
            contract.restrictions = data["restrictions"]
    
            return contract
    
        def __str__(self) -> str:
            """Human-readable string representation."""
            return (
                f"Contract(id={self.contract_id}, "
                f"creator={self.creator}, "
                f"executions={self.execution_count}, "
                f"mana_cost={self.mana_cost})"
            )
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/contracts/__init__.py
# Size: 207 bytes
# Last Modified: Thu Oct 24 00:42:04 2024
# Language: py
# ============================================================

```py
    # blockchain/contracts/__init__.py
    """Smart contract components."""
    from .smart_contract import SmartContract
    from .contract_executor import ContractExecutor
    
    __all__ = ["SmartContract", "ContractExecutor"]
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation.py
# Size: 8868 bytes
# Last Modified: Sun Oct 27 00:04:09 2024
# Language: py
# ============================================================

```py
    # ================================================================
    # File: blockchain/consensus/proof_of_cooperation.py
    # Description: Implements the Proof of Cooperation (PoC) consensus
    # mechanism for the ICN blockchain. PoC incentivizes cooperative behavior,
    # resource contribution, and equitable participation.
    # ================================================================
    
    from __future__ import annotations
    from typing import Dict, List, Optional, Tuple, Set, Any
    from datetime import datetime, timedelta
    import math
    import random
    import logging
    
    from ..core.node import Node
    from ..core.block import Block
    from .collusion_detector import CollusionDetector
    from .reputation_manager import ReputationManager
    from .sanctions_manager import SanctionsManager
    
    logger = logging.getLogger(__name__)
    
    class ProofOfCooperation:
        """
        Implements the Proof of Cooperation consensus mechanism for the ICN.
    
        Key Improvements:
        - Modular integration with collusion detection, reputation, and sanctions management.
        - Progressive reputation requirements for new nodes.
        - Dynamic scoring adjustments.
        - Enhanced validator eligibility checks.
        - Improved shard-specific handling.
        """
    
        def __init__(self, reputation_manager: ReputationManager, collusion_detector: CollusionDetector, sanctions_manager: SanctionsManager, min_reputation: float = 10.0, cooldown_blocks: int = 3):
            """
            Initialize the Proof of Cooperation mechanism with external modules.
    
            Args:
                reputation_manager (ReputationManager): Instance for managing reputation.
                collusion_detector (CollusionDetector): Instance for detecting collusion.
                sanctions_manager (SanctionsManager): Instance for managing sanctions.
                min_reputation (float): Minimum reputation required to participate.
                cooldown_blocks (int): Number of blocks for the cooldown period after validation.
            """
            self.reputation_manager = reputation_manager
            self.collusion_detector = collusion_detector
            self.sanctions_manager = sanctions_manager
            self.min_reputation = min_reputation
            self.cooldown_blocks = cooldown_blocks
            
            # Performance tracking
            self.performance_metrics = {
                "average_block_time": 0.0,
                "total_validations": 0,
                "successful_validations": 0,
                "collusion_detections": 0,
                "failed_validations": 0,
                "total_blocks_validated": 0,
                "new_node_participations": 0,
            }
    
        def _can_participate(self, node: Node, shard_id: Optional[int] = None) -> bool:
            """
            Determine if a node can participate in consensus with modular validation checks.
    
            Args:
                node (Node): Node to be checked for participation eligibility.
                shard_id (Optional[int]): Optional shard ID for shard-specific checks.
    
            Returns:
                bool: True if node can participate, False otherwise.
            """
            try:
                if not node.can_validate(shard_id):
                    return False
    
                # Check if the node is under sanctions
                sanction_level, status = self.sanctions_manager.get_sanction_status(node)
                if status == "permanently_excluded":
                    return False
    
                # Reputation checks
                reputation_requirement = self.min_reputation
                if not self.reputation_manager.can_validate(node, shard_id):
                    return False
    
                # Shard-specific checks
                if shard_id is not None and shard_id not in node.active_shards:
                    return False
    
                return True
    
            except Exception as e:
                logger.error(f"Error in participation check: {e}")
                return False
    
        def calculate_cooperation_score(self, node: Node, shard_id: Optional[int] = None) -> float:
            """
            Calculate node's cooperation score using reputation manager and collusion detection.
    
            Args:
                node (Node): Node whose cooperation score is being calculated.
                shard_id (Optional[int]): Optional shard ID for shard-specific adjustments.
    
            Returns:
                float: Calculated cooperation score.
            """
            try:
                return self.reputation_manager.calculate_cooperation_score(node, shard_id)
    
            except Exception as e:
                logger.error(f"Error calculating cooperation score: {e}")
                return 0.0
    
        def select_validator(self, nodes: List[Node], shard_id: Optional[int] = None) -> Optional[Node]:
            """
            Select validator using modular checks for eligibility and cooperation score.
    
            Args:
                nodes (List[Node]): List of potential validator nodes.
                shard_id (Optional[int]): Optional shard ID for selection.
    
            Returns:
                Optional[Node]: Selected validator node, if any.
            """
            try:
                eligible_nodes = [node for node in nodes if self._can_participate(node, shard_id)]
                if not eligible_nodes:
                    return None
    
                # Calculate cooperation scores
                scores = [self.calculate_cooperation_score(node, shard_id) for node in eligible_nodes]
                total_score = sum(scores)
                if total_score <= 0:
                    return None
    
                # Weighted random selection
                selection_point = random.uniform(0, total_score)
                current_sum = 0
                selected = None
    
                for node, score in zip(eligible_nodes, scores):
                    current_sum += score
                    if current_sum >= selection_point:
                        selected = node
                        break
    
                if selected:
                    selected.enter_cooldown(self.cooldown_blocks)
                    logger.info(f"Validator {selected.node_id} selected for shard {shard_id}")
    
                return selected
    
            except Exception as e:
                logger.error(f"Error selecting validator: {e}")
                return None
    
        def validate_block(self, block: Block, previous_block: Optional[Block], validator: Node) -> bool:
            """
            Validate block using reputation, sanctions, and collusion checks.
    
            Args:
                block (Block): The block to be validated.
                previous_block (Optional[Block]): The previous block in the chain.
                validator (Node): The node validating the block.
    
            Returns:
                bool: True if the block is valid, False otherwise.
            """
            try:
                if not self._can_validate_block(validator, block.shard_id):
                    logger.error(f"Validator {validator.node_id} not eligible")
                    return False
    
                if not block.validate(previous_block):
                    logger.error(f"Block {block.index} failed validation")
                    self._update_validation_stats(validator, block, False)
                    return False
    
                if self.collusion_detector.detect_collusion(validator, block):
                    logger.warning(f"Collusion detected in block {block.index} by validator {validator.node_id}")
                    self._update_validation_stats(validator, block, False)
                    self.sanctions_manager.apply_sanction(validator)
                    return False
    
                self._update_validation_stats(validator, block, True)
                logger.info(f"Block {block.index} validated successfully by {validator.node_id}")
                return True
    
            except Exception as e:
                logger.error(f"Error validating block: {e}")
                self._update_validation_stats(validator, block, False)
                return False
    
        def _can_validate_block(self, validator: Node, shard_id: Optional[int]) -> bool:
            """
            Check if validator can validate a block with modular eligibility checks.
    
            Args:
                validator (Node): The node attempting to validate the block.
                shard_id (Optional[int]): Optional shard ID for validation.
    
            Returns:
                bool: True if the validator can validate, False otherwise.
            """
            return self._can_participate(validator, shard_id)
    
        def _update_validation_stats(self, validator: Node, block: Block, success: bool) -> None:
            """
            Update validation statistics for modular tracking.
    
            Args:
                validator (Node): The node that validated the block.
                block (Block): The block that was validated.
                success (bool): Whether the validation was successful.
            """
            self.reputation_manager.update_stats(validator.node_id, ValidationResult(success), block.shard_id)
    
        def get_metrics(self) -> Dict:
            """
            Get comprehensive consensus metrics.
    
            Returns:
                Dict: A dictionary of consensus metrics.
            """
            return self.reputation_manager.to_dict()
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/consensus/__init__.py
# Size: 336 bytes
# Last Modified: Sat Oct 26 23:41:27 2024
# Language: py
# ============================================================

```py
    """
    Consensus mechanism components.
    
    This module serves as the entry point for the various consensus mechanisms 
    implemented within the blockchain's consensus layer, specifically focusing on 
    the Proof of Cooperation (PoC) consensus mechanism.
    """
    
    from .proof_of_cooperation import ProofOfCooperation
    
    __all__ = ["ProofOfCooperation"]
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/metrics_manager.py
# Size: 10069 bytes
# Last Modified: Sat Oct 26 23:37:48 2024
# Language: py
# ============================================================

```py
    """
    metrics_manager.py
    
    This module manages performance metrics and statistics for the Proof of Cooperation (PoC) consensus mechanism.
    It tracks validation success rates, block times, collusion detections, and other performance indicators.
    
    Classes:
        MetricsManager
    """
    
    import logging
    from typing import Dict, Optional, Any
    from datetime import datetime, timedelta
    from .types import ConsensusMetrics, ValidationResult, ValidatorHistory
    
    logger = logging.getLogger(__name__)
    
    class MetricsManager:
        """
        Manages performance metrics and statistics for the consensus mechanism.
        Tracks validation success rates, block times, and other performance indicators.
        """
    
        def __init__(self):
            """Initialize the metrics manager."""
            self.metrics = ConsensusMetrics()
            self.last_metrics_reset = datetime.now()
            self.reset_interval = timedelta(hours=24)
    
        def record_validation(self, result: ValidationResult, validator_id: str, shard_id: Optional[int] = None) -> None:
            """
            Record the result of a validation attempt.
    
            Args:
                result (ValidationResult): The validation result.
                validator_id (str): ID of the validator.
                shard_id (Optional[int]): Optional shard ID where validation occurred.
            """
            try:
                self.metrics.total_validations += 1
    
                if result.success:
                    self.metrics.successful_validations += 1
                else:
                    self.metrics.failed_validations += 1
    
                # Track per-validator metrics
                self.metrics.validator_counts[validator_id] = self.metrics.validator_counts.get(validator_id, 0) + 1
    
                # Track shard-specific metrics if applicable
                if shard_id is not None:
                    self._update_shard_metrics(result, validator_id, shard_id)
    
                # Add any custom metrics from the validation result
                self._update_custom_metrics(result.metrics)
    
            except Exception as e:
                logger.error(f"Failed to record validation metrics: {str(e)}")
    
        def _update_shard_metrics(self, result: ValidationResult, validator_id: str, shard_id: int) -> None:
            """
            Update shard-specific metrics.
    
            Args:
                result (ValidationResult): The validation result.
                validator_id (str): ID of the validator.
                shard_id (int): ID of the shard.
            """
            if shard_id not in self.metrics.shard_metrics:
                self.metrics.shard_metrics[shard_id] = {
                    "validations": 0,
                    "successful": 0,
                    "failed": 0,
                    "unique_validators": set()
                }
    
            shard_metrics = self.metrics.shard_metrics[shard_id]
            shard_metrics["validations"] += 1
    
            if result.success:
                shard_metrics["successful"] += 1
            else:
                shard_metrics["failed"] += 1
    
            shard_metrics["unique_validators"].add(validator_id)
    
        def record_block_time(self, block_time: float) -> None:
            """
            Record the time taken to create a block.
    
            Args:
                block_time (float): Time in seconds to create the block.
            """
            try:
                current_avg = self.metrics.average_block_time
                total_blocks = self.metrics.total_blocks_validated
    
                # Update running average
                self.metrics.average_block_time = (
                    (current_avg * total_blocks + block_time) / (total_blocks + 1)
                )
                self.metrics.total_blocks_validated += 1
    
            except Exception as e:
                logger.error(f"Failed to record block time: {str(e)}")
    
        def record_collusion_detection(self) -> None:
            """Record a collusion detection event."""
            self.metrics.collusion_detections += 1
    
        def record_new_node_participation(self) -> None:
            """Record participation by a new node."""
            self.metrics.new_node_participations += 1
    
        def get_validator_performance(self, validator_id: str) -> Dict[str, Any]:
            """
            Get performance metrics for a specific validator.
    
            Args:
                validator_id (str): ID of the validator.
    
            Returns:
                Dict[str, Any]: Validator's performance metrics.
            """
            try:
                total_validations = self.metrics.validator_counts.get(validator_id, 0)
                if total_validations == 0:
                    return {
                        "total_validations": 0,
                        "success_rate": 0.0,
                        "shard_participation": {}
                    }
    
                validator_successes = sum(
                    1 for shard in self.metrics.shard_metrics.values()
                    if validator_id in shard["unique_validators"] and shard["successful"] > 0
                )
                success_rate = validator_successes / total_validations
    
                shard_participation = {
                    shard_id: {
                        "validations": metrics["validations"],
                        "success_rate": (
                            metrics["successful"] / metrics["validations"]
                            if metrics["validations"] > 0 else 0.0
                        )
                    }
                    for shard_id, metrics in self.metrics.shard_metrics.items()
                    if validator_id in metrics["unique_validators"]
                }
    
                return {
                    "total_validations": total_validations,
                    "success_rate": success_rate,
                    "shard_participation": shard_participation
                }
    
            except Exception as e:
                logger.error(f"Failed to get validator performance: {str(e)}")
                return {"error": str(e)}
    
        def get_shard_metrics(self, shard_id: int) -> Dict[str, Any]:
            """
            Get metrics for a specific shard.
    
            Args:
                shard_id (int): ID of the shard.
    
            Returns:
                Dict[str, Any]: Shard metrics.
            """
            try:
                if shard_id not in self.metrics.shard_metrics:
                    return {
                        "validations": 0,
                        "successful": 0,
                        "failed": 0,
                        "validator_count": 0,
                        "success_rate": 0.0
                    }
    
                metrics = self.metrics.shard_metrics[shard_id]
                total = metrics["validations"]
    
                return {
                    "validations": total,
                    "successful": metrics["successful"],
                    "failed": metrics["failed"],
                    "validator_count": len(metrics["unique_validators"]),
                    "success_rate": metrics["successful"] / total if total > 0 else 0.0
                }
    
            except Exception as e:
                logger.error(f"Failed to get shard metrics: {str(e)}")
                return {"error": str(e)}
    
        def get_all_metrics(self) -> Dict[str, Any]:
            """
            Get all consensus metrics.
    
            Returns:
                Dict[str, Any]: All metrics.
            """
            try:
                total_validations = self.metrics.total_validations
                return {
                    "total_validations": total_validations,
                    "successful_validations": self.metrics.successful_validations,
                    "failed_validations": self.metrics.failed_validations,
                    "success_rate": (
                        self.metrics.successful_validations / total_validations
                        if total_validations > 0 else 0.0
                    ),
                    "average_block_time": self.metrics.average_block_time,
                    "collusion_detections": self.metrics.collusion_detections,
                    "new_node_participations": self.metrics.new_node_participations,
                    "total_blocks_validated": self.metrics.total_blocks_validated,
                    "active_validators": len(self.metrics.validator_counts),
                    "shard_metrics": {
                        shard_id: self.get_shard_metrics(shard_id)
                        for shard_id in self.metrics.shard_metrics
                    }
                }
    
            except Exception as e:
                logger.error(f"Failed to get all metrics: {str(e)}")
                return {"error": str(e)}
    
        def _update_custom_metrics(self, custom_metrics: Dict[str, Any]) -> None:
            """
            Update metrics with custom values from validation results.
    
            Args:
                custom_metrics (Dict[str, Any]): Dictionary of custom metrics to update.
            """
            try:
                for key, value in custom_metrics.items():
                    if not hasattr(self.metrics, key):
                        setattr(self.metrics, key, value)
                    else:
                        current_value = getattr(self.metrics, key)
                        if isinstance(current_value, (int, float)):
                            setattr(self.metrics, key, current_value + value)
                        elif isinstance(current_value, dict):
                            current_value.update(value)
    
            except Exception as e:
                logger.error(f"Failed to update custom metrics: {str(e)}")
    
        def check_metrics_reset(self) -> None:
            """Check if metrics should be reset based on reset interval."""
            if datetime.now() - self.last_metrics_reset > self.reset_interval:
                self.metrics = ConsensusMetrics()
                self.last_metrics_reset = datetime.now()
    
        def to_dict(self) -> Dict[str, Any]:
            """Convert metrics manager state to dictionary."""
            return {
                "metrics": self.metrics.to_dict(),
                "last_reset": self.last_metrics_reset.isoformat(),
                "reset_interval_seconds": self.reset_interval.total_seconds()
            }
    
        @classmethod
        def from_dict(cls, data: Dict[str, Any]) -> 'MetricsManager':
            """Create metrics manager from dictionary data."""
            manager = cls()
            manager.metrics = ConsensusMetrics.from_dict(data["metrics"])
            manager.last_metrics_reset = datetime.fromisoformat(data["last_reset"])
            manager.reset_interval = timedelta(seconds=data["reset_interval_seconds"])
            return manager
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/reputation_manager.py
# Size: 17285 bytes
# Last Modified: Sun Oct 27 00:01:15 2024
# Language: py
# ============================================================

```py
    """
    reputation_manager.py
    
    This module manages reputation scoring and calculations for the Proof of Cooperation (PoC) consensus mechanism.
    It handles all aspects of node reputation, including score calculation, decay, validation eligibility, 
    and updates to validation statistics.
    
    Classes:
        ReputationManager
    """
    
    from typing import Dict, List, Optional, Any
    from datetime import datetime, timedelta
    import logging
    import math
    from .types import ConsensusConfig, ValidationResult, ValidationStats
    from ..core.node import Node
    from .collusion_detector import CollusionDetector
    
    logger = logging.getLogger(__name__)
    
    class ReputationManager:
        """
        Manages reputation scoring and calculations for the consensus mechanism.
        Handles all aspects of node reputation, including score calculation,
        decay, dynamic adjustments, and validation eligibility.
        """
    
        def __init__(self, config: ConsensusConfig, collusion_detector: CollusionDetector):
            """
            Initialize the reputation manager.
    
            Args:
                config (ConsensusConfig): The consensus configuration parameters.
                collusion_detector (CollusionDetector): Instance of the collusion detector for integration.
            """
            self.config = config
            self.collusion_detector = collusion_detector
            self.node_stats: Dict[str, ValidationStats] = {}
            self.last_score_update: Dict[str, datetime] = {}
            self.score_cache: Dict[str, float] = {}
            self.cache_duration = timedelta(minutes=5)
    
        def calculate_cooperation_score(self, node: Node, shard_id: Optional[int] = None) -> float:
            """
            Calculate a node's cooperation score, considering various factors like diversity,
            consistency, performance, shard-specific behavior, time decay, and collusion risk.
    
            Args:
                node (Node): The node to calculate the score for.
                shard_id (Optional[int]): Optional shard ID for shard-specific scoring.
    
            Returns:
                float: The calculated cooperation score, adjusted by multiple factors.
            """
            try:
                cache_key = f"{node.node_id}:{shard_id or 'all'}"
                
                # Return cached score if it is still valid
                if cache_key in self.score_cache:
                    cache_time = self.last_score_update.get(cache_key)
                    if cache_time and datetime.now() - cache_time < self.cache_duration:
                        return self.score_cache[cache_key]
    
                # Calculate base reputation score
                base_score = sum(
                    score * self.config.reputation_weights.get(category, 1.0)
                    for category, score in node.reputation_scores.items()
                )
    
                # Calculate additional factors
                factors = [
                    self._calculate_diversity_factor(node),
                    self._calculate_consistency_factor(node),
                    self._calculate_performance_factor(node),
                    self._calculate_collusion_factor(node)
                ]
    
                if shard_id is not None:
                    factors.append(self._calculate_shard_factor(node, shard_id))
    
                # Apply factors to base score
                final_score = base_score
                for factor in factors:
                    final_score *= factor
    
                # Apply time decay
                time_factor = self._calculate_time_decay(node)
                final_score *= time_factor
    
                # Cache the calculated score
                self.score_cache[cache_key] = final_score
                self.last_score_update[cache_key] = datetime.now()
    
                return max(0.0, final_score)
    
            except Exception as e:
                logger.error(f"Error calculating cooperation score: {str(e)}")
                return 0.0
    
        def _calculate_collusion_factor(self, node: Node) -> float:
            """
            Calculate a collusion factor that reduces the score of nodes with high collusion risk.
    
            Args:
                node (Node): The node to calculate the collusion factor for.
    
            Returns:
                float: The calculated collusion factor.
            """
            try:
                risk_score = self.collusion_detector._calculate_risk_score(node)
                
                # Reduce the factor based on collusion risk
                if risk_score > 0.9:
                    return 0.2
                elif risk_score > 0.7:
                    return 0.5
                elif risk_score > 0.5:
                    return 0.7
    
                return 1.0  # No penalty for low-risk nodes
    
            except Exception as e:
                logger.error(f"Error calculating collusion factor: {str(e)}")
                return 0.5
    
        def _calculate_diversity_factor(self, node: Node) -> float:
            """
            Calculate a diversity factor based on a node's cooperative interactions. 
            It evaluates the variety of cooperatives the node interacts with, 
            favoring nodes that engage with diverse cooperatives.
    
            Args:
                node (Node): The node to calculate the diversity factor for.
    
            Returns:
                float: The calculated diversity factor.
            """
            try:
                recent_interactions = node.cooperative_interactions[-100:]
                if not recent_interactions:
                    return 1.0
    
                unique_coops = len(set(recent_interactions))
                total_interactions = len(recent_interactions)
                diversity_score = unique_coops / total_interactions
    
                if total_interactions >= 20:
                    if unique_coops >= 5:
                        return 1.0 + math.log(1 + diversity_score) * 1.5
                    return 1.0 + math.log(1 + diversity_score)
    
                return max(0.7, diversity_score)  # Minimum baseline for newer nodes
    
            except Exception as e:
                logger.error(f"Error calculating diversity factor: {str(e)}")
                return 0.7
    
        def _calculate_consistency_factor(self, node: Node) -> float:
            """
            Calculate a consistency factor based on the node's validation history.
            This factor rewards consistent performance over time.
    
            Args:
                node (Node): The node to calculate the consistency factor for.
    
            Returns:
                float: The calculated consistency factor.
            """
            try:
                if not node.validation_history:
                    return 1.0
    
                recent_validations = node.validation_history[-50:]
                successful = sum(
                    1 for v in recent_validations 
                    if v.get("evidence", {}).get("success", False)
                )
                success_rate = successful / len(recent_validations)
    
                if node.total_validations < 10:
                    min_rate = self.config.validation_thresholds["min_success_rate"] * 0.8
                else:
                    min_rate = self.config.validation_thresholds["min_success_rate"]
    
                if success_rate > 0.95:
                    return 1.8
                elif success_rate > 0.8:
                    return 1.5
                elif success_rate > min_rate:
                    return 1.0 + ((success_rate - min_rate) / (1 - min_rate))
    
                return max(0.5, success_rate / min_rate)
    
            except Exception as e:
                logger.error(f"Error calculating consistency factor: {str(e)}")
                return 0.5
    
        def _calculate_performance_factor(self, node: Node) -> float:
            """
            Calculate a performance factor based on node metrics such as availability, 
            validation success rate, and network reliability.
    
            Args:
                node (Node): The node to calculate the performance factor for.
    
            Returns:
                float: The calculated performance factor.
            """
            try:
                metrics = node.performance_metrics
                if not metrics:
                    return 1.0
    
                weights = {
                    "availability": 0.35,
                    "validation_success_rate": 0.35,
                    "network_reliability": 0.3
                }
    
                weighted_sum = sum(
                    (metrics.get(metric, 0) / 100) * weight
                    for metric, weight in weights.items()
                )
    
                if weighted_sum > 0.95:
                    return weighted_sum * 1.2
                elif weighted_sum > 0.9:
                    return weighted_sum * 1.1
    
                return max(
                    self.config.validation_thresholds["min_availability"],
                    weighted_sum
                )
    
            except Exception as e:
                logger.error(f"Error calculating performance factor: {str(e)}")
                return self.config.validation_thresholds["min_availability"]
    
        def _calculate_shard_factor(self, node: Node, shard_id: int) -> float:
            """
            Calculate a shard-specific factor that rewards experience and performance within a shard.
    
            Args:
                node (Node): The node to calculate the shard factor for.
                shard_id (int): The shard ID to calculate the factor for.
    
            Returns:
                float: The calculated shard factor.
            """
            try:
                if shard_id not in node.active_shards:
                    return 0.0
    
                time_in_shard = (datetime.now() - node.active_shards[shard_id]).total_seconds()
                experience = min(1.0, time_in_shard / (24 * 3600))
    
                stats = self.node_stats.get(node.node_id, ValidationStats())
                shard_stats = stats.shard_validations.get(shard_id, {})
    
                if shard_stats:
                    success_rate = (
                        shard_stats.get("successful", 0) /
                        max(1, shard_stats.get("selections", 1))
                    )
                else:
                    success_rate = 1.0
    
                if experience < 0.2:
                    return 0.7 + (0.3 * success_rate)
                else:
                    return 0.4 + (0.3 * experience) + (0.3 * success_rate)
    
            except Exception as e:
                logger.error(f"Error calculating shard factor: {str(e)}")
                return 0.5
    
        def _calculate_time_decay(self, node: Node) -> float:
            """
            Calculate a time-based decay factor that reduces the score of inactive nodes over time.
    
            Args:
                node (Node): The node to calculate the time decay for.
    
            Returns:
                float: The calculated time decay factor.
            """
            try:
                stats = self.node_stats.get(node.node_id)
                if not stats or not stats.last_validation:
                    return 1.0
    
                hours_inactive = (datetime.now() - stats.last_validation).total_seconds() / 3600
    
                if hours_inactive > 24:
                    return math.exp(-hours_inactive / 24)
    
                return 1.0
    
            except Exception as e:
                logger.error(f"Error calculating time decay: {str(e)}")
                return 1.0
    
        def can_validate(self, node: Node, shard_id: Optional[int] = None) -> bool:
            """
            Determine if a node is eligible to participate in validation, considering reputation,
            validation history, and specific shard requirements.
    
            Args:
                node (Node): The node to check eligibility for.
                shard_id (Optional[int]): Optional shard ID for shard-specific validation.
    
            Returns:
                bool: True if the node is eligible for validation, False otherwise.
            """
            try:
                # Handle new nodes
                if node.total_validations < 5:
                    return (
                        node.can_validate(shard_id) and
                        node.get_total_reputation() >= 
                        self.config.min_reputation * 
                        self.config.validation_thresholds["new_node_reputation_factor"]
                    )
    
                # Standard validation checks
                if not node.can_validate(shard_id):
                    return False
    
                # Calculate reputation requirement
                total_reputation = node.get_total_reputation()
                reputation_requirement = self.config.min_reputation
    
                # Adjust reputation requirement based on experience
                if node.total_validations > 20:
                    reputation_requirement *= 1.2
                elif node.total_validations > 10:
                    reputation_requirement *= 1.0
                else:
                    reputation_requirement *= 0.7
    
                if total_reputation < reputation_requirement:
                    return False
    
                # Check recent performance
                stats = self.node_stats.get(node.node_id, ValidationStats())
                if stats.selections > 0:
                    recent_success_rate = stats.successful_validations / stats.selections
                    if (
                        recent_success_rate < self.config.validation_thresholds["min_success_rate"] and
                        node.total_validations > 10
                    ):
                        return False
    
                return True
    
            except Exception as e:
                logger.error(f"Error checking validation eligibility: {str(e)}")
                return False
    
        def update_stats(self, node_id: str, result: ValidationResult, shard_id: Optional[int] = None) -> None:
            """
            Update validation statistics for a node based on the result of a validation attempt.
    
            Args:
                node_id (str): ID of the node to update.
                result (ValidationResult): The validation result.
                shard_id (Optional[int]): Optional shard ID where validation occurred.
            """
            try:
                if node_id not in self.node_stats:
                    self.node_stats[node_id] = ValidationStats()
    
                stats = self.node_stats[node_id]
                stats.selections += 1
                stats.last_validation = datetime.now()
    
                if result.success:
                    stats.successful_validations += 1
                    stats.consecutive_failures = 0
                else:
                    stats.consecutive_failures += 1
    
                if shard_id is not None:
                    if shard_id not in stats.shard_validations:
                        stats.shard_validations[shard_id] = {
                            "selections": 0,
                            "successful": 0
                        }
                    
                    shard_stats = stats.shard_validations[shard_id]
                    shard_stats["selections"] += 1
                    if result.success:
                        shard_stats["successful"] += 1
    
            except Exception as e:
                logger.error(f"Error updating validation stats: {str(e)}")
    
        def get_node_stats(self, node_id: str) -> Optional[ValidationStats]:
            """
            Retrieve validation statistics for a node.
    
            Args:
                node_id (str): ID of the node to retrieve statistics for.
    
            Returns:
                Optional[ValidationStats]: The node's validation stats if found, None otherwise.
            """
            return self.node_stats.get(node_id)
    
        def to_dict(self) -> Dict[str, Any]:
            """
            Convert the reputation manager's state to a dictionary for serialization.
    
            Returns:
                Dict[str, Any]: Dictionary representation of the reputation manager's state.
            """
            return {
                "node_stats": {
                    node_id: {
                        "selections": stats.selections,
                        "successful_validations": stats.successful_validations,
                        "consecutive_failures": stats.consecutive_failures,
                        "last_validation": stats.last_validation.isoformat() if stats.last_validation else None,
                        "shard_validations": stats.shard_validations
                    }
                    for node_id, stats in self.node_stats.items()
                },
                "score_cache": self.score_cache,
                "last_score_update": {
                    k: v.isoformat() 
                    for k, v in self.last_score_update.items()
                }
            }
    
        @classmethod
        def from_dict(cls, data: Dict[str, Any], config: ConsensusConfig, collusion_detector: CollusionDetector) -> 'ReputationManager':
            """
            Create a reputation manager instance from a dictionary of data.
    
            Args:
                data (Dict[str, Any]): The dictionary data to initialize from.
                config (ConsensusConfig): The consensus configuration parameters.
                collusion_detector (CollusionDetector): Instance of the collusion detector.
    
            Returns:
                ReputationManager: A new instance of ReputationManager.
            """
            manager = cls(config, collusion_detector)
    
            # Restore node stats
            for node_id, stats_data in data["node_stats"].items():
                stats = ValidationStats()
                stats.selections = stats_data["selections"]
                stats.successful_validations = stats_data["successful_validations"]
                stats.consecutive_failures = stats_data["consecutive_failures"]
                if stats_data["last_validation"]:
                    stats.last_validation = datetime.fromisoformat(stats_data["last_validation"])
                stats.shard_validations = stats_data["shard_validations"]
                manager.node_stats[node_id] = stats
    
            # Restore score cache and update times
            manager.score_cache = data["score_cache"]
            manager.last_score_update = {
                k: datetime.fromisoformat(v)
                for k, v in data["last_score_update"].items()
            }
    
            return manager
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/validator_manager.py
# Size: 9018 bytes
# Last Modified: Sat Oct 26 23:59:09 2024
# Language: py
# ============================================================

```py
    """
    validator_manager.py
    
    This module manages validators within the Proof of Cooperation (PoC) consensus mechanism.
    It handles validator selection, state management, and integration with the reputation system.
    
    Classes:
        ValidatorManager
    """
    
    from typing import List, Optional
    from datetime import datetime, timedelta
    from .types import Node, Shard
    from .collusion_detector import CollusionDetector
    
    class ValidatorManager:
        """
        The ValidatorManager is responsible for managing validators within the PoC mechanism.
        
        Key Responsibilities:
        - Selecting eligible validators for block validation.
        - Tracking validator states, including reputation, performance, and cooldown periods.
        - Integrating with the shard management system to ensure validator availability per shard.
        - Enforcing reputation requirements and cooldown periods for fair participation.
        - Coordinating with collusion detection for enhanced security and fairness.
        """
        
        def __init__(self, min_reputation: float, cooldown_blocks: int, collusion_detector: CollusionDetector):
            """
            Initialize the ValidatorManager with minimum reputation, cooldown settings, and collusion detection.
            
            Args:
                min_reputation (float): Minimum reputation required for validators.
                cooldown_blocks (int): Number of blocks a validator must wait after validation.
                collusion_detector (CollusionDetector): Instance of the collusion detector for integration.
            """
            self.min_reputation = min_reputation
            self.cooldown_blocks = cooldown_blocks
            self.collusion_detector = collusion_detector
            self.validator_history: List[tuple] = []  # Stores tuples of (validator_id, timestamp, shard_id)
    
        def select_validator(self, nodes: List[Node], shard_id: Optional[int] = None) -> Optional[Node]:
            """
            Select an eligible validator from the provided list of nodes.
    
            Selection Criteria:
            - Node must have reputation above the minimum threshold.
            - Node must not be in cooldown.
            - Node must be able to validate the specified shard, if shard_id is provided.
            - Nodes with higher reputation, cooperative interactions, and better performance are prioritized.
            - Nodes with lower collusion risk are prioritized.
    
            Args:
                nodes (List[Node]): List of nodes to select from.
                shard_id (Optional[int]): Shard ID for which a validator is needed.
            
            Returns:
                Optional[Node]: The selected validator node, or None if no eligible validator is found.
            """
            # Filter eligible nodes based on eligibility and collusion risk
            eligible_nodes = [node for node in nodes if self._is_eligible(node, shard_id) and not self._is_high_risk(node)]
            if not eligible_nodes:
                return None
    
            # Sort nodes by priority score
            eligible_nodes.sort(key=self._calculate_priority_score, reverse=True)
    
            # Select the top candidate
            selected_validator = eligible_nodes[0]
            self._enforce_validator_selection(selected_validator, shard_id)
            return selected_validator
    
        def _is_eligible(self, node: Node, shard_id: Optional[int]) -> bool:
            """
            Check if a node is eligible to be a validator based on reputation, cooldown, and shard assignment.
            
            Args:
                node (Node): Node to check eligibility for.
                shard_id (Optional[int]): Shard ID to validate eligibility against.
    
            Returns:
                bool: True if the node is eligible, False otherwise.
            """
            if node.reputation < self.min_reputation or node.cooldown > 0:
                return False
            if shard_id is not None and not node.can_validate(shard_id):
                return False
            return True
    
        def _is_high_risk(self, node: Node) -> bool:
            """
            Check if a node is considered high-risk for collusion based on its risk score from the collusion detector.
    
            Args:
                node (Node): Node to check for collusion risk.
    
            Returns:
                bool: True if the node is high-risk, False otherwise.
            """
            risk_score = self.collusion_detector._calculate_risk_score(node)
            return risk_score > 0.8
    
        def _calculate_priority_score(self, node: Node) -> float:
            """
            Calculate a priority score for selecting validators based on multiple factors.
    
            The score is calculated using:
            - Reputation
            - Number of cooperative interactions
            - Performance metrics (e.g., availability, validation success rate)
            - Inverse collusion risk score
    
            Args:
                node (Node): Node to calculate the priority score for.
    
            Returns:
                float: Calculated priority score.
            """
            # Weights for different factors in the priority score calculation
            reputation_weight = 0.5
            interaction_weight = 0.2
            performance_weight = 0.2
            collusion_weight = 0.1
    
            collusion_risk = self.collusion_detector._calculate_risk_score(node)
            collusion_penalty = (1 - collusion_risk) * collusion_weight
    
            score = (
                node.reputation * reputation_weight +
                len(node.cooperative_interactions) * interaction_weight +
                node.performance_metrics.get('validation_success_rate', 0) * performance_weight +
                collusion_penalty
            )
            return score
    
        def _enforce_validator_selection(self, node: Node, shard_id: Optional[int]) -> None:
            """
            Enforce validator selection, including cooldown, reputation updates, and tracking.
    
            Args:
                node (Node): The selected validator node.
                shard_id (Optional[int]): The shard ID for which the node was selected as a validator.
            """
            node.enter_cooldown(self.cooldown_blocks)
            self._track_validator_history(node, shard_id)
    
        def _track_validator_history(self, node: Node, shard_id: Optional[int]) -> None:
            """
            Track the history of validators for auditing and performance analysis.
    
            Args:
                node (Node): The validator node.
                shard_id (Optional[int]): The shard ID for which the node was selected as a validator.
            """
            self.validator_history.append((node.node_id, datetime.now(), shard_id))
            
            # Maintain a capped history size for memory efficiency
            max_history_length = 1000
            if len(self.validator_history) > max_history_length:
                self.validator_history.pop(0)
    
        def update_validator_reputation(self, node: Node, reputation_delta: float) -> None:
            """
            Update the reputation of a validator node by a specified amount.
    
            Args:
                node (Node): The validator node to update.
                reputation_delta (float): The amount to add or subtract from the node's reputation.
            """
            node.reputation += reputation_delta
            node.reputation = max(0.0, node.reputation)  # Ensure reputation does not fall below zero
    
        def enforce_cooldown(self, node: Node) -> None:
            """
            Enforce cooldown for a validator node after a validation cycle.
    
            This method increases the cooldown period for the node to prevent consecutive validations.
    
            Args:
                node (Node): The validator node to enforce cooldown on.
            """
            node.cooldown = self.cooldown_blocks
    
        def release_cooldown(self) -> None:
            """
            Release cooldowns for all validators that have completed their cooldown period.
    
            This method iterates through nodes and decreases their cooldown by one block,
            allowing them to rejoin validation once their cooldown reaches zero.
            """
            for node in self._get_all_nodes():
                if node.cooldown > 0:
                    node.cooldown -= 1
    
        def get_validator_history(self, limit: int = 100) -> List[tuple]:
            """
            Retrieve the recent history of validators, useful for auditing and analysis.
    
            Args:
                limit (int): Maximum number of records to return (default is 100).
    
            Returns:
                List[tuple]: A list of tuples containing validator history records.
            """
            return self.validator_history[-limit:]
    
        def get_active_validators(self) -> List[str]:
            """
            Retrieve a list of active validators based on their current state.
    
            Returns:
                List[str]: A list of node IDs representing active validators.
            """
            return [record[0] for record in self.validator_history if record[1] > datetime.now() - timedelta(hours=1)]
    
        def _get_all_nodes(self) -> List[Node]:
            """
            Placeholder method to retrieve all nodes in the network.
    
            This method should be replaced with actual logic to fetch nodes from the broader PoC network.
    
            Returns:
                List[Node]: List of all nodes (currently returns an empty list).
            """
            return []
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/types.py
# Size: 11674 bytes
# Last Modified: Sat Oct 26 23:40:04 2024
# Language: py
# ============================================================

```py
    """
    types.py
    
    This module defines data structures and types used within the Proof of Cooperation (PoC) consensus mechanism.
    It includes configuration settings, validation results, metrics tracking, and the overall state of the consensus.
    
    Classes:
        ConsensusConfig
        ValidationResult
        ValidatorHistory
        ValidationStats
        ConsensusMetrics
        ConsensusState
    """
    
    from dataclasses import dataclass, field
    from typing import Dict, List, Optional, Set, Any
    from datetime import datetime
    
    @dataclass
    class ConsensusConfig:
        """
        Configuration parameters for the PoC consensus mechanism.
    
        Attributes:
            min_reputation (float): Minimum reputation required for validation eligibility.
            cooldown_blocks (int): Number of blocks a validator must wait during cooldown.
            reputation_decay_factor (float): Rate at which reputation decays over time.
            collusion_threshold (float): Threshold for detecting collusion among validators.
            reputation_weights (Dict[str, float]): Weights for different reputation categories.
            validation_thresholds (Dict[str, float]): Thresholds for validation metrics.
        """
        min_reputation: float = 10.0
        cooldown_blocks: int = 3
        reputation_decay_factor: float = 0.95
        collusion_threshold: float = 0.75
        
        reputation_weights: Dict[str, float] = field(default_factory=lambda: {
            "cooperative_growth": 1.5,
            "proposal_participation": 1.2,
            "transaction_validation": 1.3,
            "resource_sharing": 1.3,
            "conflict_resolution": 1.1,
            "community_building": 1.2,
            "sustainability": 1.2,
            "innovation": 1.3,
            "network_stability": 1.4,
            "data_availability": 1.2,
        })
        
        validation_thresholds: Dict[str, float] = field(default_factory=lambda: {
            "min_participation": 0.05,
            "min_success_rate": 0.4,
            "min_availability": 0.6,
            "max_consecutive_validations": 3,
            "new_node_reputation_factor": 0.3,
            "min_interactions": 3,
        })
    
    @dataclass
    class ValidationResult:
        """
        Represents the result of a validation operation.
    
        Attributes:
            success (bool): Indicates whether the validation was successful.
            reason (Optional[str]): Reason for failure, if applicable.
            metrics (Dict[str, Any]): Additional metrics related to the validation.
        """
        success: bool
        reason: Optional[str] = None
        metrics: Dict[str, Any] = field(default_factory=dict)
    
    @dataclass
    class ValidatorHistory:
        """
        Tracks the activity of a validator within the PoC network.
    
        Attributes:
            node_id (str): Identifier of the validator node.
            timestamp (datetime): Time of the validation event.
            shard_id (Optional[int]): Shard ID where validation occurred.
            success (bool): Indicates whether the validation was successful.
            metrics (Dict[str, Any]): Additional metrics related to the validation event.
        """
        node_id: str
        timestamp: datetime
        shard_id: Optional[int]
        success: bool = True
        metrics: Dict[str, Any] = field(default_factory=dict)
    
    @dataclass
    class ValidationStats:
        """
        Tracks validation statistics for individual nodes.
    
        Attributes:
            selections (int): Number of times the node was selected for validation.
            successful_validations (int): Number of successful validations.
            consecutive_failures (int): Number of consecutive failed validations.
            last_validation (Optional[datetime]): Timestamp of the last validation.
            shard_validations (Dict[int, Dict[str, Any]]): Shard-specific validation metrics.
        """
        selections: int = 0
        successful_validations: int = 0
        consecutive_failures: int = 0
        last_validation: Optional[datetime] = None
        shard_validations: Dict[int, Dict[str, Any]] = field(default_factory=dict)
    
    @dataclass
    class ConsensusMetrics:
        """
        Tracks metrics related to the PoC consensus mechanism.
    
        Attributes:
            total_validations (int): Total number of validations performed.
            successful_validations (int): Total number of successful validations.
            failed_validations (int): Total number of failed validations.
            collusion_detections (int): Number of detected collusion events.
            total_blocks_validated (int): Total number of blocks validated.
            new_node_participations (int): Number of participations by new nodes.
            average_block_time (float): Average time taken to validate blocks.
            validator_counts (Dict[str, int]): Number of validations per validator.
            shard_metrics (Dict[int, Dict[str, Any]]): Shard-specific metrics.
        """
        total_validations: int = 0
        successful_validations: int = 0
        failed_validations: int = 0
        collusion_detections: int = 0
        total_blocks_validated: int = 0
        new_node_participations: int = 0
        average_block_time: float = 0.0
        validator_counts: Dict[str, int] = field(default_factory=dict)
        shard_metrics: Dict[int, Dict[str, Any]] = field(default_factory=dict)
    
        def to_dict(self) -> Dict[str, Any]:
            """
            Convert metrics to dictionary format.
    
            Returns:
                Dict[str, Any]: Dictionary representation of the metrics.
            """
            return {
                "total_validations": self.total_validations,
                "successful_validations": self.successful_validations,
                "failed_validations": self.failed_validations,
                "collusion_detections": self.collusion_detections,
                "total_blocks_validated": self.total_blocks_validated,
                "new_node_participations": self.new_node_participations,
                "average_block_time": self.average_block_time,
                "validator_counts": self.validator_counts.copy(),
                "shard_metrics": {
                    shard_id: metrics.copy() 
                    for shard_id, metrics in self.shard_metrics.items()
                }
            }
    
        @classmethod
        def from_dict(cls, data: Dict[str, Any]) -> 'ConsensusMetrics':
            """
            Create ConsensusMetrics from dictionary data.
    
            Args:
                data (Dict[str, Any]): Dictionary containing metrics data.
    
            Returns:
                ConsensusMetrics: An instance of ConsensusMetrics populated with the provided data.
            """
            metrics = cls()
            metrics.total_validations = data.get("total_validations", 0)
            metrics.successful_validations = data.get("successful_validations", 0)
            metrics.failed_validations = data.get("failed_validations", 0)
            metrics.collusion_detections = data.get("collusion_detections", 0)
            metrics.total_blocks_validated = data.get("total_blocks_validated", 0)
            metrics.new_node_participations = data.get("new_node_participations", 0)
            metrics.average_block_time = data.get("average_block_time", 0.0)
            metrics.validator_counts = data.get("validator_counts", {}).copy()
            metrics.shard_metrics = data.get("shard_metrics", {}).copy()
            return metrics
    
    @dataclass
    class ConsensusState:
        """
        Represents the current state of the PoC consensus mechanism.
    
        Attributes:
            config (ConsensusConfig): Configuration parameters of the consensus.
            metrics (ConsensusMetrics): Metrics tracking consensus operations.
            validator_history (List[ValidatorHistory]): History of validator activities.
            validation_stats (Dict[str, ValidationStats]): Validation statistics by node.
            active_validators (Set[str]): Set of currently active validators.
        """
        config: ConsensusConfig
        metrics: ConsensusMetrics = field(default_factory=ConsensusMetrics)
        validator_history: List[ValidatorHistory] = field(default_factory=list)
        validation_stats: Dict[str, ValidationStats] = field(default_factory=dict)
        active_validators: Set[str] = field(default_factory=set)
    
        def to_dict(self) -> Dict[str, Any]:
            """
            Convert state to dictionary format.
    
            Returns:
                Dict[str, Any]: Dictionary representation of the consensus state.
            """
            return {
                "config": {
                    "min_reputation": self.config.min_reputation,
                    "cooldown_blocks": self.config.cooldown_blocks,
                    "reputation_decay_factor": self.config.reputation_decay_factor,
                    "collusion_threshold": self.config.collusion_threshold,
                    "reputation_weights": self.config.reputation_weights.copy(),
                    "validation_thresholds": self.config.validation_thresholds.copy()
                },
                "metrics": self.metrics.to_dict(),
                "validator_history": [
                    {
                        "node_id": h.node_id,
                        "timestamp": h.timestamp.isoformat(),
                        "shard_id": h.shard_id,
                        "success": h.success,
                        "metrics": h.metrics.copy()
                    }
                    for h in self.validator_history
                ],
                "validation_stats": {
                    node_id: {
                        "selections": stats.selections,
                        "successful_validations": stats.successful_validations,
                        "consecutive_failures": stats.consecutive_failures,
                        "last_validation": stats.last_validation.isoformat() if stats.last_validation else None,
                        "shard_validations": stats.shard_validations.copy()
                    }
                    for node_id, stats in self.validation_stats.items()
                },
                "active_validators": list(self.active_validators)
            }
    
        @classmethod
        def from_dict(cls, data: Dict[str, Any]) -> 'ConsensusState':
            """
            Create ConsensusState from dictionary data.
    
            Args:
                data (Dict[str, Any]): Dictionary containing consensus state data.
    
            Returns:
                ConsensusState: An instance of ConsensusState populated with the provided data.
            """
            config = ConsensusConfig(
                min_reputation=data["config"]["min_reputation"],
                cooldown_blocks=data["config"]["cooldown_blocks"],
                reputation_decay_factor=data["config"]["reputation_decay_factor"],
                collusion_threshold=data["config"]["collusion_threshold"]
            )
            config.reputation_weights = data["config"]["reputation_weights"].copy()
            config.validation_thresholds = data["config"]["validation_thresholds"].copy()
    
            metrics = ConsensusMetrics.from_dict(data["metrics"])
    
            validator_history = [
                ValidatorHistory(
                    node_id=h["node_id"],
                    timestamp=datetime.fromisoformat(h["timestamp"]),
                    shard_id=h["shard_id"],
                    success=h["success"],
                    metrics=h["metrics"].copy()
                )
                for h in data["validator_history"]
            ]
    
            validation_stats = {
                node_id: ValidationStats(
                    selections=stats["selections"],
                    successful_validations=stats["successful_validations"],
                    consecutive_failures=stats["consecutive_failures"],
                    last_validation=datetime.fromisoformat(stats["last_validation"]) if stats["last_validation"] else None,
                    shard_validations=stats["shard_validations"].copy()
                )
                for node_id, stats in data["validation_stats"].items()
            }
    
            active_validators = set(data["active_validators"])
    
            return cls(
                config=config,
                metrics=metrics,
                validator_history=validator_history,
                validation_stats=validation_stats,
                active_validators=active_validators
            )
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/sanctions_manager.py
# Size: 10255 bytes
# Last Modified: Sun Oct 27 00:02:44 2024
# Language: py
# ============================================================

```py
    """
    sanctions_manager.py
    
    This module manages sanctions and recovery for validators in the Proof of Cooperation (PoC) consensus mechanism.
    It handles tiered penalties, escalated sanctions, and reputation recovery, and allows for integration 
    with governance for handling disputes and appeals.
    
    Classes:
        SanctionsManager
    """
    
    from typing import Dict, List, Optional, Tuple
    from datetime import datetime, timedelta
    import logging
    from .types import Node
    from .collusion_detector import CollusionDetector
    from .reputation_manager import ReputationManager
    
    logger = logging.getLogger(__name__)
    
    class SanctionsManager:
        """
        Manages sanctions and recovery for validators within the PoC mechanism.
        
        Key Responsibilities:
        - Enforcing tiered sanctions based on collusion risk and frequency of offenses.
        - Allowing validators to recover from penalties through positive behavior.
        - Providing integration points for governance to handle disputes and appeals.
        """
    
        def __init__(self, collusion_detector: CollusionDetector, reputation_manager: ReputationManager, max_sanction_level: int = 3, recovery_period: int = 7):
            """
            Initialize the SanctionsManager with collusion detection and reputation management integration.
    
            Args:
                collusion_detector (CollusionDetector): Instance of the collusion detector for integration.
                reputation_manager (ReputationManager): Instance of the reputation manager for integration.
                max_sanction_level (int): Maximum level of sanctions before permanent exclusion (default is 3).
                recovery_period (int): Number of days required for a validator to demonstrate positive behavior for recovery.
            """
            self.collusion_detector = collusion_detector
            self.reputation_manager = reputation_manager
            self.max_sanction_level = max_sanction_level
            self.recovery_period = timedelta(days=recovery_period)
            self.sanctions: Dict[str, int] = {}  # Maps validator IDs to sanction levels
            self.recovery_timers: Dict[str, datetime] = {}  # Maps validator IDs to recovery start times
    
        def apply_sanction(self, node: Node) -> None:
            """
            Apply a sanction to a validator based on collusion detection outcomes.
    
            Args:
                node (Node): The validator node to sanction.
            """
            validator_id = node.node_id
    
            # Increase sanction level for the validator
            current_sanction_level = self.sanctions.get(validator_id, 0) + 1
            self.sanctions[validator_id] = min(current_sanction_level, self.max_sanction_level)
    
            # Apply reputation slashing based on sanction level
            reputation_penalty = self._calculate_reputation_penalty(current_sanction_level)
            self.reputation_manager.update_validator_reputation(node, -reputation_penalty)
    
            # Start or reset the recovery timer
            self.recovery_timers[validator_id] = datetime.now()
    
            # Log the sanction
            logger.info(f"Sanction applied to validator {validator_id}: Level {current_sanction_level}, Reputation penalty: {reputation_penalty}")
    
            # If maximum sanction level reached, consider permanent exclusion
            if current_sanction_level >= self.max_sanction_level:
                self._handle_permanent_exclusion(node)
    
        def _calculate_reputation_penalty(self, sanction_level: int) -> float:
            """
            Calculate the reputation penalty based on the current sanction level.
    
            Args:
                sanction_level (int): The level of the sanction.
    
            Returns:
                float: The reputation penalty to apply.
            """
            base_penalty = 5.0  # Base penalty for the first level of sanctions
            penalty_multiplier = 1.5  # Multiplier for each additional level
            return base_penalty * (penalty_multiplier ** (sanction_level - 1))
    
        def _handle_permanent_exclusion(self, node: Node) -> None:
            """
            Handle permanent exclusion for a validator that has reached the maximum sanction level.
    
            Args:
                node (Node): The validator node to exclude.
            """
            validator_id = node.node_id
    
            # Mark the validator as permanently excluded
            node.metadata["status"] = "permanently_excluded"
            node.reputation = 0.0  # Set reputation to zero
            node.cooldown = float('inf')  # Indefinite cooldown
    
            # Log the permanent exclusion
            logger.warning(f"Validator {validator_id} has been permanently excluded from the network.")
    
        def evaluate_recovery(self, node: Node) -> bool:
            """
            Evaluate if a validator is eligible for recovery based on positive behavior.
    
            Args:
                node (Node): The validator node to evaluate.
    
            Returns:
                bool: True if recovery is successful, False otherwise.
            """
            validator_id = node.node_id
            last_recovery_start = self.recovery_timers.get(validator_id)
    
            # Check if the validator has demonstrated positive behavior over the recovery period
            if last_recovery_start and datetime.now() - last_recovery_start >= self.recovery_period:
                if self._is_behavior_positive(node):
                    self._recover_validator(node)
                    return True
    
            return False
    
        def _is_behavior_positive(self, node: Node) -> bool:
            """
            Check if a validator's recent behavior is positive, warranting recovery.
    
            Criteria:
            - No new collusion detections.
            - Successful validation rate above the minimum threshold.
    
            Args:
                node (Node): The validator node to check.
    
            Returns:
                bool: True if behavior is positive, False otherwise.
            """
            risk_score = self.collusion_detector._calculate_risk_score(node)
            if risk_score > 0.5:
                return False  # High collusion risk disqualifies recovery
    
            recent_validations = node.validation_history[-50:]
            successful_validations = sum(1 for v in recent_validations if v.get("evidence", {}).get("success", False))
            success_rate = successful_validations / len(recent_validations) if recent_validations else 0
    
            return success_rate >= self.reputation_manager.config.validation_thresholds["min_success_rate"]
    
        def _recover_validator(self, node: Node) -> None:
            """
            Recover a validator from sanctions, reducing the sanction level and restoring reputation.
    
            Args:
                node (Node): The validator node to recover.
            """
            validator_id = node.node_id
    
            # Decrease the sanction level and restore reputation
            current_sanction_level = self.sanctions.get(validator_id, 0)
            if current_sanction_level > 0:
                self.sanctions[validator_id] = current_sanction_level - 1
    
            # Restore reputation based on recovery
            recovery_bonus = self._calculate_recovery_bonus(current_sanction_level)
            self.reputation_manager.update_validator_reputation(node, recovery_bonus)
    
            # Reset recovery timer
            self.recovery_timers[validator_id] = datetime.now()
    
            # Log the recovery
            logger.info(f"Validator {validator_id} has recovered: Sanction level decreased to {current_sanction_level - 1}, Reputation bonus: {recovery_bonus}")
    
        def _calculate_recovery_bonus(self, sanction_level: int) -> float:
            """
            Calculate the reputation bonus for recovering from sanctions.
    
            Args:
                sanction_level (int): The level of the sanction being recovered from.
    
            Returns:
                float: The reputation bonus to apply.
            """
            base_bonus = 3.0  # Base bonus for the first level of recovery
            bonus_multiplier = 1.2  # Multiplier for each level of recovery
            return base_bonus * (bonus_multiplier ** sanction_level)
    
        def get_sanction_status(self, node: Node) -> Tuple[int, str]:
            """
            Get the current sanction status of a validator, including level and status.
    
            Args:
                node (Node): The validator node to check.
    
            Returns:
                Tuple[int, str]: A tuple containing the sanction level and status.
            """
            validator_id = node.node_id
            sanction_level = self.sanctions.get(validator_id, 0)
            status = node.metadata.get("status", "active")
    
            return sanction_level, status
    
        def handle_dispute(self, node: Node) -> None:
            """
            Handle disputes regarding sanctions, allowing validators to appeal their penalties 
            through governance mechanisms.
    
            Args:
                node (Node): The validator node appealing the sanction.
            """
            validator_id = node.node_id
            # Placeholder for governance-based dispute resolution
            logger.info(f"Validator {validator_id} has initiated a dispute against sanctions.")
            # Future implementation: Integrate with governance for proposals and voting on appeals
    
        def to_dict(self) -> Dict[str, Any]:
            """
            Convert the sanctions manager's state to a dictionary for serialization.
    
            Returns:
                Dict[str, Any]: Dictionary representation of the sanctions manager's state.
            """
            return {
                "sanctions": self.sanctions,
                "recovery_timers": {k: v.isoformat() for k, v in self.recovery_timers.items()}
            }
    
        @classmethod
        def from_dict(cls, data: Dict[str, Any], collusion_detector: CollusionDetector, reputation_manager: ReputationManager) -> 'SanctionsManager':
            """
            Create a sanctions manager instance from a dictionary of data.
    
            Args:
                data (Dict[str, Any]): The dictionary data to initialize from.
                collusion_detector (CollusionDetector): Instance of the collusion detector.
                reputation_manager (ReputationManager): Instance of the reputation manager.
    
            Returns:
                SanctionsManager: A new instance of SanctionsManager.
            """
            manager = cls(collusion_detector, reputation_manager)
    
            # Restore sanctions and recovery timers
            manager.sanctions = data.get("sanctions", {})
            manager.recovery_timers = {k: datetime.fromisoformat(v) for k, v in data.get("recovery_timers", {}).items()}
    
            return manager
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/collusion_detector.py
# Size: 8568 bytes
# Last Modified: Sat Oct 26 23:54:30 2024
# Language: py
# ============================================================

```py
    """
    collusion_detector.py
    
    This module detects collusion among validators and participants in the Proof of Cooperation (PoC) consensus mechanism.
    It identifies patterns that may indicate fraudulent behavior or attempts to manipulate the consensus process.
    
    Classes:
        CollusionDetector
    """
    
    from typing import List, Dict, Tuple, Optional
    from datetime import datetime
    from .types import Node, Transaction, Block
    import logging
    
    # Initialize logging
    logger = logging.getLogger(__name__)
    
    class CollusionDetector:
        """
        The CollusionDetector is responsible for analyzing transaction patterns and validator behavior
        to detect potential collusion within the PoC network.
        
        Key Responsibilities:
        - Analyzing transaction patterns to identify repeated suspicious behavior.
        - Monitoring validator interactions and decisions for signs of collusion.
        - Utilizing historical data to identify anomalous patterns that could indicate fraud.
        """
        
        def __init__(self, transaction_threshold: int = 10, validator_threshold: int = 3, dynamic_threshold: bool = True):
            """
            Initialize the CollusionDetector with detection thresholds.
    
            Args:
                transaction_threshold (int): Number of similar transactions required to trigger a collusion check.
                validator_threshold (int): Number of validators interacting repeatedly to trigger a collusion check.
                dynamic_threshold (bool): If True, thresholds adjust based on network conditions.
            """
            self.transaction_threshold = transaction_threshold
            self.validator_threshold = validator_threshold
            self.dynamic_threshold = dynamic_threshold
            self.suspicious_transactions: List[Transaction] = []  # Stores potentially collusive transactions
            self.suspicious_validators: Dict[str, int] = {}  # Track suspicious validator behavior
            self.network_activity: Dict[str, int] = {}  # Track overall network activity for adaptive thresholds
    
        def detect_collusion(self, validator: Node, block: Block) -> bool:
            """
            Detect potential collusion in a given block based on transaction patterns and validator behavior.
    
            Detection Criteria:
            - Repeated transactions between the same sender and receiver within the same block.
            - Validators repeatedly validating blocks with similar transactions from the same set of senders.
            - Validators interacting unusually frequently with each other.
    
            Args:
                validator (Node): The validator node to check for collusion.
                block (Block): The block to analyze for collusion.
    
            Returns:
                bool: True if collusion is detected, False otherwise.
            """
            # Adjust thresholds dynamically based on network activity
            if self.dynamic_threshold:
                self._adjust_thresholds()
    
            # Analyze transaction patterns
            transactions_suspicious = self._check_transaction_patterns(block.transactions)
    
            # Analyze validator interactions
            interactions_suspicious = self._check_validator_interactions(validator)
    
            # Mark validator as suspicious if any collusion criteria are met
            if transactions_suspicious or interactions_suspicious:
                self._mark_validator_as_suspicious(validator)
                return True
    
            return False
    
        def _adjust_thresholds(self) -> None:
            """
            Dynamically adjust detection thresholds based on current network activity.
            This allows the detection mechanism to scale with network load and complexity.
            """
            avg_activity = sum(self.network_activity.values()) / len(self.network_activity) if self.network_activity else 1
            self.transaction_threshold = max(5, int(avg_activity * 0.1))  # Example logic for scaling threshold
            self.validator_threshold = max(2, int(avg_activity * 0.05))   # Example logic for scaling threshold
    
            logger.debug(f"Dynamic thresholds adjusted: Transaction={self.transaction_threshold}, Validator={self.validator_threshold}")
    
        def _check_transaction_patterns(self, transactions: List[Transaction]) -> bool:
            """
            Check transaction patterns within a block to identify suspicious behavior.
    
            Criteria:
            - If the same sender-receiver pair appears repeatedly within a block, it is considered suspicious.
            - If a block contains an unusually high number of similar transactions, it may indicate collusion.
    
            Args:
                transactions (List[Transaction]): List of transactions in the block.
    
            Returns:
                bool: True if suspicious patterns are found, False otherwise.
            """
            transaction_count: Dict[Tuple[str, str], int] = {}
            for tx in transactions:
                pair = (tx.sender, tx.receiver)
                transaction_count[pair] = transaction_count.get(pair, 0) + 1
                if transaction_count[pair] >= self.transaction_threshold:
                    self.suspicious_transactions.append(tx)
                    logger.warning(f"Suspicious transaction pattern detected between {tx.sender} and {tx.receiver}")
                    return True
    
            return False
    
        def _check_validator_interactions(self, validator: Node) -> bool:
            """
            Check if a validator is interacting unusually frequently with other validators.
    
            Criteria:
            - If a validator consistently validates blocks from the same set of validators, it may indicate collusion.
    
            Args:
                validator (Node): The validator to analyze for repeated interactions.
    
            Returns:
                bool: True if suspicious interactions are found, False otherwise.
            """
            interaction_count: Dict[str, int] = {}
            for interaction in validator.validation_history:
                interacting_validator = interaction.get("validator_id")
                if interacting_validator:
                    interaction_count[interacting_validator] = interaction_count.get(interacting_validator, 0) + 1
                    if interaction_count[interacting_validator] >= self.validator_threshold:
                        logger.warning(f"Suspicious validator interaction detected: {validator.node_id} with {interacting_validator}")
                        return True
            return False
    
        def _mark_validator_as_suspicious(self, validator: Node) -> None:
            """
            Mark a validator as suspicious and log the event for auditing purposes.
    
            Args:
                validator (Node): The validator to mark as suspicious.
            """
            validator_id = validator.node_id
            self.suspicious_validators[validator_id] = self.suspicious_validators.get(validator_id, 0) + 1
            
            # Update validator metadata and reputation
            validator.metadata["status"] = "suspicious"
            validator.metadata["last_suspicious_activity"] = datetime.now()
            validator.reputation = max(0, validator.reputation - 5)
            validator.cooldown += 1
            
            # Log suspicious activity
            self._log_suspicious_activity(validator)
    
        def _log_suspicious_activity(self, validator: Node) -> None:
            """
            Log details of suspicious activity for auditing and monitoring.
    
            Args:
                validator (Node): The validator marked as suspicious.
            """
            validator_id = validator.node_id
            logger.info(f"[{datetime.now()}] Suspicious activity detected for validator {validator_id}.")
            logger.info(f"Reputation reduced to {validator.reputation}, status set to 'suspicious'.")
    
        def report_suspicious_transactions(self) -> List[Transaction]:
            """
            Generate a report of all suspicious transactions detected during collusion checks.
    
            Returns:
                List[Transaction]: List of suspicious transactions.
            """
            return self.suspicious_transactions
    
        def report_suspicious_validators(self) -> Dict[str, int]:
            """
            Generate a report of all validators marked as suspicious during collusion checks.
    
            Returns:
                Dict[str, int]: Dictionary of suspicious validators and their frequency of suspicious activity.
            """
            return self.suspicious_validators
    
        def reset_suspicion_data(self) -> None:
            """
            Reset the collusion detector's data for suspicious transactions and validators.
    
            This is useful for clearing past data when starting a new detection cycle.
            """
            self.suspicious_transactions.clear()
            self.suspicious_validators.clear()
            logger.info("Suspicion data has been reset.")
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/base.py
# Size: 8036 bytes
# Last Modified: Sat Oct 26 23:33:49 2024
# Language: py
# ============================================================

```py
    """
    base.py
    
    This module provides base classes and interfaces for the Proof of Cooperation (PoC) consensus mechanism.
    It establishes the fundamental structures for validators, reputation management, and transaction processing.
    
    Classes:
        BaseValidator
        BaseReputationSystem
        BaseTransaction
    """
    
    from abc import ABC, abstractmethod
    from typing import Dict, Any, Optional, Union
    
    class BaseValidator(ABC):
        """
        BaseValidator is an abstract base class that defines the fundamental structure
        for validators in the Proof of Cooperation (PoC) consensus mechanism.
    
        Validators are responsible for verifying transactions, creating blocks, and participating
        in shard management, all while maintaining a cooperative reputation system.
        """
        
        def __init__(self, node_id: str, cooperative_id: str):
            """
            Initialize a base validator with a unique node ID and cooperative ID.
    
            Args:
                node_id (str): Unique identifier for the validator node.
                cooperative_id (str): Identifier for the cooperative the node belongs to.
            """
            self.node_id = node_id
            self.cooperative_id = cooperative_id
            self.reputation: Dict[str, float] = {"validation": 0.0, "cooperation": 0.0}  # Reputation scores
            self.performance_metrics: Dict[str, Union[float, int]] = {"availability": 0.0, "success_rate": 0.0}
            self.cooldown: int = 0  # Cooldown period after validation
            self.inactivity_count: int = 0  # Track validator inactivity
    
        @abstractmethod
        def validate_transaction(self, transaction: Any) -> bool:
            """
            Validate a given transaction. This method must be implemented by subclasses.
    
            Args:
                transaction (Any): The transaction to validate.
    
            Returns:
                bool: True if the transaction is valid, False otherwise.
            """
            pass
    
        @abstractmethod
        def create_block(self) -> Optional[Any]:
            """
            Create a new block. This method must be implemented by subclasses.
    
            Returns:
                Optional[Any]: The newly created block, or None if block creation fails.
            """
            pass
    
        def enter_cooldown(self, blocks: int) -> None:
            """
            Enter a cooldown period after successful validation.
    
            Args:
                blocks (int): Number of blocks the validator must wait before participating again.
            """
            self.cooldown = blocks
    
        def decrease_cooldown(self) -> None:
            """
            Decrease the cooldown period by one block.
            """
            if self.cooldown > 0:
                self.cooldown -= 1
    
        def reset_performance_metrics(self) -> None:
            """
            Reset performance metrics to prepare for the next validation cycle.
            """
            self.performance_metrics = {"availability": 0.0, "success_rate": 0.0}
    
        def update_reputation(self, category: str, score: float) -> None:
            """
            Update the validator's reputation score for a given category.
    
            Args:
                category (str): The category of reputation to update (e.g., 'validation', 'cooperation').
                score (float): The score to add or subtract from the category.
            """
            if category in self.reputation:
                self.reputation[category] += score
                self.reputation[category] = max(0.0, min(self.reputation[category], 100.0))  # Cap reputation
    
        def apply_inactivity_decay(self) -> None:
            """
            Apply decay to the validator's reputation if it has been inactive for multiple cycles.
            """
            if self.inactivity_count > 3:
                decay_factor = 0.9
                for category in self.reputation:
                    self.reputation[category] *= decay_factor
    
        def increment_inactivity(self) -> None:
            """
            Increment the inactivity count when the validator fails to participate.
            """
            self.inactivity_count += 1
    
        def reset_inactivity(self) -> None:
            """
            Reset the inactivity count when the validator successfully participates.
            """
            self.inactivity_count = 0
    
    class BaseReputationSystem(ABC):
        """
        BaseReputationSystem is an abstract base class that defines the structure for managing
        reputation within the PoC network.
    
        Reputation is a critical component of the consensus mechanism, influencing validator selection,
        transaction validation, and cooperative interactions.
        """
        
        def __init__(self):
            self.reputation_scores: Dict[str, float] = {}  # Overall reputation scores for nodes
    
        @abstractmethod
        def update_reputation(self, node_id: str, category: str, score: float, evidence: Optional[Dict] = None) -> None:
            """
            Update the reputation score for a specific category of a node.
    
            Args:
                node_id (str): Identifier for the node whose reputation is being updated.
                category (str): The category of reputation to update (e.g., 'validation', 'cooperation').
                score (float): The score to add or subtract from the category.
                evidence (Optional[Dict]): Optional evidence to support the reputation change.
            """
            pass
    
        @abstractmethod
        def get_reputation(self, node_id: str, category: str) -> float:
            """
            Get the current reputation score for a specific category of a node.
    
            Args:
                node_id (str): Identifier for the node whose reputation is being retrieved.
                category (str): The category of reputation to retrieve.
    
            Returns:
                float: The reputation score for the specified category.
            """
            pass
    
        def apply_global_decay(self, decay_rate: float = 0.95) -> None:
            """
            Apply global decay to all reputation scores to incentivize continuous participation.
    
            Args:
                decay_rate (float): The rate at which reputation decays (default is 0.95).
            """
            for node, scores in self.reputation_scores.items():
                for category in scores:
                    scores[category] *= decay_rate
    
    class BaseTransaction(ABC):
        """
        BaseTransaction is an abstract base class that defines the structure for transactions
        within the PoC network.
    
        Transactions represent the fundamental operations within the network, including transfers,
        cooperative actions, and smart contract interactions.
        """
        
        def __init__(self, sender: str, receiver: str, action: str, data: Dict[str, Any]):
            """
            Initialize a base transaction with sender, receiver, action, and data.
    
            Args:
                sender (str): The sender's identifier.
                receiver (str): The receiver's identifier.
                action (str): The action to be performed by the transaction.
                data (Dict[str, Any]): Additional data related to the transaction.
            """
            self.sender = sender
            self.receiver = receiver
            self.action = action
            self.data = data
    
        @abstractmethod
        def execute(self) -> bool:
            """
            Execute the transaction. This method must be implemented by subclasses.
    
            Returns:
                bool: True if the transaction is executed successfully, False otherwise.
            """
            pass
    
        @abstractmethod
        def validate(self) -> bool:
            """
            Validate the transaction. This method must be implemented by subclasses.
    
            Returns:
                bool: True if the transaction is valid, False otherwise.
            """
            pass
    
        def get_cooperative_score(self) -> float:
            """
            Calculate the cooperative score of the transaction, based on its data and action.
    
            Returns:
                float: The calculated cooperative score.
            """
            return self.data.get("cooperative_score", 0.0)
    
        def log_transaction(self) -> None:
            """
            Log transaction details for auditing and debugging purposes.
            """
            print(f"Transaction from {self.sender} to {self.receiver} | Action: {self.action} | Data: {self.data}")
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/cooldown_manager.py
# Size: 6715 bytes
# Last Modified: Sat Oct 26 23:37:03 2024
# Language: py
# ============================================================

```py
    """
    cooldown_manager.py
    
    This module manages dynamic cooldown periods for validators in the Proof of Cooperation (PoC) consensus mechanism.
    It aims to prevent validator monopolization by adjusting cooldowns based on validator activity and network conditions.
    
    Classes:
        CooldownManager
    """
    
    from typing import List, Dict, Optional
    from datetime import datetime, timedelta
    from .types import Node
    
    class CooldownManager:
        """
        The CooldownManager is responsible for dynamically managing cooldown periods for validators
        within the PoC mechanism. It adjusts cooldowns based on validator participation frequency,
        network congestion, and other factors to ensure fair and diverse participation.
    
        Key Features:
        - Dynamic cooldown adjustments to prevent validator monopolization.
        - Cooldown periods vary based on validator activity, performance, and network load.
        - Ensures that validators do not dominate consecutive validation rounds.
        """
        
        def __init__(self, base_cooldown: int = 3, max_cooldown: int = 10):
            """
            Initialize the CooldownManager with base and maximum cooldown settings.
    
            Args:
                base_cooldown (int): The initial cooldown period after validation.
                max_cooldown (int): The maximum allowable cooldown period.
            """
            self.base_cooldown = base_cooldown
            self.max_cooldown = max_cooldown
            self.validator_activity: Dict[str, List[datetime]] = {}  # Track validator activity timestamps
    
        def apply_cooldown(self, validator: Node) -> None:
            """
            Apply a dynamic cooldown period to a validator based on its recent activity and performance.
    
            Cooldown Criteria:
            - If a validator has participated frequently in recent blocks, the cooldown period increases.
            - Validators with lower performance or reputation have longer cooldowns.
            - Cooldowns decrease gradually if the validator has not participated recently.
    
            Args:
                validator (Node): The validator to apply cooldown to.
            """
            # Track validator activity
            self._track_activity(validator)
    
            # Calculate dynamic cooldown based on participation frequency and performance
            participation_rate = self._calculate_participation_rate(validator)
            performance_factor = 1 - (validator.performance_metrics.get('validation_success_rate', 0) / 100)
    
            # Adjust cooldown based on participation rate and performance
            dynamic_cooldown = min(
                int(self.base_cooldown * (1 + participation_rate * 2 + performance_factor)),
                self.max_cooldown
            )
            
            validator.cooldown = dynamic_cooldown
    
        def _track_activity(self, validator: Node) -> None:
            """
            Track the activity of a validator to determine participation frequency.
    
            Args:
                validator (Node): The validator to track.
            """
            current_time = datetime.now()
            if validator.node_id not in self.validator_activity:
                self.validator_activity[validator.node_id] = []
    
            self.validator_activity[validator.node_id].append(current_time)
    
            # Maintain a limited history of activity timestamps for efficiency
            self.validator_activity[validator.node_id] = [
                timestamp for timestamp in self.validator_activity[validator.node_id]
                if timestamp > current_time - timedelta(hours=1)
            ]
    
        def _calculate_participation_rate(self, validator: Node) -> float:
            """
            Calculate the participation rate of a validator based on recent activity.
    
            The participation rate is determined by the number of blocks the validator
            has participated in over a fixed period (e.g., the last hour).
    
            Args:
                validator (Node): The validator to analyze.
    
            Returns:
                float: The participation rate as a fraction of the maximum allowable rate.
            """
            max_participation_rate = 10  # Max participations allowed per hour (adjustable)
            recent_participations = len(self.validator_activity.get(validator.node_id, []))
    
            return min(recent_participations / max_participation_rate, 1)
    
        def reset_cooldown(self, validator: Node) -> None:
            """
            Reset the cooldown period for a validator if it has not participated recently.
    
            This helps ensure validators are re-integrated into the validation process
            after extended inactivity.
    
            Args:
                validator (Node): The validator to reset.
            """
            # If validator has not participated in the last hour, reset cooldown
            if not self.validator_activity.get(validator.node_id):
                validator.cooldown = max(0, validator.cooldown - 1)
    
        def is_eligible(self, validator: Node) -> bool:
            """
            Check if a validator is eligible for participation based on its cooldown period.
    
            Args:
                validator (Node): The validator to check.
    
            Returns:
                bool: True if the validator is eligible, False otherwise.
            """
            return validator.cooldown <= 0
    
        def decay_cooldown(self) -> None:
            """
            Gradually reduce cooldowns for all validators over time to allow re-participation.
    
            This is called periodically to ensure validators can rejoin the pool after their cooldowns.
            """
            for validator_id, timestamps in self.validator_activity.items():
                if timestamps and datetime.now() - timestamps[-1] > timedelta(minutes=10):
                    node = self._get_validator_by_id(validator_id)
                    if node:
                        node.cooldown = max(0, node.cooldown - 1)
    
        def _get_validator_by_id(self, node_id: str) -> Optional[Node]:
            """
            Retrieve a validator by its node ID.
    
            Args:
                node_id (str): The ID of the node to retrieve.
    
            Returns:
                Optional[Node]: The validator node, or None if not found.
            """
            # Placeholder for integration with the broader PoC network
            # This method should interface with a node management system to retrieve nodes
            return None  # Replace with actual retrieval logic
    
        def clear_inactive_validators(self) -> None:
            """
            Clear validators from the activity tracker if they have not participated for an extended period.
    
            This helps manage memory and ensures the activity tracker remains efficient.
            """
            current_time = datetime.now()
            for validator_id, timestamps in list(self.validator_activity.items()):
                if timestamps and current_time - timestamps[-1] > timedelta(hours=2):
                    del self.validator_activity[validator_id]
```


# ============================================================
# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/__init__.py
# Size: 0 bytes
# Last Modified: Sat Oct 26 14:10:55 2024
# Language: py
# ============================================================

```py

```
