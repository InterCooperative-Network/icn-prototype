# Project Context:
The InterCooperative Network (ICN) is a decentralized cooperative management system designed to support global governance, privacy-preserving identity, and resource sharing. It uses blockchain technology for consensus and DIDs for secure identities, with modules designed for scalable, democratic interaction. The ICN promotes cooperative-based decision-making, transparent governance, and equitable resource distribution.

# Module: blockchain
# Purpose: Handles core blockchain logic, consensus mechanisms, and transaction validation.
# Vision Alignment: This module ensures decentralized, cooperative-based transactions and consensus, forming the backbone of the ICN's transparent governance and trustless operations.
# Interaction with Other Modules: Integrates with 'did' for identity verification and 'api' for interaction.


# Code Files for Module: blockchain


# File: /home/matt/icn-prototype/tests/unit/test_blockchain.py

```py
    import pytest
    import asyncio
    from datetime import datetime
    
    from blockchain.core.blockchain import Blockchain
    from blockchain.core.node import Node
    from blockchain.core.block import Block
    from blockchain.contracts.smart_contract import SmartContract
    from blockchain.core.transaction import Transaction
    
    @pytest.fixture
    def blockchain():
        """
        Fixture to create a fresh instance of the Blockchain for each test.
        """
        return Blockchain(num_shards=3, initial_mana=1000, mana_regen_rate=10)
    
    def test_initialization(blockchain):
        """
        Test the initialization of the Blockchain.
        """
        assert isinstance(blockchain, Blockchain)
        assert blockchain.cooperative_mana == 1000
        assert blockchain.mana_regen_rate == 10
        assert len(blockchain.shards) == 3
        assert blockchain.genesis_block_created is True
    
    def test_register_node(blockchain):
        """
        Test node registration functionality.
        """
        node = Node(node_id="node_1")
        assert blockchain.register_node(node) is True
        assert node.node_id in blockchain.nodes
    
        # Duplicate registration should fail
        assert blockchain.register_node(node) is False
    
    def test_create_shard(blockchain):
        """
        Test shard creation in the Blockchain.
        """
        assert blockchain.create_shard(3) is True
        assert 3 in blockchain.shards
    
        # Attempt to create an existing shard
        assert blockchain.create_shard(3) is False
    
    def test_add_transaction(blockchain):
        """
        Test adding a transaction to the Blockchain.
        """
        transaction = {
            "sender": "alice",
            "receiver": "bob",
            "action": "transfer",
            "data": {"amount": 50}
        }
    
        # Add a valid transaction
        assert blockchain.add_transaction(transaction) is True
    
        # Add an invalid transaction
        invalid_transaction = "invalid_format"
        assert blockchain.add_transaction(invalid_transaction) is False
    
    def test_create_block(blockchain):
        """
        Test block creation in the Blockchain.
        """
        node = Node(node_id="node_1")
        blockchain.register_node(node)
    
        # Create a block in a valid shard
        shard_id = 0
        block = blockchain.create_block(shard_id)
        assert block is not None
        assert isinstance(block, Block)
    
        # Attempt to create a block in an invalid shard
        invalid_shard_id = 99
        assert blockchain.create_block(invalid_shard_id) is None
    
    def test_add_block(blockchain):
        """
        Test adding a block to the Blockchain.
        """
        node = Node(node_id="node_1")
        blockchain.register_node(node)
    
        block = Block(
            index=1,
            previous_hash=blockchain.chain[-1].hash,
            timestamp=datetime.now(),
            transactions=[],
            validator="node_1",
            shard_id=0
        )
    
        # Add a valid block
        assert blockchain.add_block(block) is True
    
        # Add an invalid block (invalid previous hash)
        invalid_block = Block(
            index=2,
            previous_hash="invalid_hash",
            timestamp=datetime.now(),
            transactions=[],
            validator="node_1",
            shard_id=0
        )
        assert blockchain.add_block(invalid_block) is False
    
    def test_mana_regeneration(blockchain):
        """
        Test mana regeneration functionality.
        """
        # Deplete some mana
        blockchain.cooperative_mana -= 100
        blockchain.regenerate_mana()
    
        # Check if mana regenerated correctly
        assert blockchain.cooperative_mana == 910  # 1000 - 100 + 10
    
    def test_get_chain_metrics(blockchain):
        """
        Test retrieving blockchain metrics.
        """
        metrics = blockchain.get_chain_metrics()
        assert isinstance(metrics, dict)
        assert metrics["chain_length"] == 1  # Genesis block
        assert metrics["cooperative_mana"] == 1000
        assert metrics["active_nodes"] == 0
        assert metrics["active_shards"] == 3
    
    def test_validate_chain(blockchain):
        """
        Test the entire blockchain validation.
        """
        node = Node(node_id="node_1")
        blockchain.register_node(node)
    
        block = Block(
            index=1,
            previous_hash=blockchain.chain[-1].hash,
            timestamp=datetime.now(),
            transactions=[],
            validator="node_1",
            shard_id=0
        )
        blockchain.add_block(block)
    
        # Validate the blockchain
        assert blockchain.validate_chain() is True
    
        # Corrupt the chain
        blockchain.chain[-1].previous_hash = "corrupt_hash"
        assert blockchain.validate_chain() is False
    
    def test_smart_contract_deployment(blockchain):
        """
        Test deploying a smart contract to the Blockchain.
        """
        contract = SmartContract(
            contract_id="contract_1",
            creator="node_1",
            code="dummy_code",
            mana_cost=100
        )
    
        result = asyncio.run(blockchain.deploy_smart_contract(contract))
        assert result is True
        assert "contract_1" in blockchain.smart_contracts
    
        # Deploy an invalid contract (e.g., insufficient mana)
        contract_2 = SmartContract(
            contract_id="contract_2",
            creator="node_1",
            code="dummy_code",
            mana_cost=2000  # Exceeds available mana
        )
    
        result = asyncio.run(blockchain.deploy_smart_contract(contract_2))
        assert result is False
    
    def test_smart_contract_execution(blockchain):
        """
        Test executing a smart contract on the Blockchain.
        """
        contract = SmartContract(
            contract_id="contract_1",
            creator="node_1",
            code="dummy_code",
            mana_cost=50
        )
    
        asyncio.run(blockchain.deploy_smart_contract(contract))
    
        input_data = {"param": "value"}
        result = asyncio.run(blockchain.execute_smart_contract(
            contract_id="contract_1",
            input_data=input_data,
            caller="node_1"
        ))
        assert result is not None
    
        # Attempt to execute a non-existent contract
        result = asyncio.run(blockchain.execute_smart_contract(
            contract_id="non_existent",
            input_data=input_data,
            caller="node_1"
        ))
        assert result is None
```

# File: /home/matt/icn-prototype/blockchain/blockchain.py

```py
    # blockchain/blockchain.py
    
    import hashlib
    import time
    import math
    import random
    import json
    import signal
    import logging
    from typing import Dict, List, Optional, Tuple, Set, Any, Union
    from dataclasses import dataclass, field
    from datetime import datetime, timedelta
    from cryptography.exceptions import InvalidKey
    from abc import ABC, abstractmethod
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class Transaction:
        """Represents a transaction in the ICN blockchain."""
        sender: str
        receiver: str
        action: str
        data: Dict
        timestamp: datetime = field(default_factory=datetime.now)
        signature: Optional[bytes] = None
        shard_id: Optional[int] = None
        transaction_id: str = field(init=False)
        
        def __post_init__(self):
            """Initialize transaction ID after creation."""
            self.transaction_id = self.calculate_id()
        
        def calculate_id(self) -> str:
            """Calculate unique transaction ID."""
            tx_data = {
                'sender': self.sender,
                'receiver': self.receiver,
                'action': self.action,
                'data': self.data,
                'timestamp': self.timestamp.isoformat(),
                'shard_id': self.shard_id
            }
            return hashlib.sha256(json.dumps(tx_data, sort_keys=True).encode()).hexdigest()
        
        def to_dict(self) -> Dict:
            """Convert transaction to dictionary format."""
            return {
                'transaction_id': self.transaction_id,
                'sender': self.sender,
                'receiver': self.receiver,
                'action': self.action,
                'data': self.data,
                'timestamp': self.timestamp.isoformat(),
                'signature': self.signature.hex() if self.signature else None,
                'shard_id': self.shard_id
            }
            
        @classmethod
        def from_dict(cls, data: Dict) -> 'Transaction':
            """Create transaction from dictionary."""
            timestamp = datetime.fromisoformat(data['timestamp'])
            signature = bytes.fromhex(data['signature']) if data.get('signature') else None
            
            return cls(
                sender=data['sender'],
                receiver=data['receiver'],
                action=data['action'],
                data=data['data'],
                timestamp=timestamp,
                signature=signature,
                shard_id=data.get('shard_id')
            )
    
        def validate(self) -> bool:
            """Validate transaction structure and data."""
            try:
                # Validate basic structure
                if not all([self.sender, self.receiver, self.action]):
                    return False
                
                # Validate timestamp
                if self.timestamp > datetime.now() + timedelta(minutes=5):
                    return False
                    
                # Validate data structure
                if not isinstance(self.data, dict):
                    return False
                    
                # Validate transaction ID
                if self.transaction_id != self.calculate_id():
                    return False
                    
                return True
                
            except Exception as e:
                logger.error(f"Transaction validation failed: {e}")
                return False
    
    @dataclass
    class Block:
        """Represents a block in the ICN blockchain."""
        index: int
        previous_hash: str
        timestamp: datetime
        transactions: List[Transaction]
        validator: str
        shard_id: int
        hash: str = ""
        nonce: int = 0
        merkle_root: str = ""
        cross_shard_refs: List[str] = field(default_factory=list)
        metadata: Dict = field(default_factory=dict)
        version: str = "1.0"
        
        def __post_init__(self):
            """Initialize block after creation."""
            if not self.merkle_root:
                self.merkle_root = self.calculate_merkle_root()
            if not self.hash:
                self.hash = self.calculate_hash()
            self.metadata['created_at'] = datetime.now().isoformat()
    
        def calculate_merkle_root(self) -> str:
            """Calculate the Merkle root of transactions."""
            if not self.transactions:
                return hashlib.sha256(b"empty").hexdigest()
            
            leaves = [hashlib.sha256(json.dumps(tx.to_dict()).encode()).hexdigest()
                     for tx in self.transactions]
            
            while len(leaves) > 1:
                if len(leaves) % 2 == 1:
                    leaves.append(leaves[-1])
                leaves = [hashlib.sha256((a + b).encode()).hexdigest()
                         for a, b in zip(leaves[::2], leaves[1::2])]
            
            return leaves[0]
    
        def calculate_hash(self) -> str:
            """Calculate the hash of the block."""
            block_dict = {
                'index': self.index,
                'previous_hash': self.previous_hash,
                'timestamp': self.timestamp.isoformat(),
                'merkle_root': self.merkle_root,
                'validator': self.validator,
                'nonce': self.nonce,
                'shard_id': self.shard_id,
                'cross_shard_refs': self.cross_shard_refs,
                'version': self.version
            }
            return hashlib.sha256(json.dumps(block_dict, sort_keys=True).encode()).hexdigest()
    
        def to_dict(self) -> Dict:
            """Convert block to dictionary format."""
            return {
                'index': self.index,
                'previous_hash': self.previous_hash,
                'timestamp': self.timestamp.isoformat(),
                'transactions': [tx.to_dict() for tx in self.transactions],
                'validator': self.validator,
                'hash': self.hash,
                'nonce': self.nonce,
                'merkle_root': self.merkle_root,
                'shard_id': self.shard_id,
                'cross_shard_refs': self.cross_shard_refs,
                'metadata': self.metadata,
                'version': self.version
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> 'Block':
            """Create block from dictionary."""
            transactions = [Transaction.from_dict(tx) for tx in data['transactions']]
            timestamp = datetime.fromisoformat(data['timestamp'])
            
            return cls(
                index=data['index'],
                previous_hash=data['previous_hash'],
                timestamp=timestamp,
                transactions=transactions,
                validator=data['validator'],
                shard_id=data['shard_id'],
                hash=data['hash'],
                nonce=data['nonce'],
                merkle_root=data['merkle_root'],
                cross_shard_refs=data.get('cross_shard_refs', []),
                metadata=data.get('metadata', {}),
                version=data.get('version', "1.0")
            )
    
        def validate(self, previous_block: Optional['Block'] = None) -> bool:
            """Validate block structure and consistency."""
            try:
                # Validate hash
                if self.hash != self.calculate_hash():
                    return False
                    
                # Validate merkle root
                if self.merkle_root != self.calculate_merkle_root():
                    return False
                    
                # Validate timestamp
                if self.timestamp > datetime.now() + timedelta(minutes=5):
                    return False
                    
                # Validate transactions
                if not all(tx.validate() for tx in self.transactions):
                    return False
                    
                # Validate against previous block if provided
                if previous_block:
                    if self.previous_hash != previous_block.hash:
                        return False
                    if self.index != previous_block.index + 1:
                        return False
                    if self.timestamp <= previous_block.timestamp:
                        return False
                        
                return True
                
            except Exception as e:
                logger.error(f"Block validation failed: {e}")
                return False
                class Shard:
        """Represents a blockchain shard."""
        
        def __init__(self, shard_id: int, max_transactions_per_block: int = 100):
            self.shard_id = shard_id
            self.chain: List[Block] = []
            self.pending_transactions: List[Transaction] = []
            self.height = 0
            self.max_transactions_per_block = max_transactions_per_block
            self.last_block_time = datetime.now()
            self.state: Dict = {}
            self.metrics: Dict = {
                'total_transactions': 0,
                'average_block_time': 0,
                'blocks_created': 0,
                'pending_count': 0
            }
            self._create_genesis_block()
    
        def _create_genesis_block(self) -> None:
            """Create genesis block for this shard."""
            genesis_block = Block(
                index=0,
                previous_hash="0" * 64,
                timestamp=datetime.now(),
                transactions=[],
                validator="genesis",
                shard_id=self.shard_id
            )
            self.chain.append(genesis_block)
            self.height = 1
            self.last_block_time = genesis_block.timestamp
            self.metrics['blocks_created'] = 1
    
        def add_transaction(self, transaction: Transaction) -> bool:
            """Add a new transaction to pending pool."""
            if transaction.shard_id != self.shard_id:
                return False
                
            if len(self.pending_transactions) >= self.max_transactions_per_block * 2:
                return False
                
            if not transaction.validate():
                return False
                
            self.pending_transactions.append(transaction)
            self.metrics['pending_count'] = len(self.pending_transactions)
            return True
    
        def create_block(self, validator: str) -> Optional[Block]:
            """Create a new block from pending transactions."""
            if not self.pending_transactions:
                return None
                
            transactions = self.pending_transactions[:self.max_transactions_per_block]
            
            new_block = Block(
                index=self.height,
                previous_hash=self.chain[-1].hash,
                timestamp=datetime.now(),
                transactions=transactions,
                validator=validator,
                shard_id=self.shard_id
            )
            
            return new_block
    
        def add_block(self, block: Block) -> bool:
            """Add a validated block to the shard chain."""
            if block.shard_id != self.shard_id:
                return False
                
            if block.index != self.height:
                return False
                
            if not block.validate(self.chain[-1]):
                return False
                
            # Update metrics
            block_time = (block.timestamp - self.last_block_time).total_seconds()
            self.metrics['average_block_time'] = (
                (self.metrics['average_block_time'] * self.metrics['blocks_created'] + block_time) /
                (self.metrics['blocks_created'] + 1)
            )
            self.metrics['blocks_created'] += 1
            self.metrics['total_transactions'] += len(block.transactions)
            
            # Remove included transactions from pending pool
            tx_ids = {tx.transaction_id for tx in block.transactions}
            self.pending_transactions = [
                tx for tx in self.pending_transactions 
                if tx.transaction_id not in tx_ids
            ]
            self.metrics['pending_count'] = len(self.pending_transactions)
            
            # Add block to chain
            self.chain.append(block)
            self.height += 1
            self.last_block_time = block.timestamp
            
            return True
    
        def get_latest_block(self) -> Block:
            """Get the latest block in this shard."""
            return self.chain[-1]
    
        def validate_chain(self) -> bool:
            """Validate the entire shard chain."""
            for i in range(1, len(self.chain)):
                if not self.chain[i].validate(self.chain[i-1]):
                    return False
            return True
    
        def get_metrics(self) -> Dict:
            """Get shard metrics and statistics."""
            return {
                'shard_id': self.shard_id,
                'height': self.height,
                'pending_transactions': len(self.pending_transactions),
                'last_block_time': self.last_block_time.isoformat(),
                **self.metrics
            }
    
    
    @dataclass
    class Node:
        """Represents a node in the ICN network."""
        
        def __init__(self, node_id: str, cooperative_id: Optional[str] = None,
                     initial_stake: float = 10.0):
            self.node_id = node_id
            self.cooperative_id = cooperative_id
            self.reputation_scores = {
                'validation': 0.0,
                'proposal_creation': 0.0,
                'voting': 0.0,
                'resource_sharing': 0.0,
                'cooperative_growth': 0.0,
                'community_building': 0.0,
                'conflict_resolution': 0.0,
                'transaction_validation': 0.0,
                'data_availability': 0.0,
                'network_stability': 0.0,
                'innovation': 0.0,
                'sustainability': 0.0
            }
            self.stake = initial_stake
            self.cooperative_interactions: List[str] = []
            self.validation_history: List[Dict] = []
            self.resource_usage: Dict[str, float] = {
                'computation': 0.0,
                'storage': 0.0,
                'bandwidth': 0.0,
                'memory': 0.0,
                'energy': 0.0
            }
            self.shard_assignments: Set[int] = set()
            self.active_shards: Dict[int, datetime] = {}
            self.last_validation = 0
            self.total_validations = 0
            self.cooldown = 0
            self.total_cycles = 0
            self.cycles_since_update: Dict[str, int] = {}
            self.performance_metrics: Dict[str, float] = {
                'response_time': 0.0,
                'availability': 100.0,
                'validation_success_rate': 100.0,
                'network_reliability': 100.0
            }
            self.metadata: Dict = {
                'creation_time': datetime.now(),
                'last_active': datetime.now(),
                'version': "1.0",
                'capabilities': set(),
                'status': "active"
            }
    
        def update_reputation(self, category: str, score: float, 
                             cooperative_id: Optional[str] = None,
                             evidence: Optional[Dict] = None) -> None:
            """Update reputation score for a category with evidence."""
            if category in self.reputation_scores:
                old_score = self.reputation_scores[category]
                self.reputation_scores[category] = max(0, old_score + score)
                
                if cooperative_id:
                    self.cooperative_interactions.append(cooperative_id)
                    
                if evidence:
                    self.validation_history.append({
                        'timestamp': datetime.now(),
                        'category': category,
                        'score_change': score,
                        'evidence': evidence
                    })
                
                self.metadata['last_active'] = datetime.now()
                
                # Trim interaction history to last 1000 interactions
                if len(self.cooperative_interactions) > 1000:
                    self.cooperative_interactions = self.cooperative_interactions[-1000:]
    
        def assign_to_shard(self, shard_id: int) -> bool:
            """Assign node to a shard."""
            if len(self.active_shards) >= 3:  # Maximum 3 active shards per node
                return False
                
            self.shard_assignments.add(shard_id)
            self.active_shards[shard_id] = datetime.now()
            return True
    
        def remove_from_shard(self, shard_id: int) -> bool:
            """Remove node from a shard."""
            if shard_id in self.active_shards:
                del self.active_shards[shard_id]
                self.shard_assignments.discard(shard_id)
                return True
            return False
    
        def can_validate(self, shard_id: Optional[int] = None) -> bool:
            """Check if node can validate blocks."""
            current_time = time.time()
            
            # Basic validation checks
            if self.cooldown > 0:
                return False
            if current_time - self.last_validation < 10:  # 10 second minimum between validations
                return False
            if self.metadata['status'] != "active":
                return False
                
            # Shard-specific validation
            if shard_id is not None:
                if shard_id not in self.active_shards:
                    return False
                if (datetime.now() - self.active_shards[shard_id]).total_seconds() > 3600:  # 1 hour timeout
                    return False
                    
            return True
    
        def enter_cooldown(self, cooldown_period: int) -> None:
            """Put node into cooldown period."""
            self.cooldown = cooldown_period
            self.metadata['status'] = "cooldown"
    
        def update_metrics(self, metrics: Dict[str, float]) -> None:
            """Update node performance metrics."""
            self.performance_metrics.update(metrics)
            self.metadata['last_active'] = datetime.now()
    
        def get_total_reputation(self) -> float:
            """Calculate total reputation across all categories."""
            return sum(self.reputation_scores.values())
    
        def to_dict(self) -> Dict:
            """Convert node state to dictionary."""
            return {
                'node_id': self.node_id,
                'cooperative_id': self.cooperative_id,
                'reputation_scores': self.reputation_scores,
                'stake': self.stake,
                'shard_assignments': list(self.shard_assignments),
                'performance_metrics': self.performance_metrics,
                'resource_usage': self.resource_usage,
                'metadata': self.metadata,
                'status': self.metadata['status']
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> 'Node':
            """Create node from dictionary."""
            node = cls(
                node_id=data['node_id'],
                cooperative_id=data['cooperative_id'],
                initial_stake=data['stake']
            )
            node.reputation_scores = data['reputation_scores']
            node.shard_assignments = set(data['shard_assignments'])
            node.performance_metrics = data['performance_metrics']
            node.resource_usage = data['resource_usage']
            node.metadata = data['metadata']
            
            return node
            class ProofOfCooperation:
        """Implements the Proof of Cooperation consensus mechanism."""
        
        def __init__(self, min_reputation: float = 10.0, cooldown_blocks: int = 3):
            self.min_reputation = min_reputation
            self.cooldown_blocks = cooldown_blocks
            self.cooperation_scores: Dict[str, float] = {}
            self.reputation_weights = {
                'cooperative_growth': 1.5,
                'proposal_participation': 1.2,
                'transaction_validation': 1.0,
                'resource_sharing': 1.3,
                'conflict_resolution': 1.1,
                'community_building': 1.4,
                'sustainability': 1.2,
                'innovation': 1.3,
                'network_stability': 1.1,
                'data_availability': 1.2
            }
            self.validation_thresholds = {
                'min_participation': 0.1,
                'min_success_rate': 0.8,
                'min_availability': 0.95,
                'max_consecutive_validations': 3
            }
            self.reputation_decay_factor = 0.99
            self.collusion_threshold = 0.8
            self.validator_history: List[Tuple[str, datetime, int]] = []  # node_id, timestamp, shard_id
            self.validation_stats: Dict[str, Dict] = {}
            self.performance_metrics: Dict[str, float] = {
                'average_block_time': 0.0,
                'total_validations': 0,
                'successful_validations': 0,
                'collusion_detections': 0
            }
    
        def calculate_cooperation_score(self, node: Node, shard_id: Optional[int] = None) -> float:
            """Calculate a node's cooperation score based on multiple factors."""
            if not node.can_validate(shard_id):
                return 0.0
    
            base_score = sum(
                score * self.reputation_weights.get(category, 1.0)
                for category, score in node.reputation_scores.items()
            )
            
            diversity_factor = self._calculate_diversity_factor(node)
            consistency_factor = self._calculate_consistency_factor(node)
            performance_factor = self._calculate_performance_factor(node)
            shard_factor = self._calculate_shard_factor(node, shard_id) if shard_id else 1.0
            
            final_score = (base_score * diversity_factor * consistency_factor * 
                          performance_factor * shard_factor)
                          
            return max(0, final_score)
    
        def _calculate_diversity_factor(self, node: Node) -> float:
            """Calculate diversity factor based on cooperative interactions."""
            recent_interactions = node.cooperative_interactions[-100:]  # Last 100 interactions
            if not recent_interactions:
                return 1.0
                
            unique_coops = len(set(recent_interactions))
            total_interactions = len(recent_interactions)
            
            diversity_score = unique_coops / total_interactions
            normalized_score = 1.0 + math.log(diversity_score + 1)
            
            return max(self.validation_thresholds['min_participation'], normalized_score)
    
        def _calculate_consistency_factor(self, node: Node) -> float:
            """Calculate consistency factor based on validation history."""
            if not node.validation_history:
                return 1.0
                
            recent_validations = node.validation_history[-50:]  # Last 50 validations
            successful = sum(1 for v in recent_validations 
                            if v.get('evidence', {}).get('success', False))
            
            success_rate = successful / len(recent_validations)
            return max(self.validation_thresholds['min_success_rate'], success_rate)
    
        def _calculate_performance_factor(self, node: Node) -> float:
            """Calculate performance factor based on node metrics."""
            metrics = node.performance_metrics
            if not metrics:
                return 1.0
    
            factors = [
                metrics.get('availability', 0) / 100,
                metrics.get('validation_success_rate', 0) / 100,
                metrics.get('network_reliability', 0) / 100
            ]
            
            avg_performance = sum(factors) / len(factors)
            return max(self.validation_thresholds['min_availability'], avg_performance)
    
        def _calculate_shard_factor(self, node: Node, shard_id: int) -> float:
            """Calculate shard-specific performance factor."""
            if shard_id not in node.active_shards:
                return 0.0
                
            # Consider time spent in shard
            time_in_shard = (datetime.now() - node.active_shards[shard_id]).total_seconds()
            shard_experience = min(1.0, time_in_shard / (24 * 3600))  # Max out at 1 day
            
            return 0.5 + (0.5 * shard_experience)
    
        def select_validator(self, nodes: List[Node], shard_id: Optional[int] = None) -> Optional[Node]:
            """Select the next validator using weighted random selection."""
            eligible_nodes = [
                node for node in nodes 
                if self._is_eligible_validator(node, shard_id)
            ]
            
            if not eligible_nodes:
                return None
                
            # Calculate scores for eligible nodes
            scores = [
                self.calculate_cooperation_score(node, shard_id) 
                for node in eligible_nodes
            ]
            total_score = sum(scores)
            
            if total_score <= 0:
                # Fallback to random selection if all scores are 0
                selected = random.choice(eligible_nodes)
            else:
                # Weighted random selection
                selection_point = random.uniform(0, total_score)
                current_sum = 0
                selected = eligible_nodes[-1]  # Default to last node
                
                for node, score in zip(eligible_nodes, scores):
                    current_sum += score
                    if current_sum >= selection_point:
                        selected = node
                        break
            
            # Record selection
            self._record_validator_selection(selected, shard_id)
            selected.enter_cooldown(self.cooldown_blocks)
            
            return selected
    
        def _is_eligible_validator(self, node: Node, shard_id: Optional[int] = None) -> bool:
            """Check if a node is eligible to validate blocks."""
            if not node.can_validate(shard_id):
                return False
                
            # Check minimum reputation requirement
            if node.get_total_reputation() < self.min_reputation:
                return False
                
            # Check performance factors
            performance_factor = self._calculate_performance_factor(node)
            if performance_factor < self.validation_thresholds['min_availability']:
                return False
                
            # Check recent selections to prevent concentration
            recent_validations = [
                v[0] for v in self.validator_history[-10:]
                if v[0] == node.node_id
            ]
            if len(recent_validations) >= self.validation_thresholds['max_consecutive_validations']:
                return False
                
            return True
    
        def _record_validator_selection(self, node: Node, shard_id: Optional[int]) -> None:
            """Record validator selection for statistics."""
            self.validator_history.append((node.node_id, datetime.now(), shard_id))
            if len(self.validator_history) > 1000:
                self.validator_history = self.validator_history[-1000:]
                
            if node.node_id not in self.validation_stats:
                self.validation_stats[node.node_id] = {
                    'selections': 0,
                    'successful_validations': 0,
                    'last_selected': None,
                    'shard_validations': {}
                }
                
            stats = self.validation_stats[node.node_id]
            stats['selections'] += 1
            stats['last_selected'] = datetime.now()
            
            if shard_id is not None:
                shard_stats = stats['shard_validations'].setdefault(shard_id, {
                    'selections': 0,
                    'successful': 0
                })
                shard_stats['selections'] += 1
    
        def validate_block(self, block: Block, previous_block: Optional[Block], 
                          validator: Node) -> bool:
            """Validate a proposed block."""
            try:
                # Verify validator eligibility
                if not self._is_eligible_validator(validator, block.shard_id):
                    return False
                    
                # Perform block validation
                if not block.validate(previous_block):
                    return False
                    
                # Verify cross-shard references if present
                if block.cross_shard_refs and not self._validate_cross_shard_refs(block):
                    return False
                    
                # Update statistics
                self._update_validation_stats(validator, block, True)
                
                return True
                
            except Exception as e:
                logger.error(f"Block validation failed: {e}")
                self._update_validation_stats(validator, block, False)
                return False
    
        def _validate_cross_shard_refs(self, block: Block) -> bool:
            """Validate cross-shard references in a block."""
            # This would include validation logic for cross-shard references
            # Implementation depends on specific cross-shard protocol
            return True
    
        def _update_validation_stats(self, validator: Node, block: Block, 
                                   success: bool) -> None:
            """Update validation statistics."""
            stats = self.validation_stats.get(validator.node_id, {
                'selections': 0,
                'successful_validations': 0,
                'shard_validations': {}
            })
            
            if success:
                stats['successful_validations'] += 1
                
            if block.shard_id is not None:
                shard_stats = stats['shard_validations'].setdefault(block.shard_id, {
                    'selections': 0,
                    'successful': 0
                })
                if success:
                    shard_stats['successful'] += 1
                    
            self.validation_stats[validator.node_id] = stats
    
    class SmartContract:
        """Represents a smart contract in the ICN blockchain."""
        
        def __init__(self, contract_id: str, code: str, creator: str, 
                     mana_cost: int = 10, version: str = "1.0"):
            self.contract_id = contract_id
            self.code = code
            self.creator = creator
            self.state: Dict = {}
            self.mana_cost = mana_cost
            self.version = version
            self.created_at = datetime.now()
            self.last_executed = None
            self.execution_count = 0
            self.total_mana_consumed = 0
            self.execution_history: List[Dict] = []
            self.metadata: Dict = {
                'created_at': self.created_at,
                'version': version,
                'creator': creator,
                'description': '',
                'tags': set()
            }
            self.dependencies: Set[str] = set()
            self.allowed_callers: Set[str] = {creator}
            self.restrictions: Dict = {
                'max_state_size': 1024 * 1024,  # 1MB
                'max_execution_time': 5,  # seconds
                'max_mana_per_execution': 100,
                'max_daily_executions': 1000
            }
            self.daily_executions = 0
            self.last_reset = datetime.now()
    
        def execute(self, input_data: Dict, available_mana: int) -> Dict:
            """Execute the smart contract code with safety checks."""
            # Reset daily execution counter if needed
            self._reset_daily_executions()
            
            # Validate execution conditions
            validation_result = self._validate_execution(input_data, available_mana)
            if validation_result.get("error"):
                return validation_result
                
            execution_start = time.time()
            try:
                # Set up secure execution environment
                local_namespace = self._setup_execution_environment(input_data)
                
                # Execute contract code
                exec(self.code, {}, local_namespace)
                
                # Validate execution result
                if "execute" not in local_namespace:
                    return {"error": "Contract missing execute function"}
                    
                # Check execution time
                if time.time() - execution_start > self.restrictions['max_execution_time']:
                    return {"error": "Execution time limit exceeded"}
                    
                # Execute contract function
                result = local_namespace["execute"](input_data, self.state)
                
                # Update contract metrics
                self._update_execution_metrics(execution_start)
                
                return {
                    "state": self.state,
                    "result": result,
                    "mana_used": self.mana_cost,
                    "execution_time": time.time() - execution_start
                }
                
            except Exception as e:
                logger.error(f"Contract execution failed: {e}")
                return {"error": str(e)}
    
        def _validate_execution(self, input_data: Dict, available_mana: int) -> Dict:
            """Validate execution conditions."""
            if self.daily_executions >= self.restrictions['max_daily_executions']:
                return {"error": "Daily execution limit exceeded"}
                
            if available_mana < self.mana_cost:
                return {"error": "Insufficient mana"}
                
            if len(str(self.state)) > self.restrictions['max_state_size']:
                return {"error": "State size limit exceeded"}
                
            return {}
    
        def _setup_execution_environment(self, input_data: Dict) -> Dict:
            """Set up secure execution environment with allowed variables."""
            return {
                "input": input_data,
                "state": self.state.copy(),
                "contract_id": self.contract_id,
                "creator": self.creator,
                "version": self.version,
                "metadata": self.metadata
            }
    
        def _update_execution_metrics(self, execution_start: float) -> None:
            """Update contract execution metrics."""
            self.last_executed = datetime.now()
            self.execution_count += 1
            self.daily_executions += 1
            self.total_mana_consumed += self.mana_cost
            
            execution_record = {
                'timestamp': self.last_executed,
                'execution_time': time.time() - execution_start,
                'mana_used': self.mana_cost,
                'state_size': len(str(self.state))
            }
            
            self.execution_history.append(execution_record)
            if len(self.execution_history) > 1000:
                self.execution_history = self.execution_history[-1000:]
    
        def _reset_daily_executions(self) -> None:
            """Reset daily execution counter if needed."""
            current_time = datetime.now()
            if (current_time - self.last_reset).days >= 1:
                self.daily_executions = 0
                self.last_reset = current_time
    
        def update_metadata(self, metadata: Dict) -> bool:
            """Update contract metadata."""
            try:
                self.metadata.update(metadata)
                return True
            except Exception as e:
                logger.error(f"Failed to update metadata: {e}")
                return False
    
        def add_dependency(self, contract_id: str) -> bool:
            """Add a contract dependency."""
            self.dependencies.add(contract_id)
            return True
    
        def authorize_caller(self, caller_id: str) -> bool:
            """Add an authorized caller."""
            self.allowed_callers.add(caller_id)
            return True
    
        def revoke_caller(self, caller_id: str) -> bool:
            """Revoke caller authorization."""
            if caller_id == self.creator:
                return False
            self.allowed_callers.discard(caller_id)
            return True
    
        def get_metrics(self) -> Dict:
            """Get comprehensive contract metrics."""
            return {
                'contract_id': self.contract_id,
                'version': self.version,
                'creator': self.creator,
                'created_at': self.created_at.isoformat(),
                'last_executed': self.last_executed.isoformat() if self.last_executed else None,
                'execution_count': self.execution_count,
                'daily_executions': self.daily_executions,
                'total_mana_consumed': self.total_mana_consumed,
                'average_mana_per_execution': (
                    self.total_mana_consumed / self.execution_count 
                    if self.execution_count > 0 else 0
                ),
                'state_size': len(str(self.state)),
                'dependencies': list(self.dependencies),
                'authorized_callers': len(self.allowed_callers),
                'restrictions': self.restrictions
            }
    
        def to_dict(self) -> Dict:
            """Convert contract to dictionary format."""
            return {
                'contract_id': self.contract_id,
                'code': self.code,
                'creator': self.creator,
                'state': self.state,
                'mana_cost': self.mana_cost,
                'version': self.version,
                'metadata': self.metadata,
                'dependencies': list(self.dependencies),
                'allowed_callers': list(self.allowed_callers),
                'restrictions': self.restrictions,
                'metrics': self.get_metrics()
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> 'SmartContract':
            """Create contract from dictionary."""
            contract = cls(
                contract_id=data['contract_id'],
                code=data['code'],
                creator=data['creator'],
                mana_cost=data['mana_cost'],
                version=data['version']
            )
            contract.state = data['state']
            contract.metadata = data['metadata']
            contract.dependencies = set(data['dependencies'])
            contract.allowed_callers = set(data['allowed_callers'])
            contract.restrictions = data['restrictions']
            return contract
    
    
    class Blockchain:
        """Main blockchain implementation for ICN."""
        
        def __init__(self, num_shards: int = 4, initial_mana: int = 1000, 
                     mana_regen_rate: int = 10):
            self.num_shards = num_shards
            self.shards: Dict[int, Shard] = {
                i: Shard(i) for i in range(num_shards)
            }
            self.nodes: List[Node] = []
            self.consensus = ProofOfCooperation()
            self.contracts: Dict[str, SmartContract] = {}
            self.cooperative_mana = initial_mana
            self.mana_regen_rate = mana_regen_rate
            self.cross_shard_queue: Dict[int, List[Transaction]] = {
                i: [] for i in range(num_shards)
            }
            self.metadata: Dict = {
                'creation_time': datetime.now(),
                'last_update': datetime.now(),
                'version': "1.0",
                'network_name': "ICN MainNet",
                'network_id': hashlib.sha256(str(time.time()).encode()).hexdigest()[:8]
            }
            self.metrics: Dict = {
                'total_transactions': 0,
                'total_blocks': 0,
                'average_block_time': 0,
                'active_nodes': 0,
                'total_mana_consumed': 0
            }
            self.state: str = "active"
            self._initialize_network()
    
        def _initialize_network(self) -> None:
            """Initialize network configuration."""
            logger.info(f"Initializing ICN network {self.metadata['network_id']}")
            self._update_metrics()
    
        def add_node(self, node: Node) -> bool:
            """Add a new node to the network."""
            if any(n.node_id == node.node_id for n in self.nodes):
                return False
                
            self.nodes.append(node)
            self.metrics['active_nodes'] = len(
                [n for n in self.nodes if n.metadata['status'] == "active"]
            )
            logger.info(f"Added node {node.node_id} to network")
            return True
    
        def remove_node(self, node_id: str) -> bool:
            """Remove a node from the network."""
            node = self._get_node(node_id)
            if not node:
                return False
                
            self.nodes = [n for n in self.nodes if n.node_id != node_id]
            self.metrics['active_nodes'] = len(
                [n for n in self.nodes if n.metadata['status'] == "active"]
            )
            logger.info(f"Removed node {node_id} from network")
            return True
    
        def _get_node(self, node_id: str) -> Optional[Node]:
            """Get a node by its ID."""
            return next((n for n in self.nodes if n.node_id == node_id), None)
    
        def add_transaction(self, transaction: Dict) -> bool:
            """Add a new transaction to the network."""
            # Determine shard for transaction
            shard_id = self._calculate_shard_id(transaction)
            
            tx = Transaction(
                sender=transaction['sender'],
                receiver=transaction['receiver'],
                action=transaction['action'],
                data=transaction['data'],
                shard_id=shard_id
            )
            
            # Add to appropriate shard
            if self.shards[shard_id].add_transaction(tx):
                self.metrics['total_transactions'] += 1
                return True
            return False
    
        def _calculate_shard_id(self, transaction: Dict) -> int:
            """Calculate which shard should handle a transaction."""
            # Simple hash-based sharding
            tx_hash = hashlib.sha256(
                json.dumps(transaction, sort_keys=True).encode()
            ).hexdigest()
            return int(tx_hash, 16) % self.num_shards
    
        def create_block(self, shard_id: int) -> Optional[Block]:
            """Create a new block in specified shard."""
            shard = self.shards.get(shard_id)
            if not shard:
                return None
                
            # Select validator
            validator = self.consensus.select_validator(self.nodes, shard_id)
            if not validator:
                return None
                
            # Create block
            block = shard.create_block(validator.node_id)
            if not block:
                return None
                
            # Process cross-shard references
            self._add_cross_shard_refs(block)
            
            return block
    
        def _add_cross_shard_refs(self, block: Block) -> None:
            """Add cross-shard references to block."""
            cross_shard_txs = [
                tx for tx in block.transactions 
                if self._is_cross_shard_transaction(tx)
            ]
            
            for tx in cross_shard_txs:
                ref = self._create_cross_shard_ref(tx)
                if ref:
                    block.cross_shard_refs.append(ref)
    
        def _is_cross_shard_transaction(self, transaction: Transaction) -> bool:
            """Check if transaction involves multiple shards."""
            return 'target_shard' in transaction.data
    
        def _create_cross_shard_ref(self, transaction: Transaction) -> Optional[str]:
            """Create a reference for cross-shard transaction."""
            try:
                ref_data = {
                    'transaction_id': transaction.transaction_id,
                    'source_shard': transaction.shard_id,
                    'target_shard': transaction.data.get('target_shard'),
                    'timestamp': transaction.timestamp.isoformat()
                }
                return hashlib.sha256(
                    json.dumps(ref_data, sort_keys=True).encode()
                ).hexdigest()
            except Exception as e:
                logger.error(f"Failed to create cross-shard reference: {e}")
                return None
    
        def add_block(self, block: Block) -> bool:
            """Add a validated block to the network."""
            shard = self.shards.get(block.shard_id)
            if not shard:
                return False
                
            # Validate block
            validator = self._get_node(block.validator)
            if not validator:
                return False
                
            if not self.consensus.validate_block(block, shard.chain[-1], validator):
                return False
                
            # Add block to shard
            if shard.add_block(block):
                self._process_block_addition(block)
                return True
                
            return False
    
        def _process_block_addition(self, block: Block) -> None:
            """Process successful block addition."""
            self.metrics['total_blocks'] += 1
            self._update_metrics()
            
            # Process cross-shard references
            if block.cross_shard_refs:
                self._process_cross_shard_refs(block)
                
            logger.info(
                f"Added block {block.index} to shard {block.shard_id}")
                    def _process_cross_shard_refs(self, block: Block) -> None:
            """Process cross-shard references in a block."""
            for ref in block.cross_shard_refs:
                ref_data = self._parse_cross_shard_ref(ref)
                if ref_data:
                    target_shard = self.shards.get(ref_data['target_shard'])
                    if target_shard:
                        tx = self._create_cross_shard_transaction(ref_data)
                        target_shard.add_transaction(tx)
    
        def _parse_cross_shard_ref(self, ref: str) -> Optional[Dict]:
            """Parse cross-shard reference into transaction data."""
            try:
                ref_data = json.loads(hashlib.sha256(ref.encode()).hexdigest())
                return ref_data
            except Exception as e:
                logger.error(f"Failed to parse cross-shard reference: {e}")
                return None
    
        def _create_cross_shard_transaction(self, ref_data: Dict) -> Transaction:
            """Create a cross-shard transaction from reference data."""
            return Transaction(
                sender='cross-shard',
                receiver='target-shard',
                action='cross-shard-transfer',
                data=ref_data,
                shard_id=ref_data['target_shard']
            )
    
        def add_smart_contract(self, contract: SmartContract) -> bool:
            """Add a new smart contract to the network."""
            if contract.contract_id in self.contracts:
                return False
    
            self.contracts[contract.contract_id] = contract
            logger.info(f"Added smart contract {contract.contract_id} to network")
            return True
    
        def execute_smart_contract(self, contract_id: str, input_data: Dict) -> Dict:
            """Execute a smart contract with given input data."""
            contract = self.contracts.get(contract_id)
            if not contract:
                return {"error": "Contract not found"}
            
            # Check available mana
            if self.cooperative_mana < contract.mana_cost:
                return {"error": "Insufficient cooperative mana"}
            
            result = contract.execute(input_data, self.cooperative_mana)
            if "error" not in result:
                self.cooperative_mana -= contract.mana_cost
                self.metrics['total_mana_consumed'] += contract.mana_cost
            return result
    
        def regenerate_mana(self) -> None:
            """Regenerate cooperative mana over time."""
            self.cooperative_mana = min(
                self.cooperative_mana + self.mana_regen_rate,
                1000  # Max mana limit for demonstration purposes
            )
            self._update_metrics()
    
        def _update_metrics(self) -> None:
            """Update blockchain network metrics."""
            self.metadata['last_update'] = datetime.now().isoformat()
            self.metrics['average_block_time'] = sum(
                shard.metrics['average_block_time'] for shard in self.shards.values()
            ) / max(1, len(self.shards))
    
        def to_dict(self) -> Dict:
            """Convert blockchain to dictionary format."""
            return {
                'num_shards': self.num_shards,
                'nodes': [node.to_dict() for node in self.nodes],
                'contracts': {cid: contract.to_dict() for cid, contract in self.contracts.items()},
                'cooperative_mana': self.cooperative_mana,
                'metrics': self.metrics,
                'metadata': self.metadata
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> 'Blockchain':
            """Create blockchain from dictionary."""
            blockchain = cls(
                num_shards=data['num_shards'],
                initial_mana=data['cooperative_mana']
            )
            blockchain.nodes = [Node.from_dict(node) for node in data['nodes']]
            blockchain.contracts = {
                cid: SmartContract.from_dict(contract) 
                for cid, contract in data['contracts'].items()
            }
            blockchain.cooperative_mana = data['cooperative_mana']
            blockchain.metrics = data['metrics']
            blockchain.metadata = data['metadata']
            return blockchain
    
    
```

# File: /home/matt/icn-prototype/blockchain/integration.py

```py
    """
    blockchain/integration.py
    
    Provides system-wide initialization and integration management for the ICN blockchain.
    """
    
    import asyncio
    import logging
    from typing import Dict, Optional, Any
    from dataclasses import dataclass
    from datetime import datetime
    
    from .core.blockchain import Blockchain
    from .core.node import Node
    from .consensus.proof_of_cooperation import ProofOfCooperation
    from .network.manager import NetworkManager
    from .network.config import NetworkConfig
    from .contracts.contract_executor import ContractExecutor
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class SystemConfig:
        """System-wide configuration parameters."""
        network_config: NetworkConfig
        initial_mana: int = 1000
        mana_regen_rate: int = 10
        num_shards: int = 4
        min_nodes: int = 3
        max_nodes: int = 100
    
    class BlockchainSystem:
        """
        Manages system-wide initialization and coordination of blockchain components.
        Ensures proper interaction between core blockchain, consensus, and networking layers.
        """
    
        def __init__(self, config: SystemConfig):
            """Initialize the blockchain system with configuration."""
            self.config = config
            self.blockchain = None
            self.consensus = None
            self.network = None
            self.contract_executor = None
            self.started = False
            self.start_time = None
    
        async def initialize(self) -> bool:
            """
            Initialize all blockchain system components in the correct order.
            
            Returns:
                bool: True if initialization successful
            """
            try:
                # Initialize consensus mechanism
                self.consensus = ProofOfCooperation(
                    min_reputation=10.0,
                    cooldown_blocks=3
                )
    
                # Initialize blockchain
                self.blockchain = Blockchain(
                    num_shards=self.config.num_shards,
                    initial_mana=self.config.initial_mana,
                    mana_regen_rate=self.config.mana_regen_rate
                )
    
                # Initialize network manager
                self.network = NetworkManager(
                    config=self.config.network_config
                )
    
                # Initialize contract executor
                self.contract_executor = ContractExecutor(
                    initial_mana=self.config.initial_mana,
                    mana_regen_rate=self.config.mana_regen_rate
                )
    
                # Start network services
                await self.network.start()
    
                self.started = True
                self.start_time = datetime.now()
                
                logger.info("Blockchain system initialized successfully")
                return True
    
            except Exception as e:
                logger.error(f"Failed to initialize blockchain system: {str(e)}")
                await self.shutdown()
                return False
    
        async def shutdown(self) -> None:
            """Gracefully shutdown all system components."""
            try:
                if self.network:
                    await self.network.stop()
    
                self.started = False
                logger.info("Blockchain system shutdown completed")
    
            except Exception as e:
                logger.error(f"Error during system shutdown: {str(e)}")
    
        async def add_node(self, node: Node) -> bool:
            """
            Add a new node to the blockchain network.
            
            Args:
                node: The node to add
                
            Returns:
                bool: True if node added successfully
            """
            try:
                if len(self.blockchain.nodes) >= self.config.max_nodes:
                    logger.error("Maximum number of nodes reached")
                    return False
    
                # Register with blockchain
                if not self.blockchain.register_node(node):
                    return False
    
                # Initialize node network services
                await self.network.connect_to_peer(
                    node.node_id,
                    node.metadata.get("address", ""),
                    node.metadata.get("port", 0)
                )
    
                logger.info(f"Node {node.node_id} added successfully")
                return True
    
            except Exception as e:
                logger.error(f"Failed to add node: {str(e)}")
                return False
    
        async def process_transaction(self, transaction: Dict) -> bool:
            """
            Process a new transaction through the system.
            
            Args:
                transaction: Transaction data
                
            Returns:
                bool: True if transaction processed successfully
            """
            try:
                # Add transaction to blockchain
                if not self.blockchain.add_transaction(transaction):
                    return False
    
                # Broadcast transaction to network
                await self.network.broadcast_message(
                    "transaction",
                    {"transaction": transaction}
                )
    
                return True
    
            except Exception as e:
                logger.error(f"Failed to process transaction: {str(e)}")
                return False
    
        async def create_block(self, validator_id: str, shard_id: Optional[int] = None) -> bool:
            """
            Create a new block using the specified validator.
            
            Args:
                validator_id: ID of the validating node
                shard_id: Optional shard ID
                
            Returns:
                bool: True if block created successfully
            """
            try:
                # Get validator node
                validator = self.blockchain.nodes.get(validator_id)
                if not validator:
                    return False
    
                # Create block
                block = self.blockchain.create_block(shard_id)
                if not block:
                    return False
    
                # Validate block
                if not self.consensus.validate_block(block, self.blockchain.chain[-1], validator):
                    return False
    
                # Add block to chain
                if not self.blockchain.add_block(block):
                    return False
    
                # Broadcast block to network
                await self.network.broadcast_message(
                    "block",
                    {"block": block.to_dict()}
                )
    
                return True
    
            except Exception as e:
                logger.error(f"Failed to create block: {str(e)}")
                return False
    
        def get_system_status(self) -> Dict[str, Any]:
            """Get comprehensive system status."""
            return {
                "started": self.started,
                "uptime": (datetime.now() - self.start_time).total_seconds() if self.start_time else 0,
                "blockchain_metrics": self.blockchain.get_chain_metrics(),
                "consensus_metrics": self.consensus.get_metrics(),
                "network_metrics": self.network.get_metrics() if self.network else {},
                "node_count": len(self.blockchain.nodes),
                "shard_count": len(self.blockchain.shards)
            }
    
        def __str__(self) -> str:
            """String representation of system status."""
            return (
                f"BlockchainSystem(started={self.started}, "
                f"nodes={len(self.blockchain.nodes) if self.blockchain else 0}, "
                f"shards={self.config.num_shards})"
            )
```

# File: /home/matt/icn-prototype/blockchain/__init__.py

```py
    # blockchain/__init__.py
    """
    Import core components and make them available at the package level.
    We're using relative imports to properly handle the package hierarchy.
    """
    from .core.node import Node
    from .core.block import Block
    from .core.transaction import Transaction 
    from .core.shard import Shard
    from .core.blockchain import Blockchain
    
    __all__ = [
        "Node",
        "Block", 
        "Transaction",
        "Shard",
        "Blockchain"
    ]
```

# File: /home/matt/icn-prototype/blockchain/utils/metrics.py

```py
    # ================================================================
    # File: blockchain/utils/metrics.py
    # Description: This file contains functions and classes for managing
    # performance and operational metrics within the ICN ecosystem.
    # These metrics are used to track node performance, block creation,
    # transaction validation, and overall network health.
    # ================================================================
    
    from typing import Dict, List
    from datetime import datetime, timedelta
    import logging
    
    logger = logging.getLogger(__name__)
    
    class MetricsManager:
        """
        The MetricsManager handles the collection, analysis, and reporting of
        performance metrics within the ICN. It tracks node performance, transaction
        throughput, validation success rates, and resource utilization to provide
        real-time feedback for improving cooperative efficiency.
        """
    
        def __init__(self):
            """
            Initialize the MetricsManager.
    
            This constructor sets up the basic metrics structure, including
            performance, transaction, and resource usage metrics.
            """
            self.metrics: Dict = {
                "total_blocks_created": 0,
                "total_transactions_processed": 0,
                "average_block_creation_time": 0.0,
                "average_transaction_validation_time": 0.0,
                "resource_utilization": {
                    "cpu": 0.0,
                    "memory": 0.0,
                    "bandwidth": 0.0,
                    "storage": 0.0,
                },
                "validation_success_rate": 0.0,
                "uptime": 0.0,
            }
            self.start_time = datetime.now()
    
        def update_block_creation(self, creation_time: float) -> None:
            """
            Update metrics related to block creation.
    
            Args:
                creation_time (float): Time taken to create a new block.
            """
            try:
                self.metrics["total_blocks_created"] += 1
                total_time = (
                    self.metrics["average_block_creation_time"]
                    * (self.metrics["total_blocks_created"] - 1)
                )
                self.metrics["average_block_creation_time"] = (
                    total_time + creation_time
                ) / self.metrics["total_blocks_created"]
                logger.info("Updated block creation metrics")
    
            except Exception as e:
                logger.error(f"Failed to update block creation metrics: {str(e)}")
    
        def update_transaction_processing(self, processing_time: float) -> None:
            """
            Update metrics related to transaction processing.
    
            Args:
                processing_time (float): Time taken to validate a transaction.
            """
            try:
                self.metrics["total_transactions_processed"] += 1
                total_time = (
                    self.metrics["average_transaction_validation_time"]
                    * (self.metrics["total_transactions_processed"] - 1)
                )
                self.metrics["average_transaction_validation_time"] = (
                    total_time + processing_time
                ) / self.metrics["total_transactions_processed"]
                logger.info("Updated transaction processing metrics")
    
            except Exception as e:
                logger.error(f"Failed to update transaction metrics: {str(e)}")
    
        def update_resource_utilization(self, utilization: Dict[str, float]) -> None:
            """
            Update resource utilization metrics.
    
            Args:
                utilization (Dict[str, float]): Resource utilization metrics for
                CPU, memory, bandwidth, and storage.
            """
            try:
                for resource, value in utilization.items():
                    if resource in self.metrics["resource_utilization"]:
                        self.metrics["resource_utilization"][resource] = max(
                            0.0, value
                        )
                logger.info("Updated resource utilization metrics")
    
            except Exception as e:
                logger.error(f"Failed to update resource utilization: {str(e)}")
    
        def update_validation_success(self, successful: bool) -> None:
            """
            Update validation success rate.
    
            Args:
                successful (bool): True if the validation was successful, False otherwise.
            """
            try:
                total_validations = self.metrics.get("total_validations", 0) + 1
                successful_validations = self.metrics.get("successful_validations", 0)
    
                if successful:
                    successful_validations += 1
    
                self.metrics["validation_success_rate"] = (
                    successful_validations / total_validations * 100
                )
                self.metrics["total_validations"] = total_validations
                self.metrics["successful_validations"] = successful_validations
    
                logger.info("Updated validation success metrics")
    
            except Exception as e:
                logger.error(f"Failed to update validation success rate: {str(e)}")
    
        def calculate_uptime(self) -> None:
            """
            Calculate the node's uptime since the start of the MetricsManager.
            """
            try:
                uptime_seconds = (datetime.now() - self.start_time).total_seconds()
                self.metrics["uptime"] = uptime_seconds / 3600  # uptime in hours
                logger.info("Calculated node uptime")
    
            except Exception as e:
                logger.error(f"Failed to calculate uptime: {str(e)}")
    
        def get_metrics(self) -> Dict:
            """
            Retrieve the current metrics.
    
            Returns:
                Dict: A dictionary containing all current metrics.
            """
            try:
                self.calculate_uptime()
                return self.metrics
    
            except Exception as e:
                logger.error(f"Failed to get metrics: {str(e)}")
                return {}
    
        def reset_metrics(self) -> None:
            """
            Reset all metrics to initial values.
            """
            try:
                self.__init__()  # Re-initialize the metrics manager
                logger.info("Reset all metrics")
    
            except Exception as e:
                logger.error(f"Failed to reset metrics: {str(e)}")
```

# File: /home/matt/icn-prototype/blockchain/utils/validation.py

```py
    # ================================================================
    # File: blockchain/utils/validation.py
    # Description: Contains validation functions for transactions,
    # blocks, and cooperative interactions within the ICN. These functions
    # ensure data integrity, compliance with cooperative rules, and secure
    # operation of the ICN blockchain.
    # ================================================================
    
    from typing import Dict, List, Any, Optional
    import hashlib
    import logging
    from datetime import datetime, timedelta
    
    logger = logging.getLogger(__name__)
    
    def validate_transaction(transaction: Dict) -> bool:
        """
        Validate a transaction based on predefined rules.
    
        This function checks transaction structure, required fields, and
        cryptographic integrity, ensuring that transactions comply with the
        ICNs cooperative principles.
    
        Args:
            transaction (Dict): A dictionary representing a transaction.
    
        Returns:
            bool: True if the transaction is valid, False otherwise.
        """
        try:
            # Check required fields
            required_fields = ["transaction_id", "sender", "receiver", "amount", "signature", "timestamp"]
            for field in required_fields:
                if field not in transaction:
                    logger.error(f"Transaction missing required field: {field}")
                    return False
    
            # Validate amount
            if transaction["amount"] <= 0:
                logger.error("Transaction amount must be greater than zero")
                return False
    
            # Validate timestamp
            transaction_time = datetime.fromisoformat(transaction["timestamp"])
            current_time = datetime.now()
            if transaction_time > current_time + timedelta(minutes=5):
                logger.error("Transaction timestamp is in the future")
                return False
    
            # Verify transaction signature (placeholder logic)
            if not _verify_signature(transaction):
                logger.error("Transaction signature verification failed")
                return False
    
            logger.info(f"Transaction {transaction['transaction_id']} is valid")
            return True
    
        except Exception as e:
            logger.error(f"Transaction validation failed: {str(e)}")
            return False
    
    def validate_block(block: Dict, previous_block: Optional[Dict] = None) -> bool:
        """
        Validate a block based on structure, integrity, and consistency rules.
    
        This function checks the blocks cryptographic hash, Merkle root,
        timestamp, and transactions to ensure compliance with cooperative principles.
    
        Args:
            block (Dict): A dictionary representing a block.
            previous_block (Optional[Dict]): The previous block in the chain.
    
        Returns:
            bool: True if the block is valid, False otherwise.
        """
        try:
            # Check required fields
            required_fields = ["index", "previous_hash", "timestamp", "transactions", "hash", "merkle_root"]
            for field in required_fields:
                if field not in block:
                    logger.error(f"Block missing required field: {field}")
                    return False
    
            # Validate block index
            if previous_block and block["index"] != previous_block["index"] + 1:
                logger.error("Block index is not sequential")
                return False
    
            # Validate previous hash
            if previous_block and block["previous_hash"] != previous_block["hash"]:
                logger.error("Block previous hash does not match")
                return False
    
            # Validate timestamp
            block_time = datetime.fromisoformat(block["timestamp"])
            if block_time > datetime.now() + timedelta(minutes=5):
                logger.error("Block timestamp is in the future")
                return False
    
            if previous_block and block_time <= datetime.fromisoformat(previous_block["timestamp"]):
                logger.error("Block timestamp is not after the previous block")
                return False
    
            # Validate Merkle root
            if not _validate_merkle_root(block["transactions"], block["merkle_root"]):
                logger.error("Block Merkle root validation failed")
                return False
    
            # Validate block hash
            if not _validate_block_hash(block):
                logger.error("Block hash validation failed")
                return False
    
            logger.info(f"Block {block['index']} is valid")
            return True
    
        except Exception as e:
            logger.error(f"Block validation failed: {str(e)}")
            return False
    
    def _validate_merkle_root(transactions: List[Dict], expected_merkle_root: str) -> bool:
        """
        Validate the Merkle root of a list of transactions.
    
        Args:
            transactions (List[Dict]): List of transaction dictionaries.
            expected_merkle_root (str): The expected Merkle root hash.
    
        Returns:
            bool: True if the Merkle root is valid, False otherwise.
        """
        try:
            if not transactions:
                return expected_merkle_root == hashlib.sha256(b"empty").hexdigest()
    
            # Create leaf nodes from transactions
            leaves = [hashlib.sha256(json.dumps(tx).encode()).hexdigest() for tx in transactions]
    
            # Build Merkle tree
            while len(leaves) > 1:
                if len(leaves) % 2 == 1:
                    leaves.append(leaves[-1])
                leaves = [
                    hashlib.sha256((a + b).encode()).hexdigest()
                    for a, b in zip(leaves[::2], leaves[1::2])
                ]
    
            return leaves[0] == expected_merkle_root
    
        except Exception as e:
            logger.error(f"Failed to validate Merkle root: {str(e)}")
            return False
    
    def _validate_block_hash(block: Dict) -> bool:
        """
        Validate the block's hash by recalculating it.
    
        Args:
            block (Dict): A dictionary representing a block.
    
        Returns:
            bool: True if the hash is valid, False otherwise.
        """
        try:
            block_data = {
                "index": block["index"],
                "previous_hash": block["previous_hash"],
                "timestamp": block["timestamp"],
                "merkle_root": block["merkle_root"],
            }
            recalculated_hash = hashlib.sha256(
                json.dumps(block_data, sort_keys=True).encode()
            ).hexdigest()
    
            return recalculated_hash == block["hash"]
    
        except Exception as e:
            logger.error(f"Failed to validate block hash: {str(e)}")
            return False
    
    def _verify_signature(transaction: Dict) -> bool:
        """
        Placeholder function to verify the transaction signature.
    
        This function simulates signature verification and should be replaced with
        actual cryptographic verification logic.
    
        Args:
            transaction (Dict): A dictionary representing a transaction.
    
        Returns:
            bool: True if the signature is valid, False otherwise.
        """
        # Placeholder for signature verification logic
        return True
    
    def validate_cooperative_interaction(interaction: Dict) -> bool:
        """
        Validate cooperative interactions such as votes, proposals, and resource sharing.
    
        This function ensures that cooperative interactions comply with ICN rules,
        supporting fair governance and resource management.
    
        Args:
            interaction (Dict): A dictionary representing a cooperative interaction.
    
        Returns:
            bool: True if the interaction is valid, False otherwise.
        """
        try:
            # Check required fields
            required_fields = ["interaction_id", "type", "initiator", "target", "timestamp"]
            for field in required_fields:
                if field not in interaction:
                    logger.error(f"Interaction missing required field: {field}")
                    return False
    
            # Validate timestamp
            interaction_time = datetime.fromisoformat(interaction["timestamp"])
            if interaction_time > datetime.now() + timedelta(minutes=5):
                logger.error("Interaction timestamp is in the future")
                return False
    
            logger.info(f"Cooperative interaction {interaction['interaction_id']} is valid")
            return True
    
        except Exception as e:
            logger.error(f"Cooperative interaction validation failed: {str(e)}")
            return False
```

# File: /home/matt/icn-prototype/blockchain/utils/__init__.py

```py
    # blockchain/utils/__init__.py
    
    from .metrics import Metrics
    from .validation import validate_transaction, validate_block
    
    __all__ = [
        "Metrics",
        "validate_transaction",
        "validate_block"
    ]
```

# File: /home/matt/icn-prototype/blockchain/utils/crypto.py

```py
    # ================================================================
    # File: blockchain/utils/crypto.py
    # Description: Contains cryptographic functions for securing the ICN
    # blockchain. Includes hashing, signing, and signature verification to
    # ensure the integrity, authenticity, and confidentiality of transactions
    # and blocks.
    # ================================================================
    
    from typing import Any, Tuple, Optional
    from cryptography.hazmat.primitives import hashes, serialization
    from cryptography.hazmat.primitives.asymmetric import rsa, padding
    from cryptography.hazmat.primitives.asymmetric.utils import Prehashed
    from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
    from cryptography.hazmat.backends import default_backend
    from cryptography.hazmat.primitives.kdf.hkdf import HKDF
    from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes
    from cryptography.hazmat.primitives import hmac
    import os
    import base64
    import logging
    
    logger = logging.getLogger(__name__)
    
    # Constants for encryption/decryption
    AES_KEY_SIZE = 32
    IV_SIZE = 16
    
    def generate_rsa_key_pair() -> Tuple[rsa.RSAPrivateKey, rsa.RSAPublicKey]:
        """
        Generate an RSA key pair for signing and verification.
    
        Returns:
            Tuple: A tuple containing the RSA private key and public key.
        """
        try:
            private_key = rsa.generate_private_key(
                public_exponent=65537,
                key_size=2048,
                backend=default_backend()
            )
            public_key = private_key.public_key()
            logger.info("Generated RSA key pair")
            return private_key, public_key
    
        except Exception as e:
            logger.error(f"Failed to generate RSA key pair: {str(e)}")
            raise
    
    def sign_data(private_key: rsa.RSAPrivateKey, data: bytes) -> bytes:
        """
        Sign data using a private RSA key.
    
        Args:
            private_key (rsa.RSAPrivateKey): The private RSA key.
            data (bytes): The data to be signed.
    
        Returns:
            bytes: The signature of the data.
        """
        try:
            signature = private_key.sign(
                data,
                padding.PSS(
                    mgf=padding.MGF1(hashes.SHA256()),
                    salt_length=padding.PSS.MAX_LENGTH
                ),
                hashes.SHA256()
            )
            logger.info("Data signed successfully")
            return signature
    
        except Exception as e:
            logger.error(f"Failed to sign data: {str(e)}")
            raise
    
    def verify_signature(
        public_key: rsa.RSAPublicKey, signature: bytes, data: bytes
    ) -> bool:
        """
        Verify the signature of data using a public RSA key.
    
        Args:
            public_key (rsa.RSAPublicKey): The public RSA key.
            signature (bytes): The signature to verify.
            data (bytes): The data that was signed.
    
        Returns:
            bool: True if the signature is valid, False otherwise.
        """
        try:
            public_key.verify(
                signature,
                data,
                padding.PSS(
                    mgf=padding.MGF1(hashes.SHA256()),
                    salt_length=padding.PSS.MAX_LENGTH
                ),
                hashes.SHA256()
            )
            logger.info("Signature verified successfully")
            return True
    
        except Exception as e:
            logger.error(f"Signature verification failed: {str(e)}")
            return False
    
    def hash_data(data: bytes) -> str:
        """
        Hash data using SHA-256.
    
        Args:
            data (bytes): The data to be hashed.
    
        Returns:
            str: The SHA-256 hash of the data in hexadecimal format.
        """
        try:
            digest = hashes.Hash(hashes.SHA256(), backend=default_backend())
            digest.update(data)
            hash_hex = digest.finalize().hex()
            logger.info("Data hashed successfully")
            return hash_hex
    
        except Exception as e:
            logger.error(f"Failed to hash data: {str(e)}")
            raise
    
    def derive_key(password: bytes, salt: bytes, iterations: int = 100000) -> bytes:
        """
        Derive a cryptographic key from a password using PBKDF2-HMAC-SHA256.
    
        Args:
            password (bytes): The password to derive the key from.
            salt (bytes): The salt for key derivation.
            iterations (int): Number of iterations for the key derivation.
    
        Returns:
            bytes: The derived key.
        """
        try:
            kdf = PBKDF2HMAC(
                algorithm=hashes.SHA256(),
                length=AES_KEY_SIZE,
                salt=salt,
                iterations=iterations,
                backend=default_backend()
            )
            key = kdf.derive(password)
            logger.info("Key derived successfully from password")
            return key
    
        except Exception as e:
            logger.error(f"Failed to derive key: {str(e)}")
            raise
    
    def aes_encrypt(key: bytes, plaintext: bytes) -> Tuple[bytes, bytes]:
        """
        Encrypt data using AES in CBC mode.
    
        Args:
            key (bytes): The AES key.
            plaintext (bytes): The data to be encrypted.
    
        Returns:
            Tuple: The IV and ciphertext.
        """
        try:
            iv = os.urandom(IV_SIZE)
            cipher = Cipher(
                algorithms.AES(key),
                modes.CBC(iv),
                backend=default_backend()
            )
            encryptor = cipher.encryptor()
    
            # Pad plaintext to block size
            padding_length = AES_KEY_SIZE - (len(plaintext) % AES_KEY_SIZE)
            padded_plaintext = plaintext + bytes([padding_length] * padding_length)
    
            ciphertext = encryptor.update(padded_plaintext) + encryptor.finalize()
            logger.info("Data encrypted successfully")
            return iv, ciphertext
    
        except Exception as e:
            logger.error(f"Failed to encrypt data: {str(e)}")
            raise
    
    def aes_decrypt(key: bytes, iv: bytes, ciphertext: bytes) -> bytes:
        """
        Decrypt data using AES in CBC mode.
    
        Args:
            key (bytes): The AES key.
            iv (bytes): The initialization vector (IV).
            ciphertext (bytes): The data to be decrypted.
    
        Returns:
            bytes: The decrypted plaintext.
        """
        try:
            cipher = Cipher(
                algorithms.AES(key),
                modes.CBC(iv),
                backend=default_backend()
            )
            decryptor = cipher.decryptor()
    
            padded_plaintext = decryptor.update(ciphertext) + decryptor.finalize()
    
            # Remove padding
            padding_length = padded_plaintext[-1]
            plaintext = padded_plaintext[:-padding_length]
    
            logger.info("Data decrypted successfully")
            return plaintext
    
        except Exception as e:
            logger.error(f"Failed to decrypt data: {str(e)}")
            raise
    
    def hmac_sign(key: bytes, data: bytes) -> bytes:
        """
        Generate an HMAC signature for data using a symmetric key.
    
        Args:
            key (bytes): The symmetric key.
            data (bytes): The data to be signed.
    
        Returns:
            bytes: The HMAC signature.
        """
        try:
            hmac_obj = hmac.HMAC(key, hashes.SHA256(), backend=default_backend())
            hmac_obj.update(data)
            signature = hmac_obj.finalize()
            logger.info("HMAC signature generated successfully")
            return signature
    
        except Exception as e:
            logger.error(f"Failed to generate HMAC signature: {str(e)}")
            raise
    
    def hmac_verify(key: bytes, signature: bytes, data: bytes) -> bool:
        """
        Verify an HMAC signature for data using a symmetric key.
    
        Args:
            key (bytes): The symmetric key.
            signature (bytes): The HMAC signature to verify.
            data (bytes): The data that was signed.
    
        Returns:
            bool: True if the HMAC is valid, False otherwise.
        """
        try:
            hmac_obj = hmac.HMAC(key, hashes.SHA256(), backend=default_backend())
            hmac_obj.update(data)
            hmac_obj.verify(signature)
            logger.info("HMAC signature verified successfully")
            return True
    
        except Exception as e:
            logger.error(f"HMAC verification failed: {str(e)}")
            return False
```

# File: /home/matt/icn-prototype/blockchain/network/config.py

```py
    # ================================================================
    # File: blockchain/network/config.py
    # Description: Network configuration settings for the ICN network.
    # Defines network parameters, protocols, and connection settings
    # for the InterCooperative Network.
    # ================================================================
    
    from dataclasses import dataclass, field
    from typing import Dict, List, Optional, Set
    import os
    import json
    import logging
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class NetworkConfig:
        """Network configuration parameters."""
        
        # Node identification
        node_id: str
        cooperative_id: Optional[str] = None
        
        # Network addresses
        host: str = "0.0.0.0"
        port: int = 30303
        discovery_port: int = 30304
        
        # Connection limits
        max_peers: int = 50
        min_peers: int = 10
        max_connections_per_ip: int = 5
        connection_timeout: int = 30
        
        # Protocol settings
        supported_protocols: Set[str] = field(default_factory=lambda: {"icn/1.0", "icn/1.1"})
        min_protocol_version: str = "icn/1.0"
        max_message_size: int = 1024 * 1024  # 1MB
        
        # Discovery settings
        discovery_interval: int = 300  # 5 minutes
        bootstrap_nodes: List[Dict[str, Any]] = field(default_factory=list)
        enable_auto_discovery: bool = True
        discovery_methods: Set[str] = field(default_factory=lambda: {"broadcast", "bootstrap", "peer"})
        
        # Resource limits
        max_inbound_connections: int = 40
        max_outbound_connections: int = 20
        max_pending_connections: int = 10
        buffer_size: int = 1024 * 16  # 16KB
        
        # Performance settings
        read_timeout: float = 30.0
        write_timeout: float = 30.0
        keepalive_interval: int = 60
        ping_interval: int = 120
        
        # Security settings
        enable_encryption: bool = True
        require_node_id_verification: bool = True
        blacklist_threshold: int = 3
        reputation_threshold: float = 0.3
        
        # Cooperative settings
        prioritize_cooperative_peers: bool = True
        cooperative_connection_bonus: float = 0.2
        min_cooperative_peers: int = 5
        
        # Metrics and monitoring
        metrics_interval: int = 60
        log_metrics: bool = True
        enable_peer_scoring: bool = True
        
        @classmethod
        def load_from_file(cls, filepath: str) -> 'NetworkConfig':
            """
            Load configuration from a JSON file.
            
            Args:
                filepath: Path to configuration file
                
            Returns:
                NetworkConfig: Loaded configuration
            """
            try:
                if not os.path.exists(filepath):
                    raise FileNotFoundError(f"Configuration file not found: {filepath}")
                    
                with open(filepath, 'r') as f:
                    config_data = json.load(f)
                    
                # Validate required fields
                if "node_id" not in config_data:
                    raise ValueError("Configuration must include node_id")
                    
                return cls(**config_data)
                
            except Exception as e:
                logger.error(f"Error loading network configuration: {str(e)}")
                raise
        
        def save_to_file(self, filepath: str) -> None:
            """
            Save configuration to a JSON file.
            
            Args:
                filepath: Path to save configuration to
            """
            try:
                # Convert config to dictionary
                config_dict = {
                    "node_id": self.node_id,
                    "cooperative_id": self.cooperative_id,
                    "host": self.host,
                    "port": self.port,
                    "discovery_port": self.discovery_port,
                    "max_peers": self.max_peers,
                    "min_peers": self.min_peers,
                    "max_connections_per_ip": self.max_connections_per_ip,
                    "connection_timeout": self.connection_timeout,
                    "supported_protocols": list(self.supported_protocols),
                    "min_protocol_version": self.min_protocol_version,
                    "max_message_size": self.max_message_size,
                    "discovery_interval": self.discovery_interval,
                    "bootstrap_nodes": self.bootstrap_nodes,
                    "enable_auto_discovery": self.enable_auto_discovery,
                    "discovery_methods": list(self.discovery_methods),
                    "max_inbound_connections": self.max_inbound_connections,
                    "max_outbound_connections": self.max_outbound_connections,
                    "max_pending_connections": self.max_pending_connections,
                    "buffer_size": self.buffer_size,
                    "read_timeout": self.read_timeout,
                    "write_timeout": self.write_timeout,
                    "keepalive_interval": self.keepalive_interval,
                    "ping_interval": self.ping_interval,
                    "enable_encryption": self.enable_encryption,
                    "require_node_id_verification": self.require_node_id_verification,
                    "blacklist_threshold": self.blacklist_threshold,
                    "reputation_threshold": self.reputation_threshold,
                    "prioritize_cooperative_peers": self.prioritize_cooperative_peers,
                    "cooperative_connection_bonus": self.cooperative_connection_bonus,
                    "min_cooperative_peers": self.min_cooperative_peers,
                    "metrics_interval": self.metrics_interval,
                    "log_metrics": self.log_metrics,
                    "enable_peer_scoring": self.enable_peer_scoring
                }
                
                # Save to file
                with open(filepath, 'w') as f:
                    json.dump(config_dict, f, indent=4)
                    
                logger.info(f"Network configuration saved to {filepath}")
                
            except Exception as e:
                logger.error(f"Error saving network configuration: {str(e)}")
                raise
        
        def validate(self) -> bool:
            """
            Validate configuration settings.
            
            Returns:
                bool: True if configuration is valid
            """
            try:
                # Validate node identification
                if not self.node_id or len(self.node_id) < 8:
                    logger.error("Invalid node_id")
                    return False
                
                # Validate network settings
                if self.port < 1024 or self.port > 65535:
                    logger.error("Invalid port number")
                    return False
                    
                if self.discovery_port < 1024 or self.discovery_port > 65535:
                    logger.error("Invalid discovery port")
                    return False
                    
                # Validate connection limits
                if self.max_peers < self.min_peers:
                    logger.error("max_peers cannot be less than min_peers")
                    return False
                    
                if self.max_inbound_connections + self.max_outbound_connections > self.max_peers:
                    logger.error("Total connections cannot exceed max_peers")
                    return False
                    
                # Validate timeouts
                if self.read_timeout <= 0 or self.write_timeout <= 0:
                    logger.error("Timeouts must be positive")
                    return False
                    
                # Validate intervals
                if (self.keepalive_interval <= 0 or self.ping_interval <= 0 or 
                    self.metrics_interval <= 0 or self.discovery_interval <= 0):
                    logger.error("Intervals must be positive")
                    return False
                    
                # Validate thresholds
                if self.reputation_threshold < 0 or self.reputation_threshold > 1:
                    logger.error("Reputation threshold must be between 0 and 1")
                    return False
                    
                # Validate cooperative settings
                if self.min_cooperative_peers > self.max_peers:
                    logger.error("min_cooperative_peers cannot exceed max_peers")
                    return False
                    
                if self.cooperative_connection_bonus < 0 or self.cooperative_connection_bonus > 1:
                    logger.error("cooperative_connection_bonus must be between 0 and 1")
                    return False
                    
                # Validate protocol settings
                if not self.supported_protocols:
                    logger.error("Must support at least one protocol version")
                    return False
                    
                if self.min_protocol_version not in self.supported_protocols:
                    logger.error("min_protocol_version must be in supported_protocols")
                    return False
                    
                return True
                
            except Exception as e:
                logger.error(f"Error validating configuration: {str(e)}")
                return False
        
        def get_discovery_config(self) -> Dict[str, Any]:
            """
            Get discovery-specific configuration.
            
            Returns:
                Dict[str, Any]: Discovery configuration parameters
            """
            return {
                "port": self.discovery_port,
                "interval": self.discovery_interval,
                "bootstrap_nodes": self.bootstrap_nodes,
                "enable_auto": self.enable_auto_discovery,
                "methods": list(self.discovery_methods)
            }
        
        def get_connection_limits(self) -> Dict[str, int]:
            """
            Get connection limit configuration.
            
            Returns:
                Dict[str, int]: Connection limits
            """
            return {
                "max_peers": self.max_peers,
                "min_peers": self.min_peers,
                "max_inbound": self.max_inbound_connections,
                "max_outbound": self.max_outbound_connections,
                "max_pending": self.max_pending_connections,
                "max_per_ip": self.max_connections_per_ip
            }
    
    # Default configuration
    DEFAULT_CONFIG = NetworkConfig(
        node_id="",  # Must be set by application
        host="0.0.0.0",
        port=30303,
        discovery_port=30304,
        bootstrap_nodes=[
            {
                "node_id": "bootstrap-1",
                "address": "bootstrap1.icn.network",
                "port": 30303
            },
            {
                "node_id": "bootstrap-2",
                "address": "bootstrap2.icn.network",
                "port": 30303
            }
        ]
    )
```

# File: /home/matt/icn-prototype/blockchain/network/manager.py

```py
    # ================================================================
    # File: blockchain/network/manager.py
    # Description: Core network management for the ICN blockchain.
    # This module handles P2P networking, message routing, and peer
    # management for the InterCooperative Network.
    # ================================================================
    
    import asyncio
    import logging
    import json
    from typing import Dict, Set, Optional, Callable, Any, List
    from datetime import datetime
    from dataclasses import dataclass, field
    import hashlib
    import random
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class PeerInfo:
        """Information about a connected peer."""
        node_id: str
        address: str
        port: int
        last_seen: datetime = field(default_factory=datetime.now)
        reputation: float = 1.0
        cooperative_id: Optional[str] = None
        supported_protocols: Set[str] = field(default_factory=set)
        connection_attempts: int = 0
        is_active: bool = False
        metadata: Dict[str, Any] = field(default_factory=dict)
    
    @dataclass
    class Message:
        """Network message structure."""
        message_type: str
        payload: Dict[str, Any]
        sender: str
        timestamp: datetime = field(default_factory=datetime.now)
        message_id: str = field(init=False)
    
        def __post_init__(self):
            """Generate unique message ID after initialization."""
            message_data = f"{self.message_type}:{self.sender}:{self.timestamp.isoformat()}"
            self.message_id = hashlib.sha256(message_data.encode()).hexdigest()
    
    class NetworkManager:
        """
        Manages P2P networking for the ICN blockchain.
        
        Responsibilities:
        - Peer discovery and connection management
        - Message routing and broadcasting
        - Network state monitoring
        - Protocol version management
        """
    
        def __init__(self, node_id: str, host: str, port: int, max_peers: int = 50):
            """
            Initialize the network manager.
            
            Args:
                node_id: Unique identifier for this node
                host: Host address to bind to
                port: Port to listen on
                max_peers: Maximum number of peer connections
            """
            self.node_id = node_id
            self.host = host
            self.port = port
            self.max_peers = max_peers
    
            # Connection management
            self.peers: Dict[str, PeerInfo] = {}
            self.blacklisted_peers: Set[str] = set()
            self.pending_connections: Set[str] = set()
            self.connection_timeout = 30  # seconds
    
            # Message handling
            self.message_handlers: Dict[str, List[Callable]] = {}
            self.processed_messages: Set[str] = set()
            self.message_cache_size = 1000
    
            # Protocol versioning
            self.supported_protocols = {"icn/1.0", "icn/1.1"}
            self.min_protocol_version = "icn/1.0"
    
            # State
            self.is_running = False
            self.server: Optional[asyncio.Server] = None
            self.metrics: Dict[str, Any] = {
                "messages_processed": 0,
                "messages_sent": 0,
                "failed_connections": 0,
                "active_connections": 0
            }
    
        async def start(self) -> None:
            """Start the network manager and begin accepting connections."""
            if self.is_running:
                return
    
            try:
                # Start TCP server
                self.server = await asyncio.start_server(
                    self._handle_connection,
                    self.host,
                    self.port
                )
                self.is_running = True
                
                # Start background tasks
                asyncio.create_task(self._maintenance_loop())
                asyncio.create_task(self._metrics_loop())
                
                logger.info(f"Network manager started on {self.host}:{self.port}")
                
                # Serve forever
                async with self.server:
                    await self.server.serve_forever()
                    
            except Exception as e:
                logger.error(f"Failed to start network manager: {str(e)}")
                raise
    
        async def stop(self) -> None:
            """Stop the network manager and close all connections."""
            if not self.is_running:
                return
    
            try:
                # Close all peer connections
                close_tasks = [
                    self._close_peer_connection(peer_id)
                    for peer_id in list(self.peers.keys())
                ]
                await asyncio.gather(*close_tasks, return_exceptions=True)
    
                # Stop server
                if self.server:
                    self.server.close()
                    await self.server.wait_closed()
    
                self.is_running = False
                logger.info("Network manager stopped")
    
            except Exception as e:
                logger.error(f"Error stopping network manager: {str(e)}")
                raise
    
        async def connect_to_peer(self, peer_id: str, address: str, port: int) -> bool:
            """
            Establish connection to a new peer.
            
            Args:
                peer_id: Unique identifier of the peer
                address: Peer's network address
                port: Peer's port number
                
            Returns:
                bool: True if connection successful, False otherwise
            """
            if peer_id in self.blacklisted_peers:
                logger.warning(f"Attempted to connect to blacklisted peer: {peer_id}")
                return False
    
            if peer_id in self.peers:
                logger.debug(f"Already connected to peer: {peer_id}")
                return True
    
            if len(self.peers) >= self.max_peers:
                logger.warning("Maximum peer connections reached")
                return False
    
            try:
                # Attempt TCP connection
                reader, writer = await asyncio.open_connection(address, port)
    
                # Create peer info
                peer_info = PeerInfo(
                    node_id=peer_id,
                    address=address,
                    port=port
                )
    
                # Perform handshake
                if not await self._perform_handshake(reader, writer, peer_info):
                    writer.close()
                    await writer.wait_closed()
                    return False
    
                # Store peer connection
                self.peers[peer_id] = peer_info
                self.metrics["active_connections"] += 1
    
                # Start message handling loop
                asyncio.create_task(self._handle_peer_messages(reader, writer, peer_id))
    
                logger.info(f"Successfully connected to peer: {peer_id}")
                return True
    
            except Exception as e:
                logger.error(f"Failed to connect to peer {peer_id}: {str(e)}")
                self.metrics["failed_connections"] += 1
                return False
    
        async def broadcast_message(self, message_type: str, payload: Dict[str, Any]) -> None:
            """
            Broadcast a message to all connected peers.
            
            Args:
                message_type: Type of message to broadcast
                payload: Message payload data
            """
            message = Message(
                message_type=message_type,
                payload=payload,
                sender=self.node_id
            )
    
            try:
                send_tasks = []
                for peer_id, peer_info in self.peers.items():
                    if peer_info.is_active:
                        send_tasks.append(
                            self._send_message_to_peer(peer_id, message)
                        )
    
                await asyncio.gather(*send_tasks, return_exceptions=True)
                self.metrics["messages_sent"] += len(send_tasks)
    
            except Exception as e:
                logger.error(f"Error broadcasting message: {str(e)}")
    
        async def send_message(self, peer_id: str, message_type: str, payload: Dict[str, Any]) -> bool:
            """
            Send a message to a specific peer.
            
            Args:
                peer_id: ID of the peer to send to
                message_type: Type of message to send
                payload: Message payload data
                
            Returns:
                bool: True if message sent successfully, False otherwise
            """
            if peer_id not in self.peers:
                logger.warning(f"Attempted to send message to unknown peer: {peer_id}")
                return False
    
            message = Message(
                message_type=message_type,
                payload=payload,
                sender=self.node_id
            )
    
            try:
                await self._send_message_to_peer(peer_id, message)
                self.metrics["messages_sent"] += 1
                return True
    
            except Exception as e:
                logger.error(f"Failed to send message to peer {peer_id}: {str(e)}")
                return False
    
        def register_message_handler(self, message_type: str, handler: Callable) -> None:
            """
            Register a handler function for a specific message type.
            
            Args:
                message_type: Type of message to handle
                handler: Callback function to handle messages of this type
            """
            if message_type not in self.message_handlers:
                self.message_handlers[message_type] = []
            self.message_handlers[message_type].append(handler)
    
        async def _handle_connection(self, reader: asyncio.StreamReader, writer: asyncio.StreamWriter) -> None:
            """Handle incoming peer connection."""
            try:
                # Receive handshake
                handshake_data = await reader.read(1024)
                handshake = json.loads(handshake_data.decode())
    
                peer_id = handshake.get("node_id")
                if not peer_id:
                    writer.close()
                    return
    
                # Check if peer is blacklisted
                if peer_id in self.blacklisted_peers:
                    writer.close()
                    return
    
                # Create peer info
                peer_info = PeerInfo(
                    node_id=peer_id,
                    address=writer.get_extra_info('peername')[0],
                    port=writer.get_extra_info('peername')[1]
                )
    
                # Send handshake response
                response = {
                    "node_id": self.node_id,
                    "protocols": list(self.supported_protocols)
                }
                writer.write(json.dumps(response).encode())
                await writer.drain()
    
                # Store peer connection
                self.peers[peer_id] = peer_info
                self.metrics["active_connections"] += 1
    
                # Start message handling loop
                asyncio.create_task(self._handle_peer_messages(reader, writer, peer_id))
    
            except Exception as e:
                logger.error(f"Error handling connection: {str(e)}")
                writer.close()
    
        async def _handle_peer_messages(
            self,
            reader: asyncio.StreamReader,
            writer: asyncio.StreamWriter,
            peer_id: str
        ) -> None:
            """Handle incoming messages from a peer."""
            try:
                while True:
                    # Read message length
                    length_data = await reader.readexactly(4)
                    message_length = int.from_bytes(length_data, 'big')
    
                    # Read message data
                    message_data = await reader.readexactly(message_length)
                    message_dict = json.loads(message_data.decode())
    
                    # Create message object
                    message = Message(
                        message_type=message_dict["message_type"],
                        payload=message_dict["payload"],
                        sender=message_dict["sender"]
                    )
    
                    # Process message if not seen before
                    if message.message_id not in self.processed_messages:
                        self.processed_messages.add(message.message_id)
                        if len(self.processed_messages) > self.message_cache_size:
                            self.processed_messages.pop()
    
                        # Call registered handlers
                        handlers = self.message_handlers.get(message.message_type, [])
                        for handler in handlers:
                            try:
                                await handler(message, peer_id)
                            except Exception as e:
                                logger.error(f"Error in message handler: {str(e)}")
    
                        self.metrics["messages_processed"] += 1
    
            except asyncio.IncompleteReadError:
                # Connection closed
                await self._close_peer_connection(peer_id)
            except Exception as e:
                logger.error(f"Error handling messages from peer {peer_id}: {str(e)}")
                await self._close_peer_connection(peer_id)
    
        async def _send_message_to_peer(self, peer_id: str, message: Message) -> None:
            """Send a message to a specific peer."""
            if peer_id not in self.peers:
                raise ValueError(f"Unknown peer: {peer_id}")
    
            # Serialize message
            message_dict = {
                "message_type": message.message_type,
                "payload": message.payload,
                "sender": message.sender,
                "timestamp": message.timestamp.isoformat()
            }
            message_data = json.dumps(message_dict).encode()
    
            # Send message length followed by message data
            message_length = len(message_data)
            length_bytes = message_length.to_bytes(4, 'big')
    
            writer = self.peers[peer_id].writer
            writer.write(length_bytes + message_data)
            await writer.drain()
    
        async def _perform_handshake(
            self,
            reader: asyncio.StreamReader,
            writer: asyncio.StreamWriter,
            peer_info: PeerInfo
        ) -> bool:
            """Perform protocol handshake with a peer."""
            try:
                # Send handshake
                handshake = {
                    "node_id": self.node_id,
                    "protocols": list(self.supported_protocols)
                }
                writer.write(json.dumps(handshake).encode())
                await writer.drain()
    
                # Receive response
                response_data = await reader.read(1024)
                response = json.loads(response_data.decode())
    
                # Verify peer ID
                if response.get("node_id") != peer_info.node_id:
                    return False
    
                # Check protocol compatibility
                peer_protocols = set(response.get("protocols", []))
                if not peer_protocols & self.supported_protocols:
                    return False
    
                peer_info.supported_protocols = peer_protocols
                peer_info.is_active = True
                return True
    
            except Exception as e:
                logger.error(f"Handshake failed: {str(e)}")
                return False
    
        async def _close_peer_connection(self, peer_id: str) -> None:
            """Close connection with a peer."""
            if peer_id in self.peers:
                peer_info = self.peers[peer_id]
                if hasattr(peer_info, 'writer'):
                    peer_info.writer.close()
                    await peer_info.writer.wait_closed()
                del self.peers[peer_id]
                self.metrics["active_connections"] -= 1
    
        async def _maintenance_loop(self) -> None:
            """Periodic maintenance tasks."""
            while self.is_running:
                try:
                    # Remove inactive peers
                    now = datetime.now()
                    for peer_id, peer_info in list(self.peers.items()):
                        if (now - peer_info.last_seen).total_seconds() > 300:  # 5 minutes
                            await self._close_peer_connection(peer_id)
    
                    # Clear old processed messages
                    if len(self.processed_messages) > self.message_cache_size:
                        self.processed_messages = set(
                            list(self.processed_messages)[-self.message_cache_size:]
                        )
    
                except Exception as e:
                    logger.error(f"Error in maintenance loop: {str(e)}")
    
                await asyncio.sleep(60)
                # Continuing from the previous NetworkManager class...
    
        async def _metrics_loop(self) -> None:
            """Background task to update network metrics."""
            while self.is_running:
                try:
                    # Update peer metrics
                    active_peers = sum(1 for p in self.peers.values() if p.is_active)
                    total_reputation = sum(p.reputation for p in self.peers.values())
                    
                    self.metrics.update({
                        "active_peers": active_peers,
                        "total_peers": len(self.peers),
                        "average_reputation": total_reputation / max(1, len(self.peers)),
                        "blacklisted_peers": len(self.blacklisted_peers),
                        "pending_connections": len(self.pending_connections)
                    })
    
                    # Log metrics
                    if active_peers > 0:
                        logger.info(f"Network metrics: {self.metrics}")
    
                except Exception as e:
                    logger.error(f"Error updating metrics: {str(e)}")
    
                await asyncio.sleep(30)  # Update every 30 seconds
    
        def get_peer_info(self, peer_id: str) -> Optional[PeerInfo]:
            """
            Get information about a specific peer.
            
            Args:
                peer_id: ID of the peer
                
            Returns:
                Optional[PeerInfo]: Peer information if found
            """
            return self.peers.get(peer_id)
    
        def get_active_peers(self) -> List[PeerInfo]:
            """
            Get list of currently active peers.
            
            Returns:
                List[PeerInfo]: List of active peer information
            """
            return [peer for peer in self.peers.values() if peer.is_active]
    
        def blacklist_peer(self, peer_id: str, reason: str) -> None:
            """
            Add a peer to the blacklist.
            
            Args:
                peer_id: ID of the peer to blacklist
                reason: Reason for blacklisting
            """
            self.blacklisted_peers.add(peer_id)
            if peer_id in self.peers:
                asyncio.create_task(self._close_peer_connection(peer_id))
            logger.warning(f"Blacklisted peer {peer_id}: {reason}")
    
        def get_network_info(self) -> Dict[str, Any]:
            """
            Get comprehensive information about the network state.
            
            Returns:
                Dict[str, Any]: Network state information
            """
            return {
                "node_id": self.node_id,
                "address": f"{self.host}:{self.port}",
                "is_running": self.is_running,
                "metrics": self.metrics.copy(),
                "peers": {
                    peer_id: {
                        "address": f"{peer.address}:{peer.port}",
                        "last_seen": peer.last_seen.isoformat(),
                        "reputation": peer.reputation,
                        "is_active": peer.is_active,
                        "protocols": list(peer.supported_protocols)
                    }
                    for peer_id, peer in self.peers.items()
                },
                "protocols": list(self.supported_protocols),
                "min_protocol": self.min_protocol_version
            }
    
        async def ping_peer(self, peer_id: str) -> bool:
            """
            Send a ping message to check peer connectivity.
            
            Args:
                peer_id: ID of the peer to ping
                
            Returns:
                bool: True if ping successful, False otherwise
            """
            try:
                ping_payload = {
                    "timestamp": datetime.now().isoformat()
                }
                return await self.send_message(peer_id, "ping", ping_payload)
            except Exception as e:
                logger.error(f"Error pinging peer {peer_id}: {str(e)}")
                return False
    
        def update_peer_reputation(self, peer_id: str, change: float) -> None:
            """
            Update a peer's reputation score.
            
            Args:
                peer_id: ID of the peer
                change: Amount to change reputation by (positive or negative)
            """
            if peer_id in self.peers:
                peer = self.peers[peer_id]
                peer.reputation = max(0.0, min(1.0, peer.reputation + change))
                
                # Blacklist peers with consistently bad reputation
                if peer.reputation <= 0.1:
                    self.blacklist_peer(peer_id, "Low reputation score")
```

# File: /home/matt/icn-prototype/blockchain/network/discovery/discovery.py

```py
    # ================================================================
    # File: blockchain/network/discovery/discovery.py
    # Description: Peer discovery implementation for the ICN network.
    # Handles automatic peer discovery, peer list management, and 
    # connection bootstrapping for the InterCooperative Network.
    # ================================================================
    
    import asyncio
    import logging
    import json
    import random
    from typing import Dict, Set, List, Optional, Any
    from datetime import datetime, timedelta
    from dataclasses import dataclass, field
    import socket
    import struct
    import ipaddress
    from hashlib import sha256
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class PeerRecord:
        """Information about a discovered peer."""
        node_id: str
        address: str
        port: int
        last_seen: datetime = field(default_factory=datetime.now)
        last_successful_connection: Optional[datetime] = None
        connection_attempts: int = 0
        is_bootstrap_node: bool = False
        cooperative_id: Optional[str] = None
        metadata: Dict[str, Any] = field(default_factory=dict)
        
        @property
        def peer_score(self) -> float:
            """Calculate peer score based on reliability and history."""
            if self.is_bootstrap_node:
                return 1.0
                
            # Base score starts at 0.5
            score = 0.5
            
            # Increase score for successful connections
            if self.last_successful_connection:
                hours_since_connection = (datetime.now() - self.last_successful_connection).total_seconds() / 3600
                if hours_since_connection < 24:
                    score += 0.3
                elif hours_since_connection < 72:
                    score += 0.1
                    
            # Decrease score for failed connection attempts
            score -= min(0.4, self.connection_attempts * 0.1)
            
            return max(0.0, min(1.0, score))
    
    class PeerDiscovery:
        """
        Manages peer discovery and connection management.
        
        Features:
        - Automatic peer discovery using multiple methods
        - Bootstrap node support
        - Peer scoring and prioritization
        - Connection attempt management
        - Cooperative-aware peer selection
        """
        
        def __init__(
            self,
            node_id: str,
            host: str,
            port: int,
            bootstrap_nodes: List[Dict[str, Any]] = None,
            max_peers: int = 50,
            discovery_interval: int = 300
        ):
            """
            Initialize the peer discovery system.
            
            Args:
                node_id: Unique identifier for this node
                host: Host address to bind to
                port: Port to listen on
                bootstrap_nodes: List of known bootstrap nodes
                max_peers: Maximum number of peers to maintain
                discovery_interval: Seconds between discovery attempts
            """
            self.node_id = node_id
            self.host = host
            self.port = port
            self.max_peers = max_peers
            self.discovery_interval = discovery_interval
            
            # Peer management
            self.known_peers: Dict[str, PeerRecord] = {}
            self.connected_peers: Set[str] = set()
            self.blacklisted_peers: Set[str] = set()
            self.pending_connections: Set[str] = set()
            
            # Bootstrap configuration
            self.bootstrap_nodes = bootstrap_nodes or []
            for node in self.bootstrap_nodes:
                self._add_bootstrap_node(node)
                
            # Discovery state
            self.is_running = False
            self.last_discovery = datetime.now() - timedelta(seconds=discovery_interval)
            
            # UDP discovery
            self.discovery_socket: Optional[socket.socket] = None
            self.discovery_port = port + 1
            
            # Metrics
            self.metrics = {
                "total_discoveries": 0,
                "successful_discoveries": 0,
                "failed_discoveries": 0,
                "total_connection_attempts": 0,
                "successful_connections": 0,
                "failed_connections": 0
            }
    
        async def start(self) -> None:
            """Start the peer discovery service."""
            if self.is_running:
                return
                
            try:
                # Initialize UDP discovery socket
                self.discovery_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
                self.discovery_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
                self.discovery_socket.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)
                self.discovery_socket.bind(('', self.discovery_port))
                
                self.is_running = True
                
                # Start background tasks
                asyncio.create_task(self._discovery_loop())
                asyncio.create_task(self._maintenance_loop())
                asyncio.create_task(self._listen_for_broadcasts())
                
                logger.info(f"Peer discovery started on {self.host}:{self.port}")
                
            except Exception as e:
                logger.error(f"Failed to start peer discovery: {str(e)}")
                raise
    
        async def stop(self) -> None:
            """Stop the peer discovery service."""
            if not self.is_running:
                return
                
            try:
                self.is_running = False
                
                if self.discovery_socket:
                    self.discovery_socket.close()
                    
                logger.info("Peer discovery stopped")
                
            except Exception as e:
                logger.error(f"Error stopping peer discovery: {str(e)}")
    
        async def get_peers(self, count: int = 10, cooperative_id: Optional[str] = None) -> List[PeerRecord]:
            """
            Get a list of recommended peers to connect to.
            
            Args:
                count: Number of peers to return
                cooperative_id: Optional cooperative ID to prioritize
                
            Returns:
                List[PeerRecord]: List of recommended peers
            """
            try:
                # Filter and sort peers
                available_peers = [
                    peer for peer_id, peer in self.known_peers.items()
                    if peer_id not in self.connected_peers
                    and peer_id not in self.blacklisted_peers
                    and peer_id not in self.pending_connections
                    and (not cooperative_id or peer.cooperative_id == cooperative_id)
                ]
                
                # Sort by score
                available_peers.sort(key=lambda p: p.peer_score, reverse=True)
                
                return available_peers[:count]
                
            except Exception as e:
                logger.error(f"Error getting peers: {str(e)}")
                return []
    
        def add_peer(self, node_id: str, address: str, port: int, **kwargs) -> bool:
            """
            Add a new peer to the known peers list.
            
            Args:
                node_id: Unique identifier of the peer
                address: Peer's network address
                port: Peer's port number
                **kwargs: Additional peer metadata
                
            Returns:
                bool: True if peer was added, False otherwise
            """
            try:
                if node_id in self.blacklisted_peers:
                    return False
                    
                if node_id not in self.known_peers:
                    self.known_peers[node_id] = PeerRecord(
                        node_id=node_id,
                        address=address,
                        port=port,
                        cooperative_id=kwargs.get('cooperative_id'),
                        metadata=kwargs
                    )
                else:
                    # Update existing peer record
                    peer = self.known_peers[node_id]
                    peer.address = address
                    peer.port = port
                    peer.last_seen = datetime.now()
                    peer.metadata.update(kwargs)
                    
                return True
                
            except Exception as e:
                logger.error(f"Error adding peer: {str(e)}")
                return False
    
        def blacklist_peer(self, node_id: str, reason: str) -> None:
            """
            Add a peer to the blacklist.
            
            Args:
                node_id: ID of the peer to blacklist
                reason: Reason for blacklisting
            """
            self.blacklisted_peers.add(node_id)
            if node_id in self.known_peers:
                del self.known_peers[node_id]
            logger.warning(f"Blacklisted peer {node_id}: {reason}")
    
        async def _discovery_loop(self) -> None:
            """Background task for periodic peer discovery."""
            while self.is_running:
                try:
                    # Check if discovery is needed
                    now = datetime.now()
                    if (now - self.last_discovery).total_seconds() < self.discovery_interval:
                        await asyncio.sleep(5)
                        continue
                        
                    self.last_discovery = now
                    self.metrics["total_discoveries"] += 1
                    
                    # Perform discovery methods
                    discovery_tasks = [
                        self._broadcast_discovery(),
                        self._query_bootstrap_nodes(),
                        self._query_known_peers()
                    ]
                    
                    results = await asyncio.gather(*discovery_tasks, return_exceptions=True)
                    
                    # Update metrics
                    success = sum(1 for r in results if r and not isinstance(r, Exception))
                    self.metrics["successful_discoveries"] += success
                    self.metrics["failed_discoveries"] += (len(results) - success)
                    
                    # Log results
                    logger.info(f"Discovery round completed: {success} successful methods")
                    
                except Exception as e:
                    logger.error(f"Error in discovery loop: {str(e)}")
                    
                await asyncio.sleep(5)
    
        async def _maintenance_loop(self) -> None:
            """Background task for peer list maintenance."""
            while self.is_running:
                try:
                    now = datetime.now()
                    
                    # Remove old peers
                    for peer_id in list(self.known_peers.keys()):
                        peer = self.known_peers[peer_id]
                        if not peer.is_bootstrap_node:
                            if (now - peer.last_seen).total_seconds() > 3600:  # 1 hour
                                del self.known_peers[peer_id]
                    
                    # Clear old pending connections
                    self.pending_connections = {
                        peer_id for peer_id in self.pending_connections
                        if peer_id in self.known_peers
                    }
                    
                except Exception as e:
                    logger.error(f"Error in maintenance loop: {str(e)}")
                    
                await asyncio.sleep(60)
    
        async def _broadcast_discovery(self) -> bool:
            """Broadcast discovery message on local network."""
            try:
                # Prepare discovery message
                message = {
                    "node_id": self.node_id,
                    "address": self.host,
                    "port": self.port,
                    "timestamp": datetime.now().isoformat()
                }
                
                # Broadcast message
                data = json.dumps(message).encode()
                self.discovery_socket.sendto(data, ('<broadcast>', self.discovery_port))
                
                return True
                
            except Exception as e:
                logger.error(f"Error broadcasting discovery: {str(e)}")
                return False
    
        async def _listen_for_broadcasts(self) -> None:
            """Listen for discovery broadcasts from other nodes."""
            while self.is_running:
                try:
                    # Receive broadcast
                    data, addr = await asyncio.get_event_loop().sock_recvfrom(self.discovery_socket, 1024)
                    message = json.loads(data.decode())
                    
                    # Validate message
                    required_fields = {"node_id", "address", "port", "timestamp"}
                    if not all(field in message for field in required_fields):
                        continue
                        
                    # Add peer
                    node_id = message["node_id"]
                    if node_id != self.node_id:
                        self.add_peer(
                            node_id=node_id,
                            address=message["address"],
                            port=message["port"]
                        )
                        
                except Exception as e:
                    logger.error(f"Error processing broadcast: {str(e)}")
                    
                await asyncio.sleep(0.1)
    
        async def _query_bootstrap_nodes(self) -> bool:
            """Query bootstrap nodes for peer information."""
            try:
                # Query each bootstrap node
                for node in self.bootstrap_nodes:
                    try:
                        # Create TCP connection
                        reader, writer = await asyncio.open_connection(
                            node["address"],
                            node["port"]
                        )
                        
                        # Send peer request
                        request = {
                            "message_type": "peer_request",
                            "node_id": self.node_id,
                            "timestamp": datetime.now().isoformat()
                        }
                        writer.write(json.dumps(request).encode())
                        await writer.drain()
                        
                        # Read response
                        data = await reader.read(8192)
                        response = json.loads(data.decode())
                        
                        # Process peers
                        for peer in response.get("peers", []):
                            self.add_peer(**peer)
                            
                        writer.close()
                        await writer.wait_closed()
                        
                    except Exception as e:
                        logger.error(f"Error querying bootstrap node: {str(e)}")
                        
                return True
                
            except Exception as e:
                logger.error(f"Error in bootstrap node query: {str(e)}")
                return False
    
        async def _query_known_peers(self) -> bool:
            """Query known peers for their peer lists."""
            try:
                # Select random subset of known peers
                sample_size = min(5, len(self.known_peers))
                if sample_size == 0:
                    return False
                    
                selected_peers = random.sample(list(self.known_peers.values()), sample_size)
                
                # Query each selected peer
                for peer in selected_peers:
                    try:
                        # Create TCP connection
                        reader, writer = await asyncio.open_connection(
                            peer.address,
                            peer.port
                        )
                        
                        # Send peer request
                        request = {
                            "message_type": "peer_request",
                            "node_id": self.node_id,
                            "timestamp": datetime.now().isoformat()
                        }
                        writer.write(json.dumps(request).encode())
                        await writer.drain()
                        
                        # Read response
                        data = await reader.read(8192)
                        response = json.loads(data.decode())
                        
                        # Process peers
                        for peer_data in response.get("peers", []):
                            self.add_peer(**peer_data)
                            
                        writer.close()
                        await writer.wait_closed()
                        
                    except Exception as e:
                        logger.error(f"Error querying peer {peer.node_id}: {str(e)}")
                        peer.connection_attempts += 1
                        
                return True
                
            except Exception as e:
                logger.error(f"Error in known peer query: {str(e)}")
                return False
    
        def _add_bootstrap_node(self, node: Dict[str, Any]) -> None:
            """Add a bootstrap node to known peers."""
            self.add_peer(
                node_id=node["node_id"],
                address=node["address"],
                port=node["port"],
                is_bootstrap_node=True
            )
```

# File: /home/matt/icn-prototype/blockchain/network/sync/sync_manager.py

```py
    # ================================================================
    # File: blockchain/network/sync/sync_manager.py
    # Description: State synchronization manager for ICN network.
    # Handles blockchain state synchronization between nodes, including
    # block synchronization, state verification, and chain reorganization.
    # ================================================================
    
    import asyncio
    import logging
    from typing import Dict, Set, List, Optional, Tuple, Any
    from dataclasses import dataclass, field
    from datetime import datetime, timedelta
    import json
    import hashlib
    from enum import Enum, auto
    
    from ..config import NetworkConfig
    from ..protocol.dispatcher import MessageDispatcher, MessagePriority, MessageRoute
    from ...core.block import Block
    from ...core.transaction import Transaction
    
    logger = logging.getLogger(__name__)
    
    class SyncState(Enum):
        """State of node synchronization."""
        IDLE = auto()
        SYNCING_HEADERS = auto()
        SYNCING_BLOCKS = auto()
        SYNCING_STATE = auto()
        VERIFYING = auto()
    
    @dataclass
    class SyncProgress:
        """Track synchronization progress."""
        start_height: int
        current_height: int
        target_height: int
        start_time: datetime = field(default_factory=datetime.now)
        blocks_processed: int = 0
        blocks_verified: int = 0
        failed_blocks: int = 0
        state_size: int = 0
        
        @property
        def progress_percentage(self) -> float:
            """Calculate sync progress percentage."""
            if self.target_height == self.start_height:
                return 100.0
            return (self.current_height - self.start_height) / (self.target_height - self.start_height) * 100
    
        @property
        def blocks_per_second(self) -> float:
            """Calculate block processing rate."""
            elapsed = (datetime.now() - self.start_time).total_seconds()
            if elapsed == 0:
                return 0.0
            return self.blocks_processed / elapsed
    
        @property
        def estimated_time_remaining(self) -> timedelta:
            """Estimate remaining sync time."""
            if self.blocks_per_second == 0:
                return timedelta(hours=999)  # Large value to indicate unknown
            blocks_remaining = self.target_height - self.current_height
            seconds_remaining = blocks_remaining / self.blocks_per_second
            return timedelta(seconds=seconds_remaining)
    
    class SyncManager:
        """
        Manages blockchain state synchronization.
        
        Features:
        - Block header synchronization
        - Block data synchronization
        - State verification
        - Chain reorganization
        - Checkpoint validation
        - Parallel block downloading
        - State snapshot handling
        """
    
        def __init__(
            self,
            config: NetworkConfig,
            dispatcher: MessageDispatcher,
            chain,  # Actual blockchain instance
            max_parallel_downloads: int = 10,
            verify_interval: int = 100  # Verify every N blocks
        ):
            """Initialize the sync manager."""
            self.config = config
            self.dispatcher = dispatcher
            self.chain = chain
            self.max_parallel_downloads = max_parallel_downloads
            self.verify_interval = verify_interval
            
            # Sync state
            self.sync_state = SyncState.IDLE
            self.current_sync: Optional[SyncProgress] = None
            self.active_downloads: Set[int] = set()
            self.downloaded_blocks: Dict[int, Block] = {}
            self.verified_blocks: Set[int] = set()
            self.failed_blocks: Set[int] = set()
            
            # Peer tracking
            self.peer_heights: Dict[str, int] = {}
            self.sync_peers: Set[str] = set()
            self.banned_peers: Set[str] = set()
            
            # State verification
            self.checkpoints: Dict[int, str] = {}  # height -> state root
            self.state_roots: Dict[int, str] = {}  # height -> state root
            
            # Background tasks
            self.sync_task: Optional[asyncio.Task] = None
            self.verification_task: Optional[asyncio.Task] = None
            
            # Metrics
            self.metrics = {
                "total_syncs": 0,
                "successful_syncs": 0,
                "failed_syncs": 0,
                "blocks_downloaded": 0,
                "blocks_verified": 0,
                "reorgs_processed": 0,
                "average_sync_time": 0.0,
            }
    
        async def start(self) -> None:
            """Start the sync manager."""
            # Register message handlers
            self.dispatcher.register_handler(
                "block_headers",
                self._handle_block_headers,
                priority=MessagePriority.HIGH
            )
            self.dispatcher.register_handler(
                "block_data",
                self._handle_block_data,
                priority=MessagePriority.HIGH
            )
            self.dispatcher.register_handler(
                "state_root",
                self._handle_state_root,
                priority=MessagePriority.MEDIUM
            )
            self.dispatcher.register_handler(
                "checkpoint",
                self._handle_checkpoint,
                priority=MessagePriority.MEDIUM
            )
            
            # Start verification task
            self.verification_task = asyncio.create_task(self._verification_loop())
            
            logger.info("Sync manager started")
    
        async def stop(self) -> None:
            """Stop the sync manager."""
            if self.sync_task:
                self.sync_task.cancel()
                
            if self.verification_task:
                self.verification_task.cancel()
                
            logger.info("Sync manager stopped")
    
        async def start_sync(self, target_height: Optional[int] = None) -> bool:
            """
            Start blockchain synchronization.
            
            Args:
                target_height: Optional target height to sync to
                
            Returns:
                bool: True if sync started successfully
            """
            if self.sync_state != SyncState.IDLE:
                logger.warning("Sync already in progress")
                return False
                
            try:
                # Get current chain height
                current_height = self.chain.height
                
                # Find best peer height if no target specified
                if target_height is None:
                    peer_heights = list(self.peer_heights.values())
                    if not peer_heights:
                        logger.warning("No peers available for sync")
                        return False
                    target_height = max(peer_heights)
                
                if target_height <= current_height:
                    logger.info("Chain already synced")
                    return False
                
                # Initialize sync progress
                self.current_sync = SyncProgress(
                    start_height=current_height,
                    current_height=current_height,
                    target_height=target_height
                )
                
                # Start sync task
                self.sync_state = SyncState.SYNCING_HEADERS
                self.sync_task = asyncio.create_task(self._sync_loop())
                
                logger.info(
                    f"Starting sync from height {current_height} to {target_height}"
                )
                return True
                
            except Exception as e:
                logger.error(f"Error starting sync: {str(e)}")
                return False
    
        def get_sync_progress(self) -> Optional[SyncProgress]:
            """Get current sync progress."""
            return self.current_sync
    
        def add_checkpoint(self, height: int, state_root: str) -> None:
            """Add a trusted checkpoint."""
            self.checkpoints[height] = state_root
            logger.info(f"Added checkpoint at height {height}")
    
        async def verify_chain_state(self, height: Optional[int] = None) -> bool:
            """
            Verify chain state at specified height.
            
            Args:
                height: Height to verify, defaults to current height
                
            Returns:
                bool: True if state is valid
            """
            try:
                if height is None:
                    height = self.chain.height
                    
                # Get state root at height
                state_root = await self._calculate_state_root(height)
                if not state_root:
                    return False
                    
                # Check against checkpoint if available
                checkpoint_root = self.checkpoints.get(height)
                if checkpoint_root and checkpoint_root != state_root:
                    logger.error(f"State root mismatch at checkpoint {height}")
                    return False
                    
                # Verify against peer state roots
                peer_roots = await self._get_peer_state_roots(height)
                if not peer_roots:
                    return True  # No peers to verify against
                    
                # State is valid if it matches majority of peers
                matching_peers = sum(1 for root in peer_roots if root == state_root)
                return matching_peers > len(peer_roots) / 2
                
            except Exception as e:
                logger.error(f"Error verifying chain state: {str(e)}")
                return False
    
        async def _sync_loop(self) -> None:
            """Main synchronization loop."""
            try:
                while self.sync_state != SyncState.IDLE:
                    if self.sync_state == SyncState.SYNCING_HEADERS:
                        await self._sync_headers()
                    elif self.sync_state == SyncState.SYNCING_BLOCKS:
                        await self._sync_blocks()
                    elif self.sync_state == SyncState.SYNCING_STATE:
                        await self._sync_state()
                    elif self.sync_state == SyncState.VERIFYING:
                        await self._verify_sync()
                        
                    await asyncio.sleep(0.1)
                    
            except asyncio.CancelledError:
                logger.info("Sync loop cancelled")
            except Exception as e:
                logger.error(f"Error in sync loop: {str(e)}")
                self.metrics["failed_syncs"] += 1
                self.sync_state = SyncState.IDLE
    
        async def _sync_headers(self) -> None:
            """Synchronize block headers."""
            try:
                if not self.current_sync:
                    return
                    
                start_height = self.current_sync.current_height
                target_height = self.current_sync.target_height
                
                # Request headers in batches
                batch_size = 2000
                current_height = start_height
                
                while current_height < target_height:
                    end_height = min(current_height + batch_size, target_height)
                    
                    # Request headers from peers
                    headers = await self._request_headers(
                        current_height,
                        end_height
                    )
                    
                    if not headers:
                        logger.error("Failed to get headers")
                        self.sync_state = SyncState.IDLE
                        return
                        
                    # Verify and store headers
                    if not await self._verify_headers(headers):
                        logger.error("Header verification failed")
                        self.sync_state = SyncState.IDLE
                        return
                        
                    current_height = end_height
                    self.current_sync.current_height = current_height
                    
                # Move to block sync
                self.sync_state = SyncState.SYNCING_BLOCKS
                
            except Exception as e:
                logger.error(f"Error syncing headers: {str(e)}")
                self.sync_state = SyncState.IDLE
    
        async def _sync_blocks(self) -> None:
            """Synchronize full blocks."""
            try:
                if not self.current_sync:
                    return
                    
                while len(self.active_downloads) < self.max_parallel_downloads:
                    next_height = self._get_next_block_height()
                    if next_height is None:
                        if not self.active_downloads:
                            # All blocks downloaded
                            self.sync_state = SyncState.SYNCING_STATE
                        break
                        
                    # Start block download
                    self.active_downloads.add(next_height)
                    asyncio.create_task(self._download_block(next_height))
                    
            except Exception as e:
                logger.error(f"Error syncing blocks: {str(e)}")
                self.sync_state = SyncState.IDLE
    
        async def _sync_state(self) -> None:
            """Synchronize chain state."""
            try:
                if not self.current_sync:
                    return
                    
                # Request state snapshot
                state_data = await self._request_state_snapshot(
                    self.current_sync.current_height
                )
                
                if not state_data:
                    logger.error("Failed to get state snapshot")
                    self.sync_state = SyncState.IDLE
                    return
                    
                # Verify state
                if not await self._verify_state_snapshot(
                    state_data,
                    self.current_sync.current_height
                ):
                    logger.error("State verification failed")
                    self.sync_state = SyncState.IDLE
                    return
                    
                # Apply state
                if not await self._apply_state_snapshot(state_data):
                    logger.error("Failed to apply state snapshot")
                    self.sync_state = SyncState.IDLE
                    return
                    
                # Move to verification
                self.sync_state = SyncState.VERIFYING
                
            except Exception as e:
                logger.error(f"Error syncing state: {str(e)}")
                self.sync_state = SyncState.IDLE
    
        async def _verification_loop(self) -> None:
            """Periodic chain verification loop."""
            while True:
                try:
                    if self.chain.height % self.verify_interval == 0:
                        await self.verify_chain_state()
                        
                    await asyncio.sleep(10)
                    
                except asyncio.CancelledError:
                    break
                except Exception as e:
                    logger.error(f"Error in verification loop: {str(e)}")
                    await asyncio.sleep(10)
    
        async def _request_headers(
            self,
            start_height: int,
            end_height: int
        ) -> Optional[List[Dict[str, Any]]]:
            """Request block headers from peers."""
            try:
                response = await self.dispatcher.dispatch_message(
                    "get_headers",
                    {
                        "start_height": start_height,
                        "end_height": end_height
                    },
                    routing=MessageRoute(
                        message_type="get_headers",
                        target_shards=set(),
                        target_cooperatives=set(),
                        exclude_peers=self.banned_peers,
                        broadcast=True
                    ),
                    wait_response=True
                )
                
                if not response or "headers" not in response:
                    return None
                    
                return response["headers"]
                
            except Exception as e:
                logger.error(f"Error requesting headers: {str(e)}")
                return None
    
        async def _verify_headers(self, headers: List[Dict[str, Any]]) -> bool:
            """Verify block headers."""
            try:
                previous_hash = None
                for header in headers:
                    # Create block from header
                    block = Block.from_dict(header)
                    
                    # Verify hash chain
                    if previous_hash and block.previous_hash != previous_hash:
                        return False
                        
                    previous_hash = block.hash
                    
                    # Store header
                    self.chain.add_block_header(block)
                    
                return True
                
            except Exception as e:
                logger.error(f"Error verifying headers: {str(e)}")
                return False
    
        def _get_next_block_height(self) -> Optional[int]:
            """Get next block height to download."""
            if not self.current_sync:
                return None
                
            current_height = self.current_sync.current_height
            target_height = self.current_sync.target_height
            
            for height in range(current_height, target_height + 1):
                if (height not in self.active_downloads and
                    height not in self.downloaded_blocks and
                    height not in self.failed_blocks):
                    return height
                    
            return None
    
        async def _download_block(self, height: int) -> None:
            """Download a specific block."""
            try:
                # Request block from peers
                response = await self.dispatcher.dispatch_message(
                    "get_block",
                    {"height": height},
                    routing=MessageRoute(
                        message_type="get_block",
                        target_shards=set(),
                        target_cooperatives=set(),
                        exclude_peers=self.banned_peers,
                        broadcast=True
                    ),
                    wait_response=True
                )
                
                if not response or "block" not in response:
                    logger.error(f"Failed to download block at height {height}")
                    self.failed_blocks.add(height)
                    return
                    
                # Create and verify block
                block = Block.from_dict(response["block"])
                if not await self._verify_block(block):
                    logger.error(f"Block verification failed at height {height}")
                    self.failed_blocks.add(height)
                    return
                    
                # Store block
                self.downloaded_blocks[height] = block
                self.current_sync.blocks_processed += 1
                self.metrics["blocks_downloaded"] += 1
                
            except Exception as e:
                logger.error(f"Error downloading block {height}: {str(e)}")
                self.failed_blocks.add(height)
                
            finally:
                self.active_downloads.discard(height)
    
        async def _verify_block(self, block: Block) -> bool:
            """Verify a downloaded block."""
            try:
                # Verify basic structure
                if not block.validate(None):  # Pass None as we don't have previous block here
                    return False
                    
                # Verify transactions
                for tx in block.transactions:
                    if not await self._verify_transaction(tx):
                        return False
                        
                # Verify state transitions
                if not await self._verify_state_transitions(block):
                    return False
                    
                # Verify cooperative signatures if present
                if not await self._verify_signatures(block):
                    return False
                    
                return True
                
            except Exception as e:
                logger.error(f"Error verifying block: {str(e)}")
                return False
    
        async def _verify_transaction(self, transaction: Transaction) -> bool:
            """Verify a transaction within a block."""
            try:
                # Basic validation
                if not transaction.validate():
                    return False
                    
                # Verify signatures
                if not transaction.verify_signatures():
                    return False
                    
                # Verify state transitions
                if not await self._verify_transaction_state(transaction):
                    return False
                    
                return True
                
            except Exception as e:
                logger.error(f"Error verifying transaction: {str(e)}")
                return False
    
        async def _verify_transaction_state(self, transaction: Transaction) -> bool:
            """Verify transaction state transitions."""
            try:
                # Get pre-state
                pre_state = await self._get_account_state(transaction.sender)
                
                # Verify sender has sufficient resources
                if not await self._verify_resource_availability(transaction, pre_state):
                    return False
                    
                # Verify state transition rules
                if not await self._verify_transition_rules(transaction, pre_state):
                    return False
                    
                return True
                
            except Exception as e:
                logger.error(f"Error verifying transaction state: {str(e)}")
                return False
    
        async def _verify_state_transitions(self, block: Block) -> bool:
            """Verify state transitions in a block."""
            try:
                # Get pre-block state
                pre_state = await self._get_block_state(block.previous_hash)
                
                # Apply all transactions
                current_state = pre_state.copy()
                for tx in block.transactions:
                    if not await self._apply_transaction(tx, current_state):
                        return False
                        
                # Verify final state matches block's state root
                state_root = self._calculate_state_root_from_state(current_state)
                return state_root == block.state_root
                
            except Exception as e:
                logger.error(f"Error verifying state transitions: {str(e)}")
                return False
    
        async def _verify_signatures(self, block: Block) -> bool:
            """Verify cooperative signatures on block."""
            try:
                # Get required signers
                required_signers = await self._get_required_signers(block)
                
                # Verify all required signatures are present
                for signer in required_signers:
                    if not await self._verify_signer_signature(block, signer):
                        return False
                        
                return True
                
            except Exception as e:
                logger.error(f"Error verifying signatures: {str(e)}")
                return False
    
        async def _apply_blocks(self) -> bool:
            """Apply downloaded blocks to chain."""
            try:
                if not self.current_sync:
                    return False
                    
                current_height = self.current_sync.start_height
                target_height = self.current_sync.target_height
                
                while current_height <= target_height:
                    # Get block
                    block = self.downloaded_blocks.get(current_height)
                    if not block:
                        return False
                        
                    # Apply block
                    if not await self.chain.add_block(block):
                        return False
                        
                    # Update state roots
                    self.state_roots[current_height] = block.state_root
                    
                    current_height += 1
                    self.current_sync.blocks_verified += 1
                    self.metrics["blocks_verified"] += 1
                    
                return True
                
            except Exception as e:
                logger.error(f"Error applying blocks: {str(e)}")
                return False
    
        async def _request_state_snapshot(self, height: int) -> Optional[Dict[str, Any]]:
            """Request state snapshot from peers."""
            try:
                response = await self.dispatcher.dispatch_message(
                    "get_state_snapshot",
                    {"height": height},
                    routing=MessageRoute(
                        message_type="get_state_snapshot",
                        target_shards=set(),
                        target_cooperatives=set(),
                        exclude_peers=self.banned_peers,
                        broadcast=True
                    ),
                    wait_response=True
                )
                
                if not response or "state" not in response:
                    return None
                    
                return response["state"]
                
            except Exception as e:
                logger.error(f"Error requesting state snapshot: {str(e)}")
                return None
    
        async def _verify_state_snapshot(self, state_data: Dict[str, Any], height: int) -> bool:
            """Verify state snapshot integrity."""
            try:
                # Calculate state root
                state_root = self._calculate_state_root_from_state(state_data)
                
                # Verify against block state root
                block_state_root = self.state_roots.get(height)
                if block_state_root and state_root != block_state_root:
                    return False
                    
                # Verify against checkpoint if available
                checkpoint_root = self.checkpoints.get(height)
                if checkpoint_root and state_root != checkpoint_root:
                    return False
                    
                return True
                
            except Exception as e:
                logger.error(f"Error verifying state snapshot: {str(e)}")
                return False
    
        async def _apply_state_snapshot(self, state_data: Dict[str, Any]) -> bool:
            """Apply verified state snapshot."""
            try:
                # Backup current state
                await self._backup_current_state()
                
                # Apply new state
                return await self.chain.apply_state(state_data)
                
            except Exception as e:
                logger.error(f"Error applying state snapshot: {str(e)}")
                return False
    
        async def _verify_sync(self) -> None:
            """Verify completed synchronization."""
            try:
                if not self.current_sync:
                    return
                    
                # Verify chain continuity
                if not await self._verify_chain_continuity():
                    logger.error("Chain continuity verification failed")
                    self.sync_state = SyncState.IDLE
                    return
                    
                # Verify final state
                if not await self.verify_chain_state():
                    logger.error("Final state verification failed")
                    self.sync_state = SyncState.IDLE
                    return
                    
                # Sync completed successfully
                logger.info(
                    f"Sync completed successfully at height {self.current_sync.target_height}"
                )
                
                self.metrics["successful_syncs"] += 1
                self.sync_state = SyncState.IDLE
                self.current_sync = None
                
            except Exception as e:
                logger.error(f"Error verifying sync: {str(e)}")
                self.sync_state = SyncState.IDLE
    
        async def _backup_current_state(self) -> None:
            """Backup current chain state."""
            try:
                # TODO: Implement state backup
                pass
            except Exception as e:
                logger.error(f"Error backing up state: {str(e)}")
                raise
    
        async def _verify_chain_continuity(self) -> bool:
            """Verify continuity of synchronized chain."""
            try:
                if not self.current_sync:
                    return False
                    
                current_height = self.current_sync.start_height
                target_height = self.current_sync.target_height
                
                previous_hash = None
                while current_height <= target_height:
                    block = await self.chain.get_block(current_height)
                    if not block:
                        return False
                        
                    if previous_hash and block.previous_hash != previous_hash:
                        return False
                        
                    previous_hash = block.hash
                    current_height += 1
                    
                return True
                
            except Exception as e:
                logger.error(f"Error verifying chain continuity: {str(e)}")
                return False
    
        def get_metrics(self) -> Dict[str, Any]:
            """Get sync manager metrics."""
            metrics = self.metrics.copy()
            
            if self.current_sync:
                metrics.update({
                    "sync_progress": self.current_sync.progress_percentage,
                    "blocks_per_second": self.current_sync.blocks_per_second,
                    "estimated_time_remaining": str(self.current_sync.estimated_time_remaining),
                    "current_height": self.current_sync.current_height,
                    "target_height": self.current_sync.target_height
                })
                
            return metrics
    
    # Example usage
    async def example_usage():
        config = NetworkConfig(node_id="test_node")
        dispatcher = MessageDispatcher(config, None)  # Pass proper transport
        chain = None  # Pass actual blockchain instance
        
        sync_manager = SyncManager(config, dispatcher, chain)
        await sync_manager.start()
        
        # Start sync
        await sync_manager.start_sync(1000)  # Sync to height 1000
        
        # Wait for sync to complete
        while sync_manager.get_sync_progress():
            progress = sync_manager.get_sync_progress()
            print(f"Sync progress: {progress.progress_percentage:.2f}%")
            await asyncio.sleep(1)
        
        await sync_manager.stop()
    
    if __name__ == "__main__":
        asyncio.run(example_usage())
```

# File: /home/matt/icn-prototype/blockchain/network/protocol/base.py

```py
    # ================================================================
    # File: blockchain/network/protocol/base.py
    # Description: Base protocol implementation for ICN network communication.
    # This module defines the core protocol structures and message types
    # used for node communication in the InterCooperative Network.
    # ================================================================
    
    from abc import ABC, abstractmethod
    from typing import Dict, Any, Optional, List
    from datetime import datetime
    import json
    import logging
    from dataclasses import dataclass, field
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class ProtocolMessage:
        """Base class for all protocol messages."""
        message_type: str
        version: str
        payload: Dict[str, Any]
        timestamp: datetime = field(default_factory=datetime.now)
        sequence: int = field(default_factory=lambda: 0)
        
        def serialize(self) -> bytes:
            """Convert message to bytes for transmission."""
            message_dict = {
                "type": self.message_type,
                "version": self.version,
                "payload": self.payload,
                "timestamp": self.timestamp.isoformat(),
                "sequence": self.sequence
            }
            return json.dumps(message_dict).encode()
        
        @classmethod
        def deserialize(cls, data: bytes) -> 'ProtocolMessage':
            """Create message from received bytes."""
            message_dict = json.loads(data.decode())
            return cls(
                message_type=message_dict["type"],
                version=message_dict["version"],
                payload=message_dict["payload"],
                timestamp=datetime.fromisoformat(message_dict["timestamp"]),
                sequence=message_dict["sequence"]
            )
    
    class Protocol(ABC):
        """Base class for network protocols."""
        
        def __init__(self, version: str):
            self.version = version
            self.message_handlers: Dict[str, List[callable]] = {}
            self.sequence_counter = 0
        
        @abstractmethod
        async def handle_message(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            """
            Handle an incoming protocol message.
            
            Args:
                message: The received message
                
            Returns:
                Optional[ProtocolMessage]: Response message if any
            """
            pass
        
        @abstractmethod
        async def create_message(self, message_type: str, payload: Dict[str, Any]) -> ProtocolMessage:
            """
            Create a new protocol message.
            
            Args:
                message_type: Type of message to create
                payload: Message payload
                
            Returns:
                ProtocolMessage: The created message
            """
            pass
    
    class HandshakeProtocol(Protocol):
        """Protocol implementation for peer handshakes."""
        
        def __init__(self):
            super().__init__("icn/1.0")
            
        async def handle_message(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            if message.message_type == "handshake_init":
                return await self.create_message("handshake_ack", {
                    "accepted": True,
                    "supported_protocols": ["icn/1.0", "icn/1.1"]
                })
            return None
            
        async def create_message(self, message_type: str, payload: Dict[str, Any]) -> ProtocolMessage:
            self.sequence_counter += 1
            return ProtocolMessage(
                message_type=message_type,
                version=self.version,
                payload=payload,
                sequence=self.sequence_counter
            )
    
    class ConsensusProtocol(Protocol):
        """Protocol implementation for consensus-related messages."""
        
        def __init__(self):
            super().__init__("icn/1.0")
            
        async def handle_message(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            handlers = {
                "block_proposal": self._handle_block_proposal,
                "block_validation": self._handle_block_validation,
                "validation_result": self._handle_validation_result
            }
            
            handler = handlers.get(message.message_type)
            if handler:
                return await handler(message)
            return None
            
        async def create_message(self, message_type: str, payload: Dict[str, Any]) -> ProtocolMessage:
            self.sequence_counter += 1
            return ProtocolMessage(
                message_type=message_type,
                version=self.version,
                payload=payload,
                sequence=self.sequence_counter
            )
        
        async def _handle_block_proposal(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            """Handle incoming block proposal."""
            try:
                # Validate block proposal
                block_data = message.payload.get("block")
                if not block_data:
                    return await self.create_message("block_validation", {
                        "accepted": False,
                        "reason": "Missing block data"
                    })
                
                # TODO: Implement actual block validation logic
                
                return await self.create_message("block_validation", {
                    "accepted": True,
                    "block_hash": block_data.get("hash")
                })
                
            except Exception as e:
                logger.error(f"Error handling block proposal: {str(e)}")
                return await self.create_message("block_validation", {
                    "accepted": False,
                    "reason": str(e)
                })
        
        async def _handle_block_validation(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            """Handle block validation message."""
            try:
                validation_result = message.payload.get("accepted", False)
                if validation_result:
                    # TODO: Implement validation confirmation logic
                    return None
                
                reason = message.payload.get("reason", "Unknown reason")
                logger.warning(f"Block validation failed: {reason}")
                return None
                
            except Exception as e:
                logger.error(f"Error handling block validation: {str(e)}")
                return None
        
        async def _handle_validation_result(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            """Handle validation result message."""
            try:
                # Process validation result
                result = message.payload.get("result", {})
                block_hash = result.get("block_hash")
                is_valid = result.get("is_valid", False)
                
                if is_valid:
                    # TODO: Implement logic for accepted validation
                    pass
                else:
                    reason = result.get("reason", "Unknown reason")
                    logger.warning(f"Validation rejected for block {block_hash}: {reason}")
                
                return None
                
            except Exception as e:
                logger.error(f"Error handling validation result: {str(e)}")
                return None
    
    class SyncProtocol(Protocol):
        """Protocol implementation for state synchronization."""
        
        def __init__(self):
            super().__init__("icn/1.0")
            
        async def handle_message(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            handlers = {
                "sync_request": self._handle_sync_request,
                "sync_response": self._handle_sync_response,
                "sync_complete": self._handle_sync_complete
            }
            
            handler = handlers.get(message.message_type)
            if handler:
                return await handler(message)
            return None
            
        async def create_message(self, message_type: str, payload: Dict[str, Any]) -> ProtocolMessage:
            self.sequence_counter += 1
            return ProtocolMessage(
                message_type=message_type,
                version=self.version,
                payload=payload,
                sequence=self.sequence_counter
            )
        
        async def _handle_sync_request(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            """Handle state sync request."""
            try:
                # Get sync parameters
                start_block = message.payload.get("start_block", 0)
                end_block = message.payload.get("end_block")
                
                # TODO: Implement state gathering logic
                
                return await self.create_message("sync_response", {
                    "start_block": start_block,
                    "end_block": end_block,
                    "state": {}  # Add actual state data
                })
                
            except Exception as e:
                logger.error(f"Error handling sync request: {str(e)}")
                return await self.create_message("sync_response", {
                    "error": str(e)
                })
        
        async def _handle_sync_response(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            """Handle state sync response."""
            try:
                state_data = message.payload.get("state", {})
                if not state_data:
                    return None
                
                # TODO: Implement state application logic
                
                return await self.create_message("sync_complete", {
                    "success": True
                })
                
            except Exception as e:
                logger.error(f"Error handling sync response: {str(e)}")
                return await self.create_message("sync_complete", {
                    "success": False,
                    "error": str(e)
                })
        
        async def _handle_sync_complete(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
            """Handle sync completion message."""
            try:
                success = message.payload.get("success", False)
                if not success:
                    error = message.payload.get("error", "Unknown error")
                    logger.error(f"Sync failed: {error}")
                
                # TODO: Implement sync completion logic
                
                return None
                
            except Exception as e:
                logger.error(f"Error handling sync complete: {str(e)}")
                return None
```

# File: /home/matt/icn-prototype/blockchain/network/protocol/dispatcher.py

```py
    # ================================================================
    # File: blockchain/network/protocol/dispatcher.py
    # Description: Message dispatcher for ICN network.
    # Handles routing and processing of network messages, providing a
    # centralized point for message handling and distribution.
    # ================================================================
    
    import asyncio
    import logging
    from typing import Dict, Set, List, Optional, Callable, Any, Union
    from dataclasses import dataclass, field
    from datetime import datetime
    import json
    from enum import Enum, auto
    import hashlib
    import traceback
    
    from ..config import NetworkConfig
    from ..transport.transport import NetworkTransport, MessageFrame
    
    logger = logging.getLogger(__name__)
    
    class MessagePriority(Enum):
        """Message priority levels."""
        HIGH = auto()    # Critical messages (consensus, block propagation)
        MEDIUM = auto()  # Important but not critical (transaction propagation)
        LOW = auto()     # Regular messages (peer discovery, metrics)
    
    @dataclass
    class MessageHandler:
        """Registered message handler information."""
        callback: Callable
        priority: MessagePriority
        requires_response: bool = False
        timeout: float = 30.0
        cooperative_only: bool = False
        max_size: Optional[int] = None
        version_requirements: Optional[Set[str]] = None
    
    @dataclass
    class PendingResponse:
        """Tracks pending message responses."""
        message_id: str
        sender: str
        timestamp: datetime
        timeout: float
        future: asyncio.Future
        message_type: str
    
    @dataclass
    class MessageRoute:
        """Message routing information."""
        message_type: str
        target_shards: Set[int]
        target_cooperatives: Set[str]
        exclude_peers: Set[str]
        broadcast: bool = False
        local_only: bool = False
    
    class MessageDispatcher:
        """
        Central message handling and routing system.
        
        Features:
        - Priority-based message processing
        - Message routing and filtering
        - Request-response handling
        - Cross-shard message propagation
        - Cooperative-aware message distribution
        - Message validation and rate limiting
        """
    
        def __init__(self, config: NetworkConfig, transport: NetworkTransport):
            """
            Initialize the message dispatcher.
            
            Args:
                config: Network configuration
                transport: Network transport layer
            """
            self.config = config
            self.transport = transport
            
            # Message handling
            self.handlers: Dict[str, MessageHandler] = {}
            self.pending_responses: Dict[str, PendingResponse] = {}
            
            # Message queues (priority-based)
            self.high_priority_queue: asyncio.Queue = asyncio.Queue()
            self.medium_priority_queue: asyncio.Queue = asyncio.Queue()
            self.low_priority_queue: asyncio.Queue = asyncio.Queue()
            
            # Rate limiting
            self.message_counts: Dict[str, int] = {}  # peer_id -> count
            self.message_timestamps: Dict[str, List[datetime]] = {}  # peer_id -> timestamps
            self.rate_limit_window = 60  # seconds
            self.rate_limit_max = 1000  # messages per window
            
            # State
            self.is_running = False
            self.processing_tasks: Set[asyncio.Task] = set()
            
            # Metrics
            self.metrics = {
                "messages_processed": 0,
                "messages_routed": 0,
                "messages_dropped": 0,
                "responses_received": 0,
                "responses_timed_out": 0,
                "rate_limit_violations": 0
            }
    
        async def start(self) -> None:
            """Start the message dispatcher."""
            if self.is_running:
                return
                
            try:
                self.is_running = True
                
                # Start worker tasks for each priority queue
                self.processing_tasks.add(
                    asyncio.create_task(self._process_queue(
                        self.high_priority_queue,
                        "high"
                    ))
                )
                self.processing_tasks.add(
                    asyncio.create_task(self._process_queue(
                        self.medium_priority_queue,
                        "medium"
                    ))
                )
                self.processing_tasks.add(
                    asyncio.create_task(self._process_queue(
                        self.low_priority_queue,
                        "low"
                    ))
                )
                
                # Start maintenance task
                self.processing_tasks.add(
                    asyncio.create_task(self._maintenance_loop())
                )
                
                logger.info("Message dispatcher started")
                
            except Exception as e:
                logger.error(f"Error starting message dispatcher: {str(e)}")
                raise
    
        async def stop(self) -> None:
            """Stop the message dispatcher."""
            if not self.is_running:
                return
                
            try:
                self.is_running = False
                
                # Cancel all pending responses
                for pending in self.pending_responses.values():
                    if not pending.future.done():
                        pending.future.cancel()
                
                # Cancel all processing tasks
                for task in self.processing_tasks:
                    task.cancel()
                    
                await asyncio.gather(*self.processing_tasks, return_exceptions=True)
                self.processing_tasks.clear()
                
                logger.info("Message dispatcher stopped")
                
            except Exception as e:
                logger.error(f"Error stopping message dispatcher: {str(e)}")
    
        def register_handler(
            self,
            message_type: str,
            callback: Callable,
            priority: MessagePriority = MessagePriority.MEDIUM,
            requires_response: bool = False,
            timeout: float = 30.0,
            cooperative_only: bool = False,
            max_size: Optional[int] = None,
            version_requirements: Optional[Set[str]] = None
        ) -> None:
            """
            Register a message handler.
            
            Args:
                message_type: Type of message to handle
                callback: Handler function
                priority: Message processing priority
                requires_response: Whether handler expects a response
                timeout: Response timeout in seconds
                cooperative_only: Whether to only accept messages from cooperative peers
                max_size: Maximum message size in bytes
                version_requirements: Required protocol versions
            """
            self.handlers[message_type] = MessageHandler(
                callback=callback,
                priority=priority,
                requires_response=requires_response,
                timeout=timeout,
                cooperative_only=cooperative_only,
                max_size=max_size,
                version_requirements=version_requirements
            )
    
        async def dispatch_message(
            self,
            message_type: str,
            payload: Dict[str, Any],
            routing: Optional[MessageRoute] = None,
            wait_response: bool = False
        ) -> Optional[Dict[str, Any]]:
            """
            Dispatch a message to the network.
            
            Args:
                message_type: Type of message to send
                payload: Message payload
                routing: Optional routing information
                wait_response: Whether to wait for response
                
            Returns:
                Optional[Dict[str, Any]]: Response payload if wait_response is True
            """
            try:
                message_id = self._generate_message_id(message_type, payload)
                
                if routing and routing.local_only:
                    # Handle message locally
                    return await self._handle_local_message(
                        message_type,
                        message_id,
                        payload
                    )
                
                # Prepare message for sending
                message = {
                    "message_id": message_id,
                    "message_type": message_type,
                    "payload": payload,
                    "timestamp": datetime.now().isoformat(),
                    "sender": self.config.node_id
                }
                
                if wait_response:
                    # Create future for response
                    future = asyncio.Future()
                    self.pending_responses[message_id] = PendingResponse(
                        message_id=message_id,
                        sender=self.config.node_id,
                        timestamp=datetime.now(),
                        timeout=30.0,
                        future=future,
                        message_type=message_type
                    )
                    
                # Route message
                success = await self._route_message(message, routing)
                if not success:
                    if wait_response:
                        self.pending_responses[message_id].future.cancel()
                        del self.pending_responses[message_id]
                    return None
                
                if wait_response:
                    try:
                        # Wait for response
                        response = await asyncio.wait_for(
                            self.pending_responses[message_id].future,
                            timeout=30.0
                        )
                        return response
                    except asyncio.TimeoutError:
                        logger.warning(f"Response timeout for message {message_id}")
                        self.metrics["responses_timed_out"] += 1
                        return None
                    finally:
                        if message_id in self.pending_responses:
                            del self.pending_responses[message_id]
                
                return None
                
            except Exception as e:
                logger.error(f"Error dispatching message: {str(e)}")
                return None
    
        async def handle_message(
            self,
            peer_id: str,
            message_data: Dict[str, Any]
        ) -> None:
            """
            Handle received message from transport layer.
            
            Args:
                peer_id: ID of sending peer
                message_data: Received message data
            """
            try:
                # Extract message information
                message_type = message_data.get("message_type")
                message_id = message_data.get("message_id")
                payload = message_data.get("payload")
                
                if not all([message_type, message_id, payload]):
                    logger.error("Invalid message format")
                    return
                    
                # Check rate limits
                if not self._check_rate_limit(peer_id):
                    logger.warning(f"Rate limit exceeded for peer {peer_id}")
                    self.metrics["rate_limit_violations"] += 1
                    return
                    
                # Get handler
                handler = self.handlers.get(message_type)
                if not handler:
                    logger.warning(f"No handler for message type: {message_type}")
                    return
                    
                # Validate message
                if not await self._validate_message(
                    message_data,
                    handler,
                    peer_id
                ):
                    return
                    
                # Queue message for processing
                await self._queue_message(
                    handler.priority,
                    peer_id,
                    message_type,
                    message_id,
                    payload
                )
                
            except Exception as e:
                logger.error(f"Error handling message: {str(e)}")
    
        async def _handle_local_message(
            self,
            message_type: str,
            message_id: str,
            payload: Dict[str, Any]
        ) -> Optional[Dict[str, Any]]:
            """Handle message locally without network transmission."""
            try:
                handler = self.handlers.get(message_type)
                if not handler:
                    logger.warning(f"No handler for local message type: {message_type}")
                    return None
                    
                # Execute handler
                response = await handler.callback(self.config.node_id, payload)
                return response
                
            except Exception as e:
                logger.error(f"Error handling local message: {str(e)}")
                return None
    
        async def _route_message(
            self,
            message: Dict[str, Any],
            routing: Optional[MessageRoute]
        ) -> bool:
            """Route message according to routing information."""
            try:
                if not routing:
                    # Broadcast to all peers
                    return await self.transport.broadcast_message(
                        message["message_type"],
                        message
                    )
                
                success = True
                sent_to_peers = set()
                
                # Send to target shards
                if routing.target_shards:
                    # TODO: Implement shard-based routing
                    pass
                
                # Send to target cooperatives
                if routing.target_cooperatives:
                    # TODO: Implement cooperative-based routing
                    pass
                
                # Broadcast if specified
                if routing.broadcast:
                    for peer_id in self.transport.get_peer_ids():
                        if (peer_id not in sent_to_peers and 
                            peer_id not in routing.exclude_peers):
                            success &= await self.transport.send_message(
                                peer_id,
                                message["message_type"],
                                message
                            )
                            sent_to_peers.add(peer_id)
                
                self.metrics["messages_routed"] += len(sent_to_peers)
                return success
                
            except Exception as e:
                logger.error(f"Error routing message: {str(e)}")
                return False
    
        async def _process_queue(
            self,
            queue: asyncio.Queue,
            priority: str
        ) -> None:
            """Process messages from a priority queue."""
            while self.is_running:
                try:
                    # Get message from queue
                    peer_id, message_type, message_id, payload = await queue.get()
                    
                    # Get handler
                    handler = self.handlers[message_type]
                    
                    try:
                        # Execute handler
                        response = await handler.callback(peer_id, payload)
                        
                        # Handle response if needed
                        if message_id in self.pending_responses:
                            pending = self.pending_responses[message_id]
                            if not pending.future.done():
                                pending.future.set_result(response)
                                self.metrics["responses_received"] += 1
                        
                        self.metrics["messages_processed"] += 1
                        
                    except Exception as e:
                        logger.error(
                            f"Error processing {priority} priority message: {str(e)}\n"
                            f"{''.join(traceback.format_exc())}"
                        )
                        self.metrics["messages_dropped"] += 1
                    
                    finally:
                        queue.task_done()
                        
                except asyncio.CancelledError:
                    break
                except Exception as e:
                    logger.error(f"Error in {priority} priority queue processing: {str(e)}")
                    await asyncio.sleep(1)
    
        async def _maintenance_loop(self) -> None:
            """Periodic maintenance tasks."""
            while self.is_running:
                try:
                    current_time = datetime.now()
                    
                    # Clean up pending responses
                    for message_id in list(self.pending_responses.keys()):
                        pending = self.pending_responses[message_id]
                        if (current_time - pending.timestamp).total_seconds() > pending.timeout:
                            if not pending.future.done():
                                pending.future.cancel()
                            del self.pending_responses[message_id]
                            self.metrics["responses_timed_out"] += 1
                    
                    # Clean up rate limiting data
                    window_start = current_time.timestamp() - self.rate_limit_window
                    for peer_id in list(self.message_timestamps.keys()):
                        self.message_timestamps[peer_id] = [
                            ts for ts in self.message_timestamps[peer_id]
                            if ts.timestamp() > window_start
                        ]
                        self.message_counts[peer_id] = len(self.message_timestamps[peer_id])
                    
                except Exception as e:
                    logger.error(f"Error in maintenance loop: {str(e)}")
                    
                await asyncio.sleep(1)
    
        def _check_rate_limit(self, peer_id: str) -> bool:
            """Check if peer has exceeded rate limit."""
            current_time = datetime.now()
            
            if peer_id not in self.message_timestamps:
                self.message_timestamps[peer_id] = []
                self.message_counts[peer_id] = 0
                
            # Add new timestamp
            self.message_timestamps[peer_id].append(current_time)
            
           # Update count
            window_start = current_time.timestamp() - self.rate_limit_window
            self.message_counts[peer_id] = sum(
                1 for ts in self.message_timestamps[peer_id]
                if ts.timestamp() > window_start
            )
            
            # Check against limit
            return self.message_counts[peer_id] <= self.rate_limit_max
    
        async def _validate_message(
            self,
            message_data: Dict[str, Any],
            handler: MessageHandler,
            peer_id: str
        ) -> bool:
            """
            Validate incoming message.
            
            Args:
                message_data: Message to validate
                handler: Handler for this message type
                peer_id: ID of sending peer
                
            Returns:
                bool: True if message is valid
            """
            try:
                # Check cooperative requirement
                if handler.cooperative_only:
                    peer_info = self.transport.get_peer_info(peer_id)
                    if not peer_info or not peer_info.cooperative_id:
                        logger.warning(f"Non-cooperative peer {peer_id} sent cooperative-only message")
                        return False
                
                # Check message size
                if handler.max_size:
                    message_size = len(json.dumps(message_data))
                    if message_size > handler.max_size:
                        logger.warning(f"Message from {peer_id} exceeds size limit")
                        return False
                
                # Check version requirements
                if handler.version_requirements:
                    peer_info = self.transport.get_peer_info(peer_id)
                    if not peer_info:
                        return False
                        
                    peer_versions = peer_info.supported_protocols
                    if not peer_versions & handler.version_requirements:
                        logger.warning(f"Peer {peer_id} doesn't support required protocol version")
                        return False
                
                return True
                
            except Exception as e:
                logger.error(f"Error validating message: {str(e)}")
                return False
    
        async def _queue_message(
            self,
            priority: MessagePriority,
            peer_id: str,
            message_type: str,
            message_id: str,
            payload: Dict[str, Any]
        ) -> None:
            """Queue message for processing according to priority."""
            try:
                message_tuple = (peer_id, message_type, message_id, payload)
                
                if priority == MessagePriority.HIGH:
                    await self.high_priority_queue.put(message_tuple)
                elif priority == MessagePriority.MEDIUM:
                    await self.medium_priority_queue.put(message_tuple)
                else:
                    await self.low_priority_queue.put(message_tuple)
                    
            except Exception as e:
                logger.error(f"Error queuing message: {str(e)}")
    
        def _generate_message_id(self, message_type: str, payload: Dict[str, Any]) -> str:
            """Generate unique message ID."""
            data = f"{self.config.node_id}:{message_type}:{json.dumps(payload, sort_keys=True)}"
            return hashlib.sha256(data.encode()).hexdigest()
    
        def get_queue_sizes(self) -> Dict[str, int]:
            """Get current size of message queues."""
            return {
                "high_priority": self.high_priority_queue.qsize(),
                "medium_priority": self.medium_priority_queue.qsize(),
                "low_priority": self.low_priority_queue.qsize()
            }
    
        def get_metrics(self) -> Dict[str, int]:
            """Get dispatcher metrics."""
            metrics = self.metrics.copy()
            metrics.update({
                "pending_responses": len(self.pending_responses),
                "registered_handlers": len(self.handlers)
            })
            return metrics
    
    # Example usage
    async def example_usage():
        config = NetworkConfig(node_id="test_node")
        transport = NetworkTransport(config)
        dispatcher = MessageDispatcher(config, transport)
        
        # Register message handler
        async def handle_test_message(peer_id: str, payload: Dict[str, Any]) -> None:
            print(f"Received test message from {peer_id}: {payload}")
            
        dispatcher.register_handler(
            "test_message",
            handle_test_message,
            priority=MessagePriority.MEDIUM
        )
        
        # Start dispatcher
        await dispatcher.start()
        
        # Dispatch message
        response = await dispatcher.dispatch_message(
            "test_message",
            {"content": "Hello world"},
            routing=MessageRoute(
                message_type="test_message",
                target_shards={1},
                target_cooperatives={"coop1"},
                exclude_peers=set(),
                broadcast=True
            )
        )
        
        # Stop dispatcher
        await dispatcher.stop()
    
    if __name__ == "__main__":
        asyncio.run(example_usage())
```

# File: /home/matt/icn-prototype/blockchain/network/transport/transport.py

```py
    # ================================================================
    # File: blockchain/network/transport/transport.py
    # Description: Transport layer implementation for ICN network.
    # Handles low-level network communication, including message framing,
    # encryption, and reliable delivery.
    # ================================================================
    
    import asyncio
    import logging
    import struct
    import json
    from typing import Dict, Optional, Tuple, Any, Callable
    from dataclasses import dataclass
    from datetime import datetime
    import hashlib
    from cryptography.fernet import Fernet
    from ..config import NetworkConfig
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class MessageFrame:
        """Represents a framed network message."""
        message_type: str
        payload: bytes
        sequence: int
        timestamp: datetime
        flags: int = 0
        
        # Message frame format:
        # | Magic (2) | Version (2) | Flags (2) | Sequence (4) | Length (4) | Type (2) | Payload (...) | CRC (4) |
        FRAME_MAGIC = 0x1C4E  # ICN in hex
        FRAME_VERSION = 1
        HEADER_SIZE = 20
        
        def pack(self) -> bytes:
            """Pack message into bytes for transmission."""
            try:
                type_id = hash(self.message_type) & 0xFFFF  # Convert type to 16-bit identifier
                payload_len = len(self.payload)
                
                # Create header
                header = struct.pack(
                    ">HHHIH",  # Big-endian: magic, version, flags, sequence, length
                    self.FRAME_MAGIC,
                    self.FRAME_VERSION,
                    self.flags,
                    self.sequence,
                    payload_len
                )
                
                # Pack message type
                header += struct.pack(">H", type_id)
                
                # Combine header and payload
                message = header + self.payload
                
                # Add CRC
                crc = self._calculate_crc(message)
                message += struct.pack(">I", crc)
                
                return message
                
            except Exception as e:
                logger.error(f"Error packing message frame: {str(e)}")
                raise
        
        @classmethod
        def unpack(cls, data: bytes) -> 'MessageFrame':
            """Unpack bytes into message frame."""
            try:
                # Verify minimum length
                if len(data) < cls.HEADER_SIZE + 4:  # Header + CRC
                    raise ValueError("Message too short")
                    
                # Parse header
                magic, version, flags, sequence, payload_len, type_id = struct.unpack(
                    ">HHHIHH",
                    data[:cls.HEADER_SIZE]
                )
                
                # Verify magic number and version
                if magic != cls.FRAME_MAGIC:
                    raise ValueError("Invalid message magic number")
                if version != cls.FRAME_VERSION:
                    raise ValueError("Unsupported message version")
                    
                # Extract payload
                payload_start = cls.HEADER_SIZE
                payload_end = payload_start + payload_len
                payload = data[payload_start:payload_end]
                
                # Verify payload length
                if len(payload) != payload_len:
                    raise ValueError("Incomplete message payload")
                    
                # Verify CRC
                received_crc = struct.unpack(">I", data[payload_end:payload_end + 4])[0]
                calculated_crc = cls._calculate_crc(data[:payload_end])
                if received_crc != calculated_crc:
                    raise ValueError("CRC check failed")
                    
                # Reconstruct message type from type_id
                message_type = f"type_{type_id}"  # TODO: Implement proper type mapping
                
                return cls(
                    message_type=message_type,
                    payload=payload,
                    sequence=sequence,
                    timestamp=datetime.now(),
                    flags=flags
                )
                
            except Exception as e:
                logger.error(f"Error unpacking message frame: {str(e)}")
                raise
        
        @staticmethod
        def _calculate_crc(data: bytes) -> int:
            """Calculate CRC32 checksum."""
            return struct.unpack(">I", hashlib.crc32(data).to_bytes(4, 'big'))[0]
    
    class SecureChannel:
        """Handles encrypted communication channel."""
        
        def __init__(self, key: Optional[bytes] = None):
            """Initialize secure channel with optional encryption key."""
            self.key = key or Fernet.generate_key()
            self.cipher = Fernet(self.key)
            
        def encrypt(self, data: bytes) -> bytes:
            """Encrypt data."""
            try:
                return self.cipher.encrypt(data)
            except Exception as e:
                logger.error(f"Encryption error: {str(e)}")
                raise
                
        def decrypt(self, data: bytes) -> bytes:
            """Decrypt data."""
            try:
                return self.cipher.decrypt(data)
            except Exception as e:
                logger.error(f"Decryption error: {str(e)}")
                raise
    
    class NetworkTransport:
        """
        Handles reliable network transport with message framing and encryption.
        
        Features:
        - Message framing and sequencing
        - Optional encryption
        - Flow control
        - Error detection
        - Message acknowledgment
        """
        
        def __init__(self, config: NetworkConfig):
            """Initialize transport layer."""
            self.config = config
            self.sequence_counter = 0
            self.pending_messages: Dict[int, MessageFrame] = {}
            self.secure_channels: Dict[str, SecureChannel] = {}  # peer_id -> channel
            self.message_handlers: Dict[str, Callable] = {}
            self.retransmit_interval = 5.0  # seconds
            self.max_retransmissions = 3
            
            # Performance tracking
            self.metrics = {
                "messages_sent": 0,
                "messages_received": 0,
                "bytes_sent": 0,
                "bytes_received": 0,
                "retransmissions": 0,
                "failed_deliveries": 0,
                "encryption_errors": 0
            }
        
        async def send_message(
            self,
            peer_id: str,
            message_type: str,
            payload: Dict[str, Any],
            require_ack: bool = True
        ) -> bool:
            """
            Send a message to a peer.
            
            Args:
                peer_id: ID of the peer to send to
                message_type: Type of message
                payload: Message payload
                require_ack: Whether to wait for acknowledgment
                
            Returns:
                bool: True if message sent successfully
            """
            try:
                # Serialize payload
                payload_bytes = json.dumps(payload).encode()
                
                # Create message frame
                self.sequence_counter += 1
                frame = MessageFrame(
                    message_type=message_type,
                    payload=payload_bytes,
                    sequence=self.sequence_counter,
                    timestamp=datetime.now()
                )
                
                # Encrypt if necessary
                if self.config.enable_encryption and peer_id in self.secure_channels:
                    channel = self.secure_channels[peer_id]
                    frame.payload = channel.encrypt(frame.payload)
                    frame.flags |= 0x0001  # Set encryption flag
                
                # Pack frame
                message_data = frame.pack()
                
                # Send message
                writer = self._get_peer_writer(peer_id)
                if not writer:
                    return False
                    
                writer.write(message_data)
                await writer.drain()
                
                # Track metrics
                self.metrics["messages_sent"] += 1
                self.metrics["bytes_sent"] += len(message_data)
                
                # Handle acknowledgment
                if require_ack:
                    self.pending_messages[frame.sequence] = frame
                    acknowledgment = await self._wait_for_ack(frame.sequence)
                    return acknowledgment
                
                return True
                
            except Exception as e:
                logger.error(f"Error sending message to {peer_id}: {str(e)}")
                return False
        
        async def handle_connection(
            self,
            peer_id: str,
            reader: asyncio.StreamReader,
            writer: asyncio.StreamWriter
        ) -> None:
            """
            Handle incoming peer connection.
            
            Args:
                peer_id: ID of the connected peer
                reader: StreamReader for receiving data
                writer: StreamWriter for sending data
            """
            try:
                # Initialize encryption if enabled
                if self.config.enable_encryption:
                    await self._setup_secure_channel(peer_id, reader, writer)
                
                # Start message handling loop
                while True:
                    # Read header size
                    header_data = await reader.readexactly(MessageFrame.HEADER_SIZE)
                    
                    # Parse header
                    magic, version, flags, sequence, payload_len, _ = struct.unpack(
                        ">HHHIHH",
                        header_data
                    )
                    
                    # Verify magic number and version
                    if magic != MessageFrame.FRAME_MAGIC:
                        logger.error(f"Invalid message magic from {peer_id}")
                        break
                        
                    if version != MessageFrame.FRAME_VERSION:
                        logger.error(f"Unsupported message version from {peer_id}")
                        break
                    
                    # Read payload and CRC
                    remaining_data = await reader.readexactly(payload_len + 4)
                    message_data = header_data + remaining_data
                    
                    # Unpack message
                    message = MessageFrame.unpack(message_data)
                    
                    # Decrypt if necessary
                    if flags & 0x0001 and peer_id in self.secure_channels:
                        channel = self.secure_channels[peer_id]
                        message.payload = channel.decrypt(message.payload)
                    
                    # Track metrics
                    self.metrics["messages_received"] += 1
                    self.metrics["bytes_received"] += len(message_data)
                    
                    # Send acknowledgment
                    await self._send_ack(writer, sequence)
                    
                    # Handle message
                    await self._handle_message(peer_id, message)
                    
            except asyncio.IncompleteReadError:
                logger.info(f"Connection closed by peer {peer_id}")
            except Exception as e:
                logger.error(f"Error handling connection from {peer_id}: {str(e)}")
            finally:
                writer.close()
                await writer.wait_closed()
                if peer_id in self.secure_channels:
                    del self.secure_channels[peer_id]
        
        def register_handler(
            self,
            message_type: str,
            handler: Callable[[str, Dict[str, Any]], None]
        ) -> None:
            """
            Register a message handler.
            
            Args:
                message_type: Type of message to handle
                handler: Callback function
            """
            self.message_handlers[message_type] = handler
        
        async def _setup_secure_channel(
            self,
            peer_id: str,
            reader: asyncio.StreamReader,
            writer: asyncio.StreamWriter
        ) -> None:
            """Set up encrypted channel with peer."""
            try:
                # Exchange keys
                my_key = Fernet.generate_key()
                writer.write(my_key)
                await writer.drain()
                
                peer_key = await reader.readexactly(44)  # Fernet key length
                
                # Create secure channel
                channel = SecureChannel(peer_key)
                self.secure_channels[peer_id] = channel
                
            except Exception as e:
                logger.error(f"Error setting up secure channel with {peer_id}: {str(e)}")
                self.metrics["encryption_errors"] += 1
                raise
        
        async def _handle_message(self, peer_id: str, message: MessageFrame) -> None:
            """Handle received message."""
            try:
                # Deserialize payload
                payload = json.loads(message.payload.decode())
                
                # Call registered handler
                handler = self.message_handlers.get(message.message_type)
                if handler:
                    await handler(peer_id, payload)
                else:
                    logger.warning(f"No handler for message type: {message.message_type}")
                    
            except Exception as e:
                logger.error(f"Error handling message: {str(e)}")
        
        async def _send_ack(self, writer: asyncio.StreamWriter, sequence: int) -> None:
            """Send acknowledgment message."""
            try:
                ack = struct.pack(">I", sequence)
                writer.write(ack)
                await writer.drain()
            except Exception as e:
                logger.error(f"Error sending acknowledgment: {str(e)}")
        
        async def _wait_for_ack(self, sequence: int) -> bool:
            """Wait for message acknowledgment."""
            try:
                retries = 0
                while retries < self.max_retransmissions:
                    try:
                        # Wait for acknowledgment
                        await asyncio.sleep(self.retransmit_interval)
                        
                        # Check if message was acknowledged
                        if sequence not in self.pending_messages:
                            return True
                            
                        # Retransmit if necessary
                        if retries < self.max_retransmissions - 1:
                            frame = self.pending_messages[sequence]
                            message_data = frame.pack()
                            writer = self._get_peer_writer(frame.peer_id)
                            if writer:
                                writer.write(message_data)
                                await writer.drain()
                                self.metrics["retransmissions"] += 1
                        
                        retries += 1
                        
                    except Exception as e:
                        logger.error(f"Error in acknowledgment wait: {str(e)}")
                        retries += 1
                
                # Message delivery failed
                if sequence in self.pending_messages:
                    del self.pending_messages[sequence]
                self.metrics["failed_deliveries"] += 1
                return False
                
            except Exception as e:
                logger.error(f"Error waiting for acknowledgment: {str(e)}")
                return False
        
        def _get_peer_writer(self, peer_id: str) -> Optional[asyncio.StreamWriter]:
            """Get StreamWriter for a peer."""
            # TODO: Implement peer writer management
            return None
        
        def get_metrics(self) -> Dict[str, int]:
            """Get transport metrics."""
            return self.metrics.copy()
    
    # Example usage
    async def example_usage():
        config = NetworkConfig(node_id="test_node")
        transport = NetworkTransport(config)
        
        # Register message handler
        async def handle_message(peer_id: str, payload: Dict[str, Any]) -> None:
            print(f"Received message from {peer_id}: {payload}")
            
        transport.register_handler("test_message", handle_message)
        
        # Send message
        success = await transport.send_message(
            peer_id="peer1",
            message_type="test_message",
            payload={"hello": "world"}
        )
        print(f"Message sent: {success}")
    
    if __name__ == "__main__":
        asyncio.run(example_usage())
```

# File: /home/matt/icn-prototype/blockchain/core/node.py

```py
    from __future__ import annotations
    from datetime import datetime, timedelta
    from typing import Dict, List, Set, Optional
    import logging
    import json
    
    logger = logging.getLogger(__name__)
    
    class Node:
        """
        Represents a node in the ICN network.
    
        A node is a participant in the network that can validate transactions,
        participate in consensus, and maintain portions of the blockchain.
        """
    
        def __init__(
            self,
            node_id: str,
            cooperative_id: Optional[str] = None,
            initial_stake: float = 10.0,
        ):
            self.node_id = node_id
            self.cooperative_id = cooperative_id
            self.reputation_scores = {
                "validation": 0.0,
                "proposal_creation": 0.0,
                "voting": 0.0,
                "resource_sharing": 0.0,
                "cooperative_growth": 0.0,
                "community_building": 0.0,
                "conflict_resolution": 0.0,
                "transaction_validation": 0.0,
                "data_availability": 0.0,
                "network_stability": 0.0,
                "innovation": 0.0,
                "sustainability": 0.0,
            }
            self.stake = initial_stake
            self.cooperative_interactions: List[str] = []
            self.validation_history: List[Dict] = []
            self.resource_usage: Dict[str, float] = {
                "computation": 0.0,
                "storage": 0.0,
                "bandwidth": 0.0,
                "memory": 0.0,
                "energy": 0.0,
            }
            self.shard_assignments: Set[int] = set()
            self.active_shards: Dict[int, datetime] = {}
            self.last_validation = datetime.now().timestamp()
            self.total_validations = 0
            self.cooldown = 0
            self.performance_metrics: Dict[str, float] = {
                "response_time": 0.0,
                "availability": 100.0,
                "validation_success_rate": 100.0,
                "network_reliability": 100.0,
            }
            self.metadata: Dict = {
                "creation_time": datetime.now(),
                "last_active": datetime.now(),
                "version": "1.0",
                "capabilities": set(),
                "status": "active",
            }
    
        def update_reputation(
            self,
            category: str,
            score: float,
            cooperative_id: Optional[str] = None,
            evidence: Optional[Dict] = None,
        ) -> bool:
            """Update reputation score for a category with evidence."""
            try:
                if category not in self.reputation_scores:
                    logger.error(f"Invalid reputation category: {category}")
                    return False
    
                old_score = self.reputation_scores[category]
                self.reputation_scores[category] = max(0, old_score + score)
    
                if cooperative_id:
                    self.cooperative_interactions.append(cooperative_id)
    
                if evidence:
                    self.validation_history.append(
                        {
                            "timestamp": datetime.now(),
                            "category": category,
                            "score_change": score,
                            "evidence": evidence,
                        }
                    )
    
                self.metadata["last_active"] = datetime.now()
    
                # Trim history if needed
                if len(self.cooperative_interactions) > 1000:
                    self.cooperative_interactions = self.cooperative_interactions[-1000:]
                if len(self.validation_history) > 1000:
                    self.validation_history = self.validation_history[-1000:]
    
                return True
    
            except Exception as e:
                logger.error(f"Failed to update reputation: {str(e)}")
                return False
    
        def assign_to_shard(self, shard_id: int) -> bool:
            """Assign node to a shard."""
            if len(self.active_shards) >= 3:  # Maximum 3 active shards per node
                logger.warning(f"Node {self.node_id} already assigned to maximum shards")
                return False
    
            self.shard_assignments.add(shard_id)
            self.active_shards[shard_id] = datetime.now()
            logger.info(f"Node {self.node_id} assigned to shard {shard_id}")
            return True
    
        def remove_from_shard(self, shard_id: int) -> bool:
            """Remove node from a shard."""
            if shard_id in self.active_shards:
                del self.active_shards[shard_id]
                self.shard_assignments.discard(shard_id)
                logger.info(f"Node {self.node_id} removed from shard {shard_id}")
                return True
            return False
    
        def can_validate(self, shard_id: Optional[int] = None) -> bool:
            """Check if node can validate blocks."""
            current_time = datetime.now().timestamp()
    
            # Basic validation checks
            if self.cooldown > 0:
                return False
    
            if (current_time - self.last_validation) < 10:  # 10-second minimum
                return False
    
            if self.metadata["status"] != "active":
                return False
    
            # Shard-specific validation
            if shard_id is not None:
                if shard_id not in self.active_shards:
                    return False
    
                shard_time = self.active_shards[shard_id]
                if (datetime.now() - shard_time).total_seconds() > 3600:  # 1 hour timeout
                    return False
    
            return True
    
        def enter_cooldown(self, cooldown_period: int) -> None:
            """Put node into a cooldown period."""
            self.cooldown = cooldown_period
            self.metadata["status"] = "cooldown"
            logger.info(
                f"Node {self.node_id} entered cooldown for {cooldown_period} periods"
            )
    
        def update_metrics(self, metrics: Dict[str, float]) -> None:
            """Update node performance metrics."""
            self.performance_metrics.update(metrics)
            self.metadata["last_active"] = datetime.now()
    
            # Calculate validation success rate
            if self.total_validations > 0:
                success_rate = (
                    len(
                        [
                            v
                            for v in self.validation_history
                            if v.get("evidence", {}).get("success", False)
                        ]
                    )
                    / self.total_validations
                    * 100
                )
                self.performance_metrics["validation_success_rate"] = success_rate
    
        def get_total_reputation(self) -> float:
            """Calculate total reputation across all categories."""
            return sum(self.reputation_scores.values())
    
        def record_resource_usage(self, usage: Dict[str, float]) -> None:
            """Record resource usage metrics."""
            for resource, amount in usage.items():
                if resource in self.resource_usage:
                    self.resource_usage[resource] += amount
    
            # Update availability based on resource usage
            total_usage = sum(self.resource_usage.values())
            self.performance_metrics["availability"] = max(0, 100 - (total_usage / 5))
    
        def to_dict(self) -> Dict:
            """Convert node state to dictionary."""
            return {
                "node_id": self.node_id,
                "cooperative_id": self.cooperative_id,
                "reputation_scores": self.reputation_scores,
                "stake": self.stake,
                "shard_assignments": list(self.shard_assignments),
                "active_shards": {k: v.isoformat() for k, v in self.active_shards.items()},
                "performance_metrics": self.performance_metrics,
                "resource_usage": self.resource_usage,
                "metadata": {
                    **self.metadata,
                    "creation_time": self.metadata["creation_time"].isoformat(),
                    "last_active": self.metadata["last_active"].isoformat(),
                    "capabilities": list(self.metadata["capabilities"]),
                },
                "status": self.metadata["status"],
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> Node:
            """Create node from dictionary."""
            try:
                node = cls(
                    node_id=data["node_id"],
                    cooperative_id=data["cooperative_id"],
                    initial_stake=data["stake"],
                )
                node.reputation_scores = data["reputation_scores"]
                node.shard_assignments = set(data["shard_assignments"])
                node.active_shards = {
                    int(k): datetime.fromisoformat(v)
                    for k, v in data["active_shards"].items()
                }
                node.performance_metrics = data["performance_metrics"]
                node.resource_usage = data["resource_usage"]
    
                # Restore metadata
                node.metadata.update(data["metadata"])
                node.metadata["creation_time"] = datetime.fromisoformat(
                    data["metadata"]["creation_time"]
                )
                node.metadata["last_active"] = datetime.fromisoformat(
                    data["metadata"]["last_active"]
                )
                node.metadata["capabilities"] = set(data["metadata"]["capabilities"])
    
                return node
    
            except Exception as e:
                logger.error(f"Failed to create node from dictionary: {str(e)}")
                raise ValueError("Invalid node data")
    
        def __str__(self) -> str:
            """Return a human-readable string representation of the node."""
            return (
                f"Node(id={self.node_id}, "
                f"coop={self.cooperative_id}, "
                f"status={self.metadata['status']}, "
                f"rep={self.get_total_reputation():.2f})"
            )
```

# File: /home/matt/icn-prototype/blockchain/core/block.py

```py
    # ============================================================
    # File: blockchain/core/block.py
    # Description: Core block structure for the ICN blockchain.
    # This file defines the block class used within each shard of
    # the ICN blockchain. A block contains validated transactions
    # and includes cryptographic links to maintain chain integrity.
    # ============================================================
    
    # blockchain/core/block.py
    
    from dataclasses import dataclass, field
    from datetime import datetime, timedelta
    from typing import List, Dict, Optional
    import hashlib
    import json
    import logging
    
    from .transaction import Transaction
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class Block:
        """
        Represents a block in the ICN blockchain.
        
        A block is the fundamental unit of the blockchain, containing a list
        of transactions and cryptographic links to ensure immutability and
        integrity. Each block is validated by a node within a specific shard.
        """
    
        index: int
        previous_hash: str
        timestamp: datetime
        transactions: List[Transaction]
        validator: str
        shard_id: int
        hash: str = ""
        nonce: int = 0
        merkle_root: str = ""
        cross_shard_refs: List[str] = field(default_factory=list)
        metadata: Dict = field(default_factory=lambda: {
            "created_at": datetime.now().isoformat(),
            "version": "1.0"
        })
        version: str = "1.0"
        
        def __post_init__(self) -> None:
            """Initialize block after creation."""
            # Sort transactions by priority
            self.transactions.sort(key=lambda tx: (-tx.priority, tx.timestamp))
            
            # Calculate merkle root if not provided
            if not self.merkle_root:
                self.merkle_root = self.calculate_merkle_root()
            
            # Calculate hash if not provided
            if not self.hash:
                self.hash = self.calculate_hash()
                
            # Initialize metadata if not provided
            if "created_at" not in self.metadata:
                self.metadata["created_at"] = datetime.now().isoformat()
            if "version" not in self.metadata:
                self.metadata["version"] = self.version
    
        def calculate_merkle_root(self) -> str:
            """Calculate the Merkle root of transactions."""
            if not self.transactions:
                return hashlib.sha256(b"empty").hexdigest()
            
            # Create leaf nodes from transactions
            leaves = [tx.calculate_hash() for tx in self.transactions]
            
            # Build Merkle tree
            while len(leaves) > 1:
                if len(leaves) % 2 == 1:
                    leaves.append(leaves[-1])
                leaves = [
                    hashlib.sha256((a + b).encode()).hexdigest()
                    for a, b in zip(leaves[::2], leaves[1::2])
                ]
            
            return leaves[0]
    
        def calculate_hash(self) -> str:
            """Calculate the hash of the block."""
            block_dict = {
                "index": self.index,
                "previous_hash": self.previous_hash,
                "timestamp": self.timestamp.isoformat(),
                "merkle_root": self.merkle_root,
                "validator": self.validator,
                "nonce": self.nonce,
                "shard_id": self.shard_id,
                "cross_shard_refs": sorted(self.cross_shard_refs),
                "version": self.version,
                "transaction_ids": [tx.transaction_id for tx in self.transactions]
            }
            block_json = json.dumps(block_dict, sort_keys=True)
            return hashlib.sha256(block_json.encode()).hexdigest()
    
        def add_transaction(self, transaction: Transaction) -> bool:
            """Add a transaction to the block."""
            try:
                # Validate shard assignment
                if transaction.shard_id != self.shard_id:
                    logger.error(f"Transaction shard_id mismatch: {transaction.shard_id} != {self.shard_id}")
                    return False
                
                # Check for duplicate
                if any(tx.transaction_id == transaction.transaction_id for tx in self.transactions):
                    logger.error(f"Duplicate transaction: {transaction.transaction_id}")
                    return False
                
                # Add transaction
                self.transactions.append(transaction)
                
                # Resort transactions by priority
                self.transactions.sort(key=lambda tx: (-tx.priority, tx.timestamp))
                
                # Update merkle root and hash
                self.merkle_root = self.calculate_merkle_root()
                self.hash = self.calculate_hash()
                
                return True
                
            except Exception as e:
                logger.error(f"Error adding transaction: {str(e)}")
                return False
    
        def validate(self, previous_block: Optional['Block'] = None) -> bool:
            """Validate block structure and consistency."""
            try:
                # Validate hash
                current_hash = self.calculate_hash()
                if self.hash != current_hash:
                    logger.error("Invalid block hash")
                    return False
    
                # Validate merkle root
                current_merkle_root = self.calculate_merkle_root()
                if self.merkle_root != current_merkle_root:
                    logger.error("Invalid merkle root")
                    return False
    
                # Validate timestamp
                if self.timestamp > datetime.now() + timedelta(minutes=5):
                    logger.error("Block timestamp is in the future")
                    return False
    
                # Validate transactions
                if not all(tx.validate() for tx in self.transactions):
                    logger.error("Invalid transactions in block")
                    return False
    
                # Validate against previous block
                if previous_block:
                    if self.previous_hash != previous_block.hash:
                        logger.error("Invalid previous hash")
                        return False
                    
                    if self.index != previous_block.index + 1:
                        logger.error("Invalid block index")
                        return False
                    
                    if self.timestamp <= previous_block.timestamp:
                        logger.error("Invalid timestamp sequence")
                        return False
                        
                    if self.shard_id != previous_block.shard_id:
                        logger.error("Shard ID mismatch")
                        return False
    
                return True
    
            except Exception as e:
                logger.error(f"Block validation failed: {str(e)}")
                return False
    
        def to_dict(self) -> Dict:
            """Convert block to dictionary format."""
            return {
                "index": self.index,
                "previous_hash": self.previous_hash,
                "timestamp": self.timestamp.isoformat(),
                "transactions": [tx.to_dict() for tx in self.transactions],
                "validator": self.validator,
                "hash": self.hash,
                "nonce": self.nonce,
                "merkle_root": self.merkle_root,
                "shard_id": self.shard_id,
                "cross_shard_refs": self.cross_shard_refs.copy(),
                "metadata": self.metadata.copy(),
                "version": self.version
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> 'Block':
            """Create block instance from dictionary."""
            transactions = [Transaction.from_dict(tx) for tx in data["transactions"]]
            timestamp = datetime.fromisoformat(data["timestamp"])
            
            block = cls(
                index=data["index"],
                previous_hash=data["previous_hash"],
                timestamp=timestamp,
                transactions=transactions,
                validator=data["validator"],
                shard_id=data["shard_id"],
                hash=data["hash"],
                nonce=data["nonce"],
                merkle_root=data["merkle_root"],
                cross_shard_refs=data.get("cross_shard_refs", []).copy(),
                metadata=data.get("metadata", {}).copy(),
                version=data.get("version", "1.0")
            )
            
            return block
    
        def __str__(self) -> str:
            """Return human-readable string representation."""
            return (
                f"Block(index={self.index}, "
                f"hash={self.hash[:8]}..., "
                f"tx_count={len(self.transactions)}, "
                f"shard={self.shard_id})"
            )
```

# File: /home/matt/icn-prototype/blockchain/core/transaction.py

```py
    # blockchain/core/transaction.py
    
    from __future__ import annotations
    from dataclasses import dataclass, field
    from datetime import datetime, timedelta
    from typing import Dict, Optional, Any, List, Set
    import hashlib
    import json
    import logging
    from copy import deepcopy
    import math
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class Transaction:
        """
        Represents a transaction in the ICN blockchain.
        
        A transaction is the fundamental unit of record in the blockchain, representing
        any action or data transfer between parties in the network. Transactions in ICN
        support cooperative principles through:
        - Cross-shard operations
        - Resource sharing tracking
        - Cooperative reputation impacts
        - Fair prioritization
        """
        
        sender: str
        receiver: str
        action: str
        data: Dict[str, Any]
        timestamp: datetime = field(default_factory=datetime.now)
        signature: Optional[bytes] = None
        shard_id: Optional[int] = None
        transaction_id: str = field(init=False)
        _is_deserialized: bool = field(default=False, init=False, repr=False)
        priority: int = field(default=1)  # 1-5, with 5 being highest
        cooperative_tags: Set[str] = field(default_factory=set)
        resource_cost: Dict[str, float] = field(default_factory=lambda: {
            "computation": 1.0,
            "storage": 1.0,
            "bandwidth": 1.0
        })
        cross_shard_refs: List[str] = field(default_factory=list)
        metadata: Dict[str, Any] = field(default_factory=dict)
    
        # Maximum sizes for various fields
        MAX_DATA_SIZE = 1024 * 1024  # 1MB
        MAX_CROSS_SHARD_REFS = 10
        VALID_PRIORITIES = {1, 2, 3, 4, 5}
        VALID_ACTIONS = {
            "transfer", "stake", "unstake", "vote", "propose",
            "deploy", "execute", "store", "share", "validate"
        }
    
        def __post_init__(self) -> None:
            """Initialize transaction ID and perform validation after creation."""
            # Validate basic inputs
            if not self.sender:
                raise ValueError("Sender cannot be empty")
            if not self.receiver:
                raise ValueError("Receiver cannot be empty")
            if not self.action:
                raise ValueError("Action cannot be empty")
            
            # Validate action
            if self.action not in self.VALID_ACTIONS:
                raise ValueError(f"Invalid action. Must be one of: {self.VALID_ACTIONS}")
                
            # Validate priority
            if self.priority not in self.VALID_PRIORITIES:
                raise ValueError(f"Invalid priority. Must be between 1-5")
    
            # Deep copy mutable fields
            self.data = deepcopy(self.data)
            self.cooperative_tags = set(self.cooperative_tags)
            self.resource_cost = deepcopy(self.resource_cost)
            self.cross_shard_refs = list(self.cross_shard_refs)
            self.metadata = deepcopy(self.metadata)
    
            # Add creation metadata
            self.metadata.update({
                "created_at": datetime.now().isoformat(),
                "data_size": len(json.dumps(self.data)),
                "version": "1.0"
            })
            
            # Calculate transaction ID
            if not hasattr(self, 'transaction_id') or not self.transaction_id:
                self.transaction_id = self.calculate_id()
    
            # Calculate and store resource costs
            self._calculate_resource_costs()
    
        def _calculate_resource_costs(self) -> None:
            """Calculate resource costs based on transaction characteristics."""
            data_size = len(json.dumps(self.data))
            
            # Base computation cost
            self.resource_cost["computation"] = 1.0
            
            # Storage cost based on data size
            self.resource_cost["storage"] = math.ceil(data_size / 1024)  # Cost per KB
            
            # Bandwidth cost including cross-shard overhead
            self.resource_cost["bandwidth"] = (
                math.ceil(data_size / 1024) * 
                (1 + 0.2 * len(self.cross_shard_refs))  # 20% overhead per cross-shard ref
            )
    
        def calculate_id(self) -> str:
            """
            Calculate unique transaction ID using transaction data.
            
            Returns:
                str: The calculated transaction ID
            """
            tx_data = {
                "sender": self.sender,
                "receiver": self.receiver,
                "action": self.action,
                "data": self.data,
                "timestamp": self.timestamp.isoformat(),
                "shard_id": self.shard_id,
                "priority": self.priority,
                "cooperative_tags": sorted(list(self.cooperative_tags))
            }
            tx_json = json.dumps(tx_data, sort_keys=True)
            return hashlib.sha256(tx_json.encode()).hexdigest()
    
        def calculate_hash(self) -> str:
            """
            Calculate cryptographic hash of the transaction.
            
            Returns:
                str: The calculated hash
            """
            tx_dict = self.to_dict()
            tx_dict.pop('signature', None)  # Remove signature from hash calculation
            tx_json = json.dumps(tx_dict, sort_keys=True)
            return hashlib.sha256(tx_json.encode()).hexdigest()
    
        def validate(self) -> bool:
            """
            Validate the transaction's structure and data.
            
            Returns:
                bool: True if the transaction is valid
            """
            try:
                # Validate required fields
                if not all([self.sender, self.receiver, self.action]):
                    logger.error("Missing required transaction fields")
                    return False
    
                # Validate timestamp
                now = datetime.now()
                if self.timestamp > now + timedelta(minutes=5):
                    logger.error(f"Transaction timestamp {self.timestamp} is in the future")
                    return False
    
                if self.timestamp < now - timedelta(days=1):
                    logger.error(f"Transaction timestamp {self.timestamp} is too old")
                    return False
    
                # Validate data structure and size
                if not isinstance(self.data, dict):
                    logger.error("Transaction data must be a dictionary")
                    return False
    
                if len(json.dumps(self.data)) > self.MAX_DATA_SIZE:
                    logger.error("Transaction data exceeds maximum size")
                    return False
    
                # Validate action
                if self.action not in self.VALID_ACTIONS:
                    logger.error(f"Invalid action: {self.action}")
                    return False
    
                # Validate shard_id if present
                if self.shard_id is not None:
                    if not isinstance(self.shard_id, int) or self.shard_id < 0:
                        logger.error("Invalid shard_id value")
                        return False
    
                # Validate cross-shard references
                if len(self.cross_shard_refs) > self.MAX_CROSS_SHARD_REFS:
                    logger.error("Too many cross-shard references")
                    return False
    
                # Validate resource costs
                if not all(cost >= 0 for cost in self.resource_cost.values()):
                    logger.error("Invalid resource costs")
                    return False
    
                # Verify transaction ID consistency
                if self.transaction_id != self.calculate_id():
                    logger.error("Transaction ID mismatch")
                    return False
    
                return True
    
            except Exception as e:
                logger.error(f"Transaction validation failed: {str(e)}")
                return False
    
        def is_cross_shard(self) -> bool:
            """Check if this is a cross-shard transaction."""
            return bool(self.cross_shard_refs) or 'target_shard' in self.data
    
        def get_target_shards(self) -> Set[int]:
            """Get all shards involved in this transaction."""
            shards = {self.shard_id} if self.shard_id is not None else set()
            if 'target_shard' in self.data:
                shards.add(self.data['target_shard'])
            return shards
    
        def get_resource_impact(self) -> float:
            """Calculate total resource impact of the transaction."""
            return sum(self.resource_cost.values())
    
        def get_cooperative_score(self) -> float:
            """Calculate cooperative impact score of the transaction."""
            base_score = 1.0
            
            # Bonus for cooperative tags
            if self.cooperative_tags:
                base_score += 0.1 * len(self.cooperative_tags)
                
            # Penalty for high resource usage
            resource_impact = self.get_resource_impact()
            if resource_impact > 10:
                base_score *= 0.9
                
            # Bonus for cross-shard cooperation
            if self.is_cross_shard():
                base_score *= 1.1
                
            return base_score
    
        def to_dict(self) -> Dict:
            """
            Convert transaction to dictionary format.
            
            Returns:
                Dict: The dictionary representation
            """
            return {
                "transaction_id": self.transaction_id,
                "sender": self.sender,
                "receiver": self.receiver,
                "action": self.action,
                "data": deepcopy(self.data),
                "timestamp": self.timestamp.isoformat(),
                "signature": self.signature.hex() if self.signature else None,
                "shard_id": self.shard_id,
                "priority": self.priority,
                "cooperative_tags": sorted(list(self.cooperative_tags)),
                "resource_cost": deepcopy(self.resource_cost),
                "cross_shard_refs": self.cross_shard_refs.copy(),
                "metadata": deepcopy(self.metadata)
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> Transaction:
            """Create transaction instance from dictionary data."""
            try:
                # Extract and convert fields
                timestamp = datetime.fromisoformat(data["timestamp"])
                signature = bytes.fromhex(data["signature"]) if data.get("signature") else None
                cooperative_tags = set(data.get("cooperative_tags", []))
                resource_cost = deepcopy(data.get("resource_cost", {
                    "computation": 1.0,
                    "storage": 1.0,
                    "bandwidth": 1.0
                }))
                
                # Create transaction
                tx = cls(
                    sender=data["sender"],
                    receiver=data["receiver"],
                    action=data["action"],
                    data=deepcopy(data["data"]),
                    timestamp=timestamp,
                    signature=signature,
                    shard_id=data.get("shard_id"),
                    priority=data.get("priority", 1),
                    cooperative_tags=cooperative_tags,
                    resource_cost=resource_cost,
                    cross_shard_refs=data.get("cross_shard_refs", []),
                    metadata=data.get("metadata", {})
                )
                
                # Set the original transaction_id
                tx.transaction_id = data["transaction_id"]
                tx._is_deserialized = True
                
                return tx
    
            except Exception as e:
                logger.error(f"Failed to create transaction from dictionary: {str(e)}")
                raise ValueError(f"Invalid transaction data: {str(e)}")
    
        def __str__(self) -> str:
            """Return a human-readable string representation."""
            return (
                f"Transaction(id={self.transaction_id[:8]}..., "
                f"action={self.action}, "
                f"sender={self.sender[:8]}..., "
                f"receiver={self.receiver[:8]}..., "
                f"shard={self.shard_id}, "
                f"priority={self.priority})"
            )
```

# File: /home/matt/icn-prototype/blockchain/core/blockchain.py

```py
    # ================================================================
    # File: blockchain/core/blockchain.py
    # ================================================================
    # Description: Core Blockchain implementation for the ICN system.
    # 
    # This module manages the ICN blockchain, coordinating shards, nodes,
    # transactions, consensus, and smart contract execution.
    # ================================================================
    
    from __future__ import annotations
    from typing import List, Dict, Optional, Any
    from datetime import datetime, timedelta
    import logging
    import hashlib
    import asyncio
    
    from .block import Block
    from .node import Node
    from .shard import Shard
    from .transaction import Transaction
    from ..consensus.proof_of_cooperation import ProofOfCooperation
    from ..contracts.smart_contract import SmartContract
    from ..contracts.contract_executor import ContractExecutor
    
    logger = logging.getLogger(__name__)
    
    class Blockchain:
        """
        Core Blockchain implementation for the ICN system.
        Manages shards, transactions, blocks, nodes, consensus, and contracts.
        """
    
        def __init__(self, num_shards: int = 4, initial_mana: int = 1000, mana_regen_rate: int = 10):
            """
            Initialize the blockchain with specified shards, mana, and consensus.
            """
            self.nodes: Dict[str, Node] = {}
            self.shards: Dict[int, Shard] = {}
            self.chain: List[Block] = []
            self.transaction_pool: List[Transaction] = []
            self.smart_contracts: Dict[str, SmartContract] = {}
    
            self.consensus_mechanism = ProofOfCooperation()
            self.contract_executor = ContractExecutor()
    
            self.cooperative_mana = initial_mana
            self.mana_regen_rate = mana_regen_rate
            self.genesis_block_created = False
    
            self._initialize_shards(num_shards)
            self.create_genesis_block()
    
        def _initialize_shards(self, num_shards: int) -> None:
            """
            Initialize shards for parallel transaction processing.
            """
            for shard_id in range(num_shards):
                self.create_shard(shard_id)
    
        def create_genesis_block(self) -> None:
            """
            Create the genesis block with no transactions and a special validator.
            """
            if self.genesis_block_created:
                logger.warning("Genesis block already created")
                return
    
            genesis_block = Block(
                index=0,
                previous_hash="0" * 64,
                timestamp=datetime.now(),
                transactions=[],
                validator="genesis",
                shard_id=-1
            )
    
            self.chain.append(genesis_block)
            self.genesis_block_created = True
            logger.info("Genesis block created")
    
        def register_node(self, node: Node) -> bool:
            """
            Register a node and make it eligible for validation.
            """
            if not isinstance(node, Node) or node.node_id in self.nodes:
                logger.error(f"Invalid or duplicate node: {node.node_id}")
                return False
    
            node.is_validator = True
            self.nodes[node.node_id] = node
            logger.info(f"Node {node.node_id} registered as validator")
            return True
    
        def create_shard(self, shard_id: int) -> bool:
            """
            Create a new shard with the given ID.
            """
            if shard_id in self.shards:
                logger.error(f"Shard {shard_id} already exists")
                return False
    
            self.shards[shard_id] = Shard(shard_id=shard_id)
            logger.info(f"Shard {shard_id} created")
            return True
    
        def add_transaction(self, transaction: Dict) -> bool:
            """
            Add a transaction after initializing and validating it.
            """
            if not isinstance(transaction, dict):
                logger.error("Invalid transaction format")
                return False
    
            tx = Transaction(
                sender=transaction['sender'],
                receiver=transaction['receiver'],
                action=transaction['action'],
                data=transaction['data']
            )
    
            shard_id = self._calculate_shard_id(tx)
            tx.shard_id = shard_id
            tx.transaction_id = self._calculate_transaction_id(tx)
    
            if shard_id not in self.shards or not self.shards[shard_id].add_transaction(tx):
                logger.error(f"Failed to add transaction {tx.transaction_id} to shard {shard_id}")
                return False
    
            logger.info(f"Transaction {tx.transaction_id} added to shard {shard_id}")
            return True
    
        def _calculate_shard_id(self, transaction: Transaction) -> int:
            """
            Calculate the shard ID for the transaction using its hash.
            """
            tx_hash = hashlib.sha256(str(transaction).encode()).hexdigest()
            return int(tx_hash, 16) % len(self.shards)
    
        def _calculate_transaction_id(self, transaction: Transaction) -> str:
            """
            Calculate the transaction ID using the hash of its contents.
            """
            tx_hash = hashlib.sha256(str(transaction).encode()).hexdigest()
            return tx_hash
    
        def create_block(self, shard_id: Optional[int] = None) -> Optional[Block]:
            """
            Create a new block in the specified shard.
            """
            shard = self.shards.get(shard_id)
            if not shard:
                logger.error(f"Shard {shard_id} not found")
                return None
    
            validator = self.consensus_mechanism.select_validator(list(self.nodes.values()), shard_id)
            if not validator:
                logger.error(f"No eligible validator for shard {shard_id}")
                return None
    
            new_block = shard.create_block(validator.node_id)
            if new_block and self.add_block(new_block):
                return new_block
    
            return None
    
        def add_block(self, block: Block) -> bool:
            """
            Add a validated block to the chain.
            """
            if not isinstance(block, Block) or not block.validate(self.chain[-1]):
                logger.error("Block validation failed")
                return False
    
            self.chain.append(block)
            logger.info(f"Block {block.index} added to chain")
            return True
    
        def regenerate_mana(self) -> None:
            """
            Regenerate cooperative mana up to the cap.
            """
            self.cooperative_mana = min(1000, self.cooperative_mana + self.mana_regen_rate)
    
        def get_chain_metrics(self) -> Dict:
            """
            Return blockchain metrics including chain length and mana.
            """
            return {
                "chain_length": len(self.chain),
                "total_transactions": sum(len(block.transactions) for block in self.chain),
                "average_block_time": self._calculate_average_block_time(),
                "active_nodes": len(self.nodes),
                "active_shards": len(self.shards),
                "cooperative_mana": self.cooperative_mana,
                "contract_count": len(self.smart_contracts),
            }
    
        def _calculate_average_block_time(self) -> float:
            """
            Calculate the average time between blocks.
            """
            if len(self.chain) <= 1:
                return 0.0
    
            total_time = sum(
                (self.chain[i].timestamp - self.chain[i-1].timestamp).total_seconds()
                for i in range(1, len(self.chain))
            )
            return total_time / (len(self.chain) - 1)
    
        def validate_chain(self) -> bool:
            """
            Validate the integrity of the entire chain.
            """
            for i in range(1, len(self.chain)):
                if not self.chain[i].validate(self.chain[i-1]):
                    logger.error(f"Block {i} validation failed")
                    return False
    
            logger.info("Blockchain is valid")
            return True
    
        async def deploy_smart_contract(self, contract: SmartContract) -> bool:
            """
            Deploy a smart contract and register it.
            """
            if contract.contract_id in self.smart_contracts or self.cooperative_mana < contract.mana_cost:
                logger.error(f"Contract {contract.contract_id} deployment failed")
                return False
    
            self.smart_contracts[contract.contract_id] = contract
            self.cooperative_mana -= contract.mana_cost
            logger.info(f"Contract {contract.contract_id} deployed")
            return True
    
        async def execute_smart_contract(self, contract_id: str, input_data: Dict, caller: str) -> Optional[Dict]:
            """
            Execute a smart contract with the given input data.
            """
            contract = self.smart_contracts.get(contract_id)
            if not contract or self.cooperative_mana < contract.mana_cost:
                logger.error(f"Failed to execute contract {contract_id}")
                return None
    
            result = await self.contract_executor.execute_contract(contract_id, input_data, caller)
            if result is not None:
                self.cooperative_mana -= contract.mana_cost
                logger.info(f"Contract {contract_id} executed by {caller}")
            else:
                logger.error(f"Failed to execute contract {contract_id}")
    
            return result
```

# File: /home/matt/icn-prototype/blockchain/core/__init__.py

```py
    # blockchain/core/__init__.py
    """Core blockchain components."""
    from .node import Node
    from .block import Block
    from .transaction import Transaction
    from .shard import Shard
    from .blockchain import Blockchain
    
    __all__ = [
        "Node",
        "Block",
        "Transaction", 
        "Shard",
        "Blockchain"
    ]
```

# File: /home/matt/icn-prototype/blockchain/core/state/state_transition.py

```py
    """
    blockchain/core/state/state_transition.py
    
    Handles atomic state transitions and rollbacks for the ICN blockchain.
    Ensures consistent state changes across shards while maintaining verifiability.
    """
    
    from dataclasses import dataclass, field
    from datetime import datetime
    from typing import Dict, Optional, Any, Set
    import hashlib
    import json
    import logging
    from copy import deepcopy
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class StateTransition:
        """
        Represents an atomic state transition in the blockchain.
        
        Manages the transition between states, including validation,
        verification, and rollback capabilities. Ensures atomic updates
        and maintains transition history for auditing purposes.
        
        Attributes:
            transition_id: Unique identifier for the transition.
            old_state: Previous state before transition.
            new_state: New state after transition.
            shard_id: Optional shard identifier for shard-specific transitions.
            timestamp: Time of transition creation.
            metadata: Additional metadata for the transition.
            verified: Indicates if the transition is verified.
            applied: Indicates if the transition has been applied.
            verification_signatures: Set of validator signatures for verification.
        """
        
        transition_id: Optional[str] = None
        old_state: Dict[str, Any] = field(default_factory=dict)
        new_state: Dict[str, Any] = field(default_factory=dict)
        shard_id: Optional[int] = None
        timestamp: datetime = field(default_factory=datetime.now)
        metadata: Dict[str, Any] = field(default_factory=dict)
        verified: bool = False
        applied: bool = False
        verification_signatures: Set[str] = field(default_factory=set)
    
        def __post_init__(self):
            """Initialize transition after creation."""
            if not self.transition_id:
                self.transition_id = self._generate_id()
    
            # Deep copy states to prevent accidental modification
            self.old_state = deepcopy(self.old_state)
            self.new_state = deepcopy(self.new_state)
    
            # Initialize metadata with timestamp if not provided
            if 'created_at' not in self.metadata:
                self.metadata['created_at'] = self.timestamp.isoformat()
    
        def _generate_id(self) -> str:
            """
            Generate a unique transition ID based on state data and timestamp.
    
            Returns:
                str: A SHA-256 hash as the transition ID.
            """
            data = {
                "old_state": self.old_state,
                "new_state": self.new_state,
                "shard_id": self.shard_id,
                "timestamp": self.timestamp.isoformat()
            }
            return hashlib.sha256(json.dumps(data, sort_keys=True).encode()).hexdigest()
    
        def validate(self) -> bool:
            """
            Validate the state transition.
    
            Checks:
            - State structure validity.
            - Consistent keys between old and new states.
            - Transition ID accuracy.
            - Compliance with state invariants.
    
            Returns:
                bool: True if the transition is valid, False otherwise.
            """
            try:
                # Ensure state structures are dictionaries
                if not isinstance(self.old_state, dict) or not isinstance(self.new_state, dict):
                    logger.error("Invalid state structure")
                    return False
    
                # Ensure key consistency between old and new states
                if set(self.old_state.keys()) != set(self.new_state.keys()):
                    logger.error("Key mismatch between old and new states")
                    return False
    
                # Validate transition ID
                if self.transition_id != self._generate_id():
                    logger.error("Transition ID mismatch")
                    return False
    
                # Verify state invariants
                if not self._verify_state_invariants():
                    logger.error("State invariants violated")
                    return False
    
                return True
    
            except Exception as e:
                logger.error(f"Validation failed: {str(e)}")
                return False
    
        def _verify_state_invariants(self) -> bool:
            """
            Check that the state transition maintains necessary invariants.
    
            This function ensures that no critical state properties are violated,
            such as negative balances or broken data integrity.
    
            Returns:
                bool: True if invariants are maintained, False otherwise.
            """
            for key, value in self.new_state.items():
                if isinstance(value, (int, float)) and value < 0:
                    logger.error(f"Negative value for '{key}' in new state")
                    return False
            return True
    
        def apply(self) -> bool:
            """
            Apply the state transition, updating the old state to the new state.
    
            Returns:
                bool: True if the transition is applied successfully, False otherwise.
            """
            if not self.verified:
                logger.error("Cannot apply unverified transition")
                return False
    
            try:
                self.old_state = deepcopy(self.new_state)
                self.applied = True
                logger.info(f"Transition {self.transition_id} applied successfully")
                return True
            except Exception as e:
                logger.error(f"Failed to apply transition: {str(e)}")
                return False
    
        def rollback(self) -> bool:
            """
            Roll back the state transition to the old state.
    
            Returns:
                bool: True if rollback is successful, False otherwise.
            """
            if not self.applied:
                logger.error("Cannot roll back an unapplied transition")
                return False
    
            try:
                self.new_state = deepcopy(self.old_state)
                self.applied = False
                logger.info(f"Transition {self.transition_id} rolled back successfully")
                return True
            except Exception as e:
                logger.error(f"Failed to roll back transition: {str(e)}")
                return False
    
        def add_signature(self, signature: str) -> None:
            """
            Add a verification signature to the transition.
    
            Args:
                signature (str): The validator's signature.
            """
            self.verification_signatures.add(signature)
            logger.info(f"Signature added to transition {self.transition_id}")
    
        def is_fully_verified(self, required_signatures: int) -> bool:
            """
            Check if the transition has enough signatures for verification.
    
            Args:
                required_signatures (int): Number of required signatures.
    
            Returns:
                bool: True if the transition is fully verified, False otherwise.
            """
            return len(self.verification_signatures) >= required_signatures
    
        def to_dict(self) -> Dict[str, Any]:
            """
            Convert the state transition object to a dictionary.
    
            Returns:
                Dict[str, Any]: Dictionary representation of the transition.
            """
            return {
                "transition_id": self.transition_id,
                "old_state": self.old_state,
                "new_state": self.new_state,
                "shard_id": self.shard_id,
                "timestamp": self.timestamp.isoformat(),
                "metadata": self.metadata,
                "verified": self.verified,
                "applied": self.applied,
                "verification_signatures": list(self.verification_signatures)
            }
    
        @classmethod
        def from_dict(cls, data: Dict[str, Any]) -> "StateTransition":
            """
            Create a StateTransition object from a dictionary.
    
            Args:
                data (Dict[str, Any]): Dictionary containing transition data.
    
            Returns:
                StateTransition: A new StateTransition instance.
            """
            return cls(
                transition_id=data.get("transition_id"),
                old_state=data.get("old_state", {}),
                new_state=data.get("new_state", {}),
                shard_id=data.get("shard_id"),
                timestamp=datetime.fromisoformat(data.get("timestamp")),
                metadata=data.get("metadata", {}),
                verified=data.get("verified", False),
                applied=data.get("applied", False),
                verification_signatures=set(data.get("verification_signatures", []))
            )
```

# File: /home/matt/icn-prototype/blockchain/core/state/unified_state.py

```py
    from typing import Dict, Optional, Any, Set, List
    from datetime import datetime
    import json
    import hashlib
    import logging
    from dataclasses import dataclass, field
    from copy import deepcopy
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class StateTransition:
        """Represents a transition in blockchain state."""
        old_state: Dict[str, Any]
        new_state: Dict[str, Any]
        transaction_id: str
        shard_id: Optional[int]
        timestamp: datetime = field(default_factory=datetime.now)
        metadata: Dict[str, Any] = field(default_factory=dict)
        
        def calculate_hash(self) -> str:
            """Calculate hash of the state transition."""
            data = {
                "old_state": self.old_state,
                "new_state": self.new_state,
                "transaction_id": self.transaction_id,
                "shard_id": self.shard_id,
                "timestamp": self.timestamp.isoformat(),
                "metadata": self.metadata
            }
            return hashlib.sha256(json.dumps(data, sort_keys=True).encode()).hexdigest()
    
    class UnifiedStateManager:
        """
        Manages both global and shard-specific state in a unified way.
        Coordinates state transitions across shards while maintaining global consistency.
        """
        
        def __init__(self, shard_count: int):
            # Global state
            self.global_state: Dict[str, Any] = {
                "accounts": {},      # Global account states
                "contracts": {},     # Smart contract states
                "governance": {},    # Governance states
                "metadata": {        # Global metadata
                    "last_updated": datetime.now().isoformat(),
                    "version": "1.0",
                    "shard_count": shard_count,
                    "total_transactions": 0,
                    "total_volume": 0.0
                }
            }
            
            # Shard states
            self.shard_states: Dict[int, Dict[str, Any]] = {
                shard_id: {
                    "balances": {},  # Shard-specific balances
                    "metadata": {    # Shard metadata
                        "shard_id": shard_id,
                        "created_at": datetime.now().isoformat(),
                        "last_updated": datetime.now().isoformat(),
                        "transaction_count": 0
                    }
                }
                for shard_id in range(shard_count)
            }
            
            # State management
            self.state_transitions: List[StateTransition] = []
            self.pending_transitions: Dict[str, StateTransition] = {}
            self.state_roots: Dict[int, str] = {}  # height -> state root
            self.shard_roots: Dict[int, Dict[int, str]] = {}  # height -> shard_id -> root
            self.checkpoint_heights: Set[int] = set()
            
            self._backup_states: Dict[str, Any] = {}
    
        def begin_transition(self, transaction_id: str, shard_id: Optional[int] = None) -> None:
            """Begin a new state transition, either global or shard-specific."""
            if transaction_id in self.pending_transitions:
                raise ValueError(f"Transition already in progress for transaction {transaction_id}")
                
            # Backup relevant states
            if shard_id is not None:
                old_state = deepcopy(self.shard_states[shard_id])
                self._backup_states[f"shard_{shard_id}"] = deepcopy(self.shard_states[shard_id])
            else:
                old_state = deepcopy(self.global_state)
                self._backup_states["global"] = deepcopy(self.global_state)
                
            self.pending_transitions[transaction_id] = StateTransition(
                old_state=old_state,
                new_state=deepcopy(old_state),
                transaction_id=transaction_id,
                shard_id=shard_id
            )
    
        def update_shard_balance(self, shard_id: int, account_id: str, delta: float, transaction_id: str) -> bool:
            """Update an account balance within a specific shard."""
            try:
                if transaction_id not in self.pending_transitions:
                    raise ValueError(f"No transition in progress for transaction {transaction_id}")
                    
                transition = self.pending_transitions[transaction_id]
                if transition.shard_id != shard_id:
                    raise ValueError(f"Transaction {transaction_id} not associated with shard {shard_id}")
                    
                shard_state = transition.new_state
                
                # Initialize account if needed
                if account_id not in shard_state["balances"]:
                    shard_state["balances"][account_id] = {
                        "balance": 0.0,
                        "created_at": datetime.now().isoformat(),
                        "transaction_count": 0
                    }
                    
                # Update balance
                account = shard_state["balances"][account_id]
                new_balance = account["balance"] + delta
                
                if new_balance < 0:
                    return False
                    
                account["balance"] = new_balance
                account["transaction_count"] += 1
                account["last_updated"] = datetime.now().isoformat()
                
                return True
                
            except Exception as e:
                logger.error(f"Failed to update shard balance: {str(e)}")
                self.rollback_transition(transaction_id)
                return False
    
        def update_global_state(self, state_type: str, entity_id: str, 
                              state_update: Dict, transaction_id: str) -> bool:
            """Update global state (contracts, governance, etc)."""
            try:
                if transaction_id not in self.pending_transitions:
                    raise ValueError(f"No transition in progress for transaction {transaction_id}")
                    
                transition = self.pending_transitions[transaction_id]
                if transition.shard_id is not None:
                    raise ValueError("Cannot update global state in shard-specific transaction")
                    
                if state_type not in transition.new_state:
                    raise ValueError(f"Invalid state type: {state_type}")
                    
                # Initialize entity if needed
                if entity_id not in transition.new_state[state_type]:
                    transition.new_state[state_type][entity_id] = {
                        "created_at": datetime.now().isoformat()
                    }
                    
                # Update state
                entity_state = transition.new_state[state_type][entity_id]
                entity_state.update(state_update)
                entity_state["last_updated"] = datetime.now().isoformat()
                
                return True
                
            except Exception as e:
                logger.error(f"Failed to update global state: {str(e)}")
                self.rollback_transition(transaction_id)
                return False
    
        def commit_transition(self, transaction_id: str, block_height: int) -> bool:
            """Commit a state transition and update state roots."""
            try:
                if transaction_id not in self.pending_transitions:
                    raise ValueError(f"No transition found for transaction {transaction_id}")
                    
                transition = self.pending_transitions[transaction_id]
                
                # Update metadata
                if transition.shard_id is not None:
                    # Shard-specific commit
                    shard_state = self.shard_states[transition.shard_id]
                    shard_state.update(transition.new_state)
                    shard_state["metadata"]["last_updated"] = datetime.now().isoformat()
                    shard_state["metadata"]["transaction_count"] += 1
                    
                    # Update shard root
                    if block_height not in self.shard_roots:
                        self.shard_roots[block_height] = {}
                    self.shard_roots[block_height][transition.shard_id] = self._calculate_state_root(shard_state)
                else:
                    # Global commit
                    self.global_state.update(transition.new_state)
                    self.global_state["metadata"]["last_updated"] = datetime.now().isoformat()
                    self.global_state["metadata"]["total_transactions"] += 1
                    
                    # Update global root
                    self.state_roots[block_height] = self._calculate_state_root(self.global_state)
                
                # Store transition
                self.state_transitions.append(transition)
                
                # Cleanup
                del self.pending_transitions[transaction_id]
                if transition.shard_id is not None:
                    del self._backup_states[f"shard_{transition.shard_id}"]
                else:
                    del self._backup_states["global"]
                
                return True
                
            except Exception as e:
                logger.error(f"Failed to commit transition: {str(e)}")
                self.rollback_transition(transaction_id)
                return False
    
        def rollback_transition(self, transaction_id: str) -> None:
            """Rollback a pending state transition."""
            if transaction_id in self.pending_transitions:
                transition = self.pending_transitions[transaction_id]
                
                # Restore from backup
                if transition.shard_id is not None:
                    backup_key = f"shard_{transition.shard_id}"
                    if backup_key in self._backup_states:
                        self.shard_states[transition.shard_id] = self._backup_states[backup_key]
                        del self._backup_states[backup_key]
                else:
                    if "global" in self._backup_states:
                        self.global_state = self._backup_states["global"]
                        del self._backup_states["global"]
                        
                del self.pending_transitions[transaction_id]
    
        def create_checkpoint(self, block_height: int) -> Dict[str, str]:
            """Create a checkpoint with both global and shard state roots."""
            try:
                checkpoint = {
                    "global": self._calculate_state_root(self.global_state),
                    "shards": {
                        shard_id: self._calculate_state_root(state)
                        for shard_id, state in self.shard_states.items()
                    }
                }
                
                self.state_roots[block_height] = checkpoint["global"]
                self.shard_roots[block_height] = checkpoint["shards"]
                self.checkpoint_heights.add(block_height)
                
                return checkpoint
                
            except Exception as e:
                logger.error(f"Failed to create checkpoint: {str(e)}")
                return {}
    
        def _calculate_state_root(self, state: Dict) -> str:
            """Calculate Merkle root of a state tree."""
            state_json = json.dumps(state, sort_keys=True)
            return hashlib.sha256(state_json.encode()).hexdigest()
    
        def get_shard_balance(self, shard_id: int, account_id: str) -> float:
            """Get account balance within a specific shard."""
            return self.shard_states[shard_id]["balances"].get(
                account_id, {"balance": 0.0}
            )["balance"]
    
        def get_global_state(self, state_type: str, entity_id: str) -> Optional[Dict]:
            """Get state of a global entity (contract, governance, etc)."""
            return self.global_state.get(state_type, {}).get(entity_id)
```

# File: /home/matt/icn-prototype/blockchain/core/shard/validation_manager.py

```py
    # blockchain/core/shard/validation_manager.py
    
    from typing import Dict, Optional, List, Set
    import logging
    from datetime import datetime, timedelta
    from .shard_types import ShardMetrics, ShardConfig
    from ..block import Block
    from ..transaction import Transaction
    
    logger = logging.getLogger(__name__)
    
    class ValidationManager:
        """Handles transaction and chain validation logic."""
        
        def __init__(self, shard_id: int, config: ShardConfig):
            self.shard_id = shard_id
            self.config = config
            self.validation_cache: Dict[str, bool] = {}
            self.metrics = ShardMetrics()
            self.last_validation_time: Dict[str, datetime] = {}
            self.last_block_time = datetime.now() - timedelta(seconds=config.min_block_interval)
            self.state: Dict[str, Dict] = {"balances": {}}
    
        def validate_transaction(self, transaction: Transaction) -> bool:
            """
            Validate a transaction before adding to pool.
            
            Args:
                transaction: Transaction to validate
                
            Returns:
                bool: True if transaction is valid
            """
            try:
                # Check cache first
                tx_id = transaction.transaction_id
                if tx_id in self.validation_cache:
                    return self.validation_cache[tx_id]
    
                # Basic validation
                if not transaction.validate():
                    logger.error(f"Transaction {tx_id} failed basic validation")
                    self.validation_cache[tx_id] = False
                    return False
    
                # Check transaction amount
                amount = transaction.data.get('amount', 0)
                if amount <= 0:
                    logger.error(f"Transaction {tx_id} has invalid amount")
                    self.validation_cache[tx_id] = False
                    return False
    
                # Check shard assignment
                if transaction.shard_id != self.shard_id:
                    logger.error(f"Transaction {tx_id} has wrong shard ID")
                    self.validation_cache[tx_id] = False
                    return False
    
                # Check balance
                sender = transaction.sender
                balances = self.state.get("balances", {})
                sender_balance = balances.get(sender, 1000.0)  # Default initial balance
                if sender_balance < amount:
                    logger.error(f"Insufficient balance for transaction {tx_id}")
                    self.validation_cache[tx_id] = False
                    return False
    
                # Cache and return success
                self.validation_cache[tx_id] = True
                return True
    
            except Exception as e:
                logger.error(f"Transaction validation failed: {str(e)}")
                return False
    
        def validate_block(self, block: Block, previous_block: Optional[Block]) -> bool:
            """
            Validate a block before adding to chain.
            
            Args:
                block: Block to validate
                previous_block: Previous block in chain for validation
                
            Returns:
                bool: True if block is valid
            """
            try:
                # Basic block validation
                if not block.validate(previous_block):
                    logger.error("Block failed basic validation")
                    return False
    
                # Check shard ID
                if block.shard_id != self.shard_id:
                    logger.error("Block has wrong shard ID")
                    return False
    
                # Validate all transactions
                for tx in block.transactions:
                    if not self.validate_transaction(tx):
                        logger.error(f"Block contains invalid transaction {tx.transaction_id}")
                        return False
    
                    # Update balances for subsequent transaction validations
                    amount = float(tx.data.get('amount', 0))
                    self.state.setdefault("balances", {})
                    self.state["balances"].setdefault(tx.sender, 1000.0)
                    self.state["balances"].setdefault(tx.receiver, 1000.0)
                    self.state["balances"][tx.sender] -= amount
                    self.state["balances"][tx.receiver] += amount
    
                # Always allow the genesis block
                if previous_block is None or block.index == 0:
                    return True
    
                # Check block timing - disabled for testing
                # current_time = datetime.now()
                # time_since_last = (current_time - self.last_block_time).total_seconds()
                # if time_since_last < self.config.min_block_interval:
                #     logger.error(f"Block created too soon after previous block")
                #     return False
    
                self.last_block_time = datetime.now()
                return True
    
            except Exception as e:
                logger.error(f"Block validation failed: {str(e)}")
                return False
    
        def clear_cache(self) -> None:
            """Clear validation cache."""
            self.validation_cache.clear()
    
        def update_state(self, state: Dict) -> None:
            """Update the validation manager's state view."""
            self.state = state.copy()
    
        def get_metrics(self) -> Dict:
            """Get validation metrics."""
            return {
                "validation_cache_size": len(self.validation_cache),
                "last_validation_times": {
                    tx_id: time.isoformat()
                    for tx_id, time in self.last_validation_time.items()
                },
                "total_validations": len(self.validation_cache),
                "failed_validations": len([v for v in self.validation_cache.values() if not v])
            }
    
        def to_dict(self) -> Dict:
            """Convert manager state to dictionary format."""
            return {
                "validation_cache": self.validation_cache.copy(),
                "metrics": self.metrics.to_dict(),
                "last_validation_time": {
                    tx_id: time.isoformat()
                    for tx_id, time in self.last_validation_time.items()
                },
                "last_block_time": self.last_block_time.isoformat(),
                "state": self.state.copy()
            }
    
        @classmethod
        def from_dict(cls, data: Dict, shard_id: int, config: ShardConfig) -> 'ValidationManager':
            """Create manager from dictionary data."""
            manager = cls(shard_id, config)
            manager.validation_cache = data["validation_cache"].copy()
            manager.metrics = ShardMetrics.from_dict(data["metrics"])
            manager.last_validation_time = {
                tx_id: datetime.fromisoformat(time_str)
                for tx_id, time_str in data["last_validation_time"].items()
            }
            manager.last_block_time = datetime.fromisoformat(data["last_block_time"])
            manager.state = data["state"].copy()
            return manager
```

# File: /home/matt/icn-prototype/blockchain/core/shard/cross_shard_transaction.py

```py
    """
    blockchain/core/shard/cross_shard_transaction.py
    
    Implements atomic cross-shard transaction handling for the ICN blockchain.
    Ensures consistent state across shards during cooperative operations while
    integrating with the DID and governance systems.
    """
    
    from __future__ import annotations
    from dataclasses import dataclass, field
    from typing import Dict, List, Optional, Set
    from datetime import datetime
    import hashlib
    import json
    import logging
    
    from ...utils.validation import validate_transaction
    from ...consensus.proof_of_cooperation import ProofOfCooperation
    from ..transaction import Transaction
    from ..block import Block
    from did.base_did import BaseDID
    from system.governance import GovernanceSystem
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class CrossShardTransactionPhase:
        """Represents a phase in a cross-shard transaction."""
        phase_id: str
        shard_id: int
        status: str = "pending"  # pending, prepared, committed, aborted
        timestamp: datetime = field(default_factory=datetime.now)
        validation_signatures: Set[str] = field(default_factory=set)
        did_attestations: Set[str] = field(default_factory=set)  # DIDs that have attested this phase
    
    class CrossShardTransaction:
        """
        Manages atomic cross-shard transactions using a two-phase commit protocol.
        Ensures state consistency across shards during cooperative operations.
        """
    
        def __init__(
            self,
            transaction_id: str,
            source_shard: int,
            target_shards: Set[int],
            primary_transaction: Transaction,
            governance_system: Optional[GovernanceSystem] = None
        ):
            self.transaction_id = transaction_id
            self.source_shard = source_shard
            self.target_shards = target_shards
            self.primary_transaction = primary_transaction
            self.phases: Dict[int, CrossShardTransactionPhase] = {}
            self.state = "pending"
            self.created_at = datetime.now()
            self.completed_at: Optional[datetime] = None
            self.required_validations = 3
            self.governance_system = governance_system
            
            # Initialize phases
            self._initialize_phases()
    
        def _initialize_phases(self) -> None:
            """Initialize transaction phases for all involved shards."""
            all_shards = {self.source_shard} | self.target_shards
            for shard_id in all_shards:
                phase_id = self._generate_phase_id(shard_id)
                self.phases[shard_id] = CrossShardTransactionPhase(
                    phase_id=phase_id,
                    shard_id=shard_id
                )
    
        def prepare_phase(self, shard_id: int, validator_id: str, validator_did: BaseDID) -> bool:
            """
            Prepare phase of the two-phase commit protocol with DID attestation.
            
            Args:
                shard_id: ID of the shard being prepared
                validator_id: ID of the validating node
                validator_did: DID of the validator for attestation
                
            Returns:
                bool: True if preparation successful
            """
            try:
                if shard_id not in self.phases:
                    logger.error(f"Invalid shard ID {shard_id} for transaction {self.transaction_id}")
                    return False
    
                phase = self.phases[shard_id]
                if phase.status != "pending":
                    logger.error(f"Invalid phase status {phase.status} for preparation")
                    return False
    
                # Add validator signature and DID attestation
                phase.validation_signatures.add(validator_id)
                phase.did_attestations.add(validator_did.get_did())
                
                # Check governance rules if system is available
                if self.governance_system and not self.governance_system.validate_cross_shard_action(
                    validator_did, 
                    self.primary_transaction
                ):
                    logger.error(f"Governance validation failed for transaction {self.transaction_id}")
                    return False
                
                # Check if we have enough validations
                if len(phase.validation_signatures) >= self.required_validations:
                    phase.status = "prepared"
                    logger.info(f"Shard {shard_id} prepared for transaction {self.transaction_id}")
                    return True
                    
                return False
    
            except Exception as e:
                logger.error(f"Error in prepare phase: {str(e)}")
                return False
    
        def commit_phase(self, shard_id: int, validator_id: str, validator_did: BaseDID) -> bool:
            """
            Commit phase of the two-phase commit protocol with DID verification.
            
            Args:
                shard_id: ID of the shard being committed
                validator_id: ID of the validating node
                validator_did: DID of the validator for verification
                
            Returns:
                bool: True if commit successful
            """
            try:
                if shard_id not in self.phases:
                    return False
    
                phase = self.phases[shard_id]
                if phase.status != "prepared":
                    return False
    
                # Verify validator DID and add signature
                if not validator_did.verify():
                    logger.error(f"Invalid validator DID for commit: {validator_id}")
                    return False
    
                phase.validation_signatures.add(validator_id)
                phase.did_attestations.add(validator_did.get_did())
                
                # Check if we have enough validations
                if len(phase.validation_signatures) >= self.required_validations:
                    phase.status = "committed"
                    self._check_completion()
                    return True
                    
                return False
    
            except Exception as e:
                logger.error(f"Error in commit phase: {str(e)}")
                return False
    
        def abort_phase(self, shard_id: int, reason: str, validator_did: Optional[BaseDID] = None) -> None:
            """
            Abort the transaction phase for a shard with optional DID attestation.
            
            Args:
                shard_id: ID of the shard to abort
                reason: Reason for abortion
                validator_did: Optional DID of the validator initiating abort
            """
            try:
                if shard_id in self.phases:
                    phase = self.phases[shard_id]
                    phase.status = "aborted"
                    
                    if validator_did:
                        phase.did_attestations.add(validator_did.get_did())
                        
                    # Notify governance system if available
                    if self.governance_system:
                        self.governance_system.record_cross_shard_abort(
                            self.transaction_id,
                            shard_id,
                            reason,
                            validator_did.get_did() if validator_did else None
                        )
                    
                    logger.warning(f"Aborted phase {phase.phase_id} for shard {shard_id}: {reason}")
                    self.state = "aborted"
    
            except Exception as e:
                logger.error(f"Error aborting phase: {str(e)}")
    
        def _check_completion(self) -> None:
            """Check if all phases are committed and update transaction state."""
            try:
                if all(phase.status == "committed" for phase in self.phases.values()):
                    self.state = "completed"
                    self.completed_at = datetime.now()
                    
                    # Notify governance system of successful completion
                    if self.governance_system:
                        self.governance_system.record_cross_shard_completion(
                            self.transaction_id,
                            list(self.phases.keys()),
                            {phase_id: list(phase.did_attestations) 
                             for phase_id, phase in self.phases.items()}
                        )
                    
                    logger.info(f"Transaction {self.transaction_id} completed successfully")
    
            except Exception as e:
                logger.error(f"Error checking completion: {str(e)}")
    
        def to_dict(self) -> Dict:
            """Convert transaction to dictionary format."""
            return {
                "transaction_id": self.transaction_id,
                "source_shard": self.source_shard,
                "target_shards": list(self.target_shards),
                "primary_transaction": self.primary_transaction.to_dict(),
                "state": self.state,
                "created_at": self.created_at.isoformat(),
                "completed_at": self.completed_at.isoformat() if self.completed_at else None,
                "phases": {
                    shard_id: {
                        "phase_id": phase.phase_id,
                        "status": phase.status,
                        "timestamp": phase.timestamp.isoformat(),
                        "validation_signatures": list(phase.validation_signatures),
                        "did_attestations": list(phase.did_attestations)
                    }
                    for shard_id, phase in self.phases.items()
                }
            }
    
        @classmethod
        def from_dict(cls, data: Dict, governance_system: Optional[GovernanceSystem] = None) -> 'CrossShardTransaction':
            """Create transaction from dictionary format."""
            transaction = cls(
                transaction_id=data["transaction_id"],
                source_shard=data["source_shard"],
                target_shards=set(data["target_shards"]),
                primary_transaction=Transaction.from_dict(data["primary_transaction"]),
                governance_system=governance_system
            )
            
            transaction.state = data["state"]
            transaction.created_at = datetime.fromisoformat(data["created_at"])
            if data["completed_at"]:
                transaction.completed_at = datetime.fromisoformat(data["completed_at"])
                
            # Restore phases
            for shard_id, phase_data in data["phases"].items():
                phase = CrossShardTransactionPhase(
                    phase_id=phase_data["phase_id"],
                    shard_id=int(shard_id),
                    status=phase_data["status"],
                    timestamp=datetime.fromisoformat(phase_data["timestamp"])
                )
                phase.validation_signatures = set(phase_data["validation_signatures"])
                phase.did_attestations = set(phase_data["did_attestations"])
                transaction.phases[int(shard_id)] = phase
                
            return transaction
    
        def _generate_phase_id(self, shard_id: int) -> str:
            """Generate a unique ID for a transaction phase."""
            data = f"{self.transaction_id}:{shard_id}:{datetime.now().isoformat()}"
            return hashlib.sha256(data.encode()).hexdigest()
```

# File: /home/matt/icn-prototype/blockchain/core/shard/transaction_manager.py

```py
    # blockchain/core/shard/transaction_manager.py
    
    from typing import List, Optional, Dict, Set
    import logging
    from datetime import datetime, timedelta
    from .shard_types import ShardMetrics, ShardConfig
    from ..transaction import Transaction
    
    logger = logging.getLogger(__name__)
    
    class TransactionManager:
        """Handles transaction processing and management within a shard."""
        
        def __init__(self, shard_id: int, config: ShardConfig):
            self.shard_id = shard_id
            self.config = config
            self.pending_transactions: List[Transaction] = []
            self.processed_transactions: Set[str] = set()  # Track processed tx IDs
            self.metrics = ShardMetrics()
            self.last_prune_time = datetime.now()
    
        def add_transaction(self, transaction: Transaction) -> bool:
            """Add a new transaction to the pending pool."""
            try:
                # Check shard assignment
                if transaction.shard_id != self.shard_id:
                    logger.error(f"Transaction shard_id {transaction.shard_id} doesn't match shard {self.shard_id}")
                    return False
    
                # Check pool capacity
                if len(self.pending_transactions) >= self.config.max_pending_transactions:
                    logger.warning(f"Shard {self.shard_id} transaction pool full")
                    return False
    
                # Check for duplicate
                tx_id = transaction.transaction_id
                if tx_id in self.processed_transactions:
                    logger.warning(f"Transaction {tx_id} already processed")
                    return False
    
                if any(tx.transaction_id == tx_id for tx in self.pending_transactions):
                    logger.warning(f"Transaction {tx_id} already in pending pool")
                    return False
    
                # Add transaction
                self.pending_transactions.append(transaction)
                self.metrics.pending_count = len(self.pending_transactions)
                
                # Sort by priority
                self._sort_pending_transactions()
    
                return True
    
            except Exception as e:
                logger.error(f"Failed to add transaction: {str(e)}")
                return False
    
        def select_transactions_for_block(self) -> List[Transaction]:
            """Select and sort transactions for a new block."""
            try:
                # Get initial selection
                candidates = self.pending_transactions[:self.config.max_transactions_per_block]
                
                # Sort by priority and timestamp
                candidates.sort(key=lambda tx: (-tx.priority, tx.timestamp))
    
                # Track selected transactions
                for tx in candidates:
                    self.processed_transactions.add(tx.transaction_id)
    
                return candidates
    
            except Exception as e:
                logger.error(f"Failed to select transactions: {str(e)}")
                return []
    
        def remove_transactions(self, transaction_ids: Set[str]) -> None:
            """Remove transactions from the pending pool."""
            try:
                self.pending_transactions = [
                    tx for tx in self.pending_transactions 
                    if tx.transaction_id not in transaction_ids
                ]
                self.metrics.pending_count = len(self.pending_transactions)
    
                # Add to processed set
                self.processed_transactions.update(transaction_ids)
    
            except Exception as e:
                logger.error(f"Failed to remove transactions: {str(e)}")
    
        def get_metrics(self) -> Dict:
            """Get transaction pool metrics."""
            return {
                "pending_count": len(self.pending_transactions),
                "processed_count": len(self.processed_transactions),
                "total_transactions": self.metrics.total_transactions
            }
    
        def _sort_pending_transactions(self) -> None:
            """Sort pending transactions by priority and timestamp."""
            try:
                self.pending_transactions.sort(key=lambda tx: (-tx.priority, tx.timestamp))
            except Exception as e:
                logger.error(f"Failed to sort transactions: {str(e)}")
    
        def clear_all(self) -> None:
            """Clear all pending transactions."""
            self.pending_transactions = []
            self.metrics.pending_count = 0
            logger.info(f"Cleared all pending transactions from shard {self.shard_id}")
    
        def to_dict(self) -> Dict:
            """Convert manager state to dictionary format."""
            return {
                "pending_transactions": [tx.to_dict() for tx in self.pending_transactions],
                "processed_transactions": list(self.processed_transactions),
                "metrics": self.metrics.to_dict(),
            }
    
        @classmethod
        def from_dict(cls, data: Dict, shard_id: int, config: ShardConfig) -> 'TransactionManager':
            """Create manager from dictionary data."""
            manager = cls(shard_id, config)
            manager.pending_transactions = [
                Transaction.from_dict(tx) for tx in data["pending_transactions"]
            ]
            manager.processed_transactions = set(data["processed_transactions"])
            manager.metrics = ShardMetrics.from_dict(data["metrics"])
            return manager
```

# File: /home/matt/icn-prototype/blockchain/core/shard/state_verifier.py

```py
    """
    blockchain/core/shard/state_verifier.py
    
    Implements state verification for cross-shard operations in the ICN blockchain.
    Ensures state consistency and provides rollback mechanisms for failed operations.
    Integrates with DID verification and governance rules.
    """
    
    from __future__ import annotations
    from typing import Dict, List, Optional, Set, Any, Tuple
    from datetime import datetime, timedelta
    import hashlib
    import json
    import logging
    from dataclasses import dataclass, field
    
    from ..transaction import Transaction
    from ..block import Block
    from .cross_shard_transaction import CrossShardTransaction
    from did.base_did import BaseDID
    from system.governance import GovernanceSystem
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class StateCheckpoint:
        """Represents a state checkpoint with verification metadata."""
        shard_id: int
        state: Dict[str, Any]
        timestamp: datetime
        transaction_id: str
        validator_did: Optional[str]
        verification_signatures: Set[str] = field(default_factory=set)
        verified_by_governance: bool = False
        hash: Optional[str] = None
    
        def __post_init__(self):
            """Initialize the checkpoint hash if not provided."""
            if not self.hash:
                self.hash = self._calculate_hash()
    
        def _calculate_hash(self) -> str:
            """Calculate the hash of the checkpoint state."""
            checkpoint_data = {
                "shard_id": self.shard_id,
                "state": self.state,
                "timestamp": self.timestamp.isoformat(),
                "transaction_id": self.transaction_id,
                "validator_did": self.validator_did
            }
            return hashlib.sha256(json.dumps(checkpoint_data, sort_keys=True).encode()).hexdigest()
    
    class StateVerifier:
        """
        Manages state verification and rollback capabilities for cross-shard operations.
        Ensures state consistency across shards during cooperative transactions.
        """
    
        def __init__(self, governance_system: Optional[GovernanceSystem] = None):
            self.state_checkpoints: Dict[str, Dict[int, StateCheckpoint]] = {}  # transaction_id -> shard_id -> checkpoint
            self.verification_cache: Dict[str, Dict[str, bool]] = {}  # transaction_id -> state_hash -> result
            self.pending_verifications: Set[str] = set()  # Set of pending transaction IDs
            self.governance_system = governance_system
            self.required_verifications = 3  # Minimum number of validator verifications required
            
        async def create_checkpoint(
            self, 
            transaction_id: str, 
            shard_id: int, 
            state: Dict[str, Any],
            validator_did: Optional[BaseDID] = None
        ) -> Tuple[str, bool]:
            """
            Create a checkpoint of the current state before a cross-shard operation.
            
            Args:
                transaction_id: ID of the cross-shard transaction
                shard_id: ID of the shard
                state: Current state to checkpoint
                validator_did: Optional DID of the validator creating checkpoint
                
            Returns:
                Tuple[str, bool]: (Checkpoint hash, success status)
            """
            try:
                checkpoint = StateCheckpoint(
                    shard_id=shard_id,
                    state=state.copy(),
                    timestamp=datetime.now(),
                    transaction_id=transaction_id,
                    validator_did=validator_did.get_did() if validator_did else None
                )
                
                if transaction_id not in self.state_checkpoints:
                    self.state_checkpoints[transaction_id] = {}
                
                self.state_checkpoints[transaction_id][shard_id] = checkpoint
                
                # Record checkpoint in governance system if available
                if self.governance_system and validator_did:
                    verified = await self.governance_system.verify_state_checkpoint(
                        transaction_id,
                        shard_id,
                        checkpoint.hash,
                        validator_did.get_did()
                    )
                    checkpoint.verified_by_governance = verified
                
                logger.info(f"Created checkpoint for transaction {transaction_id} in shard {shard_id}")
                self.pending_verifications.add(transaction_id)
                
                return checkpoint.hash, True
    
            except Exception as e:
                logger.error(f"Error creating checkpoint: {str(e)}")
                return "", False
    
        async def verify_state(
            self,
            transaction: CrossShardTransaction,
            current_states: Dict[int, Dict[str, Any]],
            validator_did: Optional[BaseDID] = None
        ) -> bool:
            """
            Verify state consistency across shards after a cross-shard operation.
            
            Args:
                transaction: The cross-shard transaction
                current_states: Current states of involved shards
                validator_did: Optional DID of the verifying validator
                
            Returns:
                bool: True if states are consistent
            """
            try:
                if transaction.state == "aborted":
                    return False
    
                # Get involved shards
                shards = {transaction.source_shard} | transaction.target_shards
                
                # Verify each shard's state
                for shard_id in shards:
                    if not await self._verify_shard_state(
                        transaction.transaction_id,
                        shard_id,
                        current_states.get(shard_id, {}),
                        validator_did
                    ):
                        return False
                        
                return True
    
            except Exception as e:
                logger.error(f"Error verifying state: {str(e)}")
                return False
    
        async def _verify_shard_state(
            self,
            transaction_id: str,
            shard_id: int,
            current_state: Dict[str, Any],
            validator_did: Optional[BaseDID]
        ) -> bool:
            """
            Verify state consistency for a specific shard.
            
            Args:
                transaction_id: ID of the transaction
                shard_id: ID of the shard to verify
                current_state: Current state of the shard
                validator_did: Optional DID of the verifying validator
                
            Returns:
                bool: True if state is consistent
            """
            try:
                # Get checkpoint
                checkpoint = self.state_checkpoints.get(transaction_id, {}).get(shard_id)
                if not checkpoint:
                    logger.error(f"No checkpoint found for transaction {transaction_id} in shard {shard_id}")
                    return False
    
                # Validate state transition
                valid_transition = await self._validate_state_transition(
                    checkpoint.state,
                    current_state,
                    transaction_id,
                    shard_id
                )
                
                if not valid_transition:
                    return False
    
                # Add validator verification if DID provided
                if validator_did:
                    checkpoint.verification_signatures.add(validator_did.get_did())
                    
                    # Check governance verification if available
                    if self.governance_system:
                        checkpoint.verified_by_governance = await self.governance_system.verify_state_transition(
                            transaction_id,
                            shard_id,
                            checkpoint.hash,
                            validator_did.get_did()
                        )
    
                # Check if we have enough verifications
                if (len(checkpoint.verification_signatures) >= self.required_verifications and
                    (not self.governance_system or checkpoint.verified_by_governance)):
                    if transaction_id in self.pending_verifications:
                        self.pending_verifications.remove(transaction_id)
                    return True
    
                return False
    
            except Exception as e:
                logger.error(f"Error verifying shard state: {str(e)}")
                return False
    
        async def rollback_state(
            self,
            transaction_id: str,
            shard_id: int,
            validator_did: Optional[BaseDID] = None
        ) -> Optional[Dict[str, Any]]:
            """
            Rollback state to the last checkpoint for a failed operation.
            
            Args:
                transaction_id: ID of the failed transaction
                shard_id: ID of the shard to rollback
                validator_did: Optional DID of the validator initiating rollback
                
            Returns:
                Optional[Dict[str, Any]]: The rolled back state if successful
            """
            try:
                checkpoint = self.state_checkpoints.get(transaction_id, {}).get(shard_id)
                if not checkpoint:
                    logger.error(f"No checkpoint found for rollback of transaction {transaction_id} in shard {shard_id}")
                    return None
    
                # Record rollback in governance system if available
                if self.governance_system and validator_did:
                    await self.governance_system.record_state_rollback(
                        transaction_id,
                        shard_id,
                        checkpoint.hash,
                        validator_did.get_did()
                    )
    
                rolled_back_state = checkpoint.state.copy()
                logger.info(f"Rolled back state for transaction {transaction_id} in shard {shard_id}")
                return rolled_back_state
    
            except Exception as e:
                logger.error(f"Error rolling back state: {str(e)}")
                return None
    
        async def _validate_state_transition(
            self,
            previous_state: Dict[str, Any],
            current_state: Dict[str, Any],
            transaction_id: str,
            shard_id: int
        ) -> bool:
            """
            Validate that the state transition is consistent with transaction rules.
            
            Args:
                previous_state: State before the transaction
                current_state: State after the transaction
                transaction_id: ID of the transaction
                shard_id: ID of the shard
                
            Returns:
                bool: True if the transition is valid
            """
            try:
                # Verify all accounts exist in both states
                if set(previous_state.keys()) != set(current_state.keys()):
                    return False
    
                # Verify balances meet conservation rules
                prev_total = sum(float(val.get('balance', 0)) for val in previous_state.values())
                curr_total = sum(float(val.get('balance', 0)) for val in current_state.values())
                
                if not abs(prev_total - curr_total) < 0.0001:  # Allow for minimal floating point differences
                    return False
    
                # Verify other state invariants
                for account_id, prev_account in previous_state.items():
                    curr_account = current_state[account_id]
                    
                    # Verify non-balance fields remain unchanged
                    prev_static = {k: v for k, v in prev_account.items() if k != 'balance'}
                    curr_static = {k: v for k, v in curr_account.items() if k != 'balance'}
                    if prev_static != curr_static:
                        return False
                    
                    # Verify balance changes are within allowed limits
                    prev_balance = float(prev_account.get('balance', 0))
                    curr_balance = float(curr_account.get('balance', 0))
                    if abs(curr_balance - prev_balance) > prev_balance * 0.5:  # Max 50% change per transaction
                        return False
    
                return True
    
            except Exception as e:
                logger.error(f"Error validating state transition: {str(e)}")
                return False
    
        async def cleanup_old_checkpoints(self, max_age_hours: int = 24) -> None:
            """
            Remove old checkpoints to prevent memory bloat.
            
            Args:
                max_age_hours: Maximum age of checkpoints to keep in hours
            """
            try:
                current_time = datetime.now()
                transactions_to_remove = []
    
                for transaction_id, shards in self.state_checkpoints.items():
                    for checkpoint in shards.values():
                        age = current_time - checkpoint.timestamp
                        
                        if age > timedelta(hours=max_age_hours):
                            transactions_to_remove.append(transaction_id)
                            break
    
                for transaction_id in transactions_to_remove:
                    del self.state_checkpoints[transaction_id]
                    if transaction_id in self.verification_cache:
                        del self.verification_cache[transaction_id]
                    self.pending_verifications.discard(transaction_id)
                
                logger.info(f"Cleaned up {len(transactions_to_remove)} old checkpoints")
    
            except Exception as e:
                logger.error(f"Error cleaning up old checkpoints: {str(e)}")
    
        def get_checkpoint_metrics(self) -> Dict[str, Any]:
            """Get metrics about current checkpoints and verifications."""
            try:
                return {
                    "active_checkpoints": len(self.state_checkpoints),
                    "pending_verifications": len(self.pending_verifications),
                    "transactions": {
                        tx_id: {
                            "shards": list(shards.keys()),
                            "verifications": {
                                shard_id: len(checkpoint.verification_signatures)
                                for shard_id, checkpoint in shards.items()
                            },
                            "governance_verified": all(
                                checkpoint.verified_by_governance
                                for checkpoint in shards.values()
                            )
                        }
                        for tx_id, shards in self.state_checkpoints.items()
                    }
                }
            except Exception as e:
                logger.error(f"Error getting checkpoint metrics: {str(e)}")
                return {}
    
        def to_dict(self) -> Dict[str, Any]:
            """Convert verifier state to dictionary format."""
            try:
                return {
                    "checkpoints": {
                        tx_id: {
                            str(shard_id): {
                                "shard_id": checkpoint.shard_id,
                                "state": checkpoint.state,
                                "timestamp": checkpoint.timestamp.isoformat(),
                                "transaction_id": checkpoint.transaction_id,
                                "validator_did": checkpoint.validator_did,
                                "verification_signatures": list(checkpoint.verification_signatures),
                                "verified_by_governance": checkpoint.verified_by_governance,
                                "hash": checkpoint.hash
                            }
                            for shard_id, checkpoint in shards.items()
                        }
                        for tx_id, shards in self.state_checkpoints.items()
                    },
                    "pending_verifications": list(self.pending_verifications)
                }
            except Exception as e:
                logger.error(f"Error converting verifier to dictionary: {str(e)}")
                return {}
    
        @classmethod
        def from_dict(cls, data: Dict[str, Any], governance_system: Optional[GovernanceSystem] = None) -> 'StateVerifier':
            """Create verifier from dictionary format."""
            try:
                verifier = cls(governance_system)
                
                # Restore checkpoints
                for tx_id, shards in data.get("checkpoints", {}).items():
                    verifier.state_checkpoints[tx_id] = {}
                    for shard_id_str, checkpoint_data in shards.items():
                        checkpoint = StateCheckpoint(
                            shard_id=int(shard_id_str),
                            state=checkpoint_data["state"],
                            timestamp=datetime.fromisoformat(checkpoint_data["timestamp"]),
                            transaction_id=checkpoint_data["transaction_id"],
                            validator_did=checkpoint_data["validator_did"],
                            verification_signatures=set(checkpoint_data["verification_signatures"]),
                            verified_by_governance=checkpoint_data["verified_by_governance"],
                            hash=checkpoint_data["hash"]
                        )
                        verifier.state_checkpoints[tx_id][int(shard_id_str)] = checkpoint
                
                # Restore pending verifications
                verifier.pending_verifications = set(data.get("pending_verifications", []))
                
                return verifier
                
            except Exception as e:
                logger.error(f"Error creating verifier from dictionary: {str(e)}")
                raise
    
        def __str__(self) -> str:
            """Return string representation of the verifier."""
            try:
                metrics = self.get_checkpoint_metrics()
                return (
                    f"StateVerifier(checkpoints={metrics['active_checkpoints']}, "
                    f"pending={len(self.pending_verifications)})"
                )
            except Exception as e:
                logger.error(f"Error in string representation: {str(e)}")
                return "StateVerifier(error)"
```

# File: /home/matt/icn-prototype/blockchain/core/shard/shard_types.py

```py
    # blockchain/core/shard/shard_types.py
    
    from __future__ import annotations
    from dataclasses import dataclass, field
    from datetime import datetime
    from typing import Dict, List, Optional, Set
    
    @dataclass
    class ShardMetrics:
        """Metrics tracking for a shard."""
        total_transactions: int = 0
        average_block_time: float = 0.0
        blocks_created: int = 0
        pending_count: int = 0
        validation_failures: int = 0
        successful_blocks: int = 0
        rejected_transactions: int = 0
        total_size_bytes: int = 0
        average_transactions_per_block: float = 0.0
        cross_shard_operations: int = 0
        active_validators: int = 0
        state_size_bytes: int = 0
    
        def to_dict(self) -> Dict:
            """Convert metrics to dictionary format."""
            return {
                field.name: getattr(self, field.name)
                for field in self.__dataclass_fields__.values()
            }
    
        @classmethod 
        def from_dict(cls, data: Dict) -> 'ShardMetrics':
            """Create metrics from dictionary."""
            return cls(**{
                k: v for k, v in data.items() 
                if k in cls.__dataclass_fields__
            })
    
    @dataclass
    class ShardConfig:
        """Configuration for a shard."""
        max_transactions_per_block: int = 100
        max_pending_transactions: int = 200
        max_cross_shard_refs: int = 50
        pruning_interval: int = 60  # minutes
        min_block_interval: int = 0  # Changed to 0 for testing
        max_block_size: int = 1024 * 1024  # 1MB
        max_state_size: int = 10 * 1024 * 1024  # 10MB
        max_validators: int = 100
        cross_shard_timeout: int = 300  # seconds
    
        def to_dict(self) -> Dict:
            """Convert config to dictionary format."""
            return {
                field.name: getattr(self, field.name)
                for field in self.__dataclass_fields__.values()
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> 'ShardConfig':
            """Create config from dictionary."""
            return cls(**{
                k: v for k, v in data.items() 
                if k in cls.__dataclass_fields__
            })
    
    @dataclass
    class CrossShardRef:
        """Represents a cross-shard reference."""
        source_shard: int
        target_shard: int
        transaction_id: str
        created_at: datetime = field(default_factory=datetime.now)
        status: str = "pending"  # pending, validated, expired
        validation_time: Optional[datetime] = None
    
        def to_dict(self) -> Dict:
            """Convert reference to dictionary format."""
            return {
                "source_shard": self.source_shard,
                "target_shard": self.target_shard,
                "transaction_id": self.transaction_id,
                "created_at": self.created_at.isoformat(),
                "status": self.status,
                "validation_time": self.validation_time.isoformat() if self.validation_time else None
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> 'CrossShardRef':
            """Create reference from dictionary."""
            data = data.copy()
            data['created_at'] = datetime.fromisoformat(data['created_at'])
            if data.get('validation_time'):
                data['validation_time'] = datetime.fromisoformat(data['validation_time'])
            return cls(**data)
```

# File: /home/matt/icn-prototype/blockchain/core/shard/base.py

```py
    # blockchain/core/shard/base.py
    
    from typing import Dict, List, Optional, Set, Any, Union
    import logging
    from datetime import datetime
    from copy import deepcopy
    from .shard_types import ShardConfig, ShardMetrics
    from .transaction_manager import TransactionManager
    from .state_manager import StateManager
    from .validation_manager import ValidationManager
    from .cross_shard_manager import CrossShardManager
    from ..block import Block
    from ..transaction import Transaction
    
    logger = logging.getLogger(__name__)
    
    class Shard:
        """
        Main shard class that coordinates all shard components.
        
        This class serves as the primary interface for shard operations,
        delegating specific functionalities to specialized managers while
        maintaining backward compatibility with existing interfaces.
        """
    
        # Maintain class-level defaults for backward compatibility
        DEFAULT_MAX_TRANSACTIONS = 100
    
        def __init__(self, shard_id: int, config: Optional[ShardConfig] = None, **kwargs):
            """
            Initialize a new shard.
            
            Args:
                shard_id: Unique identifier for this shard
                config: Optional configuration, uses defaults if not provided
                **kwargs: Legacy support for direct parameter passing
                         (e.g., max_transactions_per_block)
            """
            if not isinstance(shard_id, int) or shard_id < 0:
                raise ValueError("Invalid shard_id. Must be non-negative integer.")
    
            # Handle legacy initialization
            if config is None:
                config = ShardConfig()
                if 'max_transactions_per_block' in kwargs:
                    config.max_transactions_per_block = kwargs['max_transactions_per_block']
                if 'max_pending_transactions' in kwargs:
                    config.max_pending_transactions = kwargs['max_pending_transactions']
    
            self.shard_id = shard_id
            self.config = config
            
            # Initialize managers
            try:
                self.transaction_manager = TransactionManager(shard_id, self.config)
                self.state_manager = StateManager(shard_id, self.config)
                self.validation_manager = ValidationManager(shard_id, self.config)
                self.cross_shard_manager = CrossShardManager(shard_id, self.config)
            except Exception as e:
                logger.error(f"Failed to initialize shard managers: {str(e)}")
                raise
            
            # Core properties
            self.chain: List[Block] = []
            self.height = 0
            self.known_validators: Set[str] = set()
            
            # Initialize genesis block and state
            self._create_genesis_block()
            self._initialize_state()
    
        def _initialize_state(self) -> None:
            """Initialize the shard's state with required structure."""
            try:
                self.state_manager.state.update({
                    "metadata": {
                        "shard_id": self.shard_id,
                        "created_at": datetime.now().isoformat(),
                        "last_updated": datetime.now().isoformat(),
                        "total_transactions": 0,
                        "total_volume": 0.0,
                        "version": "1.0"
                    }
                })
                
                # Ensure balances are initialized
                if "balances" not in self.state_manager.state:
                    self.state_manager.state["balances"] = {
                        f"user{i}": 1000.0 for i in range(10)
                    }
            except Exception as e:
                logger.error(f"Failed to initialize state: {str(e)}")
                raise
    
        def _create_genesis_block(self) -> None:
            """Create and add the genesis block."""
            try:
                genesis_block = Block(
                    index=0,
                    previous_hash="0" * 64,
                    timestamp=datetime.now(),
                    transactions=[],
                    validator="genesis",
                    shard_id=self.shard_id
                )
                
                self.chain.append(genesis_block)
                self.height = 1
                self.known_validators.add("genesis")
            except Exception as e:
                logger.error(f"Failed to create genesis block: {str(e)}")
                raise
    
        @property
        def max_transactions_per_block(self) -> int:
            """Property accessor for backward compatibility."""
            return self.config.max_transactions_per_block
    
        @classmethod
        def get_max_transactions_per_block(cls) -> int:
            """Class method accessor for backward compatibility."""
            return cls.DEFAULT_MAX_TRANSACTIONS
    
        @property
        def cross_shard_references(self) -> Dict[int, List[str]]:
            """Property accessor for cross shard references."""
            return self.cross_shard_manager.cross_shard_refs
    
        @property
        def average_block_time(self) -> float:
            """Calculate average time between blocks."""
            if len(self.chain) < 2:
                return 0.0
            
            total_time = sum(
                (self.chain[i].timestamp - self.chain[i-1].timestamp).total_seconds()
                for i in range(1, len(self.chain))
            )
            return total_time / (len(self.chain) - 1)
    
        @property
        def pending_transactions(self) -> List[Transaction]:
            """Property accessor for backward compatibility."""
            return self.transaction_manager.pending_transactions
    
        @property
        def state(self) -> Dict:
            """Property accessor for backward compatibility."""
            return self.state_manager.state
    
        def add_transaction(self, transaction: Transaction) -> bool:
            """Add a new transaction to the shard."""
            if not isinstance(transaction, Transaction):
                logger.error("Invalid transaction type")
                return False
    
            try:
                # Validate transaction
                if not self.validation_manager.validate_transaction(transaction):
                    logger.error(f"Transaction {transaction.transaction_id} failed validation")
                    return False
    
                # Add to transaction pool
                if not self.transaction_manager.add_transaction(transaction):
                    return False
    
                # Process any cross-shard aspects
                if transaction.cross_shard_refs or 'target_shard' in transaction.data:
                    self.cross_shard_manager.process_transaction(transaction)
    
                return True
    
            except Exception as e:
                logger.error(f"Failed to add transaction: {str(e)}")
                return False
    
        def create_block(self, validator: str) -> Optional[Block]:
            """Create a new block from pending transactions."""
            if not validator:
                logger.error("Invalid validator ID")
                return None
    
            try:
                transactions = self.transaction_manager.select_transactions_for_block()
                if not transactions:
                    return None
    
                block = Block(
                    index=self.height,
                    previous_hash=self.chain[-1].hash if self.chain else "0" * 64,
                    timestamp=datetime.now(),
                    transactions=transactions,
                    validator=validator,
                    shard_id=self.shard_id
                )
    
                # Add cross-shard references
                cross_shard_refs = self.cross_shard_manager.get_pending_validations()
                if cross_shard_refs:
                    block.cross_shard_refs.extend(ref.transaction_id for ref in cross_shard_refs)
    
                return block
    
            except Exception as e:
                logger.error(f"Failed to create block: {str(e)}")
                return None
    
        def add_block(self, block: Block) -> bool:
            """Add a validated block to the chain."""
            if not isinstance(block, Block):
                logger.error("Invalid block type")
                return False
    
            try:
                # Validate block
                if not self.validation_manager.validate_block(block, self.chain[-1] if self.chain else None):
                    logger.error("Block validation failed")
                    return False
    
                # Update state
                if not self.state_manager.update_state(block):
                    logger.error("State update failed")
                    return False
    
                # Add block to chain
                self.chain.append(block)
                self.height += 1
                self.known_validators.add(block.validator)
    
                # Update cross-shard references
                if block.cross_shard_refs:
                    for ref_id in block.cross_shard_refs:
                        self.cross_shard_manager.validate_reference(ref_id)
    
                # Remove processed transactions
                tx_ids = {tx.transaction_id for tx in block.transactions}
                self.transaction_manager.remove_transactions(tx_ids)
    
                return True
    
            except Exception as e:
                logger.error(f"Failed to add block: {str(e)}")
                return False
    
        def validate_chain(self) -> bool:
            """Validate the entire chain."""
            try:
                if not self.chain:
                    return True
    
                for i in range(1, len(self.chain)):
                    if not self.validation_manager.validate_block(self.chain[i], self.chain[i-1]):
                        return False
                return True
    
            except Exception as e:
                logger.error(f"Chain validation failed: {str(e)}")
                return False
    
        def get_metrics(self) -> Dict[str, Any]:
            """Get comprehensive shard metrics."""
            try:
                # Core metrics
                metrics = {
                    "shard_id": self.shard_id,
                    "height": self.height,
                    "chain_size": len(self.chain),
                    "known_validators": len(self.known_validators),
                    "last_block_time": self.chain[-1].timestamp.isoformat() if self.chain else None,
                    "average_block_time": self.average_block_time
                }
                
                # Add metrics from each manager
                metrics.update(self.state_manager.get_metrics())
                metrics.update(self.transaction_manager.get_metrics())
                metrics.update(self.cross_shard_manager.get_metrics())
                
                return metrics
    
            except Exception as e:
                logger.error(f"Failed to get metrics: {str(e)}")
                return {"error": str(e)}
    
        def to_dict(self) -> Dict[str, Any]:
            """Convert shard state to dictionary format."""
            try:
                return {
                    "shard_id": self.shard_id,
                    "height": self.height,
                    "chain": [block.to_dict() for block in self.chain],
                    "config": self.config.to_dict(),
                    "known_validators": list(self.known_validators),
                    "transaction_manager": self.transaction_manager.to_dict(),
                    "state_manager": self.state_manager.to_dict(),
                    "cross_shard_manager": self.cross_shard_manager.to_dict(),
                    "version": "1.0"
                }
            except Exception as e:
                logger.error(f"Failed to convert shard to dictionary: {str(e)}")
                raise
    
        @classmethod
        def from_dict(cls, data: Dict[str, Any]) -> 'Shard':
            """Create shard from dictionary data."""
            try:
                # Create instance with config
                config = ShardConfig.from_dict(data["config"])
                shard = cls(data["shard_id"], config)
                
                # Restore chain
                shard.chain = [Block.from_dict(block) for block in data["chain"]]
                shard.height = data["height"]
                shard.known_validators = set(data["known_validators"])
                
                # Restore managers
                shard.transaction_manager = TransactionManager.from_dict(
                    data["transaction_manager"],
                    shard.shard_id,
                    config
                )
                shard.state_manager = StateManager.from_dict(
                    data["state_manager"],
                    shard.shard_id,
                    config
                )
                shard.cross_shard_manager = CrossShardManager.from_dict(
                    data["cross_shard_manager"],
                    shard.shard_id,
                    config
                )
                
                return shard
                
            except Exception as e:
                logger.error(f"Failed to create shard from dictionary: {str(e)}")
                raise
    
        def __str__(self) -> str:
            """String representation."""
            return f"Shard(id={self.shard_id}, height={self.height}, validators={len(self.known_validators)})"
```

# File: /home/matt/icn-prototype/blockchain/core/shard/cross_shard_manager.py

```py
    # blockchain/core/shard/cross_shard_manager.py
    
    from typing import Dict, List, Optional, Set
    import logging
    from datetime import datetime, timedelta
    from .shard_types import ShardConfig, ShardMetrics, CrossShardRef
    from ..block import Block
    from ..transaction import Transaction
    
    logger = logging.getLogger(__name__)
    
    class CrossShardManager:
        """Manages cross-shard operations and references."""
        
        def __init__(self, shard_id: int, config: ShardConfig):
            self.shard_id = shard_id
            self.config = config
            self.cross_shard_refs: Dict[int, List[CrossShardRef]] = {}  # target_shard -> refs
            self.pending_validations: Dict[str, CrossShardRef] = {}  # tx_id -> ref
            self.validated_refs: Set[str] = set()  # Set of validated tx_ids
            self.metrics = ShardMetrics()
            self.last_cleanup = datetime.now()
    
        def process_transaction(self, transaction: Transaction) -> Optional[CrossShardRef]:
            """Process a transaction for cross-shard operations."""
            try:
                # Check if this is a cross-shard transaction
                target_shard = transaction.data.get('target_shard')
                if not target_shard or target_shard == self.shard_id:
                    return None
    
                # Create cross-shard reference
                ref = CrossShardRef(
                    source_shard=self.shard_id,
                    target_shard=target_shard,
                    transaction_id=transaction.transaction_id
                )
    
                # Add to references
                if target_shard not in self.cross_shard_refs:
                    self.cross_shard_refs[target_shard] = []
                self.cross_shard_refs[target_shard].append(ref)
                
                # Add to pending validations
                self.pending_validations[transaction.transaction_id] = ref
                
                # Update metrics
                self.metrics.cross_shard_operations += 1
                
                return ref
    
            except Exception as e:
                logger.error(f"Failed to process cross-shard transaction: {str(e)}")
                return None
    
        def update_references(self, block: Block) -> None:
            """Update cross-shard references based on a new block."""
            try:
                for tx in block.transactions:
                    # Process new cross-shard references
                    if 'target_shard' in tx.data:
                        self.process_transaction(tx)
                    
                    # Check for validation confirmations
                    if 'validate_ref' in tx.data:
                        self._handle_validation_confirmation(tx)
    
            except Exception as e:
                logger.error(f"Failed to update cross-shard references: {str(e)}")
    
        def validate_reference(self, ref_id: str) -> bool:
            """Validate a cross-shard reference."""
            try:
                if ref_id not in self.pending_validations:
                    return False
    
                ref = self.pending_validations[ref_id]
                ref.status = "validated"
                ref.validation_time = datetime.now()
                
                # Move to validated set
                self.validated_refs.add(ref_id)
                del self.pending_validations[ref_id]
                
                return True
    
            except Exception as e:
                logger.error(f"Failed to validate reference: {str(e)}")
                return False
    
        def get_pending_validations(self, target_shard: Optional[int] = None) -> List[CrossShardRef]:
            """Get pending validations, optionally filtered by target shard."""
            try:
                if target_shard is not None:
                    return [
                        ref for ref in self.pending_validations.values()
                        if ref.target_shard == target_shard
                    ]
                return list(self.pending_validations.values())
    
            except Exception as e:
                logger.error(f"Failed to get pending validations: {str(e)}")
                return []
    
        def cleanup_expired_references(self) -> None:
            """Clean up expired cross-shard references."""
            try:
                current_time = datetime.now()
                
                # Only clean up periodically
                if (current_time - self.last_cleanup).total_seconds() < 60:
                    return
    
                timeout = timedelta(seconds=self.config.cross_shard_timeout)
                expired_refs = []
    
                # Find expired references
                for tx_id, ref in self.pending_validations.items():
                    if current_time - ref.created_at > timeout:
                        ref.status = "expired"
                        expired_refs.append(tx_id)
    
                # Remove expired references
                for tx_id in expired_refs:
                    del self.pending_validations[tx_id]
    
                # Update cleanup timestamp
                self.last_cleanup = current_time
    
            except Exception as e:
                logger.error(f"Failed to cleanup expired references: {str(e)}")
    
        def _handle_validation_confirmation(self, transaction: Transaction) -> None:
            """Process a validation confirmation transaction."""
            try:
                ref_id = transaction.data.get('validate_ref')
                if not ref_id:
                    return
    
                if ref_id in self.pending_validations:
                    self.validate_reference(ref_id)
    
            except Exception as e:
                logger.error(f"Failed to handle validation confirmation: {str(e)}")
    
        def get_metrics(self) -> Dict:
            """Get cross-shard operation metrics."""
            return {
                'pending_validations': len(self.pending_validations),
                'validated_refs': len(self.validated_refs),
                'cross_shard_operations': self.metrics.cross_shard_operations,
                'refs_by_shard': {
                    shard_id: len(refs)
                    for shard_id, refs in self.cross_shard_refs.items()
                }
            }
    
        def to_dict(self) -> Dict:
            """Convert manager state to dictionary format."""
            return {
                'cross_shard_refs': {
                    shard_id: [ref.to_dict() for ref in refs]
                    for shard_id, refs in self.cross_shard_refs.items()
                },
                'pending_validations': {
                    tx_id: ref.to_dict()
                    for tx_id, ref in self.pending_validations.items()
                },
                'validated_refs': list(self.validated_refs),
                'metrics': self.metrics.to_dict()
            }
    
        @classmethod
        def from_dict(cls, data: Dict, shard_id: int, config: ShardConfig) -> 'CrossShardManager':
            """Create manager from dictionary data."""
            manager = cls(shard_id, config)
            
            # Restore cross-shard references
            for shard_id_str, refs_data in data['cross_shard_refs'].items():
                shard_id = int(shard_id_str)
                manager.cross_shard_refs[shard_id] = [
                    CrossShardRef.from_dict(ref_data)
                    for ref_data in refs_data
                ]
            
            # Restore pending validations
            manager.pending_validations = {
                tx_id: CrossShardRef.from_dict(ref_data)
                for tx_id, ref_data in data['pending_validations'].items()
            }
            
            # Restore validated refs and metrics
            manager.validated_refs = set(data['validated_refs'])
            manager.metrics = ShardMetrics.from_dict(data['metrics'])
            
            return manager
```

# File: /home/matt/icn-prototype/blockchain/core/shard/__init__.py

```py
    # blockchain/core/shard/__init__.py
    
    from .base import Shard
    from .shard_types import ShardConfig, ShardMetrics, CrossShardRef
    from .transaction_manager import TransactionManager
    from .state_manager import StateManager
    from .validation_manager import ValidationManager
    from .cross_shard_manager import CrossShardManager
    
    __all__ = [
        "Shard",
        "ShardConfig",
        "ShardMetrics", 
        "CrossShardRef",
        "TransactionManager",
        "StateManager",
        "ValidationManager",
        "CrossShardManager"
    ]
```

# File: /home/matt/icn-prototype/blockchain/contracts/contract_executor.py

```py
    """
    blockchain/contracts/contract_executor.py
    
    This module implements the ContractExecutor for the ICN blockchain, providing
    secure contract deployment, execution, and lifecycle management. It enforces
    resource limits, security constraints, and cooperative principles.
    
    Key features:
    - Secure sandbox execution environment
    - Resource management via mana system
    - Dependency resolution and validation
    - Cross-contract communication
    - State integrity protection
    - Concurrent execution handling
    """
    
    from typing import Dict, List, Optional, Set
    import logging
    from datetime import datetime
    import asyncio
    import re
    from .smart_contract import SmartContract, ContractExecutionError
    
    logger = logging.getLogger(__name__)
    
    class ContractExecutor:
        """Manages smart contract deployment, execution, and lifecycle.
    
        The ContractExecutor ensures secure and fair contract operations within
        the ICN ecosystem. It handles:
        - Contract deployment and validation
        - Secure execution environment
        - Resource management (mana)
        - Dependency resolution
        - State management
        - Concurrent execution
        """
    
        # Safe imports that contracts are allowed to use
        SAFE_IMPORTS = {
            'math', 'datetime', 'json', 'collections',
            'typing', 'dataclasses', 'enum', 'decimal'
        }
    
        # Regular expressions for code validation
        CODE_PATTERNS = {
            'import': re.compile(r'^import\s+(\w+)'),
            'from_import': re.compile(r'^from\s+(\w+)\s+import'),
            'execute_func': re.compile(r'def\s+execute\s*\([^)]*\):')
        }
    
        def __init__(self, initial_mana: int = 1000, mana_regen_rate: int = 10):
            """Initialize the ContractExecutor.
    
            Args:
                initial_mana: Starting mana pool for contract execution
                mana_regen_rate: Rate at which mana regenerates per cycle
            """
            # Contract management
            self.contracts: Dict[str, SmartContract] = {}
            self.dependency_graph: Dict[str, Set[str]] = {}
            
            # Resource management
            self.mana_pool = initial_mana
            self.mana_regen_rate = mana_regen_rate
            self.max_mana = initial_mana * 2
            
            # Execution management
            self.execution_queue: List[Dict] = []
            self.max_queue_size = 1000
            self.execution_lock = asyncio.Lock()
            
            # Performance tracking
            self.metrics = {
                "total_executions": 0,
                "failed_executions": 0,
                "total_mana_consumed": 0,
                "average_execution_time": 0.0,
                "contracts_deployed": 0,
                "successful_deployments": 0,
                "failed_deployments": 0
            }
    
        async def deploy_contract(self, contract: SmartContract) -> bool:
            """Deploy a new smart contract.
    
            Args:
                contract: SmartContract instance to deploy
    
            Returns:
                bool: True if deployment successful, False otherwise
            
            The deployment process includes:
            1. Code validation
            2. Dependency checking
            3. Security verification
            4. Resource allocation
            """
            try:
                # Check for existing contract
                if contract.contract_id in self.contracts:
                    logger.error(f"Contract {contract.contract_id} already exists")
                    return False
    
                # Validate contract code
                if not await self._validate_contract_code(contract.code):
                    return False
    
                # Check dependencies
                if not await self._validate_dependencies(contract.dependencies):
                    return False
    
                # Store contract and update graph
                self.contracts[contract.contract_id] = contract
                self.dependency_graph[contract.contract_id] = contract.dependencies.copy()
                
                # Update metrics
                self.metrics["contracts_deployed"] += 1
                self.metrics["successful_deployments"] += 1
                
                logger.info(f"Successfully deployed contract {contract.contract_id}")
                return True
    
            except Exception as e:
                logger.error(f"Contract deployment failed: {str(e)}")
                self.metrics["failed_deployments"] += 1
                return False
    
        async def _validate_contract_code(self, code: str) -> bool:
            """Validate contract code safety and structure.
    
            Args:
                code: Contract source code to validate
    
            Returns:
                bool: True if code is safe and valid
            """
            try:
                # Check for execute function
                if not self.CODE_PATTERNS['execute_func'].search(code):
                    logger.error("Contract missing execute function")
                    return False
    
                # Validate imports
                for line in code.split('\n'):
                    line = line.strip()
                    if not line or line.startswith('#'):
                        continue
    
                    # Check import statements
                    import_match = self.CODE_PATTERNS['import'].match(line)
                    from_match = self.CODE_PATTERNS['from_import'].match(line)
    
                    if import_match:
                        module = import_match.group(1)
                        if module not in self.SAFE_IMPORTS:
                            logger.error(f"Unsafe import detected: {module}")
                            return False
                    elif from_match:
                        module = from_match.group(1)
                        if module not in self.SAFE_IMPORTS:
                            logger.error(f"Unsafe import detected: {module}")
                            return False
    
                # Test compilation
                compile(code, '<string>', 'exec')
                return True
    
            except Exception as e:
                logger.error(f"Code validation failed: {str(e)}")
                return False
    
        async def execute_contract(
            self, contract_id: str, input_data: Dict, caller: str
        ) -> Dict:
            """Execute a smart contract.
    
            Args:
                contract_id: ID of contract to execute
                input_data: Input parameters for contract
                caller: ID of calling entity
    
            Returns:
                Dict containing execution results
    
            Raises:
                ContractExecutionError: If execution fails
            """
            async with self.execution_lock:
                try:
                    # Get and validate contract
                    contract = self.contracts.get(contract_id)
                    if not contract:
                        raise ContractExecutionError(f"Contract {contract_id} not found")
    
                    # Check authorization
                    if caller not in contract.allowed_callers:
                        raise ContractExecutionError(f"Caller {caller} not authorized")
    
                    # Check mana
                    if self.mana_pool < contract.mana_cost:
                        raise ContractExecutionError("Insufficient mana")
    
                    # Execute contract
                    execution_start = datetime.now()
                    result = contract.execute(input_data, self.mana_pool)
    
                    # Update resources
                    mana_used = result["mana_used"]
                    self.mana_pool = max(0, self.mana_pool - mana_used)
                    self.metrics["total_mana_consumed"] += mana_used
    
                    # Update metrics
                    execution_time = (datetime.now() - execution_start).total_seconds()
                    await self._update_metrics(execution_time, True)
    
                    return result
    
                except Exception as e:
                    await self._update_metrics(0, False)
                    raise ContractExecutionError(str(e))
    
        async def _validate_dependencies(self, dependencies: Set[str]) -> bool:
            """Validate contract dependencies.
    
            Args:
                dependencies: Set of contract IDs this contract depends on
    
            Returns:
                bool: True if dependencies are valid
            """
            try:
                # Check existence
                for dep in dependencies:
                    if dep not in self.contracts:
                        logger.error(f"Dependency not found: {dep}")
                        return False
    
                # Check for cycles
                visited: Set[str] = set()
                path: List[str] = []
    
                async def check_cycle(contract_id: str) -> bool:
                    if contract_id in path:
                        cycle = ' -> '.join(path + [contract_id])
                        logger.error(f"Circular dependency detected: {cycle}")
                        return False
    
                    if contract_id in visited:
                        return True
    
                    visited.add(contract_id)
                    path.append(contract_id)
    
                    for dep in self.dependency_graph.get(contract_id, set()):
                        if not await check_cycle(dep):
                            return False
    
                    path.pop()
                    return True
    
                # Check each dependency
                for dep in dependencies:
                    if not await check_cycle(dep):
                        return False
    
                return True
    
            except Exception as e:
                logger.error(f"Dependency validation failed: {str(e)}")
                return False
    
        async def _update_metrics(self, execution_time: float, success: bool) -> None:
            """Update executor metrics.
    
            Args:
                execution_time: Time taken for execution
                success: Whether execution was successful
            """
            try:
                self.metrics["total_executions"] += 1
                if not success:
                    self.metrics["failed_executions"] += 1
    
                # Update average execution time
                total = self.metrics["average_execution_time"] * (self.metrics["total_executions"] - 1)
                self.metrics["average_execution_time"] = (total + execution_time) / self.metrics["total_executions"]
    
            except Exception as e:
                logger.error(f"Failed to update metrics: {str(e)}")
    
        async def regenerate_mana(self) -> None:
            """Regenerate mana pool resources."""
            try:
                old_mana = self.mana_pool
                self.mana_pool = min(self.max_mana, self.mana_pool + self.mana_regen_rate)
                
                if self.mana_pool > old_mana:
                    logger.debug(f"Regenerated mana: {self.mana_pool - old_mana}")
    
            except Exception as e:
                logger.error(f"Mana regeneration failed: {str(e)}")
    
        def get_metrics(self) -> Dict:
            """Get executor metrics and statistics."""
            return {
                **self.metrics,
                "current_mana": self.mana_pool,
                "queue_length": len(self.execution_queue),
                "active_contracts": len(self.contracts)
            }
    
        async def queue_execution(self, contract_id: str, input_data: Dict, caller: str) -> bool:
            """Queue a contract execution request.
    
            Args:
                contract_id: ID of contract to execute
                input_data: Input parameters
                caller: ID of calling entity
    
            Returns:
                bool: True if successfully queued
            """
            try:
                if len(self.execution_queue) >= self.max_queue_size:
                    logger.error("Execution queue full")
                    return False
    
                self.execution_queue.append({
                    "contract_id": contract_id,
                    "input_data": input_data,
                    "caller": caller,
                    "timestamp": datetime.now()
                })
                return True
    
            except Exception as e:
                logger.error(f"Failed to queue execution: {str(e)}")
                return False
```

# File: /home/matt/icn-prototype/blockchain/contracts/smart_contract.py

```py
    """
    blockchain/contracts/smart_contract.py
    
    This module implements the SmartContract class for the ICN blockchain, providing
    a secure, sandboxed environment for executing decentralized code. The implementation
    follows cooperative principles and ensures fair resource usage.
    
    Key features:
    - Secure execution environment with restricted capabilities
    - Resource management through mana system
    - State persistence and size limitations
    - Execution history and metrics tracking
    - Caller authorization management
    - Cross-contract dependencies
    - Daily execution limits and cooldowns
    """
    
    from __future__ import annotations
    from datetime import datetime, timedelta
    from typing import Dict, List, Set, Optional, Any, Union
    import time
    import logging
    import hashlib
    import json
    import sys
    from io import StringIO
    from copy import deepcopy
    
    logger = logging.getLogger(__name__)
    
    class ContractExecutionError(Exception):
        """Exception raised for contract execution failures.
        
        This includes:
        - Code execution errors
        - Resource limit violations
        - State size exceeded
        - Authorization failures
        - Timeout errors
        """
        pass
    
    class SmartContract:
        """Smart contract implementation for the ICN blockchain.
        
        Smart contracts are self-executing code units that run in a secure sandbox.
        They maintain state, track execution metrics, and enforce resource limits
        to ensure fair usage of network resources.
        
        Attributes:
            contract_id (str): Unique identifier for the contract
            code (str): Python source code of the contract
            creator (str): Identity of contract creator
            state (Dict): Contract's persistent state storage
            mana_cost (int): Mana required per execution
            version (str): Contract version identifier
            
        Resource Limits:
            - Maximum state size (default: 1MB)
            - Maximum execution time (default: 5s)
            - Maximum mana per execution (default: 100)
            - Maximum daily executions (default: 1000)
        """
    
        # Safe built-ins allowed in contract execution
        SAFE_BUILTINS = {
            "abs": abs,
            "bool": bool,
            "dict": dict,
            "float": float,
            "int": int,
            "len": len,
            "list": list,
            "max": max,
            "min": min,
            "round": round,
            "sorted": sorted,
            "str": str,
            "sum": sum,
        }
    
        def __init__(
            self,
            contract_id: str,
            code: str,
            creator: str,
            mana_cost: int = 10,
            version: str = "1.0",
        ) -> None:
            """Initialize a new smart contract.
            
            Args:
                contract_id: Unique identifier for the contract
                code: Contract source code in Python
                creator: Identity of the contract creator
                mana_cost: Mana cost per execution
                version: Version string for the contract
                
            The constructor initializes execution tracking, state storage,
            and resource limits while setting up the secure execution environment.
            """
            # Basic contract information
            self.contract_id = contract_id
            self.code = code
            self.creator = creator
            self.state: Dict = {}
            self.mana_cost = mana_cost
            self.version = version
            
            # Execution tracking
            self.created_at = datetime.now()
            self.last_executed: Optional[datetime] = None
            self.execution_count = 0
            self.total_mana_consumed = 0
            self.execution_history: List[Dict] = []
            
            # Previous state for rollback
            self._previous_state: Optional[Dict] = None
            
            # Metadata and capabilities
            self.metadata: Dict = {
                "created_at": self.created_at,
                "version": version,
                "creator": creator,
                "description": "",
                "tags": set(),
                "last_updated": self.created_at
            }
            
            # Dependencies and authorization
            self.dependencies: Set[str] = set()
            self.allowed_callers: Set[str] = {creator}
            
            # Resource restrictions
            self.restrictions: Dict = {
                "max_state_size": 1024 * 1024,  # 1MB
                "max_execution_time": 5,         # seconds
                "max_mana_per_execution": 100,   # mana
                "max_daily_executions": 1000,    # executions
            }
            
            # Daily execution tracking
            self.daily_executions = 0
            self.last_reset = datetime.now()
    
        def execute(self, input_data: Dict, available_mana: int) -> Dict:
            """Execute the smart contract with given input data.
            
            Args:
                input_data: Dictionary of input parameters for the contract
                available_mana: Amount of mana available for execution
                
            Returns:
                Dictionary containing:
                - execution result
                - updated state
                - mana consumed
                - execution time
                - output captured
                
            Raises:
                ContractExecutionError: If execution fails or violates restrictions
            """
            self._reset_daily_executions()
            self._backup_state()
            
            try:
                # Validate execution conditions
                validation_result = self._validate_execution(input_data, available_mana)
                if validation_result.get("error"):
                    raise ContractExecutionError(validation_result["error"])
    
                execution_start = time.time()
                stdout_capture = StringIO()
                original_stdout = sys.stdout
                sys.stdout = stdout_capture
    
                try:
                    # Set up and execute
                    local_namespace = self._setup_execution_environment(input_data)
                    exec(self.code, {}, local_namespace)
    
                    if "execute" not in local_namespace:
                        raise ContractExecutionError("Contract missing execute function")
    
                    # Execute with timing check
                    if time.time() - execution_start > self.restrictions["max_execution_time"]:
                        raise ContractExecutionError("Execution time limit exceeded")
    
                    result = local_namespace["execute"](input_data, self.state)
    
                    # Validate post-execution state
                    if len(str(self.state)) > self.restrictions["max_state_size"]:
                        self._rollback_state()
                        raise ContractExecutionError("State size limit exceeded after execution")
    
                    # Update metrics and return result
                    self._update_execution_metrics(execution_start)
                    output = stdout_capture.getvalue()
    
                    return {
                        "state": self.state,
                        "result": result,
                        "mana_used": self.mana_cost,
                        "execution_time": time.time() - execution_start,
                        "output": output,
                    }
    
                finally:
                    sys.stdout = original_stdout
    
            except ContractExecutionError:
                self._rollback_state()
                raise
            except Exception as e:
                self._rollback_state()
                logger.error(f"Contract execution failed: {str(e)}")
                raise ContractExecutionError(str(e))
    
        def _validate_execution(self, input_data: Dict, available_mana: int) -> Dict:
            """Validate all conditions required for contract execution.
            
            Performs comprehensive validation including:
            - Daily execution limits
            - Mana availability
            - Current and projected state size
            - Input data format
            """
            try:
                if self.daily_executions >= self.restrictions["max_daily_executions"]:
                    return {"error": "Daily execution limit exceeded"}
    
                if available_mana < self.mana_cost:
                    return {"error": "Insufficient mana"}
    
                # Calculate potential state size
                current_state_size = len(str(self.state))
                potential_growth = len(str(input_data)) * 2  # Conservative estimate
                if current_state_size + potential_growth > self.restrictions["max_state_size"]:
                    return {"error": "Projected state size would exceed limit"}
    
                if not isinstance(input_data, dict):
                    return {"error": "Invalid input data format"}
    
                return {}
    
            except Exception as e:
                return {"error": f"Validation failed: {str(e)}"}
    
        def _backup_state(self) -> None:
            """Create a backup of the current state for potential rollback."""
            self._previous_state = deepcopy(self.state)
    
        def _rollback_state(self) -> None:
            """Rollback to the previous state if available."""
            if self._previous_state is not None:
                self.state = self._previous_state
                self._previous_state = None
    
        def _setup_execution_environment(self, input_data: Dict) -> Dict:
            """Create a secure execution environment for the contract.
            
            Sets up a restricted namespace with only safe operations allowed.
            Provides access to contract state and metadata while preventing
            access to system resources.
            """
            return {
                "input": input_data,
                "state": self.state,
                "contract_id": self.contract_id,
                "creator": self.creator,
                "version": self.version,
                "metadata": self.metadata.copy(),
                "__builtins__": self.SAFE_BUILTINS,
            }
    
        def _update_execution_metrics(self, execution_start: float) -> None:
            """Update all execution metrics after successful execution.
            
            Updates:
            - Execution count and history
            - Mana consumption
            - Timing information
            - State size tracking
            """
            self.last_executed = datetime.now()
            self.execution_count += 1
            self.daily_executions += 1
            self.total_mana_consumed += self.mana_cost
    
            execution_record = {
                "timestamp": self.last_executed,
                "execution_time": time.time() - execution_start,
                "mana_used": self.mana_cost,
                "state_size": len(str(self.state)),
            }
    
            self.execution_history.append(execution_record)
            if len(self.execution_history) > 1000:
                self.execution_history = self.execution_history[-1000:]
    
        def _reset_daily_executions(self) -> None:
            """Reset daily execution counter if a day has passed."""
            current_time = datetime.now()
            if (current_time - self.last_reset).days >= 1:
                self.daily_executions = 0
                self.last_reset = current_time
    
        def authorize_caller(self, caller_id: str) -> bool:
            """Add a new authorized caller for the contract."""
            self.allowed_callers.add(caller_id)
            return True
    
        def revoke_caller(self, caller_id: str) -> bool:
            """Revoke a caller's authorization (except creator)."""
            if caller_id == self.creator:
                return False
            self.allowed_callers.discard(caller_id)
            return True
    
        def update_restrictions(self, new_restrictions: Dict) -> bool:
            """Update contract restrictions if valid."""
            try:
                if not all(k in self.restrictions for k in new_restrictions):
                    return False
                self.restrictions.update(new_restrictions)
                self.metadata["last_updated"] = datetime.now()
                return True
            except Exception as e:
                logger.error(f"Failed to update restrictions: {str(e)}")
                return False
    
        def get_metrics(self) -> Dict:
            """Get comprehensive contract metrics."""
            return {
                "contract_id": self.contract_id,
                "version": self.version,
                "creator": self.creator,
                "created_at": self.created_at.isoformat(),
                "last_executed": (
                    self.last_executed.isoformat() if self.last_executed else None
                ),
                "execution_count": self.execution_count,
                "daily_executions": self.daily_executions,
                "total_mana_consumed": self.total_mana_consumed,
                "average_mana_per_execution": (
                    self.total_mana_consumed / self.execution_count
                    if self.execution_count > 0
                    else 0
                ),
                "state_size": len(str(self.state)),
                "dependencies": list(self.dependencies),
                "authorized_callers": len(self.allowed_callers),
                "restrictions": self.restrictions,
            }
    
        def to_dict(self) -> Dict:
            """Convert contract to dictionary representation."""
            return {
                "contract_id": self.contract_id,
                "code": self.code,
                "creator": self.creator,
                "state": self.state,
                "mana_cost": self.mana_cost,
                "version": self.version,
                "metadata": {
                    **self.metadata,
                    "created_at": self.metadata["created_at"].isoformat(),
                    "last_updated": self.metadata["last_updated"].isoformat(),
                    "tags": list(self.metadata["tags"]),
                },
                "dependencies": list(self.dependencies),
                "allowed_callers": list(self.allowed_callers),
                "restrictions": self.restrictions,
                "metrics": self.get_metrics(),
            }
    
        @classmethod
        def from_dict(cls, data: Dict) -> "SmartContract":
            """Create contract instance from dictionary data."""
            contract = cls(
                contract_id=data["contract_id"],
                code=data["code"],
                creator=data["creator"],
                mana_cost=data["mana_cost"],
                version=data["version"],
            )
    
            contract.state = data["state"]
            contract.metadata = {
                **data["metadata"],
                "created_at": datetime.fromisoformat(data["metadata"]["created_at"]),
                "last_updated": datetime.fromisoformat(data["metadata"]["last_updated"]),
                "tags": set(data["metadata"]["tags"]),
            }
            contract.dependencies = set(data["dependencies"])
            contract.allowed_callers = set(data["allowed_callers"])
            contract.restrictions = data["restrictions"]
    
            return contract
    
        def __str__(self) -> str:
            """Human-readable string representation."""
            return (
                f"Contract(id={self.contract_id}, "
                f"creator={self.creator}, "
                f"executions={self.execution_count}, "
                f"mana_cost={self.mana_cost})"
            )
```

# File: /home/matt/icn-prototype/blockchain/contracts/__init__.py

```py
    # blockchain/contracts/__init__.py
    """Smart contract components."""
    from .smart_contract import SmartContract
    from .contract_executor import ContractExecutor
    
    __all__ = ["SmartContract", "ContractExecutor"]
```

# File: /home/matt/icn-prototype/blockchain/consensus/consensus_state_manager.py

```py
    """
    blockchain/consensus/consensus_state_manager.py
    
    Manages the state of the Proof of Cooperation consensus mechanism.
    Handles state persistence, event propagation, and recovery.
    """
    
    import asyncio
    import json
    import logging
    import os
    from datetime import datetime
    from pathlib import Path
    from typing import Dict, List, Optional, Set, Any, Tuple
    from dataclasses import dataclass, field
    import aiofiles
    
    from .proof_of_cooperation.types import (
        ConsensusConfig, ConsensusState, ConsensusMetrics,
        ValidationResult, ValidatorHistory
    )
    from ..core.node import Node
    from ..core.block import Block
    from ..utils.crypto import hash_data
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class ConsensusSnapshot:
        """Represents a snapshot of consensus state for persistence."""
        timestamp: datetime
        state: ConsensusState
        active_validators: Set[str]
        pending_validations: Dict[str, ValidationResult]
        checkpoint_hash: str
    
        @property
        def snapshot_id(self) -> str:
            """Generate unique ID for this snapshot."""
            data = f"{self.timestamp.isoformat()}:{self.checkpoint_hash}"
            return hash_data(data.encode())
    
    class ConsensusStateManager:
        """
        Manages consensus state for the ICN blockchain.
        
        Responsibilities:
        - Track consensus state and metrics
        - Persist state to disk
        - Handle state recovery
        - Coordinate consensus events
        - Manage validator sets
        """
    
        def __init__(
            self, 
            config: ConsensusConfig,
            state_dir: str = "consensus_state",
            snapshot_interval: int = 100  # blocks
        ):
            """Initialize the consensus state manager."""
            self.config = config
            self.state = ConsensusState(config)
            self.state_dir = Path(state_dir)
            self.snapshot_interval = snapshot_interval
            
            # Runtime state
            self.active_validators: Set[str] = set()
            self.pending_validations: Dict[str, ValidationResult] = {}
            self.validation_queue: asyncio.Queue = asyncio.Queue()
            self.snapshots: List[ConsensusSnapshot] = []
            
            # Initialize metrics
            self.metrics = ConsensusMetrics()
            
            # Create state directory if needed
            self.state_dir.mkdir(parents=True, exist_ok=True)
            
            # Event handlers
            self.event_handlers: Dict[str, List[callable]] = {
                "state_updated": [],
                "validator_added": [],
                "validator_removed": [],
                "snapshot_created": [],
                "state_recovered": []
            }
            
            # Recovery state
            self.recovery_mode = False
            self.last_checkpoint: Optional[ConsensusSnapshot] = None
    
        async def initialize(self) -> bool:
            """Initialize consensus state and recover if needed."""
            try:
                # Attempt to load latest state
                if await self._load_latest_state():
                    logger.info("Successfully loaded existing consensus state")
                    return True
    
                # Initialize fresh state if none exists
                logger.info("No existing state found, initializing fresh state")
                await self._initialize_fresh_state()
                return True
    
            except Exception as e:
                logger.error(f"Failed to initialize consensus state: {str(e)}")
                return False
    
        async def _initialize_fresh_state(self) -> None:
            """Initialize a fresh consensus state."""
            self.state = ConsensusState(self.config)
            await self._create_snapshot()
            self._notify_event("state_updated", self.state)
    
        async def add_validator(self, validator: Node) -> bool:
            """Add a new validator to the consensus."""
            try:
                if validator.node_id in self.active_validators:
                    return False
    
                self.active_validators.add(validator.node_id)
                self.state.active_validators.add(validator.node_id)
                
                # Initialize validator metrics
                if validator.node_id not in self.state.validation_stats:
                    self.state.validation_stats[validator.node_id] = {
                        "selections": 0,
                        "successful_validations": 0,
                        "consecutive_failures": 0,
                        "last_validation": None
                    }
    
                self._notify_event("validator_added", validator)
                await self._create_snapshot()
                return True
    
            except Exception as e:
                logger.error(f"Failed to add validator {validator.node_id}: {str(e)}")
                return False
    
        async def remove_validator(self, validator_id: str) -> bool:
            """Remove a validator from consensus."""
            try:
                if validator_id not in self.active_validators:
                    return False
    
                self.active_validators.remove(validator_id)
                self.state.active_validators.remove(validator_id)
                self._notify_event("validator_removed", validator_id)
                await self._create_snapshot()
                return True
    
            except Exception as e:
                logger.error(f"Failed to remove validator {validator_id}: {str(e)}")
                return False
    
        async def record_validation(
            self,
            validator_id: str,
            result: ValidationResult,
            block: Optional[Block] = None
        ) -> None:
            """Record a validation result."""
            try:
                # Update validator stats
                if validator_id in self.state.validation_stats:
                    stats = self.state.validation_stats[validator_id]
                    stats["selections"] += 1
                    
                    if result.success:
                        stats["successful_validations"] += 1
                        stats["consecutive_failures"] = 0
                    else:
                        stats["consecutive_failures"] += 1
    
                    stats["last_validation"] = datetime.now()
    
                # Update metrics
                self.metrics.total_validations += 1
                if result.success:
                    self.metrics.successful_validations += 1
                else:
                    self.metrics.failed_validations += 1
    
                # Create validator history entry
                history_entry = ValidatorHistory(
                    node_id=validator_id,
                    timestamp=datetime.now(),
                    shard_id=block.shard_id if block else None,
                    success=result.success
                )
                self.state.validator_history.append(history_entry)
    
                # Trim history if needed
                if len(self.state.validator_history) > 1000:
                    self.state.validator_history = self.state.validator_history[-1000:]
    
                await self._create_snapshot()
    
            except Exception as e:
                logger.error(f"Failed to record validation result: {str(e)}")
    
        async def _create_snapshot(self) -> Optional[ConsensusSnapshot]:
            """Create a new state snapshot."""
            try:
                # Generate snapshot
                snapshot = ConsensusSnapshot(
                    timestamp=datetime.now(),
                    state=self.state,
                    active_validators=self.active_validators.copy(),
                    pending_validations=self.pending_validations.copy(),
                    checkpoint_hash=self._calculate_checkpoint_hash()
                )
    
                # Save snapshot
                await self._save_snapshot(snapshot)
                self.snapshots.append(snapshot)
    
                # Trim old snapshots
                if len(self.snapshots) > 10:
                    self.snapshots = self.snapshots[-10:]
    
                self._notify_event("snapshot_created", snapshot)
                return snapshot
    
            except Exception as e:
                logger.error(f"Failed to create snapshot: {str(e)}")
                return None
    
        def _calculate_checkpoint_hash(self) -> str:
            """Calculate hash of current state for checkpointing."""
            state_dict = {
                "metrics": self.metrics.to_dict(),
                "active_validators": list(self.active_validators),
                "validation_stats": self.state.validation_stats,
                "timestamp": datetime.now().isoformat()
            }
            return hash_data(json.dumps(state_dict, sort_keys=True).encode())
    
        async def _save_snapshot(self, snapshot: ConsensusSnapshot) -> bool:
            """Save snapshot to disk."""
            try:
                snapshot_path = self.state_dir / f"snapshot_{snapshot.snapshot_id}.json"
                snapshot_data = {
                    "timestamp": snapshot.timestamp.isoformat(),
                    "state": snapshot.state.to_dict(),
                    "active_validators": list(snapshot.active_validators),
                    "pending_validations": {
                        k: v.to_dict() for k, v in snapshot.pending_validations.items()
                    },
                    "checkpoint_hash": snapshot.checkpoint_hash
                }
    
                async with aiofiles.open(snapshot_path, 'w') as f:
                    await f.write(json.dumps(snapshot_data, indent=2))
                return True
    
            except Exception as e:
                logger.error(f"Failed to save snapshot: {str(e)}")
                return False
    
        async def _load_latest_state(self) -> bool:
            """Load the latest state from disk."""
            try:
                # Find latest snapshot
                snapshot_files = list(self.state_dir.glob("snapshot_*.json"))
                if not snapshot_files:
                    return False
    
                latest_snapshot = max(
                    snapshot_files,
                    key=lambda p: os.path.getctime(p)
                )
    
                # Load snapshot
                async with aiofiles.open(latest_snapshot, 'r') as f:
                    data = json.loads(await f.read())
    
                # Restore state
                self.state = ConsensusState.from_dict(data["state"])
                self.active_validators = set(data["active_validators"])
                self.pending_validations = {
                    k: ValidationResult.from_dict(v)
                    for k, v in data["pending_validations"].items()
                }
    
                # Create recovery checkpoint
                self.last_checkpoint = ConsensusSnapshot(
                    timestamp=datetime.fromisoformat(data["timestamp"]),
                    state=self.state,
                    active_validators=self.active_validators,
                    pending_validations=self.pending_validations,
                    checkpoint_hash=data["checkpoint_hash"]
                )
    
                self._notify_event("state_recovered", self.state)
                return True
    
            except Exception as e:
                logger.error(f"Failed to load latest state: {str(e)}")
                return False
    
        def register_event_handler(self, event_type: str, handler: callable) -> None:
            """Register a handler for consensus events."""
            if event_type in self.event_handlers:
                self.event_handlers[event_type].append(handler)
    
        def _notify_event(self, event_type: str, event_data: Any) -> None:
            """Notify registered handlers of an event."""
            if event_type in self.event_handlers:
                for handler in self.event_handlers[event_type]:
                    try:
                        handler(event_data)
                    except Exception as e:
                        logger.error(f"Error in event handler: {str(e)}")
    
        async def enter_recovery_mode(self) -> None:
            """Enter recovery mode after error detection."""
            self.recovery_mode = True
            if self.last_checkpoint:
                # Restore from last checkpoint
                self.state = self.last_checkpoint.state
                self.active_validators = self.last_checkpoint.active_validators
                self.pending_validations = self.last_checkpoint.pending_validations
                self._notify_event("state_recovered", self.state)
    
        async def exit_recovery_mode(self) -> None:
            """Exit recovery mode once state is restored."""
            self.recovery_mode = False
            await self._create_snapshot()
    
        def get_metrics(self) -> Dict[str, Any]:
            """Get current consensus metrics."""
            return {
                "total_validations": self.metrics.total_validations,
                "successful_validations": self.metrics.successful_validations,
                "failed_validations": self.metrics.failed_validations,
                "active_validators": len(self.active_validators),
                "pending_validations": len(self.pending_validations),
                "recovery_mode": self.recovery_mode
            }
```

# File: /home/matt/icn-prototype/blockchain/consensus/__init__.py

```py
    """
    blockchain/consensus/__init__.py
    
    Export consensus mechanism components.
    """
    
    from .proof_of_cooperation import ProofOfCooperation
    
    __all__ = ["ProofOfCooperation"]
```

# File: /home/matt/icn-prototype/blockchain/consensus/system/transaction_pool.py

```py

```

# File: /home/matt/icn-prototype/blockchain/consensus/system/chain_reorganization.py

```py
    """
    blockchain/system/chain_reorganization.py
    
    Handles chain reorganization events in the ICN blockchain system.
    Manages fork detection, chain switching, and state rollbacks while 
    maintaining cross-shard consistency and cooperative principles.
    """
    
    import asyncio
    import logging
    from typing import Dict, List, Optional, Tuple, Set
    from datetime import datetime
    from dataclasses import dataclass, field
    
    from ..core.block import Block
    from ..core.transaction import Transaction
    from ..core.state.unified_state import UnifiedStateManager
    from ..consensus.proof_of_cooperation import ProofOfCooperation
    from ..core.shard.state_verifier import StateVerifier
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class ReorgEvent:
        """Represents a chain reorganization event."""
        old_chain: List[Block]
        new_chain: List[Block]
        fork_point: Block
        timestamp: datetime = field(default_factory=datetime.now)
        affected_shards: Set[int] = field(default_factory=set)
        cross_shard_impacts: Dict[int, List[str]] = field(default_factory=dict)
        reverted_transactions: List[Transaction] = field(default_factory=list)
        reapplied_transactions: List[Transaction] = field(default_factory=list)
    
    class ChainReorganizationManager:
        """
        Manages chain reorganization events in the ICN blockchain.
        
        Responsibilities:
        - Detect and validate alternative chains
        - Manage safe chain switching
        - Handle state rollbacks and reapplication
        - Maintain cross-shard consistency
        - Preserve cooperative principles during reorgs
        """
    
        def __init__(
            self,
            state_manager: UnifiedStateManager,
            consensus: ProofOfCooperation,
            state_verifier: StateVerifier,
            max_reorg_depth: int = 100,
            min_fork_length: int = 3
        ):
            """Initialize the reorganization manager."""
            self.state_manager = state_manager
            self.consensus = consensus
            self.state_verifier = state_verifier
            self.max_reorg_depth = max_reorg_depth
            self.min_fork_length = min_fork_length
            
            # Track reorg history
            self.reorg_events: List[ReorgEvent] = []
            self.processing_reorg = False
            self.last_verification: Dict[int, datetime] = {}
    
        async def handle_potential_reorg(
            self,
            current_chain: List[Block],
            alternative_chain: List[Block],
            shard_id: Optional[int] = None
        ) -> bool:
            """
            Handle a potential chain reorganization.
    
            Args:
                current_chain: Current chain of blocks
                alternative_chain: Competing chain of blocks
                shard_id: Optional shard ID if shard-specific
    
            Returns:
                bool: True if reorganization was successful
            """
            try:
                if self.processing_reorg:
                    logger.warning("Already processing a reorganization")
                    return False
    
                self.processing_reorg = True
    
                try:
                    # Validate reorganization possibility
                    if not self._validate_reorg_possibility(current_chain, alternative_chain):
                        return False
    
                    # Find fork point
                    fork_point = await self._find_fork_point(current_chain, alternative_chain)
                    if not fork_point:
                        logger.error("Could not find valid fork point")
                        return False
    
                    # Calculate chains to revert and apply
                    to_revert, to_apply = self._calculate_chain_differences(
                        current_chain, alternative_chain, fork_point
                    )
    
                    # Verify state transitions
                    if not await self._verify_state_transitions(to_apply, fork_point):
                        logger.error("State transition verification failed")
                        return False
    
                    # Create reorg event
                    reorg_event = ReorgEvent(
                        old_chain=current_chain,
                        new_chain=alternative_chain,
                        fork_point=fork_point
                    )
    
                    # Execute the reorganization
                    success = await self._execute_reorganization(reorg_event)
                    if success:
                        self.reorg_events.append(reorg_event)
                        await self._notify_reorg_completion(reorg_event)
                        return True
    
                    return False
    
                finally:
                    self.processing_reorg = False
    
            except Exception as e:
                logger.error(f"Error handling chain reorganization: {str(e)}")
                self.processing_reorg = False
                return False
    
        async def _verify_state_transitions(
            self,
            blocks: List[Block],
            fork_point: Block
        ) -> bool:
            """
            Verify that the state transitions in the new chain are valid.
            
            Args:
                blocks: List of blocks to verify
                fork_point: The fork point block
                
            Returns:
                bool: True if state transitions are valid
            """
            try:
                # Create temporary state for verification
                temp_state = self.state_manager.create_snapshot()
                
                # Apply each block's state changes
                current_block = fork_point
                for block in blocks:
                    # Verify block links to previous
                    if block.previous_hash != current_block.hash:
                        return False
                        
                    # Verify transactions and state changes
                    if not await self.state_verifier.verify_block_state(block, temp_state):
                        return False
                        
                    # Update for next iteration    
                    current_block = block
                    
                return True
                
            except Exception as e:
                logger.error(f"Error verifying state transitions: {str(e)}")
                return False
    
        async def _execute_reorganization(self, reorg_event: ReorgEvent) -> bool:
            """
            Execute the chain reorganization.
    
            Args:
                reorg_event: The reorganization event to execute
    
            Returns:
                bool: True if reorganization was successful
            """
            try:
                # Begin state transition
                async with self.state_manager.state_transition():
                    # Revert blocks from current chain
                    for block in reversed(reorg_event.old_chain[reorg_event.fork_point.index + 1:]):
                        if not await self._revert_block(block):
                            await self.state_manager.rollback_transition()
                            return False
                        reorg_event.reverted_transactions.extend(block.transactions)
    
                    # Apply blocks from new chain
                    for block in reorg_event.new_chain[reorg_event.fork_point.index + 1:]:
                        if not await self._apply_block(block):
                            await self.state_manager.rollback_transition()
                            return False
                        reorg_event.reapplied_transactions.extend(block.transactions)
    
                    # Verify final state
                    if not await self._verify_final_state(reorg_event):
                        await self.state_manager.rollback_transition()
                        return False
    
                    # Update affected shards tracking
                    self._track_affected_shards(reorg_event)
    
                    # Commit the reorganization
                    await self.state_manager.commit_transition()
                    return True
    
            except Exception as e:
                logger.error(f"Error executing reorganization: {str(e)}")
                return False
    
        async def _revert_block(self, block: Block) -> bool:
            """
            Revert a block during reorganization.
    
            Args:
                block: Block to revert
    
            Returns:
                bool: True if block was reverted successfully
            """
            try:
                # Revert transactions in reverse order
                for tx in reversed(block.transactions):
                    if not await self.state_manager.revert_transaction(tx):
                        return False
    
                # Handle cross-shard references
                if block.cross_shard_refs:
                    for ref in block.cross_shard_refs:
                        if not await self._revert_cross_shard_ref(ref, block.shard_id):
                            return False
    
                # Update state
                return await self.state_manager.revert_block_state(block)
    
            except Exception as e:
                logger.error(f"Error reverting block: {str(e)}")
                return False
    
        async def _apply_block(self, block: Block) -> bool:
            """
            Apply a block during reorganization.
    
            Args:
                block: Block to apply
    
            Returns:
                bool: True if block was applied successfully
            """
            try:
                # Verify block validity
                if not await self.consensus.validate_block(block, None, None):
                    return False
    
                # Apply transactions
                for tx in block.transactions:
                    if not await self.state_manager.apply_transaction(tx):
                        return False
    
                # Handle cross-shard references
                if block.cross_shard_refs:
                    for ref in block.cross_shard_refs:
                        if not await self._apply_cross_shard_ref(ref, block.shard_id):
                            return False
    
                # Update state
                return await self.state_manager.apply_block_state(block)
    
            except Exception as e:
                logger.error(f"Error applying block: {str(e)}")
                return False
    
        def _track_affected_shards(self, reorg_event: ReorgEvent) -> None:
            """
            Track which shards are affected by the reorganization.
    
            Args:
                reorg_event: The reorganization event
            """
            # Track shards from old chain
            for block in reorg_event.old_chain:
                reorg_event.affected_shards.add(block.shard_id)
                if block.cross_shard_refs:
                    for ref in block.cross_shard_refs:
                        target_shard = self._get_ref_target_shard(ref)
                        if target_shard is not None:
                            reorg_event.affected_shards.add(target_shard)
                            if target_shard not in reorg_event.cross_shard_impacts:
                                reorg_event.cross_shard_impacts[target_shard] = []
                            reorg_event.cross_shard_impacts[target_shard].append(ref)
    
            # Track shards from new chain
            for block in reorg_event.new_chain:
                reorg_event.affected_shards.add(block.shard_id)
                if block.cross_shard_refs:
                    for ref in block.cross_shard_refs:
                        target_shard = self._get_ref_target_shard(ref)
                        if target_shard is not None:
                            reorg_event.affected_shards.add(target_shard)
                            if target_shard not in reorg_event.cross_shard_impacts:
                                reorg_event.cross_shard_impacts[target_shard] = []
                            reorg_event.cross_shard_impacts[target_shard].append(ref)
    
        def get_reorg_metrics(self) -> Dict:
            """Get metrics about chain reorganizations."""
            return {
                "total_reorgs": len(self.reorg_events),
                "average_reorg_depth": sum(
                    len(event.old_chain) - event.fork_point.index 
                    for event in self.reorg_events
                ) / max(1, len(self.reorg_events)),
                "max_reorg_depth": max(
                    (len(event.old_chain) - event.fork_point.index 
                     for event in self.reorg_events),
                    default=0
                ),
                "affected_shards": list(set().union(
                    *(event.affected_shards for event in self.reorg_events)
                )),
                "last_reorg_time": self.reorg_events[-1].timestamp.isoformat() 
                    if self.reorg_events else None,
                "cross_shard_impacts": sum(
                    len(event.cross_shard_impacts) for event in self.reorg_events
                )
            }
    
        def _get_ref_target_shard(self, ref: str) -> Optional[int]:
            """Extract target shard from cross-shard reference."""
            try:
                # Parse reference format to extract target shard
                # Actual implementation depends on reference format
                return int(ref.split(':')[1])
            except Exception:
                return None
```

# File: /home/matt/icn-prototype/blockchain/consensus/system/block_production.py

```py
    """
    blockchain/system/block_production.py
    
    Manages the scheduling and production of blocks in the ICN blockchain.
    Coordinates block creation across shards while ensuring fair validator
    participation and maintaining cooperative principles.
    """
    
    import asyncio
    import logging
    from typing import Dict, List, Optional, Set, Any
    from datetime import datetime, timedelta
    from dataclasses import dataclass, field
    
    from ..core.block import Block
    from ..core.node import Node
    from ..core.transaction import Transaction
    from ..consensus.proof_of_cooperation import ProofOfCooperation
    from ..core.state.unified_state import UnifiedStateManager
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class ProductionSlot:
        """Represents a scheduled block production slot."""
        timestamp: datetime
        shard_id: int
        validator_id: Optional[str] = None
        is_filled: bool = False
        block_hash: Optional[str] = None
        attempts: int = 0
        max_attempts: int = 3
        
    class BlockProductionScheduler:
        """
        Manages the scheduling and coordination of block production.
        
        Responsibilities:
        - Schedule block production slots
        - Select validators for block production
        - Coordinate cross-shard block production
        - Ensure fair validator participation
        - Handle production failures and timeouts
        """
    
        def __init__(
            self,
            consensus: ProofOfCooperation,
            state_manager: UnifiedStateManager,
            block_time: int = 15,  # seconds
            max_missed_slots: int = 3
        ):
            """Initialize the block production scheduler."""
            self.consensus = consensus
            self.state_manager = state_manager
            self.block_time = block_time
            self.max_missed_slots = max_missed_slots
            
            # Production scheduling
            self.production_slots: Dict[int, Dict[int, ProductionSlot]] = {}  # height -> shard_id -> slot
            self.current_height = 0
            self.last_production_time: Dict[int, datetime] = {}  # shard_id -> timestamp
            
            # Validator tracking
            self.active_producers: Dict[str, int] = {}  # validator_id -> assigned_height
            self.missed_slots: Dict[str, int] = {}  # validator_id -> count
            
            # Background tasks
            self.scheduler_task: Optional[asyncio.Task] = None
            self.cleanup_task: Optional[asyncio.Task] = None
            self.is_running = False
            
            # Metrics
            self.metrics = {
                "slots_scheduled": 0,
                "blocks_produced": 0,
                "missed_slots": 0,
                "validator_participation": {},
                "average_block_time": 0.0,
                "cross_shard_blocks": 0
            }
    
        async def start(self) -> None:
            """Start the block production scheduler."""
            if self.is_running:
                return
    
            self.is_running = True
            self.scheduler_task = asyncio.create_task(self._scheduling_loop())
            self.cleanup_task = asyncio.create_task(self._cleanup_loop())
            logger.info("Block production scheduler started")
    
        async def stop(self) -> None:
            """Stop the block production scheduler."""
            self.is_running = False
            
            if self.scheduler_task:
                self.scheduler_task.cancel()
                try:
                    await self.scheduler_task
                except asyncio.CancelledError:
                    pass
                
            if self.cleanup_task:
                self.cleanup_task.cancel()
                try:
                    await self.cleanup_task
                except asyncio.CancelledError:
                    pass
    
            logger.info("Block production scheduler stopped")
    
        async def schedule_block_production(self, height: int) -> None:
            """
            Schedule block production for a given height.
    
            Args:
                height: The block height to schedule
            """
            try:
                # Initialize slots for height
                self.production_slots[height] = {}
                
                # Schedule for each active shard
                active_shards = self.state_manager.get_active_shards()
                for shard_id in active_shards:
                    # Calculate slot time
                    slot_time = self._calculate_next_slot_time(shard_id)
                    
                    # Create production slot
                    slot = ProductionSlot(
                        timestamp=slot_time,
                        shard_id=shard_id
                    )
                    
                    # Assign validator
                    validator = await self._select_validator(height, shard_id)
                    if validator:
                        slot.validator_id = validator.node_id
                        self.active_producers[validator.node_id] = height
                    
                    self.production_slots[height][shard_id] = slot
                    self.metrics["slots_scheduled"] += 1
                    
                logger.info(f"Scheduled block production for height {height}")
                
            except Exception as e:
                logger.error(f"Error scheduling block production: {str(e)}")
    
        async def record_block_production(
            self,
            height: int,
            shard_id: int,
            block: Block,
            validator_id: str
        ) -> None:
            """
            Record successful block production.
    
            Args:
                height: Block height
                shard_id: Shard ID
                block: The produced block
                validator_id: ID of the producing validator
            """
            try:
                if height not in self.production_slots or shard_id not in self.production_slots[height]:
                    logger.error(f"No production slot found for height {height}, shard {shard_id}")
                    return
    
                slot = self.production_slots[height][shard_id]
                
                # Update slot status
                slot.is_filled = True
                slot.block_hash = block.hash
                
                # Update metrics
                self.metrics["blocks_produced"] += 1
                self.last_production_time[shard_id] = datetime.now()
                
                if block.cross_shard_refs:
                    self.metrics["cross_shard_blocks"] += 1
                    
                # Update validator participation
                if validator_id not in self.metrics["validator_participation"]:
                    self.metrics["validator_participation"][validator_id] = 0
                self.metrics["validator_participation"][validator_id] += 1
                
                # Clear from active producers
                if validator_id in self.active_producers:
                    del self.active_producers[validator_id]
                    
                # Reset missed slots for validator
                if validator_id in self.missed_slots:
                    del self.missed_slots[validator_id]
                    
                # Update average block time
                self._update_average_block_time(slot)
                
                logger.info(f"Recorded block production for height {height}, shard {shard_id}")
                
            except Exception as e:
                logger.error(f"Error recording block production: {str(e)}")
    
        async def record_missed_slot(self, height: int, shard_id: int) -> None:
            """
            Record a missed production slot.
    
            Args:
                height: Block height
                shard_id: Shard ID
            """
            try:
                if height not in self.production_slots or shard_id not in self.production_slots[height]:
                    return
    
                slot = self.production_slots[height][shard_id]
                validator_id = slot.validator_id
                
                if validator_id:
                    # Update missed slots count
                    if validator_id not in self.missed_slots:
                        self.missed_slots[validator_id] = 0
                    self.missed_slots[validator_id] += 1
                    
                    # Handle excessive misses
                    if self.missed_slots[validator_id] >= self.max_missed_slots:
                        await self._handle_excessive_misses(validator_id)
                        
                # Update metrics
                self.metrics["missed_slots"] += 1
                
                # Try to reassign slot if attempts remain
                if slot.attempts < slot.max_attempts:
                    slot.attempts += 1
                    await self._reassign_slot(height, shard_id, slot)
                    
                logger.warning(f"Recorded missed slot for height {height}, shard {shard_id}")
                
            except Exception as e:
                logger.error(f"Error recording missed slot: {str(e)}")
    
        async def _scheduling_loop(self) -> None:
            """Background task for scheduling block production."""
            while self.is_running:
                try:
                    # Schedule next height if needed
                    current_height = self.state_manager.get_height()
                    scheduling_horizon = 10  # Schedule 10 blocks ahead
                    
                    for height in range(current_height + 1, current_height + scheduling_horizon + 1):
                        if height not in self.production_slots:
                            await self.schedule_block_production(height)
                            
                    await asyncio.sleep(1)  # Check every second
                    
                except Exception as e:
                    logger.error(f"Error in scheduling loop: {str(e)}")
                    await asyncio.sleep(5)
    
        async def _cleanup_loop(self) -> None:
            """Background task for cleaning up old production slots."""
            while self.is_running:
                try:
                    current_height = self.state_manager.get_height()
                    cleanup_threshold = 100  # Keep 100 blocks of history
                    
                    # Remove old slots
                    for height in list(self.production_slots.keys()):
                        if height < current_height - cleanup_threshold:
                            del self.production_slots[height]
                            
                    await asyncio.sleep(60)  # Clean up every minute
                    
                except Exception as e:
                    logger.error(f"Error in cleanup loop: {str(e)}")
                    await asyncio.sleep(5)
    
        async def _select_validator(self, height: int, shard_id: int) -> Optional[Node]:
            """Select a validator for block production."""
            try:
                # Get eligible validators from consensus
                validators = await self.consensus.get_eligible_validators(shard_id)
                if not validators:
                    return None
                    
                # Filter out currently assigned validators
                available_validators = [
                    v for v in validators
                    if v.node_id not in self.active_producers
                ]
                
                if not available_validators:
                    return None
                    
                # Select validator using consensus mechanism
                selected = await self.consensus.select_validator(available_validators, shard_id)
                return selected
                
            except Exception as e:
                logger.error(f"Error selecting validator: {str(e)}")
                return None
    
        def _calculate_next_slot_time(self, shard_id: int) -> datetime:
            """Calculate the next block production slot time for a shard."""
            try:
                last_time = self.last_production_time.get(shard_id)
                if not last_time:
                    return datetime.now() + timedelta(seconds=self.block_time)
                    
                next_time = last_time + timedelta(seconds=self.block_time)
                if next_time < datetime.now():
                    next_time = datetime.now() + timedelta(seconds=self.block_time)
                    
                return next_time
                
            except Exception as e:
                logger.error(f"Error calculating slot time: {str(e)}")
                return datetime.now() + timedelta(seconds=self.block_time)
    
        async def _reassign_slot(
            self,
            height: int,
            shard_id: int,
            slot: ProductionSlot
        ) -> None:
            """Reassign a production slot to a new validator."""
            try:
                # Select new validator
                new_validator = await self._select_validator(height, shard_id)
                if new_validator:
                    # Update slot
                    slot.validator_id = new_validator.node_id
                    slot.timestamp = self._calculate_next_slot_time(shard_id)
                    self.active_producers[new_validator.node_id] = height
                    
                    logger.info(
                        f"Reassigned slot for height {height}, shard {shard_id} "
                        f"to validator {new_validator.node_id}"
                    )
                    
            except Exception as e:
                logger.error(f"Error reassigning slot: {str(e)}")
    
        async def _handle_excessive_misses(self, validator_id: str) -> None:
            """Handle a validator that has missed too many slots."""
            try:
                # Remove from active producers
                if validator_id in self.active_producers:
                    del self.active_producers[validator_id]
                    
                # Remove from missed slots tracking
                if validator_id in self.missed_slots:
                    del self.missed_slots[validator_id]
                    
                # Notify consensus mechanism
                await self.consensus.handle_validator_timeout(validator_id)
                
                logger.warning(f"Handled excessive misses for validator {validator_id}")
                
            except Exception as e:
                logger.error(f"Error handling excessive misses: {str(e)}")
    
        def _update_average_block_time(self, slot: ProductionSlot) -> None:
            """Update average block production time metrics."""
            try:
                current_avg = self.metrics["average_block_time"]
                total_blocks = self.metrics["blocks_produced"]
                
                if total_blocks == 0:
                    self.metrics["average_block_time"] = self.block_time
                    return
                    
                # Calculate new average
                actual_time = (datetime.now() - slot.timestamp).total_seconds()
                new_avg = ((current_avg * total_blocks) + actual_time) / (total_blocks + 1)
                self.metrics["average_block_time"] = new_avg
                
            except Exception as e:
                logger.error(f"Error updating average block time: {str(e)}")
    
        def get_scheduled_validators(self, height: int) -> Dict[int, str]:
            """Get scheduled validators for a height."""
            try:
                if height not in self.production_slots:
                    return {}
                    
                return {
                    shard_id: slot.validator_id
                    for shard_id, slot in self.production_slots[height].items()
                    if slot.validator_id is not None
                }
                
            except Exception as e:
                logger.error(f"Error getting scheduled validators: {str(e)}")
                return {}
    
        def get_production_metrics(self) -> Dict[str, Any]:
            """Get comprehensive block production metrics."""
            return {
                **self.metrics,
                "active_producers": len(self.active_producers),
                "current_slots": sum(
                    len(slots) for slots in self.production_slots.values()
                ),
                "filled_slots": sum(
                    len([s for s in slots.values() if s.is_filled])
                    for slots in self.production_slots.values()
                ),
                "scheduled_heights": sorted(self.production_slots.keys()),
                "validators_with_misses": len(self.missed_slots)
            }
```

# File: /home/matt/icn-prototype/blockchain/consensus/system/initialization_manager.py

```py
    """
    blockchain/system/initialization_manager.py
    
    Manages the initialization and startup sequence for the ICN blockchain system.
    Handles component initialization order, state recovery, and system health checks.
    """
    
    import asyncio
    import logging
    from typing import Dict, Optional, List, Any
    from dataclasses import dataclass
    from datetime import datetime
    import json
    from pathlib import Path
    
    from ..core.blockchain import Blockchain
    from ..core.node import Node
    from ..consensus.proof_of_cooperation import ProofOfCooperation
    from ..network.manager import NetworkManager
    from ..network.config import NetworkConfig
    from ..contracts.contract_executor import ContractExecutor
    from ..core.state.unified_state import UnifiedStateManager
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class SystemState:
        """Tracks the initialization and health state of blockchain components."""
        blockchain_ready: bool = False
        network_ready: bool = False
        consensus_ready: bool = False
        contracts_ready: bool = False
        state_ready: bool = False
        components_initialized: Dict[str, bool] = field(default_factory=dict)
        initialization_time: Optional[datetime] = None
        last_health_check: Optional[datetime] = None
        errors: List[str] = field(default_factory=list)
    
    class InitializationManager:
        """
        Manages the initialization sequence for the ICN blockchain system.
        
        Responsibilities:
        - Coordinated startup of all blockchain components
        - State recovery and verification
        - System health monitoring
        - Graceful shutdown handling
        """
    
        def __init__(self, config_path: str = "config/blockchain_config.json"):
            """Initialize the manager with configuration."""
            self.config_path = Path(config_path)
            self.state = SystemState()
            self.blockchain: Optional[Blockchain] = None
            self.network: Optional[NetworkManager] = None
            self.consensus: Optional[ProofOfCooperation] = None
            self.contract_executor: Optional[ContractExecutor] = None
            self.state_manager: Optional[UnifiedStateManager] = None
            
            # Track initialization order
            self.initialization_order = [
                "state_manager",
                "blockchain",
                "consensus",
                "network",
                "contracts"
            ]
            
            # Component status tracking
            self.component_status: Dict[str, bool] = {
                component: False for component in self.initialization_order
            }
    
        async def initialize_system(self) -> bool:
            """
            Initialize all blockchain system components in the correct order.
            
            Returns:
                bool: True if initialization successful, False otherwise
            """
            try:
                logger.info("Beginning blockchain system initialization...")
                
                # Load configuration
                config = await self._load_configuration()
                if not config:
                    return False
    
                # Initialize components in order
                for component in self.initialization_order:
                    success = await self._initialize_component(component, config)
                    if not success:
                        logger.error(f"Failed to initialize {component}")
                        return False
    
                # Verify system state
                if not await self._verify_system_state():
                    logger.error("System state verification failed")
                    return False
    
                # Start health monitoring
                asyncio.create_task(self._monitor_system_health())
                
                self.state.initialization_time = datetime.now()
                logger.info("Blockchain system initialization completed successfully")
                return True
    
            except Exception as e:
                logger.error(f"System initialization failed: {str(e)}")
                self.state.errors.append(f"Initialization error: {str(e)}")
                return False
    
        async def _load_configuration(self) -> Optional[Dict[str, Any]]:
            """Load system configuration from file."""
            try:
                if not self.config_path.exists():
                    logger.error(f"Configuration file not found: {self.config_path}")
                    return None
    
                async with aiofiles.open(self.config_path, 'r') as f:
                    config_data = json.loads(await f.read())
                    return config_data
    
            except Exception as e:
                logger.error(f"Error loading configuration: {str(e)}")
                return None
    
        async def _initialize_component(self, component: str, config: Dict[str, Any]) -> bool:
            """Initialize a specific system component."""
            try:
                logger.info(f"Initializing component: {component}")
    
                if component == "state_manager":
                    self.state_manager = UnifiedStateManager(
                        shard_count=config.get("shard_count", 4)
                    )
                    success = await self._verify_state_manager()
    
                elif component == "blockchain":
                    self.blockchain = Blockchain(
                        num_shards=config.get("shard_count", 4),
                        initial_mana=config.get("initial_mana", 1000),
                        mana_regen_rate=config.get("mana_regen_rate", 10)
                    )
                    success = self.blockchain.genesis_block_created
    
                elif component == "consensus":
                    self.consensus = ProofOfCooperation(
                        min_reputation=config.get("min_reputation", 10.0),
                        cooldown_blocks=config.get("cooldown_blocks", 3)
                    )
                    success = True
    
                elif component == "network":
                    network_config = NetworkConfig(
                        node_id=config.get("node_id", ""),
                        host=config.get("host", "0.0.0.0"),
                        port=config.get("port", 30303)
                    )
                    self.network = NetworkManager(network_config)
                    success = await self.network.start()
    
                elif component == "contracts":
                    self.contract_executor = ContractExecutor(
                        initial_mana=config.get("initial_mana", 1000),
                        mana_regen_rate=config.get("mana_regen_rate", 10)
                    )
                    success = True
    
                else:
                    logger.error(f"Unknown component: {component}")
                    return False
    
                self.component_status[component] = success
                return success
    
            except Exception as e:
                logger.error(f"Error initializing {component}: {str(e)}")
                self.state.errors.append(f"{component} initialization error: {str(e)}")
                return False
    
        async def _verify_state_manager(self) -> bool:
            """Verify state manager initialization and recovery."""
            try:
                if not self.state_manager:
                    return False
    
                # Verify state access
                test_key = "initialization_test"
                test_value = "test_data"
                
                # Test state operations
                self.state_manager.state["test"] = {test_key: test_value}
                retrieved_value = self.state_manager.state.get("test", {}).get(test_key)
                
                if retrieved_value != test_value:
                    logger.error("State manager verification failed")
                    return False
    
                # Clean up test data
                del self.state_manager.state["test"]
                return True
    
            except Exception as e:
                logger.error(f"State manager verification failed: {str(e)}")
                return False
    
        async def _verify_system_state(self) -> bool:
            """Verify overall system state after initialization."""
            try:
                # Check all components are initialized
                if not all(self.component_status.values()):
                    return False
    
                # Verify blockchain state
                if not self.blockchain or not self.blockchain.genesis_block_created:
                    return False
    
                # Verify network connectivity
                if not self.network or not self.network.is_running:
                    return False
    
                # Verify consensus mechanism
                if not self.consensus:
                    return False
    
                # Verify contract executor
                if not self.contract_executor:
                    return False
    
                self.state.blockchain_ready = True
                self.state.network_ready = True
                self.state.consensus_ready = True
                self.state.contracts_ready = True
                self.state.state_ready = True
    
                return True
    
            except Exception as e:
                logger.error(f"System state verification failed: {str(e)}")
                return False
    
        async def _monitor_system_health(self) -> None:
            """Continuously monitor system health."""
            while True:
                try:
                    # Perform health checks
                    await self._check_component_health()
                    self.state.last_health_check = datetime.now()
    
                    # Wait before next check
                    await asyncio.sleep(30)
    
                except Exception as e:
                    logger.error(f"Health monitoring error: {str(e)}")
                    await asyncio.sleep(5)
    
        async def _check_component_health(self) -> None:
            """Check health of individual components."""
            try:
                # Check blockchain health
                if self.blockchain:
                    chain_metrics = self.blockchain.get_chain_metrics()
                    if chain_metrics.get("chain_length", 0) < 1:
                        self.state.blockchain_ready = False
                        logger.warning("Blockchain health check failed")
    
                # Check network health
                if self.network:
                    if not self.network.is_running:
                        self.state.network_ready = False
                        logger.warning("Network health check failed")
    
                # Check consensus health
                if self.consensus:
                    consensus_metrics = self.consensus.get_metrics()
                    if not consensus_metrics:
                        self.state.consensus_ready = False
                        logger.warning("Consensus health check failed")
    
                # Check contract executor health
                if self.contract_executor:
                    if self.contract_executor.mana_pool <= 0:
                        self.state.contracts_ready = False
                        logger.warning("Contract executor health check failed")
    
            except Exception as e:
                logger.error(f"Component health check failed: {str(e)}")
    
        async def shutdown(self) -> None:
            """Gracefully shutdown all system components."""
            try:
                logger.info("Beginning system shutdown...")
    
                # Shutdown components in reverse order
                for component in reversed(self.initialization_order):
                    await self._shutdown_component(component)
    
                logger.info("System shutdown completed")
    
            except Exception as e:
                logger.error(f"Error during shutdown: {str(e)}")
    
        async def _shutdown_component(self, component: str) -> None:
            """Shutdown a specific system component."""
            try:
                logger.info(f"Shutting down component: {component}")
    
                if component == "network" and self.network:
                    await self.network.stop()
                elif component == "contracts" and self.contract_executor:
                    # Cleanup contract executor
                    pass
                elif component == "blockchain" and self.blockchain:
                    # Ensure state is saved
                    pass
                elif component == "consensus" and self.consensus:
                    # Cleanup consensus
                    pass
                elif component == "state_manager" and self.state_manager:
                    # Ensure state is persisted
                    pass
    
                self.component_status[component] = False
    
            except Exception as e:
                logger.error(f"Error shutting down {component}: {str(e)}")
    
        def get_system_status(self) -> Dict[str, Any]:
            """Get comprehensive system status."""
            return {
                "initialized": all(self.component_status.values()),
                "initialization_time": self.state.initialization_time.isoformat() 
                    if self.state.initialization_time else None,
                "last_health_check": self.state.last_health_check.isoformat() 
                    if self.state.last_health_check else None,
                "component_status": self.component_status.copy(),
                "errors": self.state.errors.copy(),
                "blockchain_height": self.blockchain.height if self.blockchain else 0,
                "network_peers": len(self.network.peers) if self.network else 0,
                "active_contracts": len(self.contract_executor.contracts) 
                    if self.contract_executor else 0
            }
```

# File: /home/matt/icn-prototype/blockchain/consensus/system/block_finalization.py

```py
    """
    blockchain/system/block_finalization.py
    
    This module implements block finalization for the ICN blockchain.
    It handles the process of making blocks irreversible once they meet
    specific criteria, including cooperative validation thresholds and
    cross-shard consistency requirements.
    """
    
    import asyncio
    import logging
    from typing import Dict, List, Optional, Set, Any
    from datetime import datetime, timedelta
    from dataclasses import dataclass, field
    
    from ..core.block import Block
    from ..core.state.unified_state import UnifiedStateManager
    from ..consensus.proof_of_cooperation import ProofOfCooperation
    from ..core.shard.state_verifier import StateVerifier
    from .chain_reorganization import ChainReorganizationManager
    
    logger = logging.getLogger(__name__)
    
    @dataclass
    class FinalizationCriteria:
        """Criteria required for block finalization."""
        min_validator_confirmations: int = 5
        min_cooperative_confirmations: int = 3
        confirmation_depth: int = 100
        cross_shard_validation_threshold: float = 0.8
        time_threshold: timedelta = field(default_factory=lambda: timedelta(hours=1))
    
    @dataclass
    class BlockFinalizationStatus:
        """Tracks the finalization status of a block."""
        block: Block
        validator_confirmations: Set[str] = field(default_factory=set)
        cooperative_confirmations: Set[str] = field(default_factory=set)
        cross_shard_validations: Dict[int, Set[str]] = field(default_factory=dict)
        first_confirmation_time: Optional[datetime] = None
        finalization_time: Optional[datetime] = None
        is_finalized: bool = False
    
    class BlockFinalizationManager:
        """
        Manages the process of finalizing blocks in the ICN blockchain.
        
        Responsibilities:
        - Track block confirmations from validators
        - Ensure cross-shard consistency
        - Apply finalization criteria
        - Maintain finalization history
        - Coordinate with reorganization manager
        """
    
        def __init__(
            self,
            state_manager: UnifiedStateManager,
            consensus: ProofOfCooperation,
            state_verifier: StateVerifier,
            reorg_manager: ChainReorganizationManager,
            criteria: Optional[FinalizationCriteria] = None
        ):
            """Initialize block finalization manager."""
            self.state_manager = state_manager
            self.consensus = consensus
            self.state_verifier = state_verifier
            self.reorg_manager = reorg_manager
            self.criteria = criteria or FinalizationCriteria()
            
            # Track finalization status
            self.pending_finalization: Dict[str, BlockFinalizationStatus] = {}
            self.finalized_blocks: Dict[str, BlockFinalizationStatus] = {}
            self.finalization_height: int = 0
            self.checkpoints: Dict[int, str] = {}  # height -> block_hash
            
            # Background tasks
            self._finalization_task: Optional[asyncio.Task] = None
            self._checkpoint_task: Optional[asyncio.Task] = None
            self.is_running = False
    
        async def start(self) -> None:
            """Start the finalization manager."""
            if self.is_running:
                return
    
            self.is_running = True
            self._finalization_task = asyncio.create_task(self._finalization_loop())
            self._checkpoint_task = asyncio.create_task(self._checkpoint_loop())
            logger.info("Block finalization manager started")
    
        async def stop(self) -> None:
            """Stop the finalization manager."""
            self.is_running = False
            
            if self._finalization_task:
                self._finalization_task.cancel()
                try:
                    await self._finalization_task
                except asyncio.CancelledError:
                    pass
                
            if self._checkpoint_task:
                self._checkpoint_task.cancel()
                try:
                    await self._checkpoint_task
                except asyncio.CancelledError:
                    pass
                    
            logger.info("Block finalization manager stopped")
    
        async def add_confirmation(
            self,
            block: Block,
            validator_id: str,
            cooperative_id: Optional[str] = None
        ) -> None:
            """
            Add a validator confirmation for a block.
    
            Args:
                block: The block being confirmed
                validator_id: ID of the confirming validator
                cooperative_id: Optional cooperative ID of the validator
            """
            try:
                block_hash = block.hash
                if block_hash not in self.pending_finalization:
                    self.pending_finalization[block_hash] = BlockFinalizationStatus(block=block)
                    
                status = self.pending_finalization[block_hash]
                
                # Record confirmation time if first confirmation
                if not status.first_confirmation_time:
                    status.first_confirmation_time = datetime.now()
                
                # Add validator confirmation
                status.validator_confirmations.add(validator_id)
                
                # Add cooperative confirmation if provided
                if cooperative_id:
                    status.cooperative_confirmations.add(cooperative_id)
                
                # Check if block can be finalized
                if await self._check_finalization_criteria(status):
                    await self._finalize_block(status)
                    
            except Exception as e:
                logger.error(f"Error adding confirmation: {str(e)}")
    
        async def add_cross_shard_validation(
            self,
            block: Block,
            shard_id: int,
            validator_id: str
        ) -> None:
            """
            Add a cross-shard validation for a block.
    
            Args:
                block: The block being validated
                shard_id: ID of the validating shard
                validator_id: ID of the validating node
            """
            try:
                block_hash = block.hash
                if block_hash not in self.pending_finalization:
                    self.pending_finalization[block_hash] = BlockFinalizationStatus(block=block)
                    
                status = self.pending_finalization[block_hash]
                
                # Initialize cross-shard validation set if needed
                if shard_id not in status.cross_shard_validations:
                    status.cross_shard_validations[shard_id] = set()
                    
                # Add validation
                status.cross_shard_validations[shard_id].add(validator_id)
                
                # Check if block can be finalized
                if await self._check_finalization_criteria(status):
                    await self._finalize_block(status)
                    
            except Exception as e:
                logger.error(f"Error adding cross-shard validation: {str(e)}")
    
        async def _check_finalization_criteria(self, status: BlockFinalizationStatus) -> bool:
            """
            Check if a block meets all finalization criteria.
    
            Args:
                status: The block's finalization status
    
            Returns:
                bool: True if block meets finalization criteria
            """
            try:
                # Check if already finalized
                if status.is_finalized:
                    return False
    
                # Check validator confirmations
                if len(status.validator_confirmations) < self.criteria.min_validator_confirmations:
                    return False
    
                # Check cooperative confirmations
                if len(status.cooperative_confirmations) < self.criteria.min_cooperative_confirmations:
                    return False
    
                # Check confirmation depth
                current_height = self.state_manager.get_height()
                if current_height - status.block.index < self.criteria.confirmation_depth:
                    return False
    
                # Check cross-shard validations
                if status.block.cross_shard_refs:
                    validation_ratio = self._calculate_cross_shard_validation_ratio(status)
                    if validation_ratio < self.criteria.cross_shard_validation_threshold:
                        return False
    
                # Check time threshold
                if (datetime.now() - status.first_confirmation_time
                    < self.criteria.time_threshold):
                    return False
    
                return True
    
            except Exception as e:
                logger.error(f"Error checking finalization criteria: {str(e)}")
                return False
    
        def _calculate_cross_shard_validation_ratio(
            self,
            status: BlockFinalizationStatus
        ) -> float:
            """Calculate the ratio of completed cross-shard validations."""
            try:
                total_shards = len(self.state_manager.get_active_shards())
                validated_shards = len(status.cross_shard_validations)
                
                if total_shards == 0:
                    return 0.0
                    
                return validated_shards / total_shards
                
            except Exception as e:
                logger.error(f"Error calculating validation ratio: {str(e)}")
                return 0.0
    
        async def _finalize_block(self, status: BlockFinalizationStatus) -> None:
            """
            Finalize a block that has met all criteria.
    
            Args:
                status: The block's finalization status
            """
            try:
                block_hash = status.block.hash
                
                # Update finalization status
                status.is_finalized = True
                status.finalization_time = datetime.now()
                
                # Move from pending to finalized
                self.finalized_blocks[block_hash] = status
                if block_hash in self.pending_finalization:
                    del self.pending_finalization[block_hash]
                
                # Update finalization height if necessary
                if status.block.index > self.finalization_height:
                    self.finalization_height = status.block.index
                
                # Create checkpoint if needed
                if self._should_create_checkpoint(status.block):
                    await self._create_checkpoint(status.block)
                
                # Notify components
                await self._notify_finalization(status)
                
                logger.info(f"Finalized block at height {status.block.index}")
                
            except Exception as e:
                logger.error(f"Error finalizing block: {str(e)}")
    
        async def _finalization_loop(self) -> None:
            """Background task to process pending finalizations."""
            while self.is_running:
                try:
                    # Check all pending blocks
                    for block_hash, status in list(self.pending_finalization.items()):
                        if await self._check_finalization_criteria(status):
                            await self._finalize_block(status)
                            
                    await asyncio.sleep(1)  # Prevent tight loop
                    
                except Exception as e:
                    logger.error(f"Error in finalization loop: {str(e)}")
                    await asyncio.sleep(5)  # Back off on error
    
        async def _checkpoint_loop(self) -> None:
            """Background task to create periodic checkpoints."""
            while self.is_running:
                try:
                    # Find latest finalized block
                    latest_height = max(
                        (status.block.index for status in self.finalized_blocks.values()),
                        default=0
                    )
                    
                    # Create checkpoint if needed
                    if latest_height > 0:
                        latest_block = next(
                            status.block
                            for status in self.finalized_blocks.values()
                            if status.block.index == latest_height
                        )
                        if self._should_create_checkpoint(latest_block):
                            await self._create_checkpoint(latest_block)
                    
                    await asyncio.sleep(60)  # Check every minute
                    
                except Exception as e:
                    logger.error(f"Error in checkpoint loop: {str(e)}")
                    await asyncio.sleep(5)
    
        def _should_create_checkpoint(self, block: Block) -> bool:
            """Determine if a checkpoint should be created for a block."""
            try:
                # Create checkpoint every 1000 blocks
                checkpoint_interval = 1000
                
                # Check if height is at checkpoint interval
                if block.index % checkpoint_interval != 0:
                    return False
                    
                # Check if checkpoint already exists
                if block.index in self.checkpoints:
                    return False
                    
                return True
                
            except Exception as e:
                logger.error(f"Error checking checkpoint criteria: {str(e)}")
                return False
    
        async def _create_checkpoint(self, block: Block) -> None:
            """Create a checkpoint for a finalized block."""
            try:
                # Get state root at block height
                state_root = await self.state_manager.get_state_root(block.index)
                if not state_root:
                    return
                    
                # Create checkpoint
                self.checkpoints[block.index] = block.hash
                
                # Persist checkpoint data
                checkpoint_data = {
                    "height": block.index,
                    "block_hash": block.hash,
                    "state_root": state_root,
                    "timestamp": datetime.now().isoformat()
                }
                
                await self._persist_checkpoint(checkpoint_data)
                logger.info(f"Created checkpoint at height {block.index}")
                
            except Exception as e:
                logger.error(f"Error creating checkpoint: {str(e)}")
    
        async def _persist_checkpoint(self, checkpoint_data: Dict[str, Any]) -> None:
            """Persist checkpoint data to storage."""
            try:
                # Save checkpoint to state manager
                await self.state_manager.save_checkpoint(checkpoint_data)
                
            except Exception as e:
                logger.error(f"Error persisting checkpoint: {str(e)}")
    
        async def _notify_finalization(self, status: BlockFinalizationStatus) -> None:
            """Notify relevant components about block finalization."""
            try:
                # Notify consensus mechanism
                await self.consensus.handle_block_finalization(status.block)
                
                # Notify state manager
                await self.state_manager.handle_block_finalization(status.block)
                
                # Notify reorg manager
                await self.reorg_manager.handle_block_finalization(status.block)
                
            except Exception as e:
                logger.error(f"Error notifying finalization: {str(e)}")
    
        def is_finalized(self, block_hash: str) -> bool:
            """Check if a block is finalized."""
            return block_hash in self.finalized_blocks
    
        def get_finalization_height(self) -> int:
            """Get the current finalization height."""
            return self.finalization_height
    
        def get_finalization_stats(self) -> Dict[str, Any]:
            """Get statistics about block finalization."""
            try:
                total_finalized = len(self.finalized_blocks)
                if total_finalized == 0:
                    return {
                        "total_finalized": 0,
                        "average_time_to_finalize": 0,
                        "pending_finalizations": len(self.pending_finalization)
                    }
                
                # Calculate average time to finalize
                total_time = sum(
                    (status.finalization_time - status.first_confirmation_time).total_seconds()
                    for status in self.finalized_blocks.values()
                    if status.finalization_time and status.first_confirmation_time
                )
                
                return {
                    "total_finalized": total_finalized,
                    "average_time_to_finalize": total_time / total_finalized,
                    "pending_finalizations": len(self.pending_finalization),
                    "finalization_height": self.finalization_height,
                    "checkpoints": len(self.checkpoints),
                    "latest_checkpoint": max(self.checkpoints.keys(), default=0)
                }
                
            except Exception as e:
                logger.error(f"Error getting finalization stats: {str(e)}")
                return {}
```

# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/metrics_manager.py

```py
    """
    metrics_manager.py
    
    This module manages performance metrics and statistics for the Proof of Cooperation (PoC) consensus mechanism.
    It tracks validation success rates, block times, collusion detections, and other performance indicators.
    
    Classes:
        MetricsManager
    """
    
    import logging
    from typing import Dict, Optional, Any
    from datetime import datetime, timedelta
    from .types import ConsensusMetrics, ValidationResult, ValidatorHistory
    
    logger = logging.getLogger(__name__)
    
    class MetricsManager:
        """
        Manages performance metrics and statistics for the consensus mechanism.
        Tracks validation success rates, block times, and other performance indicators.
        """
    
        def __init__(self):
            """Initialize the metrics manager."""
            self.metrics = ConsensusMetrics()
            self.last_metrics_reset = datetime.now()
            self.reset_interval = timedelta(hours=24)
    
        def record_validation(self, result: ValidationResult, validator_id: str, shard_id: Optional[int] = None) -> None:
            """
            Record the result of a validation attempt.
    
            Args:
                result (ValidationResult): The validation result.
                validator_id (str): ID of the validator.
                shard_id (Optional[int]): Optional shard ID where validation occurred.
            """
            try:
                self.metrics.total_validations += 1
    
                if result.success:
                    self.metrics.successful_validations += 1
                else:
                    self.metrics.failed_validations += 1
    
                # Track per-validator metrics
                self.metrics.validator_counts[validator_id] = self.metrics.validator_counts.get(validator_id, 0) + 1
    
                # Track shard-specific metrics if applicable
                if shard_id is not None:
                    self._update_shard_metrics(result, validator_id, shard_id)
    
                # Add any custom metrics from the validation result
                self._update_custom_metrics(result.metrics)
    
            except Exception as e:
                logger.error(f"Failed to record validation metrics: {str(e)}")
    
        def _update_shard_metrics(self, result: ValidationResult, validator_id: str, shard_id: int) -> None:
            """
            Update shard-specific metrics.
    
            Args:
                result (ValidationResult): The validation result.
                validator_id (str): ID of the validator.
                shard_id (int): ID of the shard.
            """
            if shard_id not in self.metrics.shard_metrics:
                self.metrics.shard_metrics[shard_id] = {
                    "validations": 0,
                    "successful": 0,
                    "failed": 0,
                    "unique_validators": set()
                }
    
            shard_metrics = self.metrics.shard_metrics[shard_id]
            shard_metrics["validations"] += 1
    
            if result.success:
                shard_metrics["successful"] += 1
            else:
                shard_metrics["failed"] += 1
    
            shard_metrics["unique_validators"].add(validator_id)
    
        def record_block_time(self, block_time: float) -> None:
            """
            Record the time taken to create a block.
    
            Args:
                block_time (float): Time in seconds to create the block.
            """
            try:
                current_avg = self.metrics.average_block_time
                total_blocks = self.metrics.total_blocks_validated
    
                # Update running average
                self.metrics.average_block_time = (
                    (current_avg * total_blocks + block_time) / (total_blocks + 1)
                )
                self.metrics.total_blocks_validated += 1
    
            except Exception as e:
                logger.error(f"Failed to record block time: {str(e)}")
    
        def record_collusion_detection(self) -> None:
            """Record a collusion detection event."""
            self.metrics.collusion_detections += 1
    
        def record_new_node_participation(self) -> None:
            """Record participation by a new node."""
            self.metrics.new_node_participations += 1
    
        def get_validator_performance(self, validator_id: str) -> Dict[str, Any]:
            """
            Get performance metrics for a specific validator.
    
            Args:
                validator_id (str): ID of the validator.
    
            Returns:
                Dict[str, Any]: Validator's performance metrics.
            """
            try:
                total_validations = self.metrics.validator_counts.get(validator_id, 0)
                if total_validations == 0:
                    return {
                        "total_validations": 0,
                        "success_rate": 0.0,
                        "shard_participation": {}
                    }
    
                validator_successes = sum(
                    1 for shard in self.metrics.shard_metrics.values()
                    if validator_id in shard["unique_validators"] and shard["successful"] > 0
                )
                success_rate = validator_successes / total_validations
    
                shard_participation = {
                    shard_id: {
                        "validations": metrics["validations"],
                        "success_rate": (
                            metrics["successful"] / metrics["validations"]
                            if metrics["validations"] > 0 else 0.0
                        )
                    }
                    for shard_id, metrics in self.metrics.shard_metrics.items()
                    if validator_id in metrics["unique_validators"]
                }
    
                return {
                    "total_validations": total_validations,
                    "success_rate": success_rate,
                    "shard_participation": shard_participation
                }
    
            except Exception as e:
                logger.error(f"Failed to get validator performance: {str(e)}")
                return {"error": str(e)}
    
        def get_shard_metrics(self, shard_id: int) -> Dict[str, Any]:
            """
            Get metrics for a specific shard.
    
            Args:
                shard_id (int): ID of the shard.
    
            Returns:
                Dict[str, Any]: Shard metrics.
            """
            try:
                if shard_id not in self.metrics.shard_metrics:
                    return {
                        "validations": 0,
                        "successful": 0,
                        "failed": 0,
                        "validator_count": 0,
                        "success_rate": 0.0
                    }
    
                metrics = self.metrics.shard_metrics[shard_id]
                total = metrics["validations"]
    
                return {
                    "validations": total,
                    "successful": metrics["successful"],
                    "failed": metrics["failed"],
                    "validator_count": len(metrics["unique_validators"]),
                    "success_rate": metrics["successful"] / total if total > 0 else 0.0
                }
    
            except Exception as e:
                logger.error(f"Failed to get shard metrics: {str(e)}")
                return {"error": str(e)}
    
        def get_all_metrics(self) -> Dict[str, Any]:
            """
            Get all consensus metrics.
    
            Returns:
                Dict[str, Any]: All metrics.
            """
            try:
                total_validations = self.metrics.total_validations
                return {
                    "total_validations": total_validations,
                    "successful_validations": self.metrics.successful_validations,
                    "failed_validations": self.metrics.failed_validations,
                    "success_rate": (
                        self.metrics.successful_validations / total_validations
                        if total_validations > 0 else 0.0
                    ),
                    "average_block_time": self.metrics.average_block_time,
                    "collusion_detections": self.metrics.collusion_detections,
                    "new_node_participations": self.metrics.new_node_participations,
                    "total_blocks_validated": self.metrics.total_blocks_validated,
                    "active_validators": len(self.metrics.validator_counts),
                    "shard_metrics": {
                        shard_id: self.get_shard_metrics(shard_id)
                        for shard_id in self.metrics.shard_metrics
                    }
                }
    
            except Exception as e:
                logger.error(f"Failed to get all metrics: {str(e)}")
                return {"error": str(e)}
    
        def _update_custom_metrics(self, custom_metrics: Dict[str, Any]) -> None:
            """
            Update metrics with custom values from validation results.
    
            Args:
                custom_metrics (Dict[str, Any]): Dictionary of custom metrics to update.
            """
            try:
                for key, value in custom_metrics.items():
                    if not hasattr(self.metrics, key):
                        setattr(self.metrics, key, value)
                    else:
                        current_value = getattr(self.metrics, key)
                        if isinstance(current_value, (int, float)):
                            setattr(self.metrics, key, current_value + value)
                        elif isinstance(current_value, dict):
                            current_value.update(value)
    
            except Exception as e:
                logger.error(f"Failed to update custom metrics: {str(e)}")
    
        def check_metrics_reset(self) -> None:
            """Check if metrics should be reset based on reset interval."""
            if datetime.now() - self.last_metrics_reset > self.reset_interval:
                self.metrics = ConsensusMetrics()
                self.last_metrics_reset = datetime.now()
    
        def to_dict(self) -> Dict[str, Any]:
            """Convert metrics manager state to dictionary."""
            return {
                "metrics": self.metrics.to_dict(),
                "last_reset": self.last_metrics_reset.isoformat(),
                "reset_interval_seconds": self.reset_interval.total_seconds()
            }
    
        @classmethod
        def from_dict(cls, data: Dict[str, Any]) -> 'MetricsManager':
            """Create metrics manager from dictionary data."""
            manager = cls()
            manager.metrics = ConsensusMetrics.from_dict(data["metrics"])
            manager.last_metrics_reset = datetime.fromisoformat(data["last_reset"])
            manager.reset_interval = timedelta(seconds=data["reset_interval_seconds"])
            return manager
```

# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/reputation_manager.py

```py
    """
    reputation_manager.py
    
    This module manages reputation scoring and calculations for the Proof of Cooperation (PoC) consensus mechanism.
    It handles all aspects of node reputation, including score calculation, decay, validation eligibility, 
    and updates to validation statistics.
    
    Classes:
        ReputationManager
    """
    
    from typing import Dict, List, Optional, Any
    from datetime import datetime, timedelta
    import logging
    import math
    from .types import ConsensusConfig, ValidationResult, ValidationStats
    from ..core.node import Node
    from .collusion_detector import CollusionDetector
    
    logger = logging.getLogger(__name__)
    
    class ReputationManager:
        """
        Manages reputation scoring and calculations for the consensus mechanism.
        Handles all aspects of node reputation, including score calculation,
        decay, dynamic adjustments, and validation eligibility.
        """
    
        def __init__(self, config: ConsensusConfig, collusion_detector: CollusionDetector):
            """
            Initialize the reputation manager.
    
            Args:
                config (ConsensusConfig): The consensus configuration parameters.
                collusion_detector (CollusionDetector): Instance of the collusion detector for integration.
            """
            self.config = config
            self.collusion_detector = collusion_detector
            self.node_stats: Dict[str, ValidationStats] = {}
            self.last_score_update: Dict[str, datetime] = {}
            self.score_cache: Dict[str, float] = {}
            self.cache_duration = timedelta(minutes=5)
    
        def calculate_cooperation_score(self, node: Node, shard_id: Optional[int] = None) -> float:
            """
            Calculate a node's cooperation score, considering various factors like diversity,
            consistency, performance, shard-specific behavior, time decay, and collusion risk.
    
            Args:
                node (Node): The node to calculate the score for.
                shard_id (Optional[int]): Optional shard ID for shard-specific scoring.
    
            Returns:
                float: The calculated cooperation score, adjusted by multiple factors.
            """
            try:
                cache_key = f"{node.node_id}:{shard_id or 'all'}"
                
                # Return cached score if it is still valid
                if cache_key in self.score_cache:
                    cache_time = self.last_score_update.get(cache_key)
                    if cache_time and datetime.now() - cache_time < self.cache_duration:
                        return self.score_cache[cache_key]
    
                # Calculate base reputation score
                base_score = sum(
                    score * self.config.reputation_weights.get(category, 1.0)
                    for category, score in node.reputation_scores.items()
                )
    
                # Calculate additional factors
                factors = [
                    self._calculate_diversity_factor(node),
                    self._calculate_consistency_factor(node),
                    self._calculate_performance_factor(node),
                    self._calculate_collusion_factor(node)
                ]
    
                if shard_id is not None:
                    factors.append(self._calculate_shard_factor(node, shard_id))
    
                # Apply factors to base score
                final_score = base_score
                for factor in factors:
                    final_score *= factor
    
                # Apply time decay
                time_factor = self._calculate_time_decay(node)
                final_score *= time_factor
    
                # Cache the calculated score
                self.score_cache[cache_key] = final_score
                self.last_score_update[cache_key] = datetime.now()
    
                return max(0.0, final_score)
    
            except Exception as e:
                logger.error(f"Error calculating cooperation score: {str(e)}")
                return 0.0
    
        def _calculate_collusion_factor(self, node: Node) -> float:
            """
            Calculate a collusion factor that reduces the score of nodes with high collusion risk.
    
            Args:
                node (Node): The node to calculate the collusion factor for.
    
            Returns:
                float: The calculated collusion factor.
            """
            try:
                risk_score = self.collusion_detector._calculate_risk_score(node)
                
                # Reduce the factor based on collusion risk
                if risk_score > 0.9:
                    return 0.2
                elif risk_score > 0.7:
                    return 0.5
                elif risk_score > 0.5:
                    return 0.7
    
                return 1.0  # No penalty for low-risk nodes
    
            except Exception as e:
                logger.error(f"Error calculating collusion factor: {str(e)}")
                return 0.5
    
        def _calculate_diversity_factor(self, node: Node) -> float:
            """
            Calculate a diversity factor based on a node's cooperative interactions. 
            It evaluates the variety of cooperatives the node interacts with, 
            favoring nodes that engage with diverse cooperatives.
    
            Args:
                node (Node): The node to calculate the diversity factor for.
    
            Returns:
                float: The calculated diversity factor.
            """
            try:
                recent_interactions = node.cooperative_interactions[-100:]
                if not recent_interactions:
                    return 1.0
    
                unique_coops = len(set(recent_interactions))
                total_interactions = len(recent_interactions)
                diversity_score = unique_coops / total_interactions
    
                if total_interactions >= 20:
                    if unique_coops >= 5:
                        return 1.0 + math.log(1 + diversity_score) * 1.5
                    return 1.0 + math.log(1 + diversity_score)
    
                return max(0.7, diversity_score)  # Minimum baseline for newer nodes
    
            except Exception as e:
                logger.error(f"Error calculating diversity factor: {str(e)}")
                return 0.7
    
        def _calculate_consistency_factor(self, node: Node) -> float:
            """
            Calculate a consistency factor based on the node's validation history.
            This factor rewards consistent performance over time.
    
            Args:
                node (Node): The node to calculate the consistency factor for.
    
            Returns:
                float: The calculated consistency factor.
            """
            try:
                if not node.validation_history:
                    return 1.0
    
                recent_validations = node.validation_history[-50:]
                successful = sum(
                    1 for v in recent_validations 
                    if v.get("evidence", {}).get("success", False)
                )
                success_rate = successful / len(recent_validations)
    
                if node.total_validations < 10:
                    min_rate = self.config.validation_thresholds["min_success_rate"] * 0.8
                else:
                    min_rate = self.config.validation_thresholds["min_success_rate"]
    
                if success_rate > 0.95:
                    return 1.8
                elif success_rate > 0.8:
                    return 1.5
                elif success_rate > min_rate:
                    return 1.0 + ((success_rate - min_rate) / (1 - min_rate))
    
                return max(0.5, success_rate / min_rate)
    
            except Exception as e:
                logger.error(f"Error calculating consistency factor: {str(e)}")
                return 0.5
    
        def _calculate_performance_factor(self, node: Node) -> float:
            """
            Calculate a performance factor based on node metrics such as availability, 
            validation success rate, and network reliability.
    
            Args:
                node (Node): The node to calculate the performance factor for.
    
            Returns:
                float: The calculated performance factor.
            """
            try:
                metrics = node.performance_metrics
                if not metrics:
                    return 1.0
    
                weights = {
                    "availability": 0.35,
                    "validation_success_rate": 0.35,
                    "network_reliability": 0.3
                }
    
                weighted_sum = sum(
                    (metrics.get(metric, 0) / 100) * weight
                    for metric, weight in weights.items()
                )
    
                if weighted_sum > 0.95:
                    return weighted_sum * 1.2
                elif weighted_sum > 0.9:
                    return weighted_sum * 1.1
    
                return max(
                    self.config.validation_thresholds["min_availability"],
                    weighted_sum
                )
    
            except Exception as e:
                logger.error(f"Error calculating performance factor: {str(e)}")
                return self.config.validation_thresholds["min_availability"]
    
        def _calculate_shard_factor(self, node: Node, shard_id: int) -> float:
            """
            Calculate a shard-specific factor that rewards experience and performance within a shard.
    
            Args:
                node (Node): The node to calculate the shard factor for.
                shard_id (int): The shard ID to calculate the factor for.
    
            Returns:
                float: The calculated shard factor.
            """
            try:
                if shard_id not in node.active_shards:
                    return 0.0
    
                time_in_shard = (datetime.now() - node.active_shards[shard_id]).total_seconds()
                experience = min(1.0, time_in_shard / (24 * 3600))
    
                stats = self.node_stats.get(node.node_id, ValidationStats())
                shard_stats = stats.shard_validations.get(shard_id, {})
    
                if shard_stats:
                    success_rate = (
                        shard_stats.get("successful", 0) /
                        max(1, shard_stats.get("selections", 1))
                    )
                else:
                    success_rate = 1.0
    
                if experience < 0.2:
                    return 0.7 + (0.3 * success_rate)
                else:
                    return 0.4 + (0.3 * experience) + (0.3 * success_rate)
    
            except Exception as e:
                logger.error(f"Error calculating shard factor: {str(e)}")
                return 0.5
    
        def _calculate_time_decay(self, node: Node) -> float:
            """
            Calculate a time-based decay factor that reduces the score of inactive nodes over time.
    
            Args:
                node (Node): The node to calculate the time decay for.
    
            Returns:
                float: The calculated time decay factor.
            """
            try:
                stats = self.node_stats.get(node.node_id)
                if not stats or not stats.last_validation:
                    return 1.0
    
                hours_inactive = (datetime.now() - stats.last_validation).total_seconds() / 3600
    
                if hours_inactive > 24:
                    return math.exp(-hours_inactive / 24)
    
                return 1.0
    
            except Exception as e:
                logger.error(f"Error calculating time decay: {str(e)}")
                return 1.0
    
        def can_validate(self, node: Node, shard_id: Optional[int] = None) -> bool:
            """
            Determine if a node is eligible to participate in validation, considering reputation,
            validation history, and specific shard requirements.
    
            Args:
                node (Node): The node to check eligibility for.
                shard_id (Optional[int]): Optional shard ID for shard-specific validation.
    
            Returns:
                bool: True if the node is eligible for validation, False otherwise.
            """
            try:
                # Handle new nodes
                if node.total_validations < 5:
                    return (
                        node.can_validate(shard_id) and
                        node.get_total_reputation() >= 
                        self.config.min_reputation * 
                        self.config.validation_thresholds["new_node_reputation_factor"]
                    )
    
                # Standard validation checks
                if not node.can_validate(shard_id):
                    return False
    
                # Calculate reputation requirement
                total_reputation = node.get_total_reputation()
                reputation_requirement = self.config.min_reputation
    
                # Adjust reputation requirement based on experience
                if node.total_validations > 20:
                    reputation_requirement *= 1.2
                elif node.total_validations > 10:
                    reputation_requirement *= 1.0
                else:
                    reputation_requirement *= 0.7
    
                if total_reputation < reputation_requirement:
                    return False
    
                # Check recent performance
                stats = self.node_stats.get(node.node_id, ValidationStats())
                if stats.selections > 0:
                    recent_success_rate = stats.successful_validations / stats.selections
                    if (
                        recent_success_rate < self.config.validation_thresholds["min_success_rate"] and
                        node.total_validations > 10
                    ):
                        return False
    
                return True
    
            except Exception as e:
                logger.error(f"Error checking validation eligibility: {str(e)}")
                return False
    
        def update_stats(self, node_id: str, result: ValidationResult, shard_id: Optional[int] = None) -> None:
            """
            Update validation statistics for a node based on the result of a validation attempt.
    
            Args:
                node_id (str): ID of the node to update.
                result (ValidationResult): The validation result.
                shard_id (Optional[int]): Optional shard ID where validation occurred.
            """
            try:
                if node_id not in self.node_stats:
                    self.node_stats[node_id] = ValidationStats()
    
                stats = self.node_stats[node_id]
                stats.selections += 1
                stats.last_validation = datetime.now()
    
                if result.success:
                    stats.successful_validations += 1
                    stats.consecutive_failures = 0
                else:
                    stats.consecutive_failures += 1
    
                if shard_id is not None:
                    if shard_id not in stats.shard_validations:
                        stats.shard_validations[shard_id] = {
                            "selections": 0,
                            "successful": 0
                        }
                    
                    shard_stats = stats.shard_validations[shard_id]
                    shard_stats["selections"] += 1
                    if result.success:
                        shard_stats["successful"] += 1
    
            except Exception as e:
                logger.error(f"Error updating validation stats: {str(e)}")
    
        def get_node_stats(self, node_id: str) -> Optional[ValidationStats]:
            """
            Retrieve validation statistics for a node.
    
            Args:
                node_id (str): ID of the node to retrieve statistics for.
    
            Returns:
                Optional[ValidationStats]: The node's validation stats if found, None otherwise.
            """
            return self.node_stats.get(node_id)
    
        def to_dict(self) -> Dict[str, Any]:
            """
            Convert the reputation manager's state to a dictionary for serialization.
    
            Returns:
                Dict[str, Any]: Dictionary representation of the reputation manager's state.
            """
            return {
                "node_stats": {
                    node_id: {
                        "selections": stats.selections,
                        "successful_validations": stats.successful_validations,
                        "consecutive_failures": stats.consecutive_failures,
                        "last_validation": stats.last_validation.isoformat() if stats.last_validation else None,
                        "shard_validations": stats.shard_validations
                    }
                    for node_id, stats in self.node_stats.items()
                },
                "score_cache": self.score_cache,
                "last_score_update": {
                    k: v.isoformat() 
                    for k, v in self.last_score_update.items()
                }
            }
    
        @classmethod
        def from_dict(cls, data: Dict[str, Any], config: ConsensusConfig, collusion_detector: CollusionDetector) -> 'ReputationManager':
            """
            Create a reputation manager instance from a dictionary of data.
    
            Args:
                data (Dict[str, Any]): The dictionary data to initialize from.
                config (ConsensusConfig): The consensus configuration parameters.
                collusion_detector (CollusionDetector): Instance of the collusion detector.
    
            Returns:
                ReputationManager: A new instance of ReputationManager.
            """
            manager = cls(config, collusion_detector)
    
            # Restore node stats
            for node_id, stats_data in data["node_stats"].items():
                stats = ValidationStats()
                stats.selections = stats_data["selections"]
                stats.successful_validations = stats_data["successful_validations"]
                stats.consecutive_failures = stats_data["consecutive_failures"]
                if stats_data["last_validation"]:
                    stats.last_validation = datetime.fromisoformat(stats_data["last_validation"])
                stats.shard_validations = stats_data["shard_validations"]
                manager.node_stats[node_id] = stats
    
            # Restore score cache and update times
            manager.score_cache = data["score_cache"]
            manager.last_score_update = {
                k: datetime.fromisoformat(v)
                for k, v in data["last_score_update"].items()
            }
    
            return manager
```

# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/validator_manager.py

```py
    """
    validator_manager.py
    
    This module manages validators within the Proof of Cooperation (PoC) consensus mechanism.
    It handles validator selection, state management, and integration with the reputation system.
    
    Classes:
        ValidatorManager
    """
    
    from typing import List, Optional
    from datetime import datetime, timedelta
    from .types import Node, Shard
    from .collusion_detector import CollusionDetector
    
    class ValidatorManager:
        """
        The ValidatorManager is responsible for managing validators within the PoC mechanism.
        
        Key Responsibilities:
        - Selecting eligible validators for block validation.
        - Tracking validator states, including reputation, performance, and cooldown periods.
        - Integrating with the shard management system to ensure validator availability per shard.
        - Enforcing reputation requirements and cooldown periods for fair participation.
        - Coordinating with collusion detection for enhanced security and fairness.
        """
        
        def __init__(self, min_reputation: float, cooldown_blocks: int, collusion_detector: CollusionDetector):
            """
            Initialize the ValidatorManager with minimum reputation, cooldown settings, and collusion detection.
            
            Args:
                min_reputation (float): Minimum reputation required for validators.
                cooldown_blocks (int): Number of blocks a validator must wait after validation.
                collusion_detector (CollusionDetector): Instance of the collusion detector for integration.
            """
            self.min_reputation = min_reputation
            self.cooldown_blocks = cooldown_blocks
            self.collusion_detector = collusion_detector
            self.validator_history: List[tuple] = []  # Stores tuples of (validator_id, timestamp, shard_id)
    
        def select_validator(self, nodes: List[Node], shard_id: Optional[int] = None) -> Optional[Node]:
            """
            Select an eligible validator from the provided list of nodes.
    
            Selection Criteria:
            - Node must have reputation above the minimum threshold.
            - Node must not be in cooldown.
            - Node must be able to validate the specified shard, if shard_id is provided.
            - Nodes with higher reputation, cooperative interactions, and better performance are prioritized.
            - Nodes with lower collusion risk are prioritized.
    
            Args:
                nodes (List[Node]): List of nodes to select from.
                shard_id (Optional[int]): Shard ID for which a validator is needed.
            
            Returns:
                Optional[Node]: The selected validator node, or None if no eligible validator is found.
            """
            # Filter eligible nodes based on eligibility and collusion risk
            eligible_nodes = [node for node in nodes if self._is_eligible(node, shard_id) and not self._is_high_risk(node)]
            if not eligible_nodes:
                return None
    
            # Sort nodes by priority score
            eligible_nodes.sort(key=self._calculate_priority_score, reverse=True)
    
            # Select the top candidate
            selected_validator = eligible_nodes[0]
            self._enforce_validator_selection(selected_validator, shard_id)
            return selected_validator
    
        def _is_eligible(self, node: Node, shard_id: Optional[int]) -> bool:
            """
            Check if a node is eligible to be a validator based on reputation, cooldown, and shard assignment.
            
            Args:
                node (Node): Node to check eligibility for.
                shard_id (Optional[int]): Shard ID to validate eligibility against.
    
            Returns:
                bool: True if the node is eligible, False otherwise.
            """
            if node.reputation < self.min_reputation or node.cooldown > 0:
                return False
            if shard_id is not None and not node.can_validate(shard_id):
                return False
            return True
    
        def _is_high_risk(self, node: Node) -> bool:
            """
            Check if a node is considered high-risk for collusion based on its risk score from the collusion detector.
    
            Args:
                node (Node): Node to check for collusion risk.
    
            Returns:
                bool: True if the node is high-risk, False otherwise.
            """
            risk_score = self.collusion_detector._calculate_risk_score(node)
            return risk_score > 0.8
    
        def _calculate_priority_score(self, node: Node) -> float:
            """
            Calculate a priority score for selecting validators based on multiple factors.
    
            The score is calculated using:
            - Reputation
            - Number of cooperative interactions
            - Performance metrics (e.g., availability, validation success rate)
            - Inverse collusion risk score
    
            Args:
                node (Node): Node to calculate the priority score for.
    
            Returns:
                float: Calculated priority score.
            """
            # Weights for different factors in the priority score calculation
            reputation_weight = 0.5
            interaction_weight = 0.2
            performance_weight = 0.2
            collusion_weight = 0.1
    
            collusion_risk = self.collusion_detector._calculate_risk_score(node)
            collusion_penalty = (1 - collusion_risk) * collusion_weight
    
            score = (
                node.reputation * reputation_weight +
                len(node.cooperative_interactions) * interaction_weight +
                node.performance_metrics.get('validation_success_rate', 0) * performance_weight +
                collusion_penalty
            )
            return score
    
        def _enforce_validator_selection(self, node: Node, shard_id: Optional[int]) -> None:
            """
            Enforce validator selection, including cooldown, reputation updates, and tracking.
    
            Args:
                node (Node): The selected validator node.
                shard_id (Optional[int]): The shard ID for which the node was selected as a validator.
            """
            node.enter_cooldown(self.cooldown_blocks)
            self._track_validator_history(node, shard_id)
    
        def _track_validator_history(self, node: Node, shard_id: Optional[int]) -> None:
            """
            Track the history of validators for auditing and performance analysis.
    
            Args:
                node (Node): The validator node.
                shard_id (Optional[int]): The shard ID for which the node was selected as a validator.
            """
            self.validator_history.append((node.node_id, datetime.now(), shard_id))
            
            # Maintain a capped history size for memory efficiency
            max_history_length = 1000
            if len(self.validator_history) > max_history_length:
                self.validator_history.pop(0)
    
        def update_validator_reputation(self, node: Node, reputation_delta: float) -> None:
            """
            Update the reputation of a validator node by a specified amount.
    
            Args:
                node (Node): The validator node to update.
                reputation_delta (float): The amount to add or subtract from the node's reputation.
            """
            node.reputation += reputation_delta
            node.reputation = max(0.0, node.reputation)  # Ensure reputation does not fall below zero
    
        def enforce_cooldown(self, node: Node) -> None:
            """
            Enforce cooldown for a validator node after a validation cycle.
    
            This method increases the cooldown period for the node to prevent consecutive validations.
    
            Args:
                node (Node): The validator node to enforce cooldown on.
            """
            node.cooldown = self.cooldown_blocks
    
        def release_cooldown(self) -> None:
            """
            Release cooldowns for all validators that have completed their cooldown period.
    
            This method iterates through nodes and decreases their cooldown by one block,
            allowing them to rejoin validation once their cooldown reaches zero.
            """
            for node in self._get_all_nodes():
                if node.cooldown > 0:
                    node.cooldown -= 1
    
        def get_validator_history(self, limit: int = 100) -> List[tuple]:
            """
            Retrieve the recent history of validators, useful for auditing and analysis.
    
            Args:
                limit (int): Maximum number of records to return (default is 100).
    
            Returns:
                List[tuple]: A list of tuples containing validator history records.
            """
            return self.validator_history[-limit:]
    
        def get_active_validators(self) -> List[str]:
            """
            Retrieve a list of active validators based on their current state.
    
            Returns:
                List[str]: A list of node IDs representing active validators.
            """
            return [record[0] for record in self.validator_history if record[1] > datetime.now() - timedelta(hours=1)]
    
        def _get_all_nodes(self) -> List[Node]:
            """
            Placeholder method to retrieve all nodes in the network.
    
            This method should be replaced with actual logic to fetch nodes from the broader PoC network.
    
            Returns:
                List[Node]: List of all nodes (currently returns an empty list).
            """
            return []
```

# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/types.py

```py
    """
    types.py
    
    This module defines data structures and types used within the Proof of Cooperation (PoC) consensus mechanism.
    It includes configuration settings, validation results, metrics tracking, and the overall state of the consensus.
    
    Classes:
        ConsensusConfig
        ValidationResult
        ValidatorHistory
        ValidationStats
        ConsensusMetrics
        ConsensusState
    """
    
    from dataclasses import dataclass, field
    from typing import Dict, List, Optional, Set, Any
    from datetime import datetime
    
    @dataclass
    class ConsensusConfig:
        """
        Configuration parameters for the PoC consensus mechanism.
    
        Attributes:
            min_reputation (float): Minimum reputation required for validation eligibility.
            cooldown_blocks (int): Number of blocks a validator must wait during cooldown.
            reputation_decay_factor (float): Rate at which reputation decays over time.
            collusion_threshold (float): Threshold for detecting collusion among validators.
            reputation_weights (Dict[str, float]): Weights for different reputation categories.
            validation_thresholds (Dict[str, float]): Thresholds for validation metrics.
        """
        min_reputation: float = 10.0
        cooldown_blocks: int = 3
        reputation_decay_factor: float = 0.95
        collusion_threshold: float = 0.75
        
        reputation_weights: Dict[str, float] = field(default_factory=lambda: {
            "cooperative_growth": 1.5,
            "proposal_participation": 1.2,
            "transaction_validation": 1.3,
            "resource_sharing": 1.3,
            "conflict_resolution": 1.1,
            "community_building": 1.2,
            "sustainability": 1.2,
            "innovation": 1.3,
            "network_stability": 1.4,
            "data_availability": 1.2,
        })
        
        validation_thresholds: Dict[str, float] = field(default_factory=lambda: {
            "min_participation": 0.05,
            "min_success_rate": 0.4,
            "min_availability": 0.6,
            "max_consecutive_validations": 3,
            "new_node_reputation_factor": 0.3,
            "min_interactions": 3,
        })
    
    @dataclass
    class ValidationResult:
        """
        Represents the result of a validation operation.
    
        Attributes:
            success (bool): Indicates whether the validation was successful.
            reason (Optional[str]): Reason for failure, if applicable.
            metrics (Dict[str, Any]): Additional metrics related to the validation.
        """
        success: bool
        reason: Optional[str] = None
        metrics: Dict[str, Any] = field(default_factory=dict)
    
    @dataclass
    class ValidatorHistory:
        """
        Tracks the activity of a validator within the PoC network.
    
        Attributes:
            node_id (str): Identifier of the validator node.
            timestamp (datetime): Time of the validation event.
            shard_id (Optional[int]): Shard ID where validation occurred.
            success (bool): Indicates whether the validation was successful.
            metrics (Dict[str, Any]): Additional metrics related to the validation event.
        """
        node_id: str
        timestamp: datetime
        shard_id: Optional[int]
        success: bool = True
        metrics: Dict[str, Any] = field(default_factory=dict)
    
    @dataclass
    class ValidationStats:
        """
        Tracks validation statistics for individual nodes.
    
        Attributes:
            selections (int): Number of times the node was selected for validation.
            successful_validations (int): Number of successful validations.
            consecutive_failures (int): Number of consecutive failed validations.
            last_validation (Optional[datetime]): Timestamp of the last validation.
            shard_validations (Dict[int, Dict[str, Any]]): Shard-specific validation metrics.
        """
        selections: int = 0
        successful_validations: int = 0
        consecutive_failures: int = 0
        last_validation: Optional[datetime] = None
        shard_validations: Dict[int, Dict[str, Any]] = field(default_factory=dict)
    
    @dataclass
    class ConsensusMetrics:
        """
        Tracks metrics related to the PoC consensus mechanism.
    
        Attributes:
            total_validations (int): Total number of validations performed.
            successful_validations (int): Total number of successful validations.
            failed_validations (int): Total number of failed validations.
            collusion_detections (int): Number of detected collusion events.
            total_blocks_validated (int): Total number of blocks validated.
            new_node_participations (int): Number of participations by new nodes.
            average_block_time (float): Average time taken to validate blocks.
            validator_counts (Dict[str, int]): Number of validations per validator.
            shard_metrics (Dict[int, Dict[str, Any]]): Shard-specific metrics.
        """
        total_validations: int = 0
        successful_validations: int = 0
        failed_validations: int = 0
        collusion_detections: int = 0
        total_blocks_validated: int = 0
        new_node_participations: int = 0
        average_block_time: float = 0.0
        validator_counts: Dict[str, int] = field(default_factory=dict)
        shard_metrics: Dict[int, Dict[str, Any]] = field(default_factory=dict)
    
        def to_dict(self) -> Dict[str, Any]:
            """
            Convert metrics to dictionary format.
    
            Returns:
                Dict[str, Any]: Dictionary representation of the metrics.
            """
            return {
                "total_validations": self.total_validations,
                "successful_validations": self.successful_validations,
                "failed_validations": self.failed_validations,
                "collusion_detections": self.collusion_detections,
                "total_blocks_validated": self.total_blocks_validated,
                "new_node_participations": self.new_node_participations,
                "average_block_time": self.average_block_time,
                "validator_counts": self.validator_counts.copy(),
                "shard_metrics": {
                    shard_id: metrics.copy() 
                    for shard_id, metrics in self.shard_metrics.items()
                }
            }
    
        @classmethod
        def from_dict(cls, data: Dict[str, Any]) -> 'ConsensusMetrics':
            """
            Create ConsensusMetrics from dictionary data.
    
            Args:
                data (Dict[str, Any]): Dictionary containing metrics data.
    
            Returns:
                ConsensusMetrics: An instance of ConsensusMetrics populated with the provided data.
            """
            metrics = cls()
            metrics.total_validations = data.get("total_validations", 0)
            metrics.successful_validations = data.get("successful_validations", 0)
            metrics.failed_validations = data.get("failed_validations", 0)
            metrics.collusion_detections = data.get("collusion_detections", 0)
            metrics.total_blocks_validated = data.get("total_blocks_validated", 0)
            metrics.new_node_participations = data.get("new_node_participations", 0)
            metrics.average_block_time = data.get("average_block_time", 0.0)
            metrics.validator_counts = data.get("validator_counts", {}).copy()
            metrics.shard_metrics = data.get("shard_metrics", {}).copy()
            return metrics
    
    @dataclass
    class ConsensusState:
        """
        Represents the current state of the PoC consensus mechanism.
    
        Attributes:
            config (ConsensusConfig): Configuration parameters of the consensus.
            metrics (ConsensusMetrics): Metrics tracking consensus operations.
            validator_history (List[ValidatorHistory]): History of validator activities.
            validation_stats (Dict[str, ValidationStats]): Validation statistics by node.
            active_validators (Set[str]): Set of currently active validators.
        """
        config: ConsensusConfig
        metrics: ConsensusMetrics = field(default_factory=ConsensusMetrics)
        validator_history: List[ValidatorHistory] = field(default_factory=list)
        validation_stats: Dict[str, ValidationStats] = field(default_factory=dict)
        active_validators: Set[str] = field(default_factory=set)
    
        def to_dict(self) -> Dict[str, Any]:
            """
            Convert state to dictionary format.
    
            Returns:
                Dict[str, Any]: Dictionary representation of the consensus state.
            """
            return {
                "config": {
                    "min_reputation": self.config.min_reputation,
                    "cooldown_blocks": self.config.cooldown_blocks,
                    "reputation_decay_factor": self.config.reputation_decay_factor,
                    "collusion_threshold": self.config.collusion_threshold,
                    "reputation_weights": self.config.reputation_weights.copy(),
                    "validation_thresholds": self.config.validation_thresholds.copy()
                },
                "metrics": self.metrics.to_dict(),
                "validator_history": [
                    {
                        "node_id": h.node_id,
                        "timestamp": h.timestamp.isoformat(),
                        "shard_id": h.shard_id,
                        "success": h.success,
                        "metrics": h.metrics.copy()
                    }
                    for h in self.validator_history
                ],
                "validation_stats": {
                    node_id: {
                        "selections": stats.selections,
                        "successful_validations": stats.successful_validations,
                        "consecutive_failures": stats.consecutive_failures,
                        "last_validation": stats.last_validation.isoformat() if stats.last_validation else None,
                        "shard_validations": stats.shard_validations.copy()
                    }
                    for node_id, stats in self.validation_stats.items()
                },
                "active_validators": list(self.active_validators)
            }
    
        @classmethod
        def from_dict(cls, data: Dict[str, Any]) -> 'ConsensusState':
            """
            Create ConsensusState from dictionary data.
    
            Args:
                data (Dict[str, Any]): Dictionary containing consensus state data.
    
            Returns:
                ConsensusState: An instance of ConsensusState populated with the provided data.
            """
            config = ConsensusConfig(
                min_reputation=data["config"]["min_reputation"],
                cooldown_blocks=data["config"]["cooldown_blocks"],
                reputation_decay_factor=data["config"]["reputation_decay_factor"],
                collusion_threshold=data["config"]["collusion_threshold"]
            )
            config.reputation_weights = data["config"]["reputation_weights"].copy()
            config.validation_thresholds = data["config"]["validation_thresholds"].copy()
    
            metrics = ConsensusMetrics.from_dict(data["metrics"])
    
            validator_history = [
                ValidatorHistory(
                    node_id=h["node_id"],
                    timestamp=datetime.fromisoformat(h["timestamp"]),
                    shard_id=h["shard_id"],
                    success=h["success"],
                    metrics=h["metrics"].copy()
                )
                for h in data["validator_history"]
            ]
    
            validation_stats = {
                node_id: ValidationStats(
                    selections=stats["selections"],
                    successful_validations=stats["successful_validations"],
                    consecutive_failures=stats["consecutive_failures"],
                    last_validation=datetime.fromisoformat(stats["last_validation"]) if stats["last_validation"] else None,
                    shard_validations=stats["shard_validations"].copy()
                )
                for node_id, stats in data["validation_stats"].items()
            }
    
            active_validators = set(data["active_validators"])
    
            return cls(
                config=config,
                metrics=metrics,
                validator_history=validator_history,
                validation_stats=validation_stats,
                active_validators=active_validators
            )
```

# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/sanctions_manager.py

```py
    """
    sanctions_manager.py
    
    This module manages sanctions and recovery for validators in the Proof of Cooperation (PoC) consensus mechanism.
    It handles tiered penalties, escalated sanctions, and reputation recovery, and allows for integration 
    with governance for handling disputes and appeals.
    
    Classes:
        SanctionsManager
    """
    
    from typing import Dict, List, Optional, Tuple
    from datetime import datetime, timedelta
    import logging
    from .types import Node
    from .collusion_detector import CollusionDetector
    from .reputation_manager import ReputationManager
    
    logger = logging.getLogger(__name__)
    
    class SanctionsManager:
        """
        Manages sanctions and recovery for validators within the PoC mechanism.
        
        Key Responsibilities:
        - Enforcing tiered sanctions based on collusion risk and frequency of offenses.
        - Allowing validators to recover from penalties through positive behavior.
        - Providing integration points for governance to handle disputes and appeals.
        """
    
        def __init__(self, collusion_detector: CollusionDetector, reputation_manager: ReputationManager, max_sanction_level: int = 3, recovery_period: int = 7):
            """
            Initialize the SanctionsManager with collusion detection and reputation management integration.
    
            Args:
                collusion_detector (CollusionDetector): Instance of the collusion detector for integration.
                reputation_manager (ReputationManager): Instance of the reputation manager for integration.
                max_sanction_level (int): Maximum level of sanctions before permanent exclusion (default is 3).
                recovery_period (int): Number of days required for a validator to demonstrate positive behavior for recovery.
            """
            self.collusion_detector = collusion_detector
            self.reputation_manager = reputation_manager
            self.max_sanction_level = max_sanction_level
            self.recovery_period = timedelta(days=recovery_period)
            self.sanctions: Dict[str, int] = {}  # Maps validator IDs to sanction levels
            self.recovery_timers: Dict[str, datetime] = {}  # Maps validator IDs to recovery start times
    
        def apply_sanction(self, node: Node) -> None:
            """
            Apply a sanction to a validator based on collusion detection outcomes.
    
            Args:
                node (Node): The validator node to sanction.
            """
            validator_id = node.node_id
    
            # Increase sanction level for the validator
            current_sanction_level = self.sanctions.get(validator_id, 0) + 1
            self.sanctions[validator_id] = min(current_sanction_level, self.max_sanction_level)
    
            # Apply reputation slashing based on sanction level
            reputation_penalty = self._calculate_reputation_penalty(current_sanction_level)
            self.reputation_manager.update_validator_reputation(node, -reputation_penalty)
    
            # Start or reset the recovery timer
            self.recovery_timers[validator_id] = datetime.now()
    
            # Log the sanction
            logger.info(f"Sanction applied to validator {validator_id}: Level {current_sanction_level}, Reputation penalty: {reputation_penalty}")
    
            # If maximum sanction level reached, consider permanent exclusion
            if current_sanction_level >= self.max_sanction_level:
                self._handle_permanent_exclusion(node)
    
        def _calculate_reputation_penalty(self, sanction_level: int) -> float:
            """
            Calculate the reputation penalty based on the current sanction level.
    
            Args:
                sanction_level (int): The level of the sanction.
    
            Returns:
                float: The reputation penalty to apply.
            """
            base_penalty = 5.0  # Base penalty for the first level of sanctions
            penalty_multiplier = 1.5  # Multiplier for each additional level
            return base_penalty * (penalty_multiplier ** (sanction_level - 1))
    
        def _handle_permanent_exclusion(self, node: Node) -> None:
            """
            Handle permanent exclusion for a validator that has reached the maximum sanction level.
    
            Args:
                node (Node): The validator node to exclude.
            """
            validator_id = node.node_id
    
            # Mark the validator as permanently excluded
            node.metadata["status"] = "permanently_excluded"
            node.reputation = 0.0  # Set reputation to zero
            node.cooldown = float('inf')  # Indefinite cooldown
    
            # Log the permanent exclusion
            logger.warning(f"Validator {validator_id} has been permanently excluded from the network.")
    
        def evaluate_recovery(self, node: Node) -> bool:
            """
            Evaluate if a validator is eligible for recovery based on positive behavior.
    
            Args:
                node (Node): The validator node to evaluate.
    
            Returns:
                bool: True if recovery is successful, False otherwise.
            """
            validator_id = node.node_id
            last_recovery_start = self.recovery_timers.get(validator_id)
    
            # Check if the validator has demonstrated positive behavior over the recovery period
            if last_recovery_start and datetime.now() - last_recovery_start >= self.recovery_period:
                if self._is_behavior_positive(node):
                    self._recover_validator(node)
                    return True
    
            return False
    
        def _is_behavior_positive(self, node: Node) -> bool:
            """
            Check if a validator's recent behavior is positive, warranting recovery.
    
            Criteria:
            - No new collusion detections.
            - Successful validation rate above the minimum threshold.
    
            Args:
                node (Node): The validator node to check.
    
            Returns:
                bool: True if behavior is positive, False otherwise.
            """
            risk_score = self.collusion_detector._calculate_risk_score(node)
            if risk_score > 0.5:
                return False  # High collusion risk disqualifies recovery
    
            recent_validations = node.validation_history[-50:]
            successful_validations = sum(1 for v in recent_validations if v.get("evidence", {}).get("success", False))
            success_rate = successful_validations / len(recent_validations) if recent_validations else 0
    
            return success_rate >= self.reputation_manager.config.validation_thresholds["min_success_rate"]
    
        def _recover_validator(self, node: Node) -> None:
            """
            Recover a validator from sanctions, reducing the sanction level and restoring reputation.
    
            Args:
                node (Node): The validator node to recover.
            """
            validator_id = node.node_id
    
            # Decrease the sanction level and restore reputation
            current_sanction_level = self.sanctions.get(validator_id, 0)
            if current_sanction_level > 0:
                self.sanctions[validator_id] = current_sanction_level - 1
    
            # Restore reputation based on recovery
            recovery_bonus = self._calculate_recovery_bonus(current_sanction_level)
            self.reputation_manager.update_validator_reputation(node, recovery_bonus)
    
            # Reset recovery timer
            self.recovery_timers[validator_id] = datetime.now()
    
            # Log the recovery
            logger.info(f"Validator {validator_id} has recovered: Sanction level decreased to {current_sanction_level - 1}, Reputation bonus: {recovery_bonus}")
    
        def _calculate_recovery_bonus(self, sanction_level: int) -> float:
            """
            Calculate the reputation bonus for recovering from sanctions.
    
            Args:
                sanction_level (int): The level of the sanction being recovered from.
    
            Returns:
                float: The reputation bonus to apply.
            """
            base_bonus = 3.0  # Base bonus for the first level of recovery
            bonus_multiplier = 1.2  # Multiplier for each level of recovery
            return base_bonus * (bonus_multiplier ** sanction_level)
    
        def get_sanction_status(self, node: Node) -> Tuple[int, str]:
            """
            Get the current sanction status of a validator, including level and status.
    
            Args:
                node (Node): The validator node to check.
    
            Returns:
                Tuple[int, str]: A tuple containing the sanction level and status.
            """
            validator_id = node.node_id
            sanction_level = self.sanctions.get(validator_id, 0)
            status = node.metadata.get("status", "active")
    
            return sanction_level, status
    
        def handle_dispute(self, node: Node) -> None:
            """
            Handle disputes regarding sanctions, allowing validators to appeal their penalties 
            through governance mechanisms.
    
            Args:
                node (Node): The validator node appealing the sanction.
            """
            validator_id = node.node_id
            # Placeholder for governance-based dispute resolution
            logger.info(f"Validator {validator_id} has initiated a dispute against sanctions.")
            # Future implementation: Integrate with governance for proposals and voting on appeals
    
        def to_dict(self) -> Dict[str, Any]:
            """
            Convert the sanctions manager's state to a dictionary for serialization.
    
            Returns:
                Dict[str, Any]: Dictionary representation of the sanctions manager's state.
            """
            return {
                "sanctions": self.sanctions,
                "recovery_timers": {k: v.isoformat() for k, v in self.recovery_timers.items()}
            }
    
        @classmethod
        def from_dict(cls, data: Dict[str, Any], collusion_detector: CollusionDetector, reputation_manager: ReputationManager) -> 'SanctionsManager':
            """
            Create a sanctions manager instance from a dictionary of data.
    
            Args:
                data (Dict[str, Any]): The dictionary data to initialize from.
                collusion_detector (CollusionDetector): Instance of the collusion detector.
                reputation_manager (ReputationManager): Instance of the reputation manager.
    
            Returns:
                SanctionsManager: A new instance of SanctionsManager.
            """
            manager = cls(collusion_detector, reputation_manager)
    
            # Restore sanctions and recovery timers
            manager.sanctions = data.get("sanctions", {})
            manager.recovery_timers = {k: datetime.fromisoformat(v) for k, v in data.get("recovery_timers", {}).items()}
    
            return manager
```

# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/collusion_detector.py

```py
    """
    collusion_detector.py
    
    This module detects collusion among validators and participants in the Proof of Cooperation (PoC) consensus mechanism.
    It identifies patterns that may indicate fraudulent behavior or attempts to manipulate the consensus process.
    
    Classes:
        CollusionDetector
    """
    
    from typing import List, Dict, Tuple, Optional
    from datetime import datetime
    from .types import Node, Transaction, Block
    import logging
    
    # Initialize logging
    logger = logging.getLogger(__name__)
    
    class CollusionDetector:
        """
        The CollusionDetector is responsible for analyzing transaction patterns and validator behavior
        to detect potential collusion within the PoC network.
        
        Key Responsibilities:
        - Analyzing transaction patterns to identify repeated suspicious behavior.
        - Monitoring validator interactions and decisions for signs of collusion.
        - Utilizing historical data to identify anomalous patterns that could indicate fraud.
        """
        
        def __init__(self, transaction_threshold: int = 10, validator_threshold: int = 3, dynamic_threshold: bool = True):
            """
            Initialize the CollusionDetector with detection thresholds.
    
            Args:
                transaction_threshold (int): Number of similar transactions required to trigger a collusion check.
                validator_threshold (int): Number of validators interacting repeatedly to trigger a collusion check.
                dynamic_threshold (bool): If True, thresholds adjust based on network conditions.
            """
            self.transaction_threshold = transaction_threshold
            self.validator_threshold = validator_threshold
            self.dynamic_threshold = dynamic_threshold
            self.suspicious_transactions: List[Transaction] = []  # Stores potentially collusive transactions
            self.suspicious_validators: Dict[str, int] = {}  # Track suspicious validator behavior
            self.network_activity: Dict[str, int] = {}  # Track overall network activity for adaptive thresholds
    
        def detect_collusion(self, validator: Node, block: Block) -> bool:
            """
            Detect potential collusion in a given block based on transaction patterns and validator behavior.
    
            Detection Criteria:
            - Repeated transactions between the same sender and receiver within the same block.
            - Validators repeatedly validating blocks with similar transactions from the same set of senders.
            - Validators interacting unusually frequently with each other.
    
            Args:
                validator (Node): The validator node to check for collusion.
                block (Block): The block to analyze for collusion.
    
            Returns:
                bool: True if collusion is detected, False otherwise.
            """
            # Adjust thresholds dynamically based on network activity
            if self.dynamic_threshold:
                self._adjust_thresholds()
    
            # Analyze transaction patterns
            transactions_suspicious = self._check_transaction_patterns(block.transactions)
    
            # Analyze validator interactions
            interactions_suspicious = self._check_validator_interactions(validator)
    
            # Mark validator as suspicious if any collusion criteria are met
            if transactions_suspicious or interactions_suspicious:
                self._mark_validator_as_suspicious(validator)
                return True
    
            return False
    
        def _adjust_thresholds(self) -> None:
            """
            Dynamically adjust detection thresholds based on current network activity.
            This allows the detection mechanism to scale with network load and complexity.
            """
            avg_activity = sum(self.network_activity.values()) / len(self.network_activity) if self.network_activity else 1
            self.transaction_threshold = max(5, int(avg_activity * 0.1))  # Example logic for scaling threshold
            self.validator_threshold = max(2, int(avg_activity * 0.05))   # Example logic for scaling threshold
    
            logger.debug(f"Dynamic thresholds adjusted: Transaction={self.transaction_threshold}, Validator={self.validator_threshold}")
    
        def _check_transaction_patterns(self, transactions: List[Transaction]) -> bool:
            """
            Check transaction patterns within a block to identify suspicious behavior.
    
            Criteria:
            - If the same sender-receiver pair appears repeatedly within a block, it is considered suspicious.
            - If a block contains an unusually high number of similar transactions, it may indicate collusion.
    
            Args:
                transactions (List[Transaction]): List of transactions in the block.
    
            Returns:
                bool: True if suspicious patterns are found, False otherwise.
            """
            transaction_count: Dict[Tuple[str, str], int] = {}
            for tx in transactions:
                pair = (tx.sender, tx.receiver)
                transaction_count[pair] = transaction_count.get(pair, 0) + 1
                if transaction_count[pair] >= self.transaction_threshold:
                    self.suspicious_transactions.append(tx)
                    logger.warning(f"Suspicious transaction pattern detected between {tx.sender} and {tx.receiver}")
                    return True
    
            return False
    
        def _check_validator_interactions(self, validator: Node) -> bool:
            """
            Check if a validator is interacting unusually frequently with other validators.
    
            Criteria:
            - If a validator consistently validates blocks from the same set of validators, it may indicate collusion.
    
            Args:
                validator (Node): The validator to analyze for repeated interactions.
    
            Returns:
                bool: True if suspicious interactions are found, False otherwise.
            """
            interaction_count: Dict[str, int] = {}
            for interaction in validator.validation_history:
                interacting_validator = interaction.get("validator_id")
                if interacting_validator:
                    interaction_count[interacting_validator] = interaction_count.get(interacting_validator, 0) + 1
                    if interaction_count[interacting_validator] >= self.validator_threshold:
                        logger.warning(f"Suspicious validator interaction detected: {validator.node_id} with {interacting_validator}")
                        return True
            return False
    
        def _mark_validator_as_suspicious(self, validator: Node) -> None:
            """
            Mark a validator as suspicious and log the event for auditing purposes.
    
            Args:
                validator (Node): The validator to mark as suspicious.
            """
            validator_id = validator.node_id
            self.suspicious_validators[validator_id] = self.suspicious_validators.get(validator_id, 0) + 1
            
            # Update validator metadata and reputation
            validator.metadata["status"] = "suspicious"
            validator.metadata["last_suspicious_activity"] = datetime.now()
            validator.reputation = max(0, validator.reputation - 5)
            validator.cooldown += 1
            
            # Log suspicious activity
            self._log_suspicious_activity(validator)
    
        def _log_suspicious_activity(self, validator: Node) -> None:
            """
            Log details of suspicious activity for auditing and monitoring.
    
            Args:
                validator (Node): The validator marked as suspicious.
            """
            validator_id = validator.node_id
            logger.info(f"[{datetime.now()}] Suspicious activity detected for validator {validator_id}.")
            logger.info(f"Reputation reduced to {validator.reputation}, status set to 'suspicious'.")
    
        def report_suspicious_transactions(self) -> List[Transaction]:
            """
            Generate a report of all suspicious transactions detected during collusion checks.
    
            Returns:
                List[Transaction]: List of suspicious transactions.
            """
            return self.suspicious_transactions
    
        def report_suspicious_validators(self) -> Dict[str, int]:
            """
            Generate a report of all validators marked as suspicious during collusion checks.
    
            Returns:
                Dict[str, int]: Dictionary of suspicious validators and their frequency of suspicious activity.
            """
            return self.suspicious_validators
    
        def reset_suspicion_data(self) -> None:
            """
            Reset the collusion detector's data for suspicious transactions and validators.
    
            This is useful for clearing past data when starting a new detection cycle.
            """
            self.suspicious_transactions.clear()
            self.suspicious_validators.clear()
            logger.info("Suspicion data has been reset.")
```

# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/base.py

```py
    """
    blockchain/consensus/proof_of_cooperation/base.py
    
    Implements the core Proof of Cooperation consensus mechanism.
    """
    
    from typing import List, Optional, Dict, Any
    from datetime import datetime
    import logging
    
    from .reputation_manager import ReputationManager
    from .collusion_detector import CollusionDetector
    from .sanctions_manager import SanctionsManager
    from .validator_manager import ValidatorManager
    from .metrics_manager import MetricsManager
    from .cooldown_manager import CooldownManager
    from .types import ConsensusConfig, ValidationResult
    from ...core.node import Node
    from ...core.block import Block
    
    logger = logging.getLogger(__name__)
    
    class ProofOfCooperation:
        """
        Implements the Proof of Cooperation consensus mechanism for the ICN.
        
        Key Features:
        - Modular integration with collusion detection, reputation, and sanctions management.
        - Progressive reputation requirements for new nodes.
        - Dynamic scoring adjustments.
        - Enhanced validator eligibility checks.
        - Improved shard-specific handling.
        """
    
        def __init__(self, min_reputation: float = 10.0, cooldown_blocks: int = 3):
            """Initialize the PoC mechanism with its component managers."""
            self.config = ConsensusConfig(
                min_reputation=min_reputation,
                cooldown_blocks=cooldown_blocks
            )
            
            # Initialize component managers
            self.reputation_manager = ReputationManager(self.config)
            self.collusion_detector = CollusionDetector()
            self.sanctions_manager = SanctionsManager(self.collusion_detector, self.reputation_manager)
            self.validator_manager = ValidatorManager(
                min_reputation=min_reputation, 
                cooldown_blocks=cooldown_blocks, 
                collusion_detector=self.collusion_detector
            )
            self.metrics_manager = MetricsManager()
            self.cooldown_manager = CooldownManager(cooldown_blocks)
    
        def select_validator(self, nodes: List[Node], shard_id: Optional[int] = None) -> Optional[Node]:
            """
            Select a validator using modular checks for eligibility and cooperation score.
            
            Args:
                nodes: List of potential validator nodes
                shard_id: Optional shard ID for selection
                
            Returns:
                Optional[Node]: Selected validator node, if any
            """
            try:
                # Get list of eligible nodes
                eligible_nodes = [
                    node for node in nodes 
                    if self._can_validate(node, shard_id)
                ]
                
                if not eligible_nodes:
                    logger.warning("No eligible validators available")
                    return None
    
                # Calculate cooperation scores
                scores = [
                    self.reputation_manager.calculate_cooperation_score(node, shard_id)
                    for node in eligible_nodes
                ]
                total_score = sum(scores)
                
                if total_score <= 0:
                    return None
    
                # Weighted random selection
                selection_point = random.uniform(0, total_score)
                current_sum = 0
                
                for node, score in zip(eligible_nodes, scores):
                    current_sum += score
                    if current_sum >= selection_point:
                        # Apply cooldown and record selection
                        self.cooldown_manager.apply_cooldown(node)
                        self.metrics_manager.record_validation(
                            ValidationResult(success=True), node.node_id, shard_id
                        )
                        logger.info(f"Selected validator {node.node_id} for shard {shard_id}")
                        return node
    
                return None
    
            except Exception as e:
                logger.error(f"Error selecting validator: {str(e)}")
                return None
    
        def validate_block(self, block: Block, previous_block: Optional[Block], validator: Node) -> bool:
            """
            Validate a block using reputation, sanctions, and collusion checks.
            
            Args:
                block: The block to validate
                previous_block: Previous block in the chain
                validator: The validating node
                
            Returns:
                bool: True if block is valid
            """
            try:
                # Basic validation checks
                if not self._can_validate_block(validator, block.shard_id):
                    logger.error(f"Validator {validator.node_id} not eligible")
                    return False
    
                if not block.validate(previous_block):
                    logger.error(f"Block {block.index} failed validation")
                    self._update_validation_stats(validator, block, False)
                    return False
    
                # Check for collusion
                if self.collusion_detector.detect_collusion(validator, block):
                    logger.warning(f"Collusion detected for block {block.index}")
                    self.sanctions_manager.apply_sanction(validator)
                    self._update_validation_stats(validator, block, False)
                    return False
    
                # Update metrics and return success
                self._update_validation_stats(validator, block, True)
                logger.info(f"Block {block.index} validated successfully")
                return True
    
            except Exception as e:
                logger.error(f"Error validating block: {str(e)}")
                self._update_validation_stats(validator, block, False)
                return False
    
        def _can_validate(self, node: Node, shard_id: Optional[int] = None) -> bool:
            """
            Determine if a node can participate in consensus.
            
            Args:
                node: Node to check
                shard_id: Optional shard ID for specific checks
                
            Returns:
                bool: True if node can participate
            """
            try:
                # Check if node is under sanctions
                if self.sanctions_manager.get_sanction_status(node)[0] > 0:
                    return False
    
                # Check reputation requirements
                if not self.reputation_manager.can_validate(node, shard_id):
                    return False
    
                # Check cooldown status
                if not self.cooldown_manager.is_eligible(node):
                    return False
    
                # Shard-specific checks
                if shard_id is not None and not node.can_validate(shard_id):
                    return False
    
                return True
    
            except Exception as e:
                logger.error(f"Error checking validation eligibility: {str(e)}")
                return False
    
        def _can_validate_block(self, validator: Node, shard_id: Optional[int]) -> bool:
            """Check if validator can validate a specific block."""
            return self._can_validate(validator, shard_id)
    
        def _update_validation_stats(self, validator: Node, block: Block, success: bool) -> None:
            """
            Update validation statistics for a validator.
            
            Args:
                validator: The validating node
                block: The validated block
                success: Whether validation was successful
            """
            try:
                result = ValidationResult(
                    success=success,
                    block_height=block.index,
                    shard_id=block.shard_id
                )
                
                # Update component metrics
                self.metrics_manager.record_validation(result, validator.node_id, block.shard_id)
                self.reputation_manager.update_stats(validator.node_id, result, block.shard_id)
                
                # Update validator reputation
                if success:
                    self.reputation_manager.update_validator_reputation(validator, 1.0)
                else:
                    self.reputation_manager.update_validator_reputation(validator, -1.0)
    
            except Exception as e:
                logger.error(f"Error updating validation stats: {str(e)}")
    
        def get_metrics(self) -> Dict[str, Any]:
            """Get comprehensive consensus metrics."""
            return {
                "reputation_metrics": self.reputation_manager.get_metrics(),
                "validation_metrics": self.metrics_manager.get_metrics(),
                "sanctions_metrics": self.sanctions_manager.get_metrics(),
                "collusion_metrics": self.collusion_detector.get_metrics()
            }
    
        def to_dict(self) -> Dict[str, Any]:
            """Convert consensus state to dictionary format."""
            return {
                "config": self.config.to_dict(),
                "reputation_manager": self.reputation_manager.to_dict(),
                "sanctions_manager": self.sanctions_manager.to_dict(),
                "metrics_manager": self.metrics_manager.to_dict(),
                "cooldown_manager": self.cooldown_manager.to_dict()
            }
    
        @classmethod
        def from_dict(cls, data: Dict[str, Any]) -> 'ProofOfCooperation':
            """Create consensus instance from dictionary."""
            config = ConsensusConfig.from_dict(data["config"])
            instance = cls(
                min_reputation=config.min_reputation,
                cooldown_blocks=config.cooldown_blocks
            )
            
            instance.reputation_manager = ReputationManager.from_dict(data["reputation_manager"])
            instance.sanctions_manager = SanctionsManager.from_dict(data["sanctions_manager"])
            instance.metrics_manager = MetricsManager.from_dict(data["metrics_manager"])
            instance.cooldown_manager = CooldownManager.from_dict(data["cooldown_manager"])
            
            return instance
```

# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/cooldown_manager.py

```py
    """
    cooldown_manager.py
    
    This module manages dynamic cooldown periods for validators in the Proof of Cooperation (PoC) consensus mechanism.
    It aims to prevent validator monopolization by adjusting cooldowns based on validator activity and network conditions.
    
    Classes:
        CooldownManager
    """
    
    from typing import List, Dict, Optional
    from datetime import datetime, timedelta
    from .types import Node
    
    class CooldownManager:
        """
        The CooldownManager is responsible for dynamically managing cooldown periods for validators
        within the PoC mechanism. It adjusts cooldowns based on validator participation frequency,
        network congestion, and other factors to ensure fair and diverse participation.
    
        Key Features:
        - Dynamic cooldown adjustments to prevent validator monopolization.
        - Cooldown periods vary based on validator activity, performance, and network load.
        - Ensures that validators do not dominate consecutive validation rounds.
        """
        
        def __init__(self, base_cooldown: int = 3, max_cooldown: int = 10):
            """
            Initialize the CooldownManager with base and maximum cooldown settings.
    
            Args:
                base_cooldown (int): The initial cooldown period after validation.
                max_cooldown (int): The maximum allowable cooldown period.
            """
            self.base_cooldown = base_cooldown
            self.max_cooldown = max_cooldown
            self.validator_activity: Dict[str, List[datetime]] = {}  # Track validator activity timestamps
    
        def apply_cooldown(self, validator: Node) -> None:
            """
            Apply a dynamic cooldown period to a validator based on its recent activity and performance.
    
            Cooldown Criteria:
            - If a validator has participated frequently in recent blocks, the cooldown period increases.
            - Validators with lower performance or reputation have longer cooldowns.
            - Cooldowns decrease gradually if the validator has not participated recently.
    
            Args:
                validator (Node): The validator to apply cooldown to.
            """
            # Track validator activity
            self._track_activity(validator)
    
            # Calculate dynamic cooldown based on participation frequency and performance
            participation_rate = self._calculate_participation_rate(validator)
            performance_factor = 1 - (validator.performance_metrics.get('validation_success_rate', 0) / 100)
    
            # Adjust cooldown based on participation rate and performance
            dynamic_cooldown = min(
                int(self.base_cooldown * (1 + participation_rate * 2 + performance_factor)),
                self.max_cooldown
            )
            
            validator.cooldown = dynamic_cooldown
    
        def _track_activity(self, validator: Node) -> None:
            """
            Track the activity of a validator to determine participation frequency.
    
            Args:
                validator (Node): The validator to track.
            """
            current_time = datetime.now()
            if validator.node_id not in self.validator_activity:
                self.validator_activity[validator.node_id] = []
    
            self.validator_activity[validator.node_id].append(current_time)
    
            # Maintain a limited history of activity timestamps for efficiency
            self.validator_activity[validator.node_id] = [
                timestamp for timestamp in self.validator_activity[validator.node_id]
                if timestamp > current_time - timedelta(hours=1)
            ]
    
        def _calculate_participation_rate(self, validator: Node) -> float:
            """
            Calculate the participation rate of a validator based on recent activity.
    
            The participation rate is determined by the number of blocks the validator
            has participated in over a fixed period (e.g., the last hour).
    
            Args:
                validator (Node): The validator to analyze.
    
            Returns:
                float: The participation rate as a fraction of the maximum allowable rate.
            """
            max_participation_rate = 10  # Max participations allowed per hour (adjustable)
            recent_participations = len(self.validator_activity.get(validator.node_id, []))
    
            return min(recent_participations / max_participation_rate, 1)
    
        def reset_cooldown(self, validator: Node) -> None:
            """
            Reset the cooldown period for a validator if it has not participated recently.
    
            This helps ensure validators are re-integrated into the validation process
            after extended inactivity.
    
            Args:
                validator (Node): The validator to reset.
            """
            # If validator has not participated in the last hour, reset cooldown
            if not self.validator_activity.get(validator.node_id):
                validator.cooldown = max(0, validator.cooldown - 1)
    
        def is_eligible(self, validator: Node) -> bool:
            """
            Check if a validator is eligible for participation based on its cooldown period.
    
            Args:
                validator (Node): The validator to check.
    
            Returns:
                bool: True if the validator is eligible, False otherwise.
            """
            return validator.cooldown <= 0
    
        def decay_cooldown(self) -> None:
            """
            Gradually reduce cooldowns for all validators over time to allow re-participation.
    
            This is called periodically to ensure validators can rejoin the pool after their cooldowns.
            """
            for validator_id, timestamps in self.validator_activity.items():
                if timestamps and datetime.now() - timestamps[-1] > timedelta(minutes=10):
                    node = self._get_validator_by_id(validator_id)
                    if node:
                        node.cooldown = max(0, node.cooldown - 1)
    
        def _get_validator_by_id(self, node_id: str) -> Optional[Node]:
            """
            Retrieve a validator by its node ID.
    
            Args:
                node_id (str): The ID of the node to retrieve.
    
            Returns:
                Optional[Node]: The validator node, or None if not found.
            """
            # Placeholder for integration with the broader PoC network
            # This method should interface with a node management system to retrieve nodes
            return None  # Replace with actual retrieval logic
    
        def clear_inactive_validators(self) -> None:
            """
            Clear validators from the activity tracker if they have not participated for an extended period.
    
            This helps manage memory and ensures the activity tracker remains efficient.
            """
            current_time = datetime.now()
            for validator_id, timestamps in list(self.validator_activity.items()):
                if timestamps and current_time - timestamps[-1] > timedelta(hours=2):
                    del self.validator_activity[validator_id]
```

# File: /home/matt/icn-prototype/blockchain/consensus/proof_of_cooperation/__init__.py

```py
    """
    blockchain/consensus/proof_of_cooperation/__init__.py
    
    Export the Proof of Cooperation consensus mechanism components.
    """
    
    from .base import ProofOfCooperation
    from .reputation_manager import ReputationManager
    from .collusion_detector import CollusionDetector
    from .sanctions_manager import SanctionsManager
    from .validator_manager import ValidatorManager
    from .metrics_manager import MetricsManager
    from .cooldown_manager import CooldownManager
    from .types import ConsensusConfig, ValidationResult
    
    __all__ = [
        "ProofOfCooperation",
        "ReputationManager",
        "CollusionDetector",
        "SanctionsManager",
        "ValidatorManager",
        "MetricsManager",
        "CooldownManager",
        "ConsensusConfig",
        "ValidationResult"
    ]
```
